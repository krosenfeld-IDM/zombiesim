import os
import google.generativeai as genai

genai.configure(api_key=os.environ["GEMINI_API_KEY"])

# Create the model
generation_config = {
  "temperature": 1,
  "top_p": 0.95,
  "top_k": 40,
  "max_output_tokens": 8192,
  "response_mime_type": "text/plain",
}

model = genai.GenerativeModel(
  model_name="gemini-1.5-flash",
  generation_config=generation_config,
)

chat_session = model.start_chat(
  history=[
    {
      "role": "user",
      "parts": [
        "Here is the diff information for an update to the starsim (ss) package:",
        "diff --git a/.flake8 b/.flake8\nnew file mode 100644\nindex 0000000..bf54591\n--- /dev/null\n+++ b/.flake8\n@@ -0,0 +1,11 @@\n+# Custom settings for Starsim. Changes:\n+# E221: allow multiple spaces before operator\n+# E225: allow space around arithmetic operators\n+# E226: allow space around arithmetic operators\n+# E261: allow one space before comment\n+# E272: allow multiple spaces before keyword\n+# E501: allow long lines\n+# E701: allow multiple statements on a line\n+\n+[flake8]\n+ignore = E221, E225, E226, E261, E272, E501, E701\n\\ No newline at end of file\ndiff --git a/.github/dependabot.yaml b/.github/dependabot.yaml\nnew file mode 100644\nindex 0000000..2390d8c\n--- /dev/null\n+++ b/.github/dependabot.yaml\n@@ -0,0 +1,10 @@\n+version: 2\n+updates:\n+  - package-ecosystem: \"github-actions\"\n+    directory: \"/\"\n+    schedule:\n+      interval: \"monthly\"\n+    groups:\n+      github-actions:\n+        patterns:\n+          - \"*\"\ndiff --git a/.github/workflows/tests.yaml b/.github/workflows/tests.yaml\nindex d740e20..e5a1d6f 100644\n--- a/.github/workflows/tests.yaml\n+++ b/.github/workflows/tests.yaml\n@@ -9,12 +9,12 @@ jobs:\n       max-parallel: 8\n       matrix:\n         os: ['ubuntu-latest']\n-        python-version: ['3.9', '3.11']\n+        python-version: ['3.10', '3.12']\n     runs-on: ${{ matrix.os }}\n     name: Install and test\n     steps:\n       - name: Checkout sources\n-        uses: actions/checkout@v2\n+        uses: actions/checkout@v4\n       - uses: actions/setup-python@master\n         with:\n           python-version: ${{ matrix.python-version }}\n@@ -28,7 +28,7 @@ jobs:\n         working-directory: ./tests\n         run: pytest test_*.py -n auto --durations=0 --junitxml=test-results.xml # Run actual tests\n       - name: Upload test results\n-        uses: actions/upload-artifact@v1\n+        uses: actions/upload-artifact@v4\n         if: failure()\n         with:\n           name: test_results\ndiff --git a/.pylintrc b/.pylintrc\nnew file mode 100644\nindex 0000000..aca48ac\n--- /dev/null\n+++ b/.pylintrc\n@@ -0,0 +1,116 @@\n+[BASIC]\n+\n+# Regular expression matching correct argument names. Overrides argument-\n+# naming-style. If left empty, argument names will be checked with the set\n+# naming style.\n+argument-rgx=[a-z_][a-z0-9_]{0,15}$ # Starsim\n+variable-rgx=[a-z_][a-z0-9_]{0,15}$ # Starsim\n+attr-rgx=[a-z_][a-z0-9_]{0,15}$ # Starsim\n+class-attribute-rgx=[a-z_][a-z0-9_]{0,15}$ # Starsim\n+function-rgx=[a-z_][a-z0-9_]{0,15}$ # Starsim\n+method-rgx=[a-z_][a-z0-9_]{0,15}$ # Starsim\n+class-rgx=[a-zA-Z_][a-zA-Z0-9_]{0,15}$ # Starsim\n+\n+# Good variable names which should always be accepted, separated by a comma.\n+good-names=E # Starsim\n+\n+\n+[DESIGN]\n+\n+# Maximum number of arguments for function / method.\n+max-args=20 # Starsim\n+\n+# Maximum number of attributes for a class (see R0902).\n+max-attributes=20 # Starsim\n+\n+# Maximum number of boolean expressions in an if statement (see R0916).\n+max-bool-expr=5\n+\n+# Maximum number of branch for function / method body.\n+max-branches=15 # Starsim\n+\n+# Maximum number of locals for function / method body.\n+max-locals=20 # Starsim\n+\n+# Maximum number of parents for a class (see R0901).\n+max-parents=7\n+\n+# Maximum number of public methods for a class (see R0904).\n+max-public-methods=20\n+\n+# Maximum number of return / yield for function / method body.\n+max-returns=5 # Starsim\n+\n+# Maximum number of statements in function / method body.\n+max-statements=200 # Starsim\n+\n+# Minimum number of public methods for a class (see R0903).\n+min-public-methods=2\n+\n+\n+[FORMAT]\n+\n+# Maximum number of characters on a single line.\n+max-line-length=200 # Starsim\n+\n+# Maximum number of lines in a module.\n+max-module-lines=2000 # Starsim\n+\n+# Allow the body of an if to be on the same line as the test if there is no\n+# else.\n+single-line-if-stmt=yes # Starsim\n+\n+\n+[IMPORTS]\n+\n+# Allow wildcard imports from modules that define __all__.\n+allow-wildcard-with-all=yes # Starsim\n+\n+\n+[MESSAGES CONTROL]\n+\n+# Disable the message, report, category or checker with the given id(s). You\n+# can either give multiple identifiers separated by comma (,) or put this\n+# option multiple times (only on the command line, not in the configuration\n+# file where it should appear only once). You can also use \"--disable=all\" to\n+# disable everything first and then re-enable specific checks. For example, if\n+# you want to run only the similarities checker, you can use \"--disable=all\n+# --enable=similarities\". If you want to run only the classes checker, but have\n+# no Warning level messages displayed, use \"--disable=all --enable=classes\n+# --disable=W\".\n+disable=raw-checker-failed,\n+        bad-inline-option,\n+        locally-disabled,\n+        file-ignored,\n+        suppressed-message,\n+        useless-suppression,\n+        deprecated-pragma,\n+        use-symbolic-message-instead,\n+        C0103, # Starsim: allow lowercase constants\n+        C0321, # Starsim: multiple statements on a line\n+        C0325, # Starsim: allow parentheses in if\n+        C0411, # Starsim: allow different import order\n+        C0412, # Starsim: allow ungrouped imports\n+        C0413, # Starsim: allow imports not at the top\n+        E1101, # Starsim: don't check class membership (dynamic classes)\n+        R1705, # Starsim: allow else-return\n+        R1711, # Starsim: empty return\n+        R1720, # Starsim: allow else after raise\n+        R1735, # Starsim: dict literal\n+        W0702, # Starsim: allow bare except\n+        W0718 # Starsim: allow general exception\n+\n+# Enable the message, report, category or checker with the given id(s). You can\n+# either give multiple identifier separated by comma (,) or put this option\n+# multiple time (only on the command line, not in the configuration file where\n+# it should appear only once). See also the \"--disable\" option for examples.\n+enable=c-extension-no-member\n+\n+\n+[MISCELLANEOUS]\n+\n+# List of note tags to take in consideration, separated by a comma.\n+notes=FIXME,\n+      XXX,\n+      TODO,\n+      TEMP # Starsim\n\\ No newline at end of file\ndiff --git a/CHANGELOG.rst b/CHANGELOG.rst\nindex e5bc96f..ec18f25 100644\n--- a/CHANGELOG.rst\n+++ b/CHANGELOG.rst\n@@ -7,6 +7,240 @@ What's new\n All notable changes to the codebase are documented in this file. Changes that may result in differences in model output, or are required in order to run an old parameter set with the current version, are flagged with the term \"Regression information\".\n \n \n+\n+Version 2.1.1 (2024-11-08)\n+---------------------------\n+- Adds improved Jupyter support for plotting (to prevent plots from appearing twice); you can disable this by setting ``ss.options.set(jupyter=False)``.\n+- Adds ``auto_plot`` to ``Result`` objects, to indicate if it should appear in ``sim.plot()`` by default.\n+- Adds ``copy()`` to the Sim and modules.\n+- Networks now store their length on each timestep as a result.\n+- Improves ``sim.shrink()``, with typical size reductions of >99%.\n+- Adds additional plotting options ``show_module`` (include the module name in the plot title), ``show_label`` (use the simulation label as the figure title), and ``show_skipped`` (shows results even if ``auto_plot=False``).\n+- *GitHub info*: PR `745 <https://github.com/starsimhub/starsim/pull/745>`_\n+\n+\n+Version 2.1.0 (2024-11-07)\n+---------------------------\n+\n+Summary\n+~~~~~~~\n+- Time in simulations is now handled by an ``ss.Time()`` class, which unifies how time is represented between the ``Sim`` and each module.\n+- In addition to networks, there is now a new way of implementing disease transmission via mixing pools.\n+\n+Time\n+~~~~\n+- Time handling now performed by the ``ss.Time()`` class. This has inputs similar to before (``start``, ``stop``, ``unit``, ``dt``, with ``dur`` still available as a sim input). However, instead of the previous ``timevec`` and ``abs_tvec`` arrays, there are now multiple ways of representing time (including ``datevec`` and ``yearvec``), regardless of what the inputs were.\n+- Dates are now represented in a native format, ``ss.date``, that is based on ``pd.Timestamp``.\n+\n+Mixing pools\n+~~~~~~~~~~~~\n+- Adds a new approach to disease transmission called mixing pools. A mixing pool is a \"mean field\" coupling wherein susceptible agents are exposed to the average infectious agent. The user can create a single mixing pool using the ``ss.MixingPool`` class, or create many pools using ``MixingPools``. Such mixing pools could be used to simulate contact matrices, for example as published by Prem et al.\n+- There is a new ``ss.Route`` class, which is the base class for ``ss.Network`` and ``ss.MixingPool``.\n+\n+Other changes\n+~~~~~~~~~~~~~\n+- Demographic modules have been updated to fix various bugs around different time units.\n+- The method for hashing distribution trace strings into seeds has changed, meaning that results will be stochastically different compared to Starsim v2.0.\n+- Fixed a bug with how timepars were updated in parameters.\n+- There is a new ``ss.Base`` class, which both ``ss.Sim`` and ``ss.Module`` inherit from.\n+- Results now print as a single line rather than the full array. The latter is available as ``result.disp()``.\n+- ``sim.to_df()`` now works even if different modules have different numbers of timepoints.\n+- The ``timepars`` module has been renamed to ``time``.\n+- In demographics modules, ``units`` has been renamed ``rate_units``.\n+- There are two new options, ``ss.options.date_sep`` and  ``ss.options.license``. The former sets the date separator (default ``.``, e.g. ``2024.04.0.4``), and the latter sets if the license prints when Starsim is imported.\n+- *GitHub info*: PR `724 <https://github.com/starsimhub/starsim/pull/724>`_\n+\n+\n+Version 2.0.0 (2024-10-01)\n+--------------------------\n+\n+Summary\n+~~~~~~~\n+Version 2.0 contains several major changes. These include: module-specific timesteps and time-aware parameters (including a day/year ``unit`` flag for modules, and  ``ss.dur()`` and ``ss.rate()`` classes for parameters), and changes to module types and integration (e.g. renaming ``update()`` and ``apply()`` methods to ``step()``;).\n+\n+Time-aware parameters and modules\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+- Added ``ss.dur()``, ``ss.rate()``, and ``ss.time_prob()`` classes, for automatic handling of time units in simulations. There are also convenience classes ``ss.days()``, ``ss.years()``, ``ss.perday()``, ``ss.peryear()``, and ``ss.beta()`` for special cases of these.\n+- ``ss.dur()`` and ``ss.rate()``, along with modules and the sim itself, have a ``unit`` parameter which can be ``'day'``, ``'week'``, ``'month'``, or ``'year'`` (default). Modules now also have their own timestep ``dt``. Different units and timesteps can be mixed and matched. Time parameters have a ``to()`` method, e.g. ``ss.dur(1, 'year').to('day')`` will return ``ss.dur(365, unit='day')``.\n+- The ``ss.Sim`` parameter ``n_years`` has been renamed ``dur``; ``sim.yearvec`` is now ``sim.timevec``, which can have units of days (usually starting at 0), dates (e.g. ``'2020-01-01'``), or years (e.g. ``2020``). ``sim.abs_tvec`` is the translation of ``sim.timevec`` as a numeric array starting at 0, using the sim's units (usually ``'day'`` or ``'year'``). For example, if ``sim.timevec`` is a list of daily dates from ``'2022-01-01'`` to ``'2022-12-31'``, ``sim.abs_tvec`` will be ``np.arange(365)``.\n+- Each module also has its own ``mod.timevec``; this can be different from the sim if it defines its own time unit and/or timestep. ``mod.abs_tvec`` always starts at 0 and always uses the sim's unit.\n+- There is a new ``Loop`` class which handles the integration loop. You can view the integration plan via ``sim.loop.to_df()`` or ``sim.loop.plot()``. You can see how long each part of the sim took with ``sim.loop.plot_cpu()``.\n+- There are more advanced debugging tools. You can run a single sim timestep with ``sim.run_one_step()`` (which in turn calls multiple functions), and you can run a single function from the integration loop with ``sim.loop.run_one_step()``.\n+\n+Module changes\n+~~~~~~~~~~~~~~\n+- Functionality has been moved from ``ss.Plugin`` to ``ss.Module``, and the former has been removed.\n+- ``ss.Connector`` functionality has been moved to ``ss.Module``. ``ss.Module`` objects can be placed anywhere in the list of modules (e.g., in demographics, networks, diseases, interventions), depending on when you want them to execute. However, ``ss.Connector`` objects are applied after ``Disease.step_state()`` and before ``Network.step()``.\n+- Many of the module methods have been renamed; in particular, all modules now have a ``step()`` method, which replaces ``update()`` (for demographics and networks), ``apply()`` (for interventions and analyzers), and ``make_new_cases()`` (for diseases). For both the sim and modules, ``initialize()`` has been renamed ``init()``.\n+- All modules are treated the same in the integration loop, except for diseases, which have ``step_state()`` and ``step_die()`` methods.\n+- The Starsim module ``states.py`` has been moved to ``arrays.py``, and ``network.py`` has been moved to ``networks.py``.\n+\n+State and array changes\n+~~~~~~~~~~~~~~~~~~~~~~~\n+- ``ss.Arr``, ``ss.TimePar``, and ``ss.Result`` all inherit from the new class ``ss.BaseArr``, which provides functionality similar to a NumPy array, except all values are stored in ``arr.values`` (like a ``pd.Series``).\n+- Whereas before, computations on an ``ss.Arr`` usually returned a NumPy array, calculations now usually return the same type. To access the NumPy array, use ``arr.values``. \n+- There is a new ``ss.State`` class, which is a subtype of ``ss.BoolArr``. Typically, ``ss.State`` is used for boolean disease states, such as ``infected``, ``susceptible``, etc., where you want to automatically generate results (e.g. ``n_infected``). You can continue using ``ss.BoolArr`` for other agent attributes that you don't necessarily want to automatically generate results for, e.g. ``ever_vaccinated``.\n+\n+Results changes\n+~~~~~~~~~~~~~~~\n+- Results are now defined differently. They should be defined in ``ss.Module.init_results()``, not ``ss.Module.init_pre()``. They now take the module name, number of points, and time vector from the parent module. As a result, they are usually initialized via ``ss.Module.define_results(res1, res2)`` (as opposed to ``mod.results += [res1, res2]`` previously). ``define_results()`` automatically adds these properties from the parent module; they can still be defined explicitly if needed however.\n+- Because results now store their own time information, they can be plotted in a self-contained way. Both ``ss.Result`` and ``ss.Results`` objects now have ``plot()`` and ``to_df()`` methods.\n+\n+Demographics changes\n+~~~~~~~~~~~~~~~~~~~~\n+- Fixed a bug in how results were defined for ``ss.Births`` and ``ss.Deaths``.\n+- The ``ss.Pregnancy`` module has been significantly rewritten, including: (1) Agents now have a ``parent`` which indicates the UID of the parent; (2) Women now track ``child_uid``; (3) On neonatal death, the pregnancy state of the mother is corrected; (4) Pregnancy rates now adjusted for infecund rather than pregnant; (4) Pregnancy now has a burn-in, which defaults to ``True``; (5) Pregnancy has a ``p_neonatal_death`` parameter to capture fetal and neonatal death if the mother dies.\n+- Slots now has a minimum, default of 100, to account for small initial population sizes that grow dramatically over time.\n+\n+Computational changes\n+~~~~~~~~~~~~~~~~~~~~~\n+- There have been several performance improvements. The default float type is now ``np.float32``. Transmission is now handled by a specialized ``Infection.compute_transmission()`` method. Several additional functions now use Numba, including ``fastmath=True``, which leverages Intel's short vector math library.\n+- A new ``ss.multi_random()`` distribution class has been added, that allows random numbers to be generated by two (or more) agents. It largely replaces ``ss.combine_rands()`` and is 5-10x faster.\n+- A new ``ss.gamma()`` distribution has also been added.\n+- Distributions have a new ``jump_dt`` method that jumps by much more than a single state update.\n+- ``ss.parallel()`` and ``ss.MultiSim.run()`` now modify simulations in place by default. Instead of ``sims = ss.parallel(sim1, sim2).sims; sims[0].plot()``, you can now simply do ``ss.parallel(sim1, sim2); sim1.plot()``.\n+\n+Other changes\n+~~~~~~~~~~~~~\n+- Data can now be supplied to a simulation; it will be automatically plotted by ``sim.plot()``.\n+- ``ss.Calibration`` has been significantly reworked, and now includes more flexible parameter setting, plus plotting (``calib.plot_sims()`` and ``calib.plot_trend()``). It also has a ``debug`` argument (which runs in serial rather than paralell), which can be helpful for troubleshooting issues.\n+- ``MultiSim`` now has display methods ``brief()`` (minimal), ``show()`` (moderate), and ``disp`` (verbose).\n+- ``sim.export_df()`` has been renamed ``sim.to_df()``.\n+- Most classes now have ``to_json()`` methods (which can also export to a dict).\n+- Fixed a bug in how the ``InfectionLog`` is added to disease modules.\n+- ``Sim.gitinfo`` has been replaced with ``Sim.metadata`` (which includes git info).\n+- ``Infection.validate_beta()`` is now applied on every timestep, so changes to beta during the simulation are now honored.\n+- ``sim.get_intervention()`` and ``sim.get_analyzer()`` have been removed; use built-in ``ndict`` operations (e.g., the label) to find the object you're after.\n+- ``requires`` has been removed from modules, but ``ss.check_requires()`` is still available if needed. Call it manually from ``init_pre()`` if desired, e.g. a PMTCT intervention might call ``ss.check_requires(self.sim, ['hiv', 'maternalnet'])``.\n+- For networks, ``contacts`` has been renamed ``edges`` except in cases where it refers to an *agent's* contacts. For example, ``network.contacts`` has been renamed ``network.edges``, but ``ss.find_contacts()`` remains the same.\n+- Networks now have a ``to_graph()`` method that exports to NetworkX.\n+- ``ss.diff_sims()`` can now handle ``MultiSim`` objects.\n+- ``Sim._orig_pars`` has been removed.\n+- ``ss.unique()`` has been removed.\n+\n+Regression information\n+~~~~~~~~~~~~~~~~~~~~~~\n+- Note: the list here covers major changes only; in general, Starsim v1.0 scripts will not be compatible with Starsim v2.0.\n+- Results from Starsim v2.0 will be stochastically (but not statistically) different from Starsim v1.0.\n+- All duration and rate parameters should now be wrapped with ``ss.dur()`` and ``ss.rate()``. Events that represent probabilities over time (i.e. hazard rates) can also be wrapped with ``ss.time_prob()``, although this is similar to ``ss.rate()`` unless the value is relatively large.\n+- ``ss.Plugin`` has been removed. Use ``ss.Module`` instead.\n+- ``init_results()`` is now called by ``init_pre()``, and does not need to be called explicitly.\n+- ``default_pars()`` has been renamed ``define_pars()``.\n+- ``add_states()`` has been renamed ``define_states()``\n+- ``initialize()`` has been renamed ``init()``.\n+- ``Demographics.update()`` has been renamed ``Demographics.step()``.\n+- ``Network.update()`` has been renamed ``Network.step()``.\n+- ``Disease.update_pre()`` has been renamed ``Disease.step_state()``.\n+- ``Disease.make_new_cases()`` has been renamed ``Disease.step()``.\n+- ``Disease.update_death()`` has been renamed ``Disease.step_die()`` (which is now called by ``People.step_die()``).\n+- ``Infection._set_cases()`` has been renamed ``Infection.set_outcomes()``.\n+- ``Intervention.apply(sim)`` has been renamed ``Intervention.step()``; ditto for ``Analyzer``.\n+- ``Module.step()`` no longer takes ``sim`` as an argument (e.g., replace ``intervention.apply(sim)`` with ``intervention.step()``).\n+- All modules now have methods for ``start_step()``, ``finish_step()``, ``init_results()``, and ``update_results()``.\n+- ``Network.contacts`` has been renamed ``Network.edges``.\n+- ``sim.get_intervention()`` and ``sim.get_analyzer()`` have been removed; simply call directly instead (e.g. replace ``sim.get_intervention('vaccine')`` with ``sim.interventions['vaccine']``).\n+- ``requires`` is no longer an attribute of modules; call the ``ss.check_requires()`` function directly if needed.\n+- ``People.resolve_deaths()`` has been renamed ``People.check_deaths()``\n+- ``ss.unique()`` has been removed.\n+- *GitHub info*: PR `626 <https://github.com/starsimhub/starsim/pull/626>`_\n+\n+\n+Version 1.0.3 (2024-09-26)\n+---------------------------\n+- Fixes a bug in which some intervention parameters (e.g. eligibility) do not get set properly.\n+- *GitHub info*: PR `639 <https://github.com/starsimhub/starsim/pull/639>`_\n+\n+\n+Version 1.0.2 (2024-09-25)\n+---------------------------\n+- Fixes a bug in which random numbers drawn from auto-jumped distributions would overlap with random numbers drawn from subsequent timesteps.\n+- *GitHub info*: PR `639 <https://github.com/starsimhub/starsim/pull/639>`_\n+\n+\n+Version 1.0.1 (2024-07-22)\n+---------------------------\n+- Adds a new distribution, ``ss.rand_raw()``, that samples raw integers from the random number bit generator, for use with calculating transmission. This version is roughly 20-30% faster than the previous implementation.\n+- Adds interpolation to age-standardized fertility rate (ASFR) data.\n+- Adds flexibility to ART initiation.\n+- *GitHub info*: PR `593 <https://github.com/starsimhub/starsim/pull/593>`_\n+\n+\n+Version 1.0.0 (2024-07-10)\n+---------------------------\n+- Official release of Starsim!\n+- Adds a ``Calibration`` class, based on `Optuna <https://optuna.org>`_, to facilitate the calibration of Starsim models.\n+- Adds ``mean()``, ``median()``, and ``plot()`` methods to ``MultiSim``.\n+- Adds ``low`` and ``high`` attributes to ``Result`` objects.\n+- Adds a ``flatten()`` method to ``Results``, allowing nested ``Results`` objects to be turned into flat dictionaries.\n+- Removes duplicate UIDs among new infections, and adds a ``unique()`` method to ``ss.uids``.\n+- Fixes a bug that prevented ``ss.lognorm_im()`` from using callable parameters.\n+- Updates the default ``Sim`` string representation to be a single line; the more verbose version is available via ``sim.disp()``.\n+- *GitHub info*: PR `581 <https://github.com/starsimhub/starsim/pull/581>`_\n+\n+\n+Version 0.5.10 (2024-07-03)\n+---------------------------\n+- Adds two new common-random-number-safe networks. The first is an Erdős-Rényi network that is similar to ``RandomNet`` but parameterized differently. The second is a 2D spatial network with connectivity between agents within a given radius; these agents can also optionally move.\n+- *GitHub info*: PR `575 <https://github.com/starsimhub/starsim/pull/575>`_\n+\n+\n+Version 0.5.9 (2024-06-30)\n+--------------------------\n+- Added a ``ss.histogram()`` distribution, which allows generating new random values from an empirical histogram.\n+- When binned age data is provided to specify the initial ages for new agents, the ages are now distributed throughout the year/bin rather than new agents being assigned integer ages\n+- Initial age data is now accepted as a ``pd.Series`` rather than a ``pd.DataFrame`` where the index corresponds to the age values, thereby avoiding the need for specific dataframe column names to be used to specify the age and value\n+- *GitHub info*: PR `572 <https://github.com/starsimhub/starsim/pull/572>`_\n+\n+\n+Version 0.5.8 (2024-06-30)\n+--------------------------\n+- Revert to making infection logging disabled by default. However, the infection log will now always be created so disease subclasses can override logging behaviour where required (e.g., to capture additional metadata)\n+- **Backwards-compatibility notes:** Logging has been moved from an argument to ``Disease`` to ``pars``. Existing code such as ``Disease(log=True)`` should be changed to ``Disease(pars={'log':True})``. The 'log' option can be added to the pars passed to any subclass e.g., ``ss.HIV(pars={...,log=True})``.\n+- *GitHub info*: PR `573 <https://github.com/starsimhub/starsim/pull/573>`_\n+\n+Version 0.5.7 (2024-06-27)\n+--------------------------\n+- Implemented a new ``ss.combine_rands()`` function based on a bitwise-XOR, since the previous modulo-based approach could introduce correlations between pairs of agents.\n+- *GitHub info*: PR `546 <https://github.com/starsimhub/starsim/pull/546>`_\n+\n+\n+Version 0.5.6 (2024-06-22)\n+--------------------------\n+- ``ss.Infection.make_new_cases()`` now returns the index of the network associated with each transmission event\n+- If a ``People`` object is provided to the ``Arr`` constructor, the arrays will be pre-initialized to index the current UIDs in the ``People`` object. This enables construction of temporary ``Arr`` instances that can be used to perform intermediate calculations (e.g., inside ``Intervention.apply()`` or within a module update step)\n+- Deprecated ``Arr(raw=...)`` argument to simplify initialization, as in practice the ``raw`` variable is not directly set, and this update also introduces a new pathway for initializating the `raw` attribute\n+- ``ss.uids.to_numpy()`` now returns a view rather than a copy\n+- ``ss.bernoulli.filter()`` now supports ``ss.BoolArr`` as an input, where the filtering will operate on the ``uids`` returned by ``ss.BoolArr.uids``\n+- ``ss.uids()`` supports construction from ``set`` objects (via ``np.fromiter()``)\n+- *GitHub info*: PR `565 <https://github.com/starsimhub/starsim/pull/555>`_\n+\n+\n+Version 0.5.5 (2024-06-19)\n+--------------------------\n+- Added labels to ``Result`` and state (``Arr``) objects.\n+- Added Numba decorator to ``find_contacts`` to significantly increase performance.\n+- Fixed bug when comparing ``uids`` and ``BoolArr`` objects.\n+- *GitHub info*: PR `562 <https://github.com/starsimhub/starsim/pull/555>`_\n+\n+\n+Version 0.5.4 (2024-06-18)\n+--------------------------\n+- Adjusted ``RandomNet`` to avoid connections to unborn agents and use random rounding for half edges\n+- Adds ``get_analyzers`` and ``get_analyzer``\n+- Refactor how data is pre-processed for births/pregnancy/death rates, giving about a 10% decrease in run time for the STIsim HIV model\n+- ``BoolArr.uids`` is automatically called when doing set operations on ``uids`` with a ``BoolArr``\n+- *GitHub info*: PR `555 <https://github.com/starsimhub/starsim/pull/555>`_\n+\n+\n+Version 0.5.3 (2024-06-10)\n+--------------------------\n+- ``ss.uids`` class implements set operators to facilitate combining or otherwise operating on collections of UIDs\n+- ``FloatArr.isnan`` and ``FloatArr.notnan`` return ``BoolArr`` instances rather than UIDs (so as to facilitate logical operations with other ``BoolArr`` instances, and to align more closely with `np.isnan`)\n+- ``Arr.true()`` and ``Arr.false()`` are supported for all ``Arr`` subclasses\n+- ``BoolArr.isnan`` and ``Boolarr.notnan`` are also implemented (although since ``BoolArr`` cannot store NaN values, these always return ``False`` and ``True``, respectively)\n+- *GitHub info*: PR `544 <https://github.com/starsimhub/starsim/pull/544>`_\n+\n+\n Version 0.5.2 (2024-06-04)\n --------------------------\n - Renames ``network.contacts`` to ``network.edges``.\ndiff --git a/LICENSE b/LICENSE\nindex 705f935..bba8252 100644\n--- a/LICENSE\n+++ b/LICENSE\n@@ -1,6 +1,6 @@\n MIT License\n \n-Copyright (c) 2023 by the Starsim Development Team\n+Copyright (c) 2023 - 2024 Bill & Melinda Gates Foundation\n \n Permission is hereby granted, free of charge, to any person obtaining a copy\n of this software and associated documentation files (the \"Software\"), to deal\ndiff --git a/README.rst b/README.rst\nindex e8e1caf..7ae3053 100644\n--- a/README.rst\n+++ b/README.rst\n@@ -1,13 +1,13 @@\n Starsim\n =======\n \n-**Warning! Starsim is still in the early stages of development. It is being shared solely for transparency and to facilitate collaborative development. It is not ready to be used for real research or policy questions.**\n+Starsim is an agent-based modeling framework for simulating the spread of diseases among agents via dynamic transmission networks. Starsim supports the co-transmission of multiple diseases at once, capturing how they interact biologically and behaviorally. Users can also include non-infectious diseases either on their own or as factors affecting infectious diseases. Starsim allows detailed modeling of mother-child relationships from conception to study birth-related diseases. Additionally, Starsim lets users compare different intervention strategies, like vaccines or treatments, to see their impact through various delivery methods such as mass campaigns or targeted outreach.\n \n-Starsim is an agent-based modeling framework in which users can design and configure simulations of diseases (or other health states) that progress over time within each agent and pass from one agent to the next along dynamic transmission networks. The framework explicitly supports co-transmission of multiple pathogens, allowing users to concurrently simulate several diseases while capturing behavioral and biological interactions. Non-communicable diseases can be included as well, either as a co-factor for transmissible pathogens or as an independent exploration. Detailed modeling of mother-child relationships can be simulated from the timepoint of conception, enabling study of congenital diseases and associated birth outcomes. Finally, Starsim facilitates the comparison of one or more intervention scenarios to a baseline scenario in evaluating the impact of various products like vaccines, therapeutics, and novel diagnostics delivered via flexible routes including mass campaigns, screen and treat, and targeted outreach.\n+Examples of diseases that have already been implemented in Starsim include sexually transmitted infections (HIV, HPV, and syphilis, including co-transmission), respiratory infections (tuberculosis and RSV), plus other diseases (Ebola and cholera) and underlying determinants of health (such as malnutrition).\n \n-The framework is appropriate for simulating sexually transmitted infections (including syphilis, gonorrhea, chlamydia, HPV, and HIV, including co-transmission), respiratory infections (like RSV and tuberculosis), and other diseases and underlying determinants (such as Ebola, diabetes, and malnutrition).\n+Note: Starsim is a general-purpose, multi-disease framework that builds on our previous suite of disease-specific models, which included `Covasim <https://covasim.org>`_, `HPVsim <https://hpvsim.org>`_, and `FPsim <https://fpsim.org>`_. In cases where a distinction needs to be made, Starsim is also known as the \"Starsim framework\", while this collection of other models is known as the \"Starsim suite\".\n \n-Starsim is a general-purpose modeling framework that is part of the same suite of tools as `Covasim <https://covasim.org>`_, `HPVsim <https://hpvsim.org>`_, and `FPsim <https://fpsim.org>`_.\n+For more information about Starsim, please see the `documentation <https://docs.starsim.org>`__.\n \n \n Requirements\n@@ -25,53 +25,64 @@ Starsim is most easily installed via PyPI: ``pip install starsim``.\n \n Starsim can also be installed locally. To do this, clone first this repository, then run ``pip install -e .`` (don't forget the dot at the end!).\n \n+*Note:* Starsim leverages Intel's `short vector math library <https://numba.readthedocs.io/en/stable/user/performance-tips.html#intel-svml>`_. If you want to use this (for a ~10% speed improvement), install via `conda install intel-cmplr-lib-rt`.\n+\n \n Usage and documentation\n -----------------------\n \n-Documentation, including tutorials and an API reference, is available at https://docs.starsim.org. \n+Full documentation, including tutorials and an API reference, is available at https://docs.starsim.org. \n+\n+You can run a simple demo via::\n+\n+  import starsim as ss\n+  ss.demo()\n \n-If everything is working, the following Python commands will run a simulation with the simplest version of a Starsim model. We'll make a version of a classic SIR model::\n+Here is a slightly more realistic example of an SIR model with random connections between agents::\n \n   import starsim as ss\n-  \n+\n   # Define the parameters\n   pars = dict(\n-    n_agents = 5_000,   # Number of agents to simulate\n-    networks = dict(    # *Networks* add detail on how agents interact w/ each other\n-      type = 'random',  # Here, we use a 'random' network\n-      n_contacts = 10   # Each person has an average of 10 contacts w/ other people  \n-    ),\n-    diseases = dict(    # *Diseases* add detail on what diseases to model\n-      type = 'sir',     # Here, we're creating an SIR disease\n-      init_prev = 0.1,  # Proportion of the population initially infected\n-      beta = 0.5,       # Probability of transmission between contacts\n-    )\n+      n_agents = 5_000,     # Number of agents to simulate\n+      networks = dict(      # Networks define how agents interact w/ each other\n+          type = 'random',  # Here, we use a 'random' network\n+          n_contacts = 10   # Each person has 10 contacts with other people  \n+      ),\n+      diseases = dict(      # *Diseases* add detail on what diseases to model\n+          type = 'sir',     # Here, we're creating an SIR disease\n+          init_prev = 0.01, # Proportion of the population initially infected\n+          beta = 0.05,      # Probability of transmission between contacts\n+      )\n   )\n-  \n+\n   # Make the sim, run and plot\n   sim = ss.Sim(pars)\n   sim.run()\n-  sim.plot()\n+  sim.plot() # Plot all the sim results\n+  sim.diseases.sir.plot() # Plot the standard SIR curves\n \n-More usage examples are available in the ``tests`` folder.\n+More usage examples are available in the tutorials, as well as the ``tests`` folder.\n \n \n-Model structure\n----------------\n+Starsim structure\n+-----------------\n \n All core model code is located in the ``starsim`` subfolder; standard usage is ``import starsim as ss``.\n \n-The model consists of core classes including Sim, Run, People, State, Network, Connectors, Analyzers, Interventions, Results, and more. These classes contain methods for running, building simple or dynamic networks, generating random numbers, calculating results, plotting, etc.\n+The model consists of core classes including ``Sim``, ``People``, ``Disease``, ``Network``, ``Intervention``, and more. These classes contain methods for running, building simple or dynamic networks, generating random numbers, calculating results, plotting, etc.\n \n-The structure of the starsim folder is as follows, roughly in the order in which the modules are imported, building from most fundamental to most complex:\n+The submodules of the Starsim folder are as follows:\n \n+• ``arrays.py``: Classes to handle store and update states for people in networks in the simulation including living, mother, child, susceptible, infected, inoculated, recovered, etc.\n+• ``calibration.py``: Class to handle automated calibration of the model to data.\n •\t``demographics.py``: Classes to transform initial condition input parameters for use in building and utilizing networks.\n •\t``disease.py``: Classes to manage infection rate of spread, prevalence, waning effects, and other parameters for specific diseases.\n-•\t``distributions.py``: Classes that handle statistical distributions used throughout Starsim.\n+•\t``distributions.py``: Classes that handle statistical distributions used throughout Starsim to produce random numbers.\n •\t``interventions.py``: The Intervention class, for adding interventions and dynamically modifying parameters, and classes for each of the specific interventions derived from it. The Analyzers class (for performing analyses on the sim while it's running), and other classes and functions for analyzing simulations.\n+• ``loop.py``: The logic for the main simulation integration loop.\n •\t``modules.py``: Class to handle \"module\" logic, such as updates (diseases, networks, etc).\n-•\t``network.py``: Classes for creating simple and dynamic networks of people based on input parameters.\n+•\t``networks.py``: Classes for creating simple and dynamic networks of people based on input parameters.\n •\t``parameters.py``: Classes for creating the simulation parameters.\n •\t``people.py``: The People class, for handling updates of state for each person.\n •\t``products.py``: Classes to manage the deployment of vaccines and treatments.\n@@ -80,11 +91,11 @@ The structure of the starsim folder is as follows, roughly in the order in which\n •\t``samples.py``: Class to store data from a large number of simulations.\n •\t``settings.py``: User-customizable options for Starsim (e.g. default font size).\n •\t``sim.py``: The Sim class, which performs most of the heavy lifting: initializing the model, running, and plotting.\n-•\t``states.py``: Classes to handle store and update states for people in networks in the simulation including living, mother, child, susceptible, infected, inoculated, recovered, etc.\n+• ``time.py``: The Time class, which coordinates time between the Sim and different modules.\n •\t``utils.py``: Helper functions.\n •\t``version.py``: Version, date, and license information.\n \n-The ``diseases`` folder within the Starsim package contains loading scripts for the epidemiological data specific to each respective disease.\n+The ``diseases`` folder within the Starsim package contains definitions of different types of diseases, including STIs, Ebola, and cholera.\n \n \n Contributing\n@@ -96,6 +107,4 @@ Questions or comments can be directed to `info@starsim.org <mailto:info@starsim.\n Disclaimer\n ----------\n \n-The code in this repository was developed by IDM, the Burnet Institute, and other collaborators to support our joint research on flexible agent-based modeling. We've made it publicly available under the MIT License to provide others with a better understanding of our research and an opportunity to build upon it for their own work. We make no representations that the code works as intended or that we will provide support, address issues that are found, or accept pull requests. You are welcome to create your own fork and modify the code to suit your own modeling needs as permitted under the MIT License.\n-\n-\n+The code in this repository was developed by `IDM <https://idmod.org>`_, the `Burnet Institute <https://burnet.edu.au>`_, and other collaborators to support our joint research on flexible agent-based modeling. We've made it publicly available under the MIT License to provide others with a better understanding of our research and an opportunity to build upon it for their own work. We make no representations that the code works as intended or that we will provide support, address issues that are found, or accept pull requests. You are welcome to create your own fork and modify the code to suit your own modeling needs as permitted under the MIT License.\ndiff --git a/docs/api/index.rst b/docs/api/index.rst\nindex 3c9540c..67630e4 100644\n--- a/docs/api/index.rst\n+++ b/docs/api/index.rst\n@@ -12,19 +12,22 @@ This page lists Starsim's full API, including all functions and classes.\n    :recursive:\n    :nosignatures:\n \n-   starsim.demographics\n-   starsim.disease\n-   starsim.distributions\n-   starsim.interventions\n-   starsim.modules\n-   starsim.network\n-   starsim.parameters\n-   starsim.people\n-   starsim.products\n-   starsim.results\n-   starsim.run\n-   starsim.samples\n-   starsim.settings\n-   starsim.sim\n-   starsim.states\n-   starsim.utils\n+   arrays\n+   calibration\n+   demographics\n+   disease\n+   distributions\n+   interventions\n+   loop\n+   modules\n+   networks\n+   parameters\n+   people\n+   products\n+   results\n+   run\n+   samples\n+   settings\n+   sim\n+   time\n+   utils\ndiff --git a/docs/build_docs b/docs/build_docs\nindex 4bc5046..3b327cc 100755\n--- a/docs/build_docs\n+++ b/docs/build_docs\n@@ -20,10 +20,10 @@ make clean # Delete previous build\n # Handle notebook build options\n if [[ \"$*\" == *\"never\"* ]]; then\n     export NBSPHINX_EXECUTE=never\n-elif [[ \"$*\" == *\"always\"* ]]; then\n-    export NBSPHINX_EXECUTE=always\n-else\n+elif [[ \"$*\" == *\"auto\"* ]]; then\n     export NBSPHINX_EXECUTE=auto\n+else\n+    export NBSPHINX_EXECUTE=always\n fi\n \n \ndiff --git a/docs/conf.py b/docs/conf.py\nindex 4099148..726962c 100644\n--- a/docs/conf.py\n+++ b/docs/conf.py\n@@ -6,9 +6,6 @@ import os\n import sys\n import sciris as sc\n import starsim as ss\n-\n-# Set environment\n-os.environ['SPHINX_BUILD'] = 'True' # This is used so ss.options.set('jupyter') doesn't reset the Matplotlib renderer\n on_rtd = os.environ.get('READTHEDOCS') == 'True'\n \n \n@@ -119,11 +116,8 @@ def setup(app):\n \n \n # Modify this to not rerun the Jupyter notebook cells -- usually set by build_docs\n-nb_ex_default = ['auto', 'never'][0]\n-nb_ex = os.getenv('NBSPHINX_EXECUTE')\n-if not nb_ex: nb_ex = nb_ex_default\n-print(f'\\n\\nBuilding Jupyter notebooks with build option: {nb_ex}\\n\\n')\n-nbsphinx_execute = nb_ex\n+nbsphinx_execute = 'always'\n+nbsphinx_timeout = 300\n \n # OpenSearch options\n html_use_opensearch = 'docs.idmod.org/projects/starsim/en/latest'\ndiff --git a/docs/requirements.txt b/docs/requirements.txt\nindex ed9af80..d2303a8 100644\n--- a/docs/requirements.txt\n+++ b/docs/requirements.txt\n@@ -1,15 +1,15 @@\n pandoc\n pypandoc\n-sphinx\n+sphinx>=7.3.7\n sphinx-autodoc-typehints\n pydata-sphinx-theme\n sphinx-design\n readthedocs-sphinx-search\n+sphinxcontrib-napoleon\n ipykernel # For tutorials\n-nbconvert==7.13.0 # For tutorials; >=7.14 does not work\n-nbsphinx # For tutorials\n+ipywidgets # For the tutorials\n+nbconvert>=7.10.0 # For tutorials\n+nbsphinx>=0.9.5 # For tutorials\n plantweb\n-ipykernel\n-nbsphinx\n optuna\n seaborn\ndiff --git a/docs/run_tutorials b/docs/run_tutorials\nnew file mode 120000\nindex 0000000..9d6178e\n--- /dev/null\n+++ b/docs/run_tutorials\n@@ -0,0 +1 @@\n+tutorials/run_tutorials\n\\ No newline at end of file\ndiff --git a/docs/tutorials.rst b/docs/tutorials.rst\nindex 574924b..b121e51 100644\n--- a/docs/tutorials.rst\n+++ b/docs/tutorials.rst\n@@ -9,8 +9,8 @@ User tutorials\n     tutorials/tut_intro.ipynb\n     tutorials/tut_buildsim.ipynb\n     tutorials/tut_demographics.ipynb\n-    tutorials/tut_networks.ipynb\n     tutorials/tut_diseases.ipynb\n+    tutorials/tut_transmission.ipynb\n     tutorials/tut_interventions.ipynb\n \n Developer tutorials\n@@ -20,4 +20,7 @@ Developer tutorials\n     :maxdepth: 1\n \n     tutorials/dev_tut_diseases.ipynb\n+    tutorials/dev_tut_pars.ipynb\n+    tutorials/dev_tut_analyzers.ipynb\n+    tutorials/dev_tut_nonstandard.ipynb\n     \ndiff --git a/docs/tutorials/dev_tut_analyzers.ipynb b/docs/tutorials/dev_tut_analyzers.ipynb\nnew file mode 100644\nindex 0000000..606d811\n--- /dev/null\n+++ b/docs/tutorials/dev_tut_analyzers.ipynb\n@@ -0,0 +1,188 @@\n+{\n+ \"cells\": [\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"2b9940bf\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"# Developer tutorial: Analyzers\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"b1167214\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"<div class=\\\"alert alert-info\\\">\\n\",\n+    \"    \\n\",\n+    \"An interactive version of this notebook is available on [Google Colab](https://colab.research.google.com/github/starsimhub/starsim/blob/main/docs/tutorials/dev_tut_analyzers.ipynb?install=starsim) or [Binder](https://mybinder.org/v2/gh/starsimhub/starsim/HEAD?labpath=docs%2Ftutorials%2Fdev_tut_analyzers.ipynb).\\n\",\n+    \"    \\n\",\n+    \"</div>\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"17f9cc01\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"## Reporting results\\n\",\n+    \"\\n\",\n+    \"Each Starsim module can have its own results, which get added to the full list of results in the Sim object. For example, the `ss.Pregnancy` module adds results like `sim.results.pregnancy.pregnant`, and the `ss.HIV` module adds results like `sim.results.hiv.new_infections`. If you are writing your own module, you can add whatever custom results you want. However, another option is to create an `Analyzer` to store results that you might need for one particular analysis but won't need all the time. An `Analyzer` is very similar to other Starsim modules in its structure, but the general idea of an analyzer is that it gets called at the end of a timestep, and reports of the state of things after everything else has been updated without changing any of the module states itself.\\n\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"9c34dcc8\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"## Simple usage\\n\",\n+    \"\\n\",\n+    \"For simple reporting, it's possible to use a single function as an analyzer. In this case, the function receives a single argument, `sim`, which it has full access to. For example, if you wanted to know the number of connections in the network on each timestep, you could write a small analyzer as follows:\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"id\": \"306a385e\",\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"import starsim as ss\\n\",\n+    \"import matplotlib.pyplot as plt\\n\",\n+    \"\\n\",\n+    \"# Store the number of edges\\n\",\n+    \"n_edges = []\\n\",\n+    \"\\n\",\n+    \"def count_edges(sim):\\n\",\n+    \"    \\\"\\\"\\\" Print out the number of edges in the network on each timestep \\\"\\\"\\\"\\n\",\n+    \"    network = sim.networks[0] # Get the first network\\n\",\n+    \"    n = len(network)\\n\",\n+    \"    n_edges.append(n)\\n\",\n+    \"    print(f'Number of edges for network {network.name} on step {sim.ti}: {n}')\\n\",\n+    \"    return\\n\",\n+    \"\\n\",\n+    \"# Create the sim\\n\",\n+    \"pars = dict(\\n\",\n+    \"    diseases='sis',\\n\",\n+    \"    networks = 'mf',\\n\",\n+    \"    analyzers = count_edges,\\n\",\n+    \"    demographics = True,\\n\",\n+    \")\\n\",\n+    \"\\n\",\n+    \"# Run the sim\\n\",\n+    \"sim = ss.Sim(pars).run()\\n\",\n+    \"sim.plot()\\n\",\n+    \"\\n\",\n+    \"# Plot the number of edges\\n\",\n+    \"plt.figure()\\n\",\n+    \"plt.plot(sim.timevec, n_edges)\\n\",\n+    \"plt.title('Number of edges over time')\\n\",\n+    \"plt.show()\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"10599c01\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"Is that what you expected it to look like? The reason it looks like that is that initially, agents die (either from aging or from disease), reducing the number of edges. New agents are being born, but they don't participate in male-female networks until the age of debut -- which is 15 years old by default, which is why the trend reverses (and tracks population size) after 2015. This illustrates the importance of model burn-in!\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"79869fb8\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"## Advanced usage\\n\",\n+    \"\\n\",\n+    \"Suppose we wanted to create an analyzer that would report on the number of new HIV infections in pregnant women:\\n\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"id\": \"639d87f1\",\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"import starsim as ss\\n\",\n+    \"import pandas as pd\\n\",\n+    \"\\n\",\n+    \"class HIV_preg(ss.Analyzer):\\n\",\n+    \"    def __init__(self, *args, **kwargs):\\n\",\n+    \"        super().__init__(*args, **kwargs)\\n\",\n+    \"        return\\n\",\n+    \"    \\n\",\n+    \"    def init_results(self):\\n\",\n+    \"        super().init_results()\\n\",\n+    \"        self.define_results(\\n\",\n+    \"            ss.Result('new_infections_pregnancy'),\\n\",\n+    \"        )\\n\",\n+    \"        return\\n\",\n+    \"\\n\",\n+    \"    def step(self):\\n\",\n+    \"        sim = self.sim\\n\",\n+    \"        ti = sim.ti\\n\",\n+    \"        hiv = sim.diseases.hiv\\n\",\n+    \"        pregnant = sim.demographics.pregnancy.pregnant\\n\",\n+    \"        newly_infected = hiv.ti_infected == ti\\n\",\n+    \"        self.results['new_infections_pregnancy'][ti] = len((newly_infected & pregnant).uids)\\n\",\n+    \"        return\\n\",\n+    \"\\n\",\n+    \"pregnancy = ss.Pregnancy(pars=dict(fertility_rate=pd.read_csv('test_data/nigeria_asfr.csv')))\\n\",\n+    \"hiv = ss.HIV(beta={'mfnet':[0.5,0.25]})\\n\",\n+    \"sim = ss.Sim(diseases=hiv, networks='mfnet', demographics=pregnancy, analyzers=HIV_preg())\\n\",\n+    \"sim.run()\\n\",\n+    \"print(f'Total infections among pregnant women: {sim.results.hiv_preg.new_infections_pregnancy.sum()}')\\n\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"69d050f3\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"Analyzers are ideal for adding custom results, and because they get added to the sim in the same way as any other result, they also get automatically exported in the same format, e.g. using `sim.to_df()`.\\n\",\n+    \"\\n\",\n+    \"Here's a plot of the results from our HIV in pregnancy analyzer:\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"id\": \"29072323\",\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"import matplotlib.pyplot as plt\\n\",\n+    \"\\n\",\n+    \"res = sim.results.hiv_preg\\n\",\n+    \"\\n\",\n+    \"plt.figure()\\n\",\n+    \"plt.bar(res.timevec, res.new_infections_pregnancy)\\n\",\n+    \"plt.title('HIV infections acquired during pregnancy')\\n\",\n+    \"plt.show()\"\n+   ]\n+  }\n+ ],\n+ \"metadata\": {\n+  \"kernelspec\": {\n+   \"display_name\": \"base\",\n+   \"language\": \"python\",\n+   \"name\": \"python3\"\n+  },\n+  \"language_info\": {\n+   \"codemirror_mode\": {\n+    \"name\": \"ipython\",\n+    \"version\": 3\n+   },\n+   \"file_extension\": \".py\",\n+   \"mimetype\": \"text/x-python\",\n+   \"name\": \"python\",\n+   \"nbconvert_exporter\": \"python\",\n+   \"pygments_lexer\": \"ipython3\",\n+   \"version\": \"3.12.2\"\n+  }\n+ },\n+ \"nbformat\": 4,\n+ \"nbformat_minor\": 5\n+}\ndiff --git a/docs/tutorials/dev_tut_diseases.ipynb b/docs/tutorials/dev_tut_diseases.ipynb\nindex 69e93b6..c1d04ef 100644\n--- a/docs/tutorials/dev_tut_diseases.ipynb\n+++ b/docs/tutorials/dev_tut_diseases.ipynb\n@@ -2,13 +2,27 @@\n  \"cells\": [\n   {\n    \"cell_type\": \"markdown\",\n+   \"id\": \"397b7212\",\n    \"metadata\": {},\n    \"source\": [\n-    \"# Developer tutorial - Diseases\"\n+    \"# Developer tutorial: Diseases\"\n    ]\n   },\n   {\n    \"cell_type\": \"markdown\",\n+   \"id\": \"a30cce76\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"<div class=\\\"alert alert-info\\\">\\n\",\n+    \"    \\n\",\n+    \"An interactive version of this notebook is available on [Google Colab](https://colab.research.google.com/github/starsimhub/starsim/blob/main/docs/tutorials/dev_tut_diseases.ipynb?install=starsim) or [Binder](https://mybinder.org/v2/gh/starsimhub/starsim/HEAD?labpath=docs%2Ftutorials%2Fdev_tut_diseases.ipynb).\\n\",\n+    \"    \\n\",\n+    \"</div>\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"6adf65fe\",\n    \"metadata\": {},\n    \"source\": [\n     \"## Overview of Starsim's disease structure\\n\",\n@@ -22,6 +36,7 @@\n   },\n   {\n    \"cell_type\": \"markdown\",\n+   \"id\": \"03077b6c\",\n    \"metadata\": {\n     \"collapsed\": false,\n     \"jupyter\": {\n@@ -35,14 +50,8 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": null,\n-   \"metadata\": {},\n-   \"outputs\": [],\n-   \"source\": []\n-  },\n-  {\n-   \"cell_type\": \"code\",\n-   \"execution_count\": 3,\n+   \"execution_count\": 1,\n+   \"id\": \"8b1bf68d\",\n    \"metadata\": {\n     \"collapsed\": false,\n     \"jupyter\": {\n@@ -52,67 +61,79 @@\n    \"outputs\": [],\n    \"source\": [\n     \"import numpy as np\\n\",\n+    \"import matplotlib.pyplot as plt\\n\",\n     \"import starsim as ss\\n\",\n     \"\\n\",\n-    \"\\n\",\n     \"class SEIR(ss.SIR):\\n\",\n     \"    def __init__(self, pars=None, *args, **kwargs):\\n\",\n-    \"        \\n\",\n-    \"        # Additional pars beyond the SIR model ones\\n\",\n-    \"        pars = ss.omerge({\\n\",\n-    \"            'dur_exp': 0.5,  \\n\",\n-    \"        }, pars)\\n\",\n-    \"        \\n\",\n-    \"        # Initialize the SIR model, which will add all the parameters and states of that model.\\n\",\n-    \"        super().__init__(pars=pars, *args, **kwargs)\\n\",\n+    \"        super().__init__()\\n\",\n+    \"        self.define_pars(\\n\",\n+    \"            dur_exp = ss.lognorm_ex(0.5),\\n\",\n+    \"        )\\n\",\n+    \"        self.update_pars(pars, **kwargs)\\n\",\n     \"\\n\",\n     \"        # Additional states beyond the SIR ones \\n\",\n-    \"        self.exposed = ss.State('exposed', bool, False)\\n\",\n-    \"        self.ti_exposed = ss.State('ti_exposed', float, np.nan)\\n\",\n-    \"\\n\",\n+    \"        self.define_states(\\n\",\n+    \"            ss.State('exposed', label='Exposed'),\\n\",\n+    \"            ss.FloatArr('ti_exposed', label='TIme of exposure'),\\n\",\n+    \"        )\\n\",\n     \"        return\\n\",\n     \"\\n\",\n     \"    @property\\n\",\n     \"    def infectious(self):\\n\",\n     \"        return self.infected | self.exposed\\n\",\n     \"\\n\",\n-    \"    def update_pre(self, sim):\\n\",\n-    \"        # Make all the updates from the SIR model \\n\",\n-    \"        n_deaths = super().update_pre(sim)\\n\",\n+    \"    def step_state(self):\\n\",\n+    \"        \\\"\\\"\\\" Make all the updates from the SIR model \\\"\\\"\\\"\\n\",\n+    \"        # Perform SIR updates\\n\",\n+    \"        super().step_state()\\n\",\n     \"\\n\",\n     \"        # Additional updates: progress exposed -> infected\\n\",\n-    \"        infected = ss.true(self.exposed & (self.ti_infected <= sim.ti))\\n\",\n+    \"        infected = self.exposed & (self.ti_infected <= self.ti)\\n\",\n     \"        self.exposed[infected] = False\\n\",\n     \"        self.infected[infected] = True\\n\",\n+    \"        return\\n\",\n     \"\\n\",\n-    \"        return n_deaths\\n\",\n-    \"\\n\",\n-    \"    def update_death(self, sim, uids):\\n\",\n-    \"        super().update_death(sim, uids)\\n\",\n+    \"    def step_die(self, uids):\\n\",\n+    \"        super().step_die(uids)\\n\",\n     \"        self.exposed[uids] = False\\n\",\n     \"        return\\n\",\n     \"\\n\",\n-    \"    def set_prognoses(self, sim, uids, from_uids):\\n\",\n-    \"        # Carry out state changes associated with infection\\n\",\n+    \"    def set_prognoses(self, uids, sources=None):\\n\",\n+    \"        \\\"\\\"\\\" Carry out state changes associated with infection \\\"\\\"\\\"\\n\",\n+    \"        super().set_prognoses(uids, sources)\\n\",\n+    \"        ti = self.ti\\n\",\n     \"        self.susceptible[uids] = False\\n\",\n     \"        self.exposed[uids] = True\\n\",\n-    \"        self.ti_exposed[uids] = sim.ti\\n\",\n+    \"        self.ti_exposed[uids] = ti\\n\",\n     \"\\n\",\n     \"        # Calculate and schedule future outcomes\\n\",\n     \"        dur_exp = self.pars['dur_exp'].rvs(uids)\\n\",\n-    \"        self.ti_infected[uids] = sim.ti + dur_exp / sim.dt\\n\",\n+    \"        self.ti_infected[uids] = ti + dur_exp\\n\",\n     \"        dur_inf = self.pars['dur_inf'].rvs(uids)\\n\",\n     \"        will_die = self.pars['p_death'].rvs(uids)        \\n\",\n-    \"        self.ti_recovered[uids[~will_die]] = sim.ti + dur_inf[~will_die] / sim.dt\\n\",\n-    \"        self.ti_dead[uids[will_die]] = sim.ti + dur_inf[will_die] / sim.dt\\n\",\n+    \"        self.ti_recovered[uids[~will_die]] = ti + dur_inf[~will_die]\\n\",\n+    \"        self.ti_dead[uids[will_die]] = ti + dur_inf[will_die]\\n\",\n     \"\\n\",\n     \"        # Update result count of new infections \\n\",\n-    \"        self.results['new_infections'][sim.ti] += len(uids)\\n\",\n-    \"        return\\n\"\n+    \"        self.results['new_infections'][self.ti] += len(uids)\\n\",\n+    \"        return\\n\",\n+    \"    \\n\",\n+    \"    def plot(self):\\n\",\n+    \"        \\\"\\\"\\\" Update the plot with the exposed compartment \\\"\\\"\\\"\\n\",\n+    \"        with ss.options.context(jupyter=False):\\n\",\n+    \"            fig = super().plot()\\n\",\n+    \"            ax = plt.gca()\\n\",\n+    \"            res = self.results.n_exposed\\n\",\n+    \"            ax.plot(res.timevec, res, label=res.label)\\n\",\n+    \"            plt.legend()\\n\",\n+    \"        return ss.return_fig(fig)\\n\",\n+    \"\\n\"\n    ]\n   },\n   {\n    \"cell_type\": \"markdown\",\n+   \"id\": \"572ec8fe\",\n    \"metadata\": {\n     \"collapsed\": false,\n     \"jupyter\": {\n@@ -127,11 +148,33 @@\n     \"3. We updated `update_pre` and `update_death` to include changes to the `exposed` state \\n\",\n     \"4. We rewrote `set_prognoses` to include the new exposed state.\\n\"\n    ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"c6a7f164\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"Here's how it would look in practice:\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"id\": \"2d627cb8\",\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"seir = SEIR()\\n\",\n+    \"sim = ss.Sim(diseases=seir, networks='random')\\n\",\n+    \"sim.run()\\n\",\n+    \"sim.plot()\\n\",\n+    \"sim.diseases.seir.plot()\"\n+   ]\n   }\n  ],\n  \"metadata\": {\n   \"kernelspec\": {\n-   \"display_name\": \"Python 3 (ipykernel)\",\n+   \"display_name\": \"base\",\n    \"language\": \"python\",\n    \"name\": \"python3\"\n   },\n@@ -145,31 +188,9 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.10.11\"\n-  },\n-  \"pycharm\": {\n-   \"stem_cell\": {\n-    \"cell_type\": \"raw\",\n-    \"metadata\": {\n-     \"collapsed\": false\n-    },\n-    \"source\": []\n-   }\n-  },\n-  \"toc\": {\n-   \"base_numbering\": 1,\n-   \"nav_menu\": {},\n-   \"number_sections\": true,\n-   \"sideBar\": true,\n-   \"skip_h1_title\": false,\n-   \"title_cell\": \"Table of Contents\",\n-   \"title_sidebar\": \"Contents\",\n-   \"toc_cell\": false,\n-   \"toc_position\": {},\n-   \"toc_section_display\": true,\n-   \"toc_window_display\": false\n+   \"version\": \"3.12.2\"\n   }\n  },\n  \"nbformat\": 4,\n- \"nbformat_minor\": 4\n+ \"nbformat_minor\": 5\n }\ndiff --git a/docs/tutorials/dev_tut_nonstandard.ipynb b/docs/tutorials/dev_tut_nonstandard.ipynb\nnew file mode 100644\nindex 0000000..1503f91\n--- /dev/null\n+++ b/docs/tutorials/dev_tut_nonstandard.ipynb\n@@ -0,0 +1,313 @@\n+{\n+ \"cells\": [\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"65d05112\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"# Developer tutorial: Nonstandard usage\\n\",\n+    \"\\n\",\n+    \"Although Starsim is primarily intended as an agent-based disease model, due to its modular structure, it can be used for other applications as well. This tutorial describes how Starsim can be used (1) as a compartmental disease model, and (2) as a general-purpose agent-based model.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"d5d9ebcb\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"<div class=\\\"alert alert-info\\\">\\n\",\n+    \"    \\n\",\n+    \"An interactive version of this notebook is available on [Google Colab](https://colab.research.google.com/github/starsimhub/starsim/blob/main/docs/tutorials/dev_tut_nonstandard.ipynb?install=starsim) or [Binder](https://mybinder.org/v2/gh/starsimhub/starsim/HEAD?labpath=docs%2Ftutorials%2Fdev_tut_nonstandard.ipynb).\\n\",\n+    \"    \\n\",\n+    \"</div>\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"3517ab31\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"## Compartmental modeling\\n\",\n+    \"\\n\",\n+    \"Much of Starsim's power comes from how it handles agents. However, agent-based modeling may be too slow or too complex for some problems. While in many cases it probably makes more sense to do compartmental disease modeling in another framework (such as [Atomica](https://atomica.tools/)), it is also possible to do it within Starsim, taking advantage of features such as demographics, time units, etc. This is especially useful for a multi-disease simulation where some diseases need the detail and flexibility of an ABM, while others can be modeled more simply (and faster) as compartmental models.\\n\",\n+    \"\\n\",\n+    \"### Setting up the model\\n\",\n+    \"\\n\",\n+    \"Here we will define a simple compartmental susceptible-infectious-susceptible (SIS) model. The model definition here is quite similar to the agent-based implementation in Starsim's [SIR module](https://github.com/starsimhub/starsim/blob/main/starsim/diseases/sir.py); differences are noted in comments. Note that the model runs extremely fast, since a three-state compartmental model (susceptible, infecious, and immunity) runs as fast as an agent-based model with three agents!\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"id\": \"8b4b1e6d\",\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"\\\"\\\"\\\"\\n\",\n+    \"Example compartmental SIS model for Starsim\\n\",\n+    \"\\\"\\\"\\\"\\n\",\n+    \"\\n\",\n+    \"import starsim as ss\\n\",\n+    \"import sciris as sc\\n\",\n+    \"import matplotlib.pyplot as plt\\n\",\n+    \"\\n\",\n+    \"\\n\",\n+    \"class CompartmentalSIS(ss.Module): # We don't need the extra functionality of the Infection class, so just inherit from Module\\n\",\n+    \"    def __init__(self, pars=None, *args, **kwargs):\\n\",\n+    \"        super().__init__()\\n\",\n+    \"        self.define_pars(\\n\",\n+    \"            beta = ss.rate(0.8), # Leverage Starsim's automatic time unit handling\\n\",\n+    \"            init_prev = 0.01, # NB: this is a scalar, rather than a distribution for an ABM\\n\",\n+    \"            recovery = ss.rate(0.1), # Also not a distribution\\n\",\n+    \"            waning = ss.rate(0.05),\\n\",\n+    \"            imm_boost = 1.0,\\n\",\n+    \"            use_immunity = True,\\n\",\n+    \"        )\\n\",\n+    \"        self.update_pars(pars=pars, *args, **kwargs)\\n\",\n+    \"        \\n\",\n+    \"        # Don't need to define states; just use scalars\\n\",\n+    \"        self.N = 0\\n\",\n+    \"        self.S = 0\\n\",\n+    \"        self.I = 0\\n\",\n+    \"        self.immunity = 0\\n\",\n+    \"        return\\n\",\n+    \"    \\n\",\n+    \"    def init_post(self):\\n\",\n+    \"        \\\"\\\"\\\" Finish initialization \\\"\\\"\\\"\\n\",\n+    \"        super().init_post()\\n\",\n+    \"        self.N = len(self.sim.people) # Assumes a static population; could also use a dynamic population size\\n\",\n+    \"        i0 = self.pars.init_prev\\n\",\n+    \"        self.S = self.N*(1-i0)\\n\",\n+    \"        self.I = self.N*i0\\n\",\n+    \"        self.immunity = i0\\n\",\n+    \"        return\\n\",\n+    \"        \\n\",\n+    \"    @property\\n\",\n+    \"    def rel_sus(self):\\n\",\n+    \"        return 1 - self.immunity\\n\",\n+    \"    \\n\",\n+    \"    def step(self):\\n\",\n+    \"        \\\"\\\"\\\" Carry out disease transmission logic \\\"\\\"\\\"\\n\",\n+    \"        self.immunity *= (1 - self.pars.waning) # Update immunity from waning\\n\",\n+    \"        rel_sus = self.rel_sus if self.pars.use_immunity else 1.0\\n\",\n+    \"        infected = (self.S*self.I/self.N)*self.pars.beta*rel_sus # Replaces Infection.infect()\\n\",\n+    \"        recovered = self.I*self.pars.recovery # Replaces setting a time to recovery and checking that time\\n\",\n+    \"        net = infected - recovered # Net change in number infectious\\n\",\n+    \"        self.S -= net\\n\",\n+    \"        self.I += net\\n\",\n+    \"        self.immunity += infected/self.N*self.pars.imm_boost # Update immunity from new infections\\n\",\n+    \"        return\\n\",\n+    \"    \\n\",\n+    \"    def init_results(self):\\n\",\n+    \"        \\\"\\\"\\\" Initialize results \\\"\\\"\\\"\\n\",\n+    \"        super().init_results()\\n\",\n+    \"        self.define_results(\\n\",\n+    \"            ss.Result('S', label='Susceptible'),\\n\",\n+    \"            ss.Result('I', label='Infectious'),\\n\",\n+    \"        )\\n\",\n+    \"        return\\n\",\n+    \"\\n\",\n+    \"    def update_results(self):\\n\",\n+    \"        \\\"\\\"\\\" Store the current state \\\"\\\"\\\"\\n\",\n+    \"        super().update_results()\\n\",\n+    \"        self.results['S'][self.ti] = self.S\\n\",\n+    \"        self.results['I'][self.ti] = self.I\\n\",\n+    \"        return \\n\",\n+    \"\\n\",\n+    \"    def plot(self):\\n\",\n+    \"        \\\"\\\"\\\" Default plot for SIS model \\\"\\\"\\\"\\n\",\n+    \"        fig = plt.figure()\\n\",\n+    \"        res = self.results\\n\",\n+    \"        kw = dict(lw=2, alpha=0.7)\\n\",\n+    \"        for rkey in ['S', 'I']:\\n\",\n+    \"            plt.plot(res.timevec, res[rkey], label=res[rkey].label, **kw)\\n\",\n+    \"        plt.legend(frameon=False)\\n\",\n+    \"        plt.xlabel('Time')\\n\",\n+    \"        plt.ylabel('Number of people')\\n\",\n+    \"        plt.ylim(bottom=0)\\n\",\n+    \"        sc.boxoff()\\n\",\n+    \"        sc.commaticks() \\n\",\n+    \"        plt.show()      \\n\",\n+    \"        return\\n\",\n+    \"    \\n\",\n+    \"\\n\",\n+    \"# Run the compartmental simulation (csim)\\n\",\n+    \"csim = ss.Sim(diseases=CompartmentalSIS(), dur=100, dt=0.1, verbose=0.01)\\n\",\n+    \"csim.run()\\n\",\n+    \"\\n\",\n+    \"# Plot the results\\n\",\n+    \"csim.diseases.compartmentalsis.plot()\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"58588afb\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"Let's compare to our standard agent-based SIS model with similar parameters:\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"id\": \"6805c893\",\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"import starsim as ss\\n\",\n+    \"\\n\",\n+    \"# Run the model\\n\",\n+    \"abm = ss.Sim(diseases=ss.SIS(beta=0.03), networks='random', dur=100, dt=0.1, verbose=0.01)\\n\",\n+    \"abm.run()\\n\",\n+    \"\\n\",\n+    \"# Plot the results\\n\",\n+    \"abm.diseases.sis.plot()\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"960efa16\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"The results are broadly similar, although there are differences due to the network transmission, duration of infection, etc. Note that the compartmental version runs 20 times faster than the agent-based version. Does this mean that compartmental models are better than agent-based models? If all you want to simulate is a simple SIS model, then ... the answer is probably yes!\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"aed50612\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"## Mesa: Wealth model\\n\",\n+    \"\\n\",\n+    \"This example illustrates a simple \\\"weath model\\\", in which each agent starts with a single unit of wealth, and on each timestep, every agent with more than zero wealth gives one unit of wealth to another agent.\\n\",\n+    \"\\n\",\n+    \"This tutorial is adapted from the following example:\\n\",\n+    \"\\n\",\n+    \"https://mesa.readthedocs.io/en/stable/tutorials/intro_tutorial.html\\n\",\n+    \"\\n\",\n+    \"### Setting up the model\\n\",\n+    \"\\n\",\n+    \"We could define the wealth model as any type of module, since they all can store states and update them. Here we will define wealth as a subclass of `ss.Intervention` (though it could equally well be a subclass of `ss.Demographics` or even `ss.Disease`, if you are so inclined). All we need to do is update the `wealth` state (which we can store inside the \\\"intervention\\\"), and we can also use this class to track the wealth distribution over time and plot it. The full model looks like this:\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"id\": \"d42479c7\",\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"\\\"\\\"\\\"\\n\",\n+    \"Define the classic agent-based \\\"wealth model\\\" in Starsim\\n\",\n+    \"\\\"\\\"\\\"\\n\",\n+    \"\\n\",\n+    \"# Imports\\n\",\n+    \"import numpy as np\\n\",\n+    \"import starsim as ss\\n\",\n+    \"import matplotlib.pyplot as plt\\n\",\n+    \"\\n\",\n+    \"# Define the model\\n\",\n+    \"class WealthModel(ss.Module):\\n\",\n+    \"    \\\"\\\"\\\" A simple wealth transfer model\\\"\\\"\\\"\\n\",\n+    \"    \\n\",\n+    \"    def init_post(self, bins=10):\\n\",\n+    \"        \\\"\\\"\\\" Define custom model attributes \\\"\\\"\\\"\\n\",\n+    \"        super().init_post()\\n\",\n+    \"        self.npts = len(self.sim) # Number of timepoints\\n\",\n+    \"        self.n_agents = len(sim.people) # Number of agents\\n\",\n+    \"        self.wealth = np.ones(self.n_agents) # Initial wealth of each agent\\n\",\n+    \"        self.bins = np.arange(bins+1) # Bins used for plotting\\n\",\n+    \"        self.wealth_dist = np.zeros((self.npts, len(self.bins)-1)) # Wealth distribution over time\\n\",\n+    \"        return\\n\",\n+    \"        \\n\",\n+    \"    def step(self):\\n\",\n+    \"        \\\"\\\"\\\" Transfer wealth between agents -- core model logic \\\"\\\"\\\"\\n\",\n+    \"        self.wealth_hist() # Store the wealth at this time point\\n\",\n+    \"        givers = self.wealth > 0 # People need wealth to be givers\\n\",\n+    \"        receivers = np.random.choice(self.sim.people.uid, size=givers.sum()) # Anyone can be a receiver\\n\",\n+    \"        self.wealth[givers] -= 1 # Givers are unique, so can use vectorized version\\n\",\n+    \"        for receive in receivers: # Vectorized version is: np.add.at(sim.people.wealth.raw, receivers, 1)\\n\",\n+    \"            self.wealth[receive] += 1\\n\",\n+    \"        return\\n\",\n+    \"    \\n\",\n+    \"    def wealth_hist(self):\\n\",\n+    \"        \\\"\\\"\\\" Calculate the wealth histogram \\\"\\\"\\\"\\n\",\n+    \"        ti = self.sim.ti # Current timestep\\n\",\n+    \"        self.wealth_dist[ti,:], _ = np.histogram(self.wealth, bins=self.bins)\\n\",\n+    \"        return\\n\",\n+    \"    \\n\",\n+    \"    def plot(self):\\n\",\n+    \"        \\\"\\\"\\\" Plot a 2D histogram of the final wealth distribution \\\"\\\"\\\"\\n\",\n+    \"        plt.figure()\\n\",\n+    \"        plt.bar(self.bins[:-1], self.wealth_dist[-1,:])\\n\",\n+    \"        plt.title('Wealth distribution at final time point')\\n\",\n+    \"        plt.xlabel('Wealth')\\n\",\n+    \"        plt.ylabel('Number of agents')\\n\",\n+    \"        plt.show()\\n\",\n+    \"        return\\n\",\n+    \"    \\n\",\n+    \"    def plot3d(self):\\n\",\n+    \"        \\\"\\\"\\\" Plot a 3D heatmap of the wealth distribution over time \\\"\\\"\\\"\\n\",\n+    \"        plt.figure()\\n\",\n+    \"        plt.pcolor(self.wealth_dist.T, cmap='turbo')\\n\",\n+    \"        plt.title('Wealth distribution over time')\\n\",\n+    \"        plt.xlabel('Time')\\n\",\n+    \"        plt.ylabel('Wealth')\\n\",\n+    \"        plt.colorbar().set_label('Number of agents', rotation=270)\\n\",\n+    \"        plt.show()\\n\",\n+    \"        return\\n\",\n+    \"\\n\",\n+    \"# Create sim inputs, including the wealth model\\n\",\n+    \"wealth = WealthModel()\\n\",\n+    \"pars = dict(\\n\",\n+    \"    n_agents = 100, # Number of agents\\n\",\n+    \"    start = 0,\\n\",\n+    \"    stop = 100,\\n\",\n+    \"    demographics = wealth,\\n\",\n+    \")\\n\",\n+    \"\\n\",\n+    \"# Run the model\\n\",\n+    \"sim = ss.Sim(pars, copy_inputs=False) # copy_inputs=False lets us reuse the \\\"wealth\\\" object from above\\n\",\n+    \"sim.run()\\n\",\n+    \"\\n\",\n+    \"# Plot the results\\n\",\n+    \"wealth.plot()\\n\",\n+    \"wealth.plot3d()\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"f4391653\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"### Comparison with Mesa\\n\",\n+    \"\\n\",\n+    \"While the implementation in Starsim is similar to Mesa, there are a couple key differences:\\n\",\n+    \"\\n\",\n+    \"- Because Starsim's people object is vectorized, the wealth definition and update is vectorized as well.\\n\",\n+    \"- Both Mesa and Starsim versions of the model are quite simple, but there is a little less boilerplate in the Starsim version.\"\n+   ]\n+  }\n+ ],\n+ \"metadata\": {\n+  \"kernelspec\": {\n+   \"display_name\": \"base\",\n+   \"language\": \"python\",\n+   \"name\": \"python3\"\n+  },\n+  \"language_info\": {\n+   \"codemirror_mode\": {\n+    \"name\": \"ipython\",\n+    \"version\": 3\n+   },\n+   \"file_extension\": \".py\",\n+   \"mimetype\": \"text/x-python\",\n+   \"name\": \"python\",\n+   \"nbconvert_exporter\": \"python\",\n+   \"pygments_lexer\": \"ipython3\",\n+   \"version\": \"3.12.2\"\n+  }\n+ },\n+ \"nbformat\": 4,\n+ \"nbformat_minor\": 5\n+}\ndiff --git a/docs/tutorials/dev_tut_pars.ipynb b/docs/tutorials/dev_tut_pars.ipynb\nnew file mode 100644\nindex 0000000..d3897ac\n--- /dev/null\n+++ b/docs/tutorials/dev_tut_pars.ipynb\n@@ -0,0 +1,167 @@\n+{\n+ \"cells\": [\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"51cebe65\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"# Developer tutorial: Flexible parameters\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"2f2bbf84\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"<div class=\\\"alert alert-info\\\">\\n\",\n+    \"    \\n\",\n+    \"An interactive version of this notebook is available on [Google Colab](https://colab.research.google.com/github/starsimhub/starsim/blob/main/docs/tutorials/dev_tut_pars.ipynb?install=starsim) or [Binder](https://mybinder.org/v2/gh/starsimhub/starsim/HEAD?labpath=docs%2Ftutorials%2Fdev_tut_pars.ipynb).\\n\",\n+    \"    \\n\",\n+    \"</div>\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"f3048bcb\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"## Defining default parameters\\n\",\n+    \"\\n\",\n+    \"When you create a module using Starsim, you have the opportunity to define the default format for parameters. Let's look at an example from the SIR disease model:\\n\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": 14,\n+   \"id\": \"78162546\",\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"import starsim as ss\\n\",\n+    \"\\n\",\n+    \"class SIR(ss.SIR):\\n\",\n+    \"    def __init__(self, pars=None, **kwargs):\\n\",\n+    \"        super().__init__()\\n\",\n+    \"        self.define_pars(\\n\",\n+    \"            beta = ss.beta(0.1),\\n\",\n+    \"            init_prev = ss.bernoulli(p=0.01),\\n\",\n+    \"            dur_inf = ss.lognorm_ex(mean=ss.dur(6)),\\n\",\n+    \"            p_death = ss.bernoulli(p=0.01),\\n\",\n+    \"        )\\n\",\n+    \"        self.update_pars(pars, **kwargs)\\n\",\n+    \"\\n\",\n+    \"        self.define_states(\\n\",\n+    \"            ss.State('susceptible', default=True, label='Susceptible'),\\n\",\n+    \"            ss.State('infected', label='Infectious'),\\n\",\n+    \"            ss.State('recovered', label='Recovered'),\\n\",\n+    \"            ss.FloatArr('ti_infected', label='Time of infection'),\\n\",\n+    \"            ss.FloatArr('ti_recovered', label='Time of recovery'),\\n\",\n+    \"            ss.FloatArr('ti_dead', label='Time of death'),\\n\",\n+    \"            ss.FloatArr('rel_sus', default=1.0, label='Relative susceptibility'),\\n\",\n+    \"            ss.FloatArr('rel_trans', default=1.0, label='Relative transmission'),\\n\",\n+    \"        )\\n\",\n+    \"        return\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"486245ab\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"The point of `self.define_pars()` is to set the ground truth for the format that the parameters should take. When users enter their own parameters for defining an instance of this module, the parameter values they enter will be processed within `self.update_pars()` and will be checked for consistency with the format provided in the original parameters (`define_pars`). For example, the parameter `p_death` in the SIR example above is specified initially as a Bernoulli distribution. It would be perfectly legitimate to create an instance of the SIR model using any of the following formats:\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": 15,\n+   \"id\": \"3b9db922\",\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"sir1 = SIR(p_death=0.02)\\n\",\n+    \"sir2 = SIR(p_death=ss.bernoulli(p=0.2))\\n\",\n+    \"sir3 = SIR(pars=dict(p_death=0.03))\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"d89c53a3\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"However, it would NOT be ok to create an SIR model with e.g. `SIR(p_death=ss.lognorm_ex(4))`, because if a distribution is defined as a Bernoulli in the default_pars, it can't be changed. This is only the case for Bernoulli distributions; other distributions can be changed, e.g. `SIR(dur_inf=ss.normal(4))` would be okay.\\n\",\n+    \"\\n\",\n+    \"## Using callable parameters\\n\",\n+    \" \\n\",\n+    \"One of the most flexible aspects of how Starsim's distributions are defined is that they can take callable functions as parameter values. For example, in reality the duration of infection of a disease might vary by age. We could model this as follows:\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"id\": \"379f6ed7\",\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"import sciris as sc\\n\",\n+    \"import matplotlib.pyplot as plt\\n\",\n+    \"\\n\",\n+    \"# Create and run the simulation\\n\",\n+    \"sir = SIR(dur_inf=ss.normal(loc=10))  # Define an SIR model with a default duration of 10 days\\n\",\n+    \"sir.pars.dur_inf.set(loc = lambda self, sim, uids: sim.people.age[uids] / 10)  # Change the mean duration so it scales with age\\n\",\n+    \"sim = ss.Sim(n_agents=20e3, dur=10, diseases=sir, networks='random')\\n\",\n+    \"sim.run()\\n\",\n+    \"sim.plot()\\n\",\n+    \"\\n\",\n+    \"# Show the age distribution of infections\\n\",\n+    \"ages = sim.people.age[:]\\n\",\n+    \"infected_ages = ages[sim.diseases.sir.infected]\\n\",\n+    \"\\n\",\n+    \"fig = plt.figure()\\n\",\n+    \"\\n\",\n+    \"plt.subplot(2,1,1)\\n\",\n+    \"plt.hist(ages, bins=range(0,100,5))\\n\",\n+    \"plt.title('Simulation age distribution')\\n\",\n+    \"plt.xlabel('Age')\\n\",\n+    \"plt.ylabel('Number of people')\\n\",\n+    \"\\n\",\n+    \"plt.subplot(2,1,2)\\n\",\n+    \"plt.hist(infected_ages, bins=range(0,100,5))\\n\",\n+    \"plt.title('Infection age distribution')\\n\",\n+    \"plt.xlabel('Age')\\n\",\n+    \"plt.ylabel('Number of people')\\n\",\n+    \"\\n\",\n+    \"sc.figlayout()\\n\",\n+    \"plt.show()\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"b4dcf2fc\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"Using similar logic, any other parameter could be set to depend on anything that the sim is aware of, including time or agent properties like age, sex, or health attributes.\\n\"\n+   ]\n+  }\n+ ],\n+ \"metadata\": {\n+  \"kernelspec\": {\n+   \"display_name\": \"base\",\n+   \"language\": \"python\",\n+   \"name\": \"python3\"\n+  },\n+  \"language_info\": {\n+   \"codemirror_mode\": {\n+    \"name\": \"ipython\",\n+    \"version\": 3\n+   },\n+   \"file_extension\": \".py\",\n+   \"mimetype\": \"text/x-python\",\n+   \"name\": \"python\",\n+   \"nbconvert_exporter\": \"python\",\n+   \"pygments_lexer\": \"ipython3\",\n+   \"version\": \"3.12.2\"\n+  }\n+ },\n+ \"nbformat\": 4,\n+ \"nbformat_minor\": 5\n+}\ndiff --git a/docs/tutorials/normalize_notebooks b/docs/tutorials/normalize_notebooks\nnew file mode 100755\nindex 0000000..29492a1\n--- /dev/null\n+++ b/docs/tutorials/normalize_notebooks\n@@ -0,0 +1,30 @@\n+#!/usr/bin/env python\n+\"\"\"\n+Normalize Jupyter notebooks\n+\"\"\"\n+\n+import sciris as sc\n+import nbformat\n+\n+T = sc.timer()\n+\n+filenames = sc.getfilelist('*.ipynb')\n+\n+print('Normalizing notebooks...')\n+for filename in filenames:\n+\n+    # Load file\n+    print(filename)\n+    with open(filename, \"r\") as file:\n+        nb_orig = nbformat.reader.read(file)\n+\n+    # Perform validation\n+    nbformat.validator.validate(nb_orig)\n+    nb_fixed = nbformat.validator.normalize(nb_orig)\n+    nbformat.validator.validate(nb_fixed[1])\n+\n+    # Write output\n+    with open(filename, \"w\") as file:\n+        nbformat.write(nb_fixed[1], file)\n+\n+T.toc()\n\\ No newline at end of file\ndiff --git a/docs/tutorials/run_tutorials b/docs/tutorials/run_tutorials\nnew file mode 100755\nindex 0000000..df269b7\n--- /dev/null\n+++ b/docs/tutorials/run_tutorials\n@@ -0,0 +1,62 @@\n+#!/usr/bin/env python\n+\"\"\"\n+Run all the Jupyter notebook tutorials. Usage:\n+  ./run_tutorials\n+\n+It will execute all notebooks in parallel, print out any errors\n+encountered, and print a summary of results.\n+\n+NB: The execute() function was drafted in part via ChatGPT.\n+\"\"\"\n+\n+import os\n+import sciris as sc\n+import nbformat\n+import nbconvert.preprocessors as nbp\n+\n+folder = sc.path(__file__).resolve().parent # Ensure it's the real path if it's symlinked\n+timeout = 600\n+yay = '✓'\n+boo = '😢'\n+\n+\n+def execute(path):\n+    \"\"\" Executes a single Jupyter notebook and returns success/failure \"\"\"\n+    try:\n+        with open(path) as f:\n+            print(f'Executing {path}...')\n+            nb = nbformat.read(f, as_version=4)\n+            ep = nbp.ExecutePreprocessor(timeout=timeout)\n+            ep.preprocess(nb, {'metadata': {'path': os.path.dirname(path)}})\n+        return f'{yay} {path} executed successfully.'\n+    except nbp.CellExecutionError as e:\n+        return f'{boo} Execution failed for {path}: {str(e)}'\n+    except Exception as e:\n+        return f'{boo} Error processing {path}: {str(e)}'\n+\n+\n+def main():\n+    \"\"\" Executes the notebooks in parallel and prints the results \"\"\"\n+    notebooks = sc.getfilepaths(folder=folder, pattern='*.ipynb')\n+    results = sc.parallelize(execute, notebooks)\n+    string = sc.newlinejoin(results)\n+    \n+    sc.heading('Results')\n+    print(string)\n+    \n+    sc.heading('Summary')\n+    n_yay = string.count(yay)\n+    n_boo = string.count(boo)\n+    summary = f'{n_yay} succeeded, {n_boo} failed'\n+    if n_boo:\n+        for i in range(len(notebooks)):\n+            if boo in results[i]:\n+                summary += f'\\nFailed: {notebooks[i]}'\n+    print(summary)\n+    \n+    return results\n+\n+\n+if __name__ == '__main__':\n+    results = main()\n+\ndiff --git a/docs/tutorials/tut_buildsim.ipynb b/docs/tutorials/tut_buildsim.ipynb\nindex 0a374c4..978e063 100644\n--- a/docs/tutorials/tut_buildsim.ipynb\n+++ b/docs/tutorials/tut_buildsim.ipynb\n@@ -2,6 +2,7 @@\n  \"cells\": [\n   {\n    \"cell_type\": \"markdown\",\n+   \"id\": \"79a4bb76\",\n    \"metadata\": {},\n    \"source\": [\n     \"# T2 - How to build your model\\n\",\n@@ -13,8 +14,24 @@\n   },\n   {\n    \"cell_type\": \"markdown\",\n+   \"id\": \"13049772\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"<div class=\\\"alert alert-info\\\">\\n\",\n+    \"    \\n\",\n+    \"An interactive version of this notebook is available on [Google Colab](https://colab.research.google.com/github/starsimhub/starsim/blob/main/docs/tutorials/tut_buildsim.ipynb?install=starsim) or [Binder](https://mybinder.org/v2/gh/starsimhub/starsim/HEAD?labpath=docs%2Ftutorials%2Ftut_buildsim.ipynb).\\n\",\n+    \"    \\n\",\n+    \"</div>\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"36126a51\",\n    \"metadata\": {\n-    \"collapsed\": false\n+    \"collapsed\": false,\n+    \"jupyter\": {\n+     \"outputs_hidden\": false\n+    }\n    },\n    \"source\": [\n     \"## Simple SIR model\\n\",\n@@ -25,8 +42,12 @@\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n+   \"id\": \"e39a8782\",\n    \"metadata\": {\n-    \"collapsed\": false\n+    \"collapsed\": false,\n+    \"jupyter\": {\n+     \"outputs_hidden\": false\n+    }\n    },\n    \"outputs\": [],\n    \"source\": [\n@@ -49,13 +70,17 @@\n     \"# Make the sim, run and plot\\n\",\n     \"sim = ss.Sim(pars)\\n\",\n     \"sim.run()\\n\",\n-    \"sim.plot();\"\n+    \"sim.plot()\"\n    ]\n   },\n   {\n    \"cell_type\": \"markdown\",\n+   \"id\": \"b35591f8\",\n    \"metadata\": {\n-    \"collapsed\": false\n+    \"collapsed\": false,\n+    \"jupyter\": {\n+     \"outputs_hidden\": false\n+    }\n    },\n    \"source\": [\n     \"Now let's look at the `pars` dictionary in more detail. The one we've created here has 3 things in it: the number of agents (`n_agents`), detail on how the agents interact with each other (`networks`) and detail on what disease we're modeling (`diseases`). When we create and run the model, what happens 'under the hood' is that the simulation creates 5,000 people, and allows them to the interact with one another over the network and transmit the infection. \\n\",\n@@ -67,6 +92,7 @@\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n+   \"id\": \"b3e79bfc\",\n    \"metadata\": {},\n    \"outputs\": [],\n    \"source\": [\n@@ -75,13 +101,17 @@\n     \"sir = ss.SIR(init_prev=0.1, beta=0.1)\\n\",\n     \"sim = ss.Sim(diseases=sir, people=people, networks=network)\\n\",\n     \"sim.run()\\n\",\n-    \"sim.plot();\"\n+    \"sim.plot()\"\n    ]\n   },\n   {\n    \"cell_type\": \"markdown\",\n+   \"id\": \"64e760ac\",\n    \"metadata\": {\n-    \"collapsed\": false\n+    \"collapsed\": false,\n+    \"jupyter\": {\n+     \"outputs_hidden\": false\n+    }\n    },\n    \"source\": [\n     \"Rather than bundling everything under pars, we're now defining components individually for people, networks, and diseases. As for the disease/network details, instead of putting all information in one bucket (`pars['diseases'] = dict(name='sir', init_prev=0.1, beta=0.1)`), we're now using `ss.SIR() `which serves as a prepared 'template' where we fill in the details. This new way provides us more flexibility to adjust details of the disease as we need.\\n\",\n@@ -96,20 +126,28 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": null,\n+   \"execution_count\": 7,\n+   \"id\": \"d17dd68a\",\n    \"metadata\": {\n-    \"collapsed\": false\n+    \"collapsed\": false,\n+    \"jupyter\": {\n+     \"outputs_hidden\": false\n+    }\n    },\n    \"outputs\": [],\n    \"source\": [\n     \"network = ss.RandomNet(pars={'n_contacts': ss.poisson(4)})\\n\",\n-    \"network = ss.RandomNet(pars=dict(n_contacts=dict(type='poisson', scale=4)))\"\n+    \"network = ss.RandomNet(n_contacts=dict(type='poisson', lam=4))\"\n    ]\n   },\n   {\n    \"cell_type\": \"markdown\",\n+   \"id\": \"24a9599d\",\n    \"metadata\": {\n-    \"collapsed\": false\n+    \"collapsed\": false,\n+    \"jupyter\": {\n+     \"outputs_hidden\": false\n+    }\n    },\n    \"source\": [\n     \"If we use this network, our agents will have varying numbers of contacts.\"\n@@ -117,8 +155,12 @@\n   },\n   {\n    \"cell_type\": \"markdown\",\n+   \"id\": \"be4847a8\",\n    \"metadata\": {\n-    \"collapsed\": false\n+    \"collapsed\": false,\n+    \"jupyter\": {\n+     \"outputs_hidden\": false\n+    }\n    },\n    \"source\": [\n     \"## Accessing results \\n\",\n@@ -131,18 +173,27 @@\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n+   \"id\": \"ad4fac82\",\n    \"metadata\": {\n-    \"collapsed\": false\n+    \"collapsed\": false,\n+    \"jupyter\": {\n+     \"outputs_hidden\": false\n+    }\n    },\n    \"outputs\": [],\n    \"source\": [\n-    \"sim = ss.Sim(start=2020, n_years=1, dt=1/12)  # Simulate from 2020 for 1 year with a monthly timestep\"\n+    \"sim = ss.Sim(start='2020-01-01', stop='2021-01-01', unit='month', diseases='sis', networks=network)  # Simulate from 2020 for 1 year with a monthly timestep\\n\",\n+    \"sim.run().plot()\"\n    ]\n   },\n   {\n    \"cell_type\": \"markdown\",\n+   \"id\": \"c42bb5d0\",\n    \"metadata\": {\n-    \"collapsed\": false\n+    \"collapsed\": false,\n+    \"jupyter\": {\n+     \"outputs_hidden\": false\n+    }\n    },\n    \"source\": [\n     \"## Summary \\n\",\n@@ -157,7 +208,7 @@\n  ],\n  \"metadata\": {\n   \"kernelspec\": {\n-   \"display_name\": \"Python 3 (ipykernel)\",\n+   \"display_name\": \"base\",\n    \"language\": \"python\",\n    \"name\": \"python3\"\n   },\n@@ -171,31 +222,9 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.11.7\"\n-  },\n-  \"pycharm\": {\n-   \"stem_cell\": {\n-    \"cell_type\": \"raw\",\n-    \"metadata\": {\n-     \"collapsed\": false\n-    },\n-    \"source\": []\n-   }\n-  },\n-  \"toc\": {\n-   \"base_numbering\": 1,\n-   \"nav_menu\": {},\n-   \"number_sections\": true,\n-   \"sideBar\": true,\n-   \"skip_h1_title\": false,\n-   \"title_cell\": \"Table of Contents\",\n-   \"title_sidebar\": \"Contents\",\n-   \"toc_cell\": false,\n-   \"toc_position\": {},\n-   \"toc_section_display\": true,\n-   \"toc_window_display\": false\n+   \"version\": \"3.12.2\"\n   }\n  },\n  \"nbformat\": 4,\n- \"nbformat_minor\": 4\n+ \"nbformat_minor\": 5\n }\ndiff --git a/docs/tutorials/tut_demographics.ipynb b/docs/tutorials/tut_demographics.ipynb\nindex 93c3981..a7a0385 100644\n--- a/docs/tutorials/tut_demographics.ipynb\n+++ b/docs/tutorials/tut_demographics.ipynb\n@@ -2,16 +2,37 @@\n  \"cells\": [\n   {\n    \"cell_type\": \"markdown\",\n+   \"id\": \"e0c09801\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"# T3 - Demographics \"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"5f220c21\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"<div class=\\\"alert alert-info\\\">\\n\",\n+    \"    \\n\",\n+    \"An interactive version of this notebook is available on [Google Colab](https://colab.research.google.com/github/starsimhub/starsim/blob/main/docs/tutorials/tut_demographics.ipynb?install=starsim) or [Binder](https://mybinder.org/v2/gh/starsimhub/starsim/HEAD?labpath=docs%2Ftutorials%2Ftut_demographics.ipynb).\\n\",\n+    \"    \\n\",\n+    \"</div>\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"4a666d81\",\n    \"metadata\": {},\n    \"source\": [\n-    \"# T3 - Demographics \\n\",\n     \"\\n\",\n     \"There are a few basic ways to add vital dynamics to your model, e.g. \"\n    ]\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": null,\n+   \"execution_count\": 1,\n+   \"id\": \"7dc8b21a\",\n    \"metadata\": {\n     \"collapsed\": false\n    },\n@@ -30,17 +51,19 @@\n   },\n   {\n    \"cell_type\": \"markdown\",\n+   \"id\": \"2f5ad9e8\",\n    \"metadata\": {\n     \"collapsed\": false\n    },\n    \"source\": [\n     \"\\n\",\n-    \"This will apply annual birth and death rates as specified in the `pars` dict. Alternatively, we can make demographic components:\"\n+    \"This will apply annual birth and death rates as specified in the `pars` dict. Alternatively, we can make demographic components, which achieves the same thing:\"\n    ]\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n+   \"id\": \"acfa0a44\",\n    \"metadata\": {\n     \"collapsed\": false\n    },\n@@ -50,16 +73,40 @@\n     \"    ss.Births(birth_rate=20),\\n\",\n     \"    ss.Deaths(death_rate=15)\\n\",\n     \"]\\n\",\n-    \"sim = ss.Sim(diseases='sir', networks='random', demographics=demographics)\"\n+    \"sim = ss.Sim(demographics=demographics)\"\n    ]\n   },\n   {\n    \"cell_type\": \"markdown\",\n-   \"metadata\": {\n-    \"collapsed\": false\n-   },\n+   \"id\": \"8b9d6b6d\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"You can even simply set `demographics=True` to use default rates:\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"id\": \"3b914207\",\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"ss.Sim(demographics=True).run().plot();\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"cbeb0b9a\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"By default, agents age if and only if at least one demographics module is included. You can override this behavior by setting `use_aging`, e.g. `ss.Sim(use_aging=False)`\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"2027fecb\",\n+   \"metadata\": {},\n    \"source\": [\n-    \"Both achieve the same thing. \\n\",\n     \"\\n\",\n     \"## Scaling results to whole populations\\n\",\n     \"Even though we've been simulating populations of a few thousand agents, we can also use the `total_pop` parameter to scale our results so that they reflect a much larger population. You can think of this as a kind of statistical sampling approximation. If we want to model the population of Nigeria, for example, it would be much too computationally intensive to simulate 200 million agents. However, we could simulate 50,000 agents and then say that each agent represents 4,000 people. Again, we can do this by passing `total_pop=200e6` to the sim or in the `pars` dictionary. Here's an example:\"\n@@ -67,7 +114,8 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": null,\n+   \"execution_count\": 3,\n+   \"id\": \"753528fa\",\n    \"metadata\": {\n     \"collapsed\": false\n    },\n@@ -82,6 +130,7 @@\n   },\n   {\n    \"cell_type\": \"markdown\",\n+   \"id\": \"e5b0bd8a\",\n    \"metadata\": {\n     \"collapsed\": false\n    },\n@@ -93,6 +142,7 @@\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n+   \"id\": \"4bf3309e\",\n    \"metadata\": {\n     \"collapsed\": false\n    },\n@@ -100,13 +150,14 @@\n    \"source\": [\n     \"import starsim as ss\\n\",\n     \"import pandas as pd\\n\",\n+    \"import matplotlib.pyplot as plt\\n\",\n     \"\\n\",\n     \"# Read in age-specific fertility rates\\n\",\n     \"fertility_rates = pd.read_csv('test_data/nigeria_asfr.csv')\\n\",\n     \"pregnancy = ss.Pregnancy(pars={'fertility_rate': fertility_rates})\\n\",\n     \"\\n\",\n     \"death_rates = pd.read_csv('test_data/nigeria_deaths.csv')\\n\",\n-    \"death = ss.Deaths(pars={'death_rate': death_rates, 'units': 1})\\n\",\n+    \"death = ss.Deaths(pars={'death_rate': death_rates, 'rate_units': 1})\\n\",\n     \"\\n\",\n     \"demographics = [pregnancy, death]\\n\",\n     \"\\n\",\n@@ -125,31 +176,31 @@\n     \"data = nigeria_popsize[(nigeria_popsize.year >= 1995) & (nigeria_popsize.year <= 2030)]\\n\",\n     \"\\n\",\n     \"# Plot the overall population size - simulated vs data\\n\",\n-    \"import matplotlib.pyplot as plt\\n\",\n     \"fig, ax = plt.subplots(1, 1)\\n\",\n+    \"res = sim.results\\n\",\n     \"ax.scatter(data.year, data.n_alive, alpha=0.5, label='Data')\\n\",\n-    \"ax.plot(sim.yearvec, sim.results.n_alive, color='k', label='Model')\\n\",\n+    \"ax.plot(res.timevec, res.n_alive, color='k', label='Model')\\n\",\n     \"ax.legend()\\n\",\n     \"ax.set_title('Population')\\n\",\n-    \"plt.show();\"\n+    \"plt.show()\"\n    ]\n   },\n   {\n    \"cell_type\": \"markdown\",\n+   \"id\": \"42921340\",\n    \"metadata\": {\n     \"collapsed\": false\n    },\n    \"source\": [\n     \"If you want to use realistic demographics for your model, you can adapt the data files and code snippet above to read in the relevant demographic data files for your country/setting.\\n\",\n     \"\\n\",\n-    \"Note:\\n\",\n-    \"- In the code block above, we set the units of the mortality data to 1, as opposed to 1/1000. If your data come in the form of deaths per 1000 people, set units to 1/1000. \"\n+    \"*Note*: In the code block above, we set the units of the mortality data to 1, as opposed to 1/1000. If your data come in the form of deaths per 1000 people, set units to 1/1000. Note also that as per standard definitions, `fertility_rate` is defined per *woman*, whereas `birth_rate` is defined per *person*.\"\n    ]\n   }\n  ],\n  \"metadata\": {\n   \"kernelspec\": {\n-   \"display_name\": \"Python 3 (ipykernel)\",\n+   \"display_name\": \"base\",\n    \"language\": \"python\",\n    \"name\": \"python3\"\n   },\n@@ -163,31 +214,9 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.11.7\"\n-  },\n-  \"pycharm\": {\n-   \"stem_cell\": {\n-    \"cell_type\": \"raw\",\n-    \"metadata\": {\n-     \"collapsed\": false\n-    },\n-    \"source\": []\n-   }\n-  },\n-  \"toc\": {\n-   \"base_numbering\": 1,\n-   \"nav_menu\": {},\n-   \"number_sections\": true,\n-   \"sideBar\": true,\n-   \"skip_h1_title\": false,\n-   \"title_cell\": \"Table of Contents\",\n-   \"title_sidebar\": \"Contents\",\n-   \"toc_cell\": false,\n-   \"toc_position\": {},\n-   \"toc_section_display\": true,\n-   \"toc_window_display\": false\n+   \"version\": \"3.12.2\"\n   }\n  },\n  \"nbformat\": 4,\n- \"nbformat_minor\": 4\n+ \"nbformat_minor\": 5\n }\ndiff --git a/docs/tutorials/tut_diseases.ipynb b/docs/tutorials/tut_diseases.ipynb\nindex 2ba4a8e..32e24e8 100644\n--- a/docs/tutorials/tut_diseases.ipynb\n+++ b/docs/tutorials/tut_diseases.ipynb\n@@ -2,9 +2,29 @@\n  \"cells\": [\n   {\n    \"cell_type\": \"markdown\",\n+   \"id\": \"49cd23ac\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"# T4 - Diseases\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"8d394d0f\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"<div class=\\\"alert alert-info\\\">\\n\",\n+    \"    \\n\",\n+    \"An interactive version of this notebook is available on [Google Colab](https://colab.research.google.com/github/starsimhub/starsim/blob/main/docs/tutorials/tut_diseases.ipynb?install=starsim) or [Binder](https://mybinder.org/v2/gh/starsimhub/starsim/HEAD?labpath=docs%2Ftutorials%2Ftut_diseases.ipynb).\\n\",\n+    \"    \\n\",\n+    \"</div>\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"f2202221\",\n    \"metadata\": {},\n    \"source\": [\n-    \"# T5 - Diseases\\n\",\n     \"\\n\",\n     \"Diseases are the cornerstone of almost any Starsim analysis. This is where you add details about what disease you are modeling, including transmissibility, natural history, and mortality outcomes.      \\n\",\n     \"\\n\",\n@@ -15,6 +35,7 @@\n   },\n   {\n    \"cell_type\": \"markdown\",\n+   \"id\": \"dc2a1cb6\",\n    \"metadata\": {},\n    \"source\": [\n     \"## Modifying a disease\\n\",\n@@ -25,6 +46,7 @@\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n+   \"id\": \"ba3ff270\",\n    \"metadata\": {},\n    \"outputs\": [],\n    \"source\": [\n@@ -36,6 +58,7 @@\n   },\n   {\n    \"cell_type\": \"markdown\",\n+   \"id\": \"cd44e476\",\n    \"metadata\": {\n     \"collapsed\": false,\n     \"jupyter\": {\n@@ -52,6 +75,7 @@\n   },\n   {\n    \"cell_type\": \"markdown\",\n+   \"id\": \"08391ccb\",\n    \"metadata\": {\n     \"collapsed\": false,\n     \"jupyter\": {\n@@ -60,12 +84,13 @@\n    },\n    \"source\": [\n     \"## Adding multiple diseases\\n\",\n-    \"You can add multiple diseases to the same simulation, like so. Here we are making use of a _connector_. A connector is a special thing in Starsim that tells you how two things relate to one another - in this case, how HIV modifies a person's transmissibility and susceptibility to gonorrhea and vice versa \"\n+    \"You can add multiple diseases to the same simulation, like so. Here we are making use of a \\\"connector\\\". A connector is a module in Starsim that tells you how two things relate to one another - in this case, how HIV modifies a person's transmissibility and susceptibility to gonorrhea and vice versa. Unlike dieases, networks, interventions, etc., connectors don't have any pre-specified location in the sim. Instead, they can be placed wherever they make the most sense (for example, a connector that mediated how two networks behaved might be placed at the beginning or end of the list of networks; for diseases, it might be placed at the beginning or end of the list of diseases).\"\n    ]\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n+   \"id\": \"269ba6a1\",\n    \"metadata\": {\n     \"collapsed\": false,\n     \"jupyter\": {\n@@ -76,14 +101,12 @@\n    \"source\": [\n     \"import sciris as sc\\n\",\n     \"import starsim as ss\\n\",\n-    \"import pylab as pl\\n\",\n-    \"sc.options(jupyter=True)\\n\",\n     \"\\n\",\n-    \"class simple_hiv_ng(ss.Connector):\\n\",\n+    \"class simple_hiv_ng(ss.Module):\\n\",\n     \"    \\\"\\\"\\\" Simple connector whereby rel_sus to NG doubles if CD4 count is <200\\\"\\\"\\\"\\n\",\n-    \"    def __init__(self, pars=None, **kwargs):\\n\",\n-    \"        super().__init__(label='HIV-Gonorrhea', requires=[ss.HIV, ss.Gonorrhea])\\n\",\n-    \"        self.default_pars(\\n\",\n+    \"    def __init__(self, pars=None, label='HIV-Gonorrhea', **kwargs):\\n\",\n+    \"        super().__init__()\\n\",\n+    \"        self.define_pars(\\n\",\n     \"            rel_trans_hiv  = 2,\\n\",\n     \"            rel_trans_aids = 5,\\n\",\n     \"            rel_sus_hiv    = 2,\\n\",\n@@ -92,7 +115,7 @@\n     \"        self.update_pars(pars, **kwargs)\\n\",\n     \"        return\\n\",\n     \"\\n\",\n-    \"    def update(self):\\n\",\n+    \"    def step(self):\\n\",\n     \"        \\\"\\\"\\\" Specify how HIV increases NG rel_sus and rel_trans \\\"\\\"\\\"\\n\",\n     \"        people = self.sim.people\\n\",\n     \"        people.gonorrhea.rel_sus[people.hiv.cd4 < 500] = self.pars.rel_sus_hiv\\n\",\n@@ -115,16 +138,16 @@\n     \"\\n\",\n     \"# Make the sim, including a connector betweeh HIV and gonorrhea:\\n\",\n     \"n_agents = 5_000\\n\",\n-    \"sim = ss.Sim(n_agents=n_agents, networks='mf', diseases=[hiv, ng], connectors=simple_hiv_ng())\\n\",\n+    \"sim = ss.Sim(n_agents=n_agents, networks='mf', diseases=[simple_hiv_ng(), hiv, ng])\\n\",\n     \"sim.run()\\n\",\n     \"sim.plot('hiv')\\n\",\n-    \"sim.plot('gonorrhea');\"\n+    \"sim.plot('gonorrhea')\"\n    ]\n   }\n  ],\n  \"metadata\": {\n   \"kernelspec\": {\n-   \"display_name\": \"Python 3 (ipykernel)\",\n+   \"display_name\": \"base\",\n    \"language\": \"python\",\n    \"name\": \"python3\"\n   },\n@@ -138,31 +161,9 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.11.7\"\n-  },\n-  \"pycharm\": {\n-   \"stem_cell\": {\n-    \"cell_type\": \"raw\",\n-    \"metadata\": {\n-     \"collapsed\": false\n-    },\n-    \"source\": []\n-   }\n-  },\n-  \"toc\": {\n-   \"base_numbering\": 1,\n-   \"nav_menu\": {},\n-   \"number_sections\": true,\n-   \"sideBar\": true,\n-   \"skip_h1_title\": false,\n-   \"title_cell\": \"Table of Contents\",\n-   \"title_sidebar\": \"Contents\",\n-   \"toc_cell\": false,\n-   \"toc_position\": {},\n-   \"toc_section_display\": true,\n-   \"toc_window_display\": false\n+   \"version\": \"3.12.2\"\n   }\n  },\n  \"nbformat\": 4,\n- \"nbformat_minor\": 4\n+ \"nbformat_minor\": 5\n }\ndiff --git a/docs/tutorials/tut_interventions.ipynb b/docs/tutorials/tut_interventions.ipynb\nindex 053294c..53bf9ec 100644\n--- a/docs/tutorials/tut_interventions.ipynb\n+++ b/docs/tutorials/tut_interventions.ipynb\n@@ -2,6 +2,7 @@\n  \"cells\": [\n   {\n    \"cell_type\": \"markdown\",\n+   \"id\": \"0911386d\",\n    \"metadata\": {},\n    \"source\": [\n     \"# T6 - Interventions\\n\",\n@@ -11,6 +12,19 @@\n   },\n   {\n    \"cell_type\": \"markdown\",\n+   \"id\": \"c4a4a2ee\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"<div class=\\\"alert alert-info\\\">\\n\",\n+    \"    \\n\",\n+    \"An interactive version of this notebook is available on [Google Colab](https://colab.research.google.com/github/starsimhub/starsim/blob/main/docs/tutorials/tut_interventions.ipynb?install=starsim) or [Binder](https://mybinder.org/v2/gh/starsimhub/starsim/HEAD?labpath=docs%2Ftutorials%2Ftut_interventions.ipynb).\\n\",\n+    \"    \\n\",\n+    \"</div>\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"4574ce23\",\n    \"metadata\": {},\n    \"source\": [\n     \"## Products and interventions\\n\",\n@@ -35,7 +49,8 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": null,\n+   \"execution_count\": 2,\n+   \"id\": \"d609380d\",\n    \"metadata\": {},\n    \"outputs\": [],\n    \"source\": [\n@@ -59,6 +74,7 @@\n   },\n   {\n    \"cell_type\": \"markdown\",\n+   \"id\": \"39bb9ca3\",\n    \"metadata\": {\n     \"collapsed\": false\n    },\n@@ -69,6 +85,7 @@\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n+   \"id\": \"33d18540\",\n    \"metadata\": {\n     \"collapsed\": false\n    },\n@@ -93,6 +110,7 @@\n   },\n   {\n    \"cell_type\": \"markdown\",\n+   \"id\": \"abe7afff\",\n    \"metadata\": {\n     \"collapsed\": false\n    },\n@@ -103,6 +121,7 @@\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n+   \"id\": \"4a563cdc\",\n    \"metadata\": {\n     \"collapsed\": false\n    },\n@@ -114,16 +133,17 @@\n     \"res_intv = sim_intv.results\\n\",\n     \"\\n\",\n     \"plt.figure()\\n\",\n-    \"plt.plot(res_base.yearvec, res_base.sir.prevalence, label='Baseline')\\n\",\n-    \"plt.plot(res_intv.yearvec, res_intv.sir.prevalence, label='Vax')\\n\",\n+    \"plt.plot(res_base.timevec, res_base.sir.prevalence, label='Baseline')\\n\",\n+    \"plt.plot(res_intv.timevec, res_intv.sir.prevalence, label='Vax')\\n\",\n     \"plt.axvline(x=2015, color='k', ls='--')\\n\",\n     \"plt.title('Prevalence')\\n\",\n     \"plt.legend()\\n\",\n-    \"plt.show();\"\n+    \"plt.show()\"\n    ]\n   },\n   {\n    \"cell_type\": \"markdown\",\n+   \"id\": \"7353fc91\",\n    \"metadata\": {\n     \"collapsed\": false\n    },\n@@ -134,7 +154,7 @@\n  ],\n  \"metadata\": {\n   \"kernelspec\": {\n-   \"display_name\": \"Python 3 (ipykernel)\",\n+   \"display_name\": \"base\",\n    \"language\": \"python\",\n    \"name\": \"python3\"\n   },\n@@ -148,31 +168,9 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.11.7\"\n-  },\n-  \"pycharm\": {\n-   \"stem_cell\": {\n-    \"cell_type\": \"raw\",\n-    \"metadata\": {\n-     \"collapsed\": false\n-    },\n-    \"source\": []\n-   }\n-  },\n-  \"toc\": {\n-   \"base_numbering\": 1,\n-   \"nav_menu\": {},\n-   \"number_sections\": true,\n-   \"sideBar\": true,\n-   \"skip_h1_title\": false,\n-   \"title_cell\": \"Table of Contents\",\n-   \"title_sidebar\": \"Contents\",\n-   \"toc_cell\": false,\n-   \"toc_position\": {},\n-   \"toc_section_display\": true,\n-   \"toc_window_display\": false\n+   \"version\": \"3.12.2\"\n   }\n  },\n  \"nbformat\": 4,\n- \"nbformat_minor\": 4\n+ \"nbformat_minor\": 5\n }\ndiff --git a/docs/tutorials/tut_intro.ipynb b/docs/tutorials/tut_intro.ipynb\nindex f26e4b4..d97d51d 100644\n--- a/docs/tutorials/tut_intro.ipynb\n+++ b/docs/tutorials/tut_intro.ipynb\n@@ -2,6 +2,7 @@\n  \"cells\": [\n   {\n    \"cell_type\": \"markdown\",\n+   \"id\": \"dd65a1f9\",\n    \"metadata\": {},\n    \"source\": [\n     \"# T1 - Getting started\\n\",\n@@ -23,6 +24,19 @@\n   },\n   {\n    \"cell_type\": \"markdown\",\n+   \"id\": \"c00c109e\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"<div class=\\\"alert alert-info\\\">\\n\",\n+    \"    \\n\",\n+    \"An interactive version of this notebook is available on [Google Colab](https://colab.research.google.com/github/starsimhub/starsim/blob/main/docs/tutorials/tut_intro.ipynb?install=starsim) or [Binder](https://mybinder.org/v2/gh/starsimhub/starsim/HEAD?labpath=docs%2Ftutorials%2Ftut_intro.ipynb).\\n\",\n+    \"    \\n\",\n+    \"</div>\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"2ae50b40\",\n    \"metadata\": {},\n    \"source\": [\n     \"## Hello world\\n\",\n@@ -33,6 +47,7 @@\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n+   \"id\": \"c6b0dfc8\",\n    \"metadata\": {},\n    \"outputs\": [],\n    \"source\": [\n@@ -40,26 +55,28 @@\n     \"\\n\",\n     \"# Define the parameters\\n\",\n     \"pars = dict(\\n\",\n-    \"    n_agents = 5_000,     # Number of agents to simulate\\n\",\n+    \"    n_agents = 10_000,    # Number of agents to simulate\\n\",\n     \"    networks = dict(      # *Networks* add detail on how the agents interact with each other \\n\",\n     \"        type = 'random',  # Here, we use a 'random' network\\n\",\n-    \"        n_contacts = 10    # Each person has an average of 10 contacts with other people\\n\",\n+    \"        n_contacts = 10   # Each person has an average of 10 contacts with other people\\n\",\n     \"    ),\\n\",\n     \"    diseases = dict(      # *Diseases* add detail on what diseases to model \\n\",\n     \"        type = 'sir',     # Here, we're creating an SIR disease \\n\",\n-    \"        init_prev = 0.1,  # Proportion of the population initially infected \\n\",\n-    \"        beta = 0.5,       # Probability of transmission between contacts\\n\",\n+    \"        init_prev = 0.01, # Proportion of the population initially infected \\n\",\n+    \"        beta = 0.05,      # Probability of transmission between contacts\\n\",\n     \"    )\\n\",\n     \")\\n\",\n     \"\\n\",\n     \"# Make the sim, run and plot\\n\",\n     \"sim = ss.Sim(pars)\\n\",\n     \"sim.run()\\n\",\n-    \"sim.plot();\"\n+    \"sim.plot()\\n\",\n+    \"sim.diseases.sir.plot()\"\n    ]\n   },\n   {\n    \"cell_type\": \"markdown\",\n+   \"id\": \"02be91b3\",\n    \"metadata\": {},\n    \"source\": [\n     \"As the tutorials progress we'll show how to extend this different diseases with different transmission pathways, and how to customize the model in lots of different ways.\"\n@@ -68,7 +85,7 @@\n  ],\n  \"metadata\": {\n   \"kernelspec\": {\n-   \"display_name\": \"Python 3 (ipykernel)\",\n+   \"display_name\": \"base\",\n    \"language\": \"python\",\n    \"name\": \"python3\"\n   },\n@@ -82,7 +99,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.11.7\"\n+   \"version\": \"3.12.2\"\n   }\n  },\n  \"nbformat\": 4,\ndiff --git a/docs/tutorials/tut_networks.ipynb b/docs/tutorials/tut_networks.ipynb\ndeleted file mode 100644\nindex 939134c..0000000\n--- a/docs/tutorials/tut_networks.ipynb\n+++ /dev/null\n@@ -1,211 +0,0 @@\n-{\n- \"cells\": [\n-  {\n-   \"cell_type\": \"markdown\",\n-   \"metadata\": {},\n-   \"source\": [\n-    \"# T4 - Networks\\n\",\n-    \"\\n\",\n-    \"Many infectious diseases transmit when people come into contact with one another. In the basic SIR example that we covered in the first two tutorials, we used a 'random' contact network, which creates random pairings of people. Generally speaking, the structure of network that you use depends on what disease you're modeling. In addition to the 'random' network, Starim contains some basic sexual networks for modeling sexually transmitted infections (STIs) and a 'maternal' network for modeling mother-to-child transmission.  \\n\",\n-    \"\\n\",\n-    \"In this tutorial, we'll demonstrate a couple of the built-in networks, and give an overview of how you might create your own for your own disease modeling work.\"\n-   ]\n-  },\n-  {\n-   \"cell_type\": \"markdown\",\n-   \"metadata\": {},\n-   \"source\": [\n-    \"## Overview of Starsim's network structure\\n\",\n-    \"\\n\",\n-    \"Starsim's networks are stored in the `networks.py` file. At the top of this file you'll see the `Network` class, which provides the template for all the other networks. At a high level, all you need to know is that network stores various *parameters* that determine how pairs of people form and dissolve, and a collection of all the *contacts* that exist at a given point in time. Let's look at a simple example of the `random` network:\"\n-   ]\n-  },\n-  {\n-   \"cell_type\": \"code\",\n-   \"execution_count\": null,\n-   \"metadata\": {\n-    \"tags\": []\n-   },\n-   \"outputs\": [],\n-   \"source\": [\n-    \"import starsim as ss\\n\",\n-    \"\\n\",\n-    \"# Make random network\\n\",\n-    \"random = ss.RandomNet()\"\n-   ]\n-  },\n-  {\n-   \"cell_type\": \"markdown\",\n-   \"metadata\": {\n-    \"collapsed\": false\n-   },\n-   \"source\": [\n-    \"The network we just made stores two very important things: the list of contacts (found in `random.contacts`) and the parameters (`random.pars`).  \\n\",\n-    \"\\n\",\n-    \"If we just make a network on its own like this, it's not very interesting. Like all components of Starsim, it needs to be initialized within a sim before the database of contacts gets populated:\"\n-   ]\n-  },\n-  {\n-   \"cell_type\": \"code\",\n-   \"execution_count\": null,\n-   \"metadata\": {},\n-   \"outputs\": [],\n-   \"source\": [\n-    \"network = ss.RandomNet()\\n\",\n-    \"sir = ss.SIR()\\n\",\n-    \"sim = ss.Sim(n_agents=2_000, diseases=sir, networks=network)\\n\",\n-    \"sim.initialize()\"\n-   ]\n-  },\n-  {\n-   \"cell_type\": \"markdown\",\n-   \"metadata\": {\n-    \"collapsed\": false\n-   },\n-   \"source\": [\n-    \"Now `sim.networks.random.contacts` has all the information about which agents (referenced by their UID) are paired with which other agents.\\n\",\n-    \"\\n\",\n-    \"## Sexual networks\\n\",\n-    \"Starsim contains a few basic sexual networks, including an `mf` network for modeling heterosexual partnerships and an `msm` network for men having sex with men. Modeling STIs is a straightforward extension of the SIR example we looked at previously. Here's an example modeling syphilis:\"\n-   ]\n-  },\n-  {\n-   \"cell_type\": \"code\",\n-   \"execution_count\": null,\n-   \"metadata\": {\n-    \"collapsed\": false\n-   },\n-   \"outputs\": [],\n-   \"source\": [\n-    \"# Create the disease\\n\",\n-    \"syph = ss.Syphilis(\\n\",\n-    \"    beta = {'mf': [0.25, 0.15]},    # See notes below \\n\",\n-    \")\\n\",\n-    \"\\n\",\n-    \"# Create a heterosexual network\\n\",\n-    \"mf = ss.MFNet(\\n\",\n-    \"    duration=1/24,  # Using very short relationships so that we get more transmission \\n\",\n-    \"    acts=80,        # Distribution of the number of coital acts/year\\n\",\n-    \")\\n\",\n-    \"\\n\",\n-    \"pars = dict(dt=1/12, start=2000, n_years=20)\\n\",\n-    \"sim = ss.Sim(pars=pars, diseases=syph, networks=mf)\"\n-   ]\n-  },\n-  {\n-   \"cell_type\": \"markdown\",\n-   \"metadata\": {\n-    \"collapsed\": false\n-   },\n-   \"source\": [\n-    \"The main difference here is that we've added the line `syph.pars['beta'] = {'mf': [0.25, 0.15]}`. Because STIs are generally more transmissible from males to females than vice versa, we can specify `beta` as a list, and we can also allow it to vary between networks. For instance, if we also had an MSM network here, we could set \\n\",\n-    \"```\\n\",\n-    \"syph.pars.update(beta = {'mf': [0.25, 0.15], 'msm': [0.4, 0.4]})\\n\",\n-    \"```\\n\",\n-    \"The sexual network itself is structurally similar to the `random` network that we looked at previously, and can be customized by changing the `pars` dictionary that's used to construct it.\\n\",\n-    \" \\n\",\n-    \"## Maternal networks\\n\",\n-    \"Maternal networks are useful for capturing mother-to-child transmission. If you want to use them, you also need to model pregnancy. Here's an example showing how you would do this for syphilis:\"\n-   ]\n-  },\n-  {\n-   \"cell_type\": \"code\",\n-   \"execution_count\": null,\n-   \"metadata\": {\n-    \"collapsed\": false\n-   },\n-   \"outputs\": [],\n-   \"source\": [\n-    \"syph = ss.Syphilis(\\n\",\n-    \"    beta = {'mf': [0.25, 0.15], 'maternal': [0.99, 0]}\\n\",\n-    \")\\n\",\n-    \"\\n\",\n-    \"# Make demographic modules\\n\",\n-    \"pregnancy = ss.Pregnancy(fertility_rate=20)\\n\",\n-    \"death = ss.Deaths(death_rate=15)\\n\",\n-    \"\\n\",\n-    \"# Make maternal network\\n\",\n-    \"maternal = ss.MaternalNet()\\n\",\n-    \"\\n\",\n-    \"# Make sim\\n\",\n-    \"sim = ss.Sim(pars=pars, diseases=syph, networks=[mf, maternal], demographics=[pregnancy, death])\"\n-   ]\n-  },\n-  {\n-   \"cell_type\": \"markdown\",\n-   \"metadata\": {\n-    \"collapsed\": false\n-   },\n-   \"source\": [\n-    \"## Making your own network\\n\",\n-    \"If you want to make your own network, a good place to start is by inheriting from one of the templates in networks.py. For example, if you wanted to make an `mf` network that has more age structure, you could do something like this:\"\n-   ]\n-  },\n-  {\n-   \"cell_type\": \"code\",\n-   \"execution_count\": null,\n-   \"metadata\": {\n-    \"collapsed\": false\n-   },\n-   \"outputs\": [],\n-   \"source\": [\n-    \"class age_mf(ss.MFNet):\\n\",\n-    \"    def add_pairs(self, people, ti=None):\\n\",\n-    \"        # Custom code to select pairs based on age\\n\",\n-    \"        return \"\n-   ]\n-  },\n-  {\n-   \"cell_type\": \"markdown\",\n-   \"metadata\": {\n-    \"collapsed\": false\n-   },\n-   \"source\": [\n-    \"This network would operate exactly like the existing `mf` network, but you could control how new pairs were added.\\n\"\n-   ]\n-  }\n- ],\n- \"metadata\": {\n-  \"kernelspec\": {\n-   \"display_name\": \"Python 3 (ipykernel)\",\n-   \"language\": \"python\",\n-   \"name\": \"python3\"\n-  },\n-  \"language_info\": {\n-   \"codemirror_mode\": {\n-    \"name\": \"ipython\",\n-    \"version\": 3\n-   },\n-   \"file_extension\": \".py\",\n-   \"mimetype\": \"text/x-python\",\n-   \"name\": \"python\",\n-   \"nbconvert_exporter\": \"python\",\n-   \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.11.7\"\n-  },\n-  \"pycharm\": {\n-   \"stem_cell\": {\n-    \"cell_type\": \"raw\",\n-    \"metadata\": {\n-     \"collapsed\": false\n-    },\n-    \"source\": []\n-   }\n-  },\n-  \"toc\": {\n-   \"base_numbering\": 1,\n-   \"nav_menu\": {},\n-   \"number_sections\": true,\n-   \"sideBar\": true,\n-   \"skip_h1_title\": false,\n-   \"title_cell\": \"Table of Contents\",\n-   \"title_sidebar\": \"Contents\",\n-   \"toc_cell\": false,\n-   \"toc_position\": {},\n-   \"toc_section_display\": true,\n-   \"toc_window_display\": false\n-  }\n- },\n- \"nbformat\": 4,\n- \"nbformat_minor\": 4\n-}\ndiff --git a/docs/tutorials/tut_transmission.ipynb b/docs/tutorials/tut_transmission.ipynb\nnew file mode 100644\nindex 0000000..5634948\n--- /dev/null\n+++ b/docs/tutorials/tut_transmission.ipynb\n@@ -0,0 +1,507 @@\n+{\n+ \"cells\": [\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"a8590a81\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"# T5 - Transmission\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"1ada2412\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"<div class=\\\"alert alert-info\\\">\\n\",\n+    \"    \\n\",\n+    \"An interactive version of this notebook is available on [Google Colab](https://colab.research.google.com/github/starsimhub/starsim/blob/main/docs/tutorials/tut_transmission.ipynb?install=starsim) or [Binder](https://mybinder.org/v2/gh/starsimhub/starsim/HEAD?labpath=docs%2Ftutorials%2Ftut_transmission.ipynb).\\n\",\n+    \"    \\n\",\n+    \"</div>\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"884f0f84\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"\\n\",\n+    \"Many infectious diseases transmit when people come into contact with one another. In the basic SIR example that we covered in the first two tutorials, we used a 'random' contact network, which creates random pairings of people. Generally speaking, the structure of network that you use depends on what disease you're modeling.\\n\",\n+    \"\\n\",\n+    \"Starsim contains two different approaches to disease transmission.\\n\",\n+    \"\\n\",\n+    \"**Contact network:** Disease transmits on individual person-to-person relationships. These are networks in the sense that each agent (person) can be viewed as a node and each contact is an edge. Networks are undirected in the sense that an edge will allow transmission in both directions, however you can make transmission stronger one way (p1-->p2) than the other (p2-->p1). The framework includes several pre-built contact network algorithms, each of which manages a list of edges that can change on each simulation step. In addition to the 'random' network, the framework include algorithms representing basic sexual networks for modeling sexually transmitted infections (STIs) and a 'maternal' network for modeling mother-to-child transmission.\\n\",\n+    \"\\n\",\n+    \"**Mixing pools:** Simulate well-mixed transmission from one group of agents to another. Each mixing pool simulates directed transmission from a group of source agents to a group of destination agents. Instead of simulating individual edges like in a contact network, mixing pools first compute the total \\\"contagion\\\" that is shed by the source group. This total contagion value is normalized by the number of agents in the source group to arrive at a value that represents a typical infectious source agent. Then, each destination agent is exposed to this typical (average) infectious agent, likely resulting in new infections in the destination group. Multiple mixing pools can be run simultaneously to simulate heterogeneous transmission between various source and destination groups. Mixing pools could be used with age contact matrices like those developed by Prem et al.\\n\",\n+    \"\\n\",\n+    \"Note that contact networks and mixing pools can be used together in a single simulation.\\n\",\n+    \"\\n\",\n+    \"In this tutorial, we'll demonstrate a couple of the built-in contact networks, and give an overview of how you might create your own for your own disease modeling work. We'll also demonstrate how to use mixing pools.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"123831c1\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"## Overview of Starsim's contact network structure\\n\",\n+    \"\\n\",\n+    \"Starsim's networks are stored in the `networks.py` file. At the top of this file you'll see the `Network` class, which provides the template for all the other networks. At a high level, all you need to know is that network stores various *parameters* that determine how pairs of people form and dissolve, and a collection of all the *edges* that exist at a given point in time. Let's look at a simple example of the `random` network:\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": 13,\n+   \"id\": \"04b07551\",\n+   \"metadata\": {\n+    \"tags\": []\n+   },\n+   \"outputs\": [],\n+   \"source\": [\n+    \"import starsim as ss\\n\",\n+    \"import numpy as np\\n\",\n+    \"import matplotlib.pyplot as plt\\n\",\n+    \"\\n\",\n+    \"# Make random network\\n\",\n+    \"random = ss.RandomNet()\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"5e16e5ea\",\n+   \"metadata\": {\n+    \"collapsed\": false\n+   },\n+   \"source\": [\n+    \"The network we just made stores two very important things: the list of contacts (found in `random.edges`) and the parameters (`random.pars`).  \\n\",\n+    \"\\n\",\n+    \"If we just make a network on its own like this, it's not very interesting. Like all components of Starsim, it needs to be initialized within a `sim` before the database of contacts gets populated:\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"id\": \"f2b1686b\",\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"net = ss.RandomNet()\\n\",\n+    \"sir = ss.SIR()\\n\",\n+    \"sim = ss.Sim(n_agents=100, diseases=sir, networks=net) # Decreasing n_agents so we can plot the network below\\n\",\n+    \"sim.init()\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"34922029\",\n+   \"metadata\": {\n+    \"collapsed\": false\n+   },\n+   \"source\": [\n+    \"We can easily take a look at the list of edges between agents. All networks are stored in `sim.networks`, and individual networks can be found at their class name after conversion to lower case. So for this example, `sim.networks.randomnet.edges` has all the information about which agents (referenced by their UID) are paired with which other agents as well as a per-edge transmission multiplier called `beta` and a per-edge duration, `dur`.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"id\": \"a835439d\",\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"sim.networks.randomnet\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"0affb7bc\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"Networks provide some basic functionality, for example to identify contacts. Additionally, the edge list can be quickly converted to a Pandas data frame for further analysis and manipulation.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"id\": \"09da79de\",\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"net = sim.networks.randomnet\\n\",\n+    \"\\n\",\n+    \"# Use the \\\"find_contacts\\\" function to find all contacts of agent with uid 0\\n\",\n+    \"contacts_of_agent_0 = net.find_contacts([0])\\n\",\n+    \"print('The following agents were identified as contacts of agent 0:', contacts_of_agent_0)\\n\",\n+    \"\\n\",\n+    \"# Convert to a pandas DataFrame and manually find all edges involving agent with uid 0\\n\",\n+    \"df = net.to_df()\\n\",\n+    \"uid0_edges = df.loc[(df['p1']==0) | (df['p2']==0)]\\n\",\n+    \"print('\\\\nEdges involving UID 0 extracted from the edge list data frame:')\\n\",\n+    \"display(uid0_edges)\\n\",\n+    \"\\n\",\n+    \"import networkx as nx\\n\",\n+    \"G = net.to_graph()\\n\",\n+    \"nx.draw(G, with_labels=True)\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"285679db\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"\\n\",\n+    \"## Sexual networks\\n\",\n+    \"Starsim contains a few basic sexual networks, including an `mf` network for modeling heterosexual partnerships and an `msm` network for men having sex with men. Modeling STIs is a straightforward extension of the SIR example we looked at previously. Here's an example modeling syphilis:\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": 17,\n+   \"id\": \"dd802fdd\",\n+   \"metadata\": {\n+    \"collapsed\": false\n+   },\n+   \"outputs\": [],\n+   \"source\": [\n+    \"# Create the disease\\n\",\n+    \"syph = ss.Syphilis(\\n\",\n+    \"    beta = {'mf': [0.25, 0.15]},    # See notes below \\n\",\n+    \")\\n\",\n+    \"\\n\",\n+    \"# Create a heterosexual network\\n\",\n+    \"mf = ss.MFNet(\\n\",\n+    \"    duration=1/24,  # Using very short relationships so that we get more transmission \\n\",\n+    \"    acts=80,        # Distribution of the number of coital acts/year\\n\",\n+    \")\\n\",\n+    \"\\n\",\n+    \"pars = dict(start=2000, dur=20, dt=1/12)\\n\",\n+    \"sim = ss.Sim(pars=pars, diseases=syph, networks=mf)\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"e0905383\",\n+   \"metadata\": {\n+    \"collapsed\": false\n+   },\n+   \"source\": [\n+    \"The main difference here is that we've added the line `syph.pars['beta'] = {'mf': [0.25, 0.15]}`. Because STIs are generally more transmissible from males to females than vice versa, we can specify `beta` as a list, and we can also allow it to vary between networks. For instance, if we also had an MSM network here, we could set \\n\",\n+    \"```\\n\",\n+    \"syph.pars.update(beta = {'mf': [0.25, 0.15], 'msm': [0.4, 0.4]})\\n\",\n+    \"```\\n\",\n+    \"The sexual network itself is structurally similar to the `random` network that we looked at previously, and can be customized by changing the `pars` dictionary that's used to construct it.\\n\",\n+    \" \\n\",\n+    \"## Maternal networks\\n\",\n+    \"Maternal networks are useful for capturing mother-to-child transmission. If you want to use them, you also need to model pregnancy. As new agents are born via pregnancy, edges are automatically added between mother and prenatal child in the maternal network. Here's an example showing how you would do this for syphilis:\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"id\": \"860b879b\",\n+   \"metadata\": {\n+    \"collapsed\": false\n+   },\n+   \"outputs\": [],\n+   \"source\": [\n+    \"syph = ss.Syphilis(\\n\",\n+    \"    beta = {'mf': [0.25, 0.15], 'maternal': [0.99, 0]}\\n\",\n+    \")\\n\",\n+    \"\\n\",\n+    \"# Make demographic modules\\n\",\n+    \"pregnancy = ss.Pregnancy(fertility_rate=20)\\n\",\n+    \"death = ss.Deaths(death_rate=15)\\n\",\n+    \"\\n\",\n+    \"# Make maternal network\\n\",\n+    \"maternal = ss.MaternalNet()\\n\",\n+    \"\\n\",\n+    \"# Make sim\\n\",\n+    \"sim = ss.Sim(pars=pars, diseases=syph, networks=[mf, maternal], demographics=[pregnancy, death], dur=10)\\n\",\n+    \"sim.run().plot(show_module=False)\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"c2267da9\",\n+   \"metadata\": {\n+    \"collapsed\": false\n+   },\n+   \"source\": [\n+    \"## Making your own contact network\\n\",\n+    \"If you want to make your own network, a good place to start is by inheriting from one of the templates in networks.py. For example, if you wanted to make an `mf` network that has more age structure, you could do something like this:\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": 19,\n+   \"id\": \"90ebaea5\",\n+   \"metadata\": {\n+    \"collapsed\": false\n+   },\n+   \"outputs\": [],\n+   \"source\": [\n+    \"class age_mf(ss.MFNet):\\n\",\n+    \"    def add_pairs(self, people, ti=None):\\n\",\n+    \"        # Custom code to select pairs based on age\\n\",\n+    \"        return \"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"cdf7586a\",\n+   \"metadata\": {\n+    \"collapsed\": false\n+   },\n+   \"source\": [\n+    \"This network would operate exactly like the existing `mf` network, but you could control how new pairs were added.\\n\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"46760c64\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"# Mixing Pools\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"fc8725f0\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"Let's compare a simple SIR model configured with transmission using a single Mixing Pool to a similar model using a contact network. Mixing pools are not the same as contact networks, so the results are not expected to be identical.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"id\": \"e0298394\",\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"# Transmission using a mixing pool\\n\",\n+    \"mp = ss.MixingPool(beta=ss.beta(0.1), contacts=ss.poisson(lam=3)) # A single mixing pool\\n\",\n+    \"sir = ss.SIR() # Beta doesn't matter, that's just for networks\\n\",\n+    \"sim1 = ss.Sim(diseases=sir, networks=mp, verbose=0, label='Mixing Pool')\\n\",\n+    \"\\n\",\n+    \"# Transmission using a network\\n\",\n+    \"net = ss.RandomNet(n_contacts=ss.poisson(lam=3))\\n\",\n+    \"sir = ss.SIR(beta=ss.beta(0.1))\\n\",\n+    \"sim2 = ss.Sim(diseases=sir, networks=net, verbose=0, label='Contact Network')\\n\",\n+    \"\\n\",\n+    \"msim = ss.MultiSim([sim1, sim2]).run()\\n\",\n+    \"msim.plot()\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"0bf06ad9\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"Each MixingPool has several configuration parameters, including `src` and `dst`. The value of these parameters can either be an array of uids, like `ss.uids([0,1,2])` or a callable function that takes `sim` as an argument and returns an array of uids (or a BoolArr) like `lambda sim: sim.people.age<10`. One helper class we have created is called `AgeGroup`, which takes `low` and `high` ages as parameters. This class has some performance advantages when using multiple pools via `MixingPools` through caching.\\n\",\n+    \"\\n\",\n+    \"While mixing pools do not represent individual agent-to-agent connections, each agent does have an \\\"effective\\\" number of contacts, typically drawn from a Poisson distribution. Individuals retain their number of contacts within each pool for the duration of the simulation. Effective contacts are used on the acquisition sides. On the transmission side, the \\\"average\\\" infection level, called `trans`, against which susceptible agents are challenged is computed as:\\n\",\n+    \"```python\\n\",\n+    \"trans = np.mean(disease.infectious[self.src_uids] * disease.rel_trans[self.src_uids])\\n\",\n+    \"```\\n\",\n+    \"And on the acquisition side, each susceptible agent can be thought of as connected to `eff_contacts` average infectious agents, computed as:\\n\",\n+    \"```python\\n\",\n+    \"acq = self.eff_contacts[self.dst_uids] * disease.susceptible[self.dst_uids] * disease.rel_sus[self.dst_uids]\\n\",\n+    \"```\\n\",\n+    \"Ultimately, the acquisition probability for each susceptible agent in `dst_uids` is computed as\\n\",\n+    \"```python\\n\",\n+    \"p = self.pars.beta * trans * acq\\n\",\n+    \"```\\n\",\n+    \"\\n\",\n+    \"You can see the `beta` parameter here, which is another pool parameter and should use `ss.beta()` to automatically adjust for time units. Mixing pools do not currently use the `beta` parameters configured in individual disease modules.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"id\": \"aa28b522\",\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"mp = ss.MixingPool(\\n\",\n+    \"    diseases = 'sir', # Use this pool only for SIR, not other diseases (HIV in this example)\\n\",\n+    \"    src = lambda sim: sim.people.age < 15, # Infection sources will be agents under age 15\\n\",\n+    \"    dst = ss.AgeGroup(low=15, high=None), # Here demonstrating the AgeGroup class, identical to lambda sim: sim.people.age >= 15\\n\",\n+    \"    contacts = ss.poisson(lam=2), # Contacts will be poisson distributed with a mean of 2\\n\",\n+    \"    beta = ss.beta(0.2), # And we set beta to 0.2, automatically adjusting for time units via the ss.beta wrapper\\n\",\n+    \")\\n\",\n+    \"sim = ss.Sim(diseases=['sir', 'hiv'], networks=mp) # Two diseases, only \\\"sir\\\" will have transmission\\n\",\n+    \"sim.run()\\n\",\n+    \"sim.plot()\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"8756491b\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"`MixingPools` (plural) allows you to configure multiple individual `MixingPool` pools. This first example shows how to do age mixing. Like `MixingPool`, `MixingPools` also takes `src` and `dst`, however each of these parameters must be a dictionary with key specifying the name of each group and value as in the singlular mixing pool proving the uids by a callable function or list of uids.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"id\": \"25a9ed2a\",\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"lows = np.arange(0, 80, 5)\\n\",\n+    \"groups = ss.ndict([ss.AgeGroup(low=low, high=low+5) for low in lows[:-1]])\\n\",\n+    \"groups.append(ss.AgeGroup(low=lows[-1], high=None)) # 80+\\n\",\n+    \"n_groups = len(groups)\\n\",\n+    \"\\n\",\n+    \"# Let's create a random contact matrix. If using contact matrices from Prem et al., put data here.\\n\",\n+    \"cm = np.random.random((n_groups, n_groups)) + 3*np.diag(np.random.rand(n_groups))\\n\",\n+    \"\\n\",\n+    \"print('The first axis (rows) of the contact matrix is the SOURCE group')\\n\",\n+    \"print('The second axis (columns) of the contact matrix is the DESTINATION group')\\n\",\n+    \"plt.imshow(cm)\\n\",\n+    \"\\n\",\n+    \"mps = ss.MixingPools(\\n\",\n+    \"    contacts = cm,\\n\",\n+    \"    beta = ss.beta(0.2),\\n\",\n+    \"    src = groups,\\n\",\n+    \"    dst = groups,\\n\",\n+    \")\\n\",\n+    \"\\n\",\n+    \"# Track new infections by age using an Analyzer, you'll learn about these in a subsequent tutorial\\n\",\n+    \"class New_Infections_By_Age(ss.Analyzer):\\n\",\n+    \"    def __init__(self, bins, **kwargs):\\n\",\n+    \"        super().__init__(**kwargs)\\n\",\n+    \"        self.bins = bins\\n\",\n+    \"\\n\",\n+    \"    def init_post(self):\\n\",\n+    \"        super().init_post()\\n\",\n+    \"        self.new_cases = np.zeros((len(self), len(self.bins)-1))\\n\",\n+    \"\\n\",\n+    \"    def step(self):\\n\",\n+    \"        new_inf = self.sim.diseases.sir.ti_infected == self.ti\\n\",\n+    \"        if not new_inf.any(): return\\n\",\n+    \"        self.new_cases[self.ti, :] = np.histogram(self.sim.people.age[new_inf], bins=self.bins)[0]\\n\",\n+    \"\\n\",\n+    \"    def plot(self):\\n\",\n+    \"        fig, ax = plt.subplots()\\n\",\n+    \"        ax.set_prop_cycle('color', plt.cm.nipy_spectral(np.linspace(0, 1, len(self.bins))))\\n\",\n+    \"\\n\",\n+    \"        for i, (b1, b2) in enumerate(zip(self.bins[:-1], self.bins[1:])):\\n\",\n+    \"            ax.plot(self.timevec, self.new_cases[:,i], label=f'Age {b1}-{b2}')\\n\",\n+    \"        ax.legend(); ax.set_xlabel('Year'); ax.set_ylabel('New Infections')\\n\",\n+    \"\\n\",\n+    \"az = New_Infections_By_Age(np.concatenate([lows, [1000]]))\\n\",\n+    \"\\n\",\n+    \"sir = ss.SIR()\\n\",\n+    \"sim = ss.Sim(diseases=sir, networks=mps, analyzers=az, dur=5, dt=1/4, n_agents=1000, verbose=0)\\n\",\n+    \"sim.run()\\n\",\n+    \"sim.analyzers[0].plot()\\n\",\n+    \"print('↑ The default age distribution is uniform, so the 75+ group contains many more people than the other age groups, explaining the larger number of new infections.')\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"55650f48\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"Mixing pools work well with properties other than age. Here's an example that mixes by socio-economic status (SES).\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"id\": \"0263e430\",\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"from enum import IntEnum\\n\",\n+    \"class SES(IntEnum):\\n\",\n+    \"    LOW = 0\\n\",\n+    \"    MID = 1\\n\",\n+    \"    HIGH = 2\\n\",\n+    \"\\n\",\n+    \"# Create 5,000 people adding 50% LOW, 30% MID, and 20% HIGH SES\\n\",\n+    \"ses = ss.FloatArr('ses', default=ss.choice(a=[SES.LOW, SES.MID, SES.HIGH], p=[0.5, 0.3, 0.2]))\\n\",\n+    \"ppl = ss.People(n_agents=5_000, extra_states=ses)\\n\",\n+    \"\\n\",\n+    \"# Create the mixing pools, note that the contact matrix need not be symmetric\\n\",\n+    \"mps = ss.MixingPools(\\n\",\n+    \"    src = {s.name: lambda sim, s=s: ss.uids(sim.people.ses == s) for s in [SES.LOW, SES.MID, SES.HIGH]},\\n\",\n+    \"    dst = {s.name: lambda sim, s=s: ss.uids(sim.people.ses == s) for s in [SES.LOW, SES.MID]}, # People in the HIGH group have not route to acquire new infections, for demonstration purposes here\\n\",\n+    \"\\n\",\n+    \"    # src on rows (1st dimension), dst on cols (2nd dimension)\\n\",\n+    \"    contacts = np.array([\\n\",\n+    \"        [2.50, 0.00], # LOW->LOW,  LOW->MID\\n\",\n+    \"        [0.05, 1.75], # MID->LOW,  MID->MID\\n\",\n+    \"        [0.00, 0.15], # HIGH->LOW, HIGH->MID\\n\",\n+    \"    ]),\\n\",\n+    \"\\n\",\n+    \"    beta = ss.beta(0.2),\\n\",\n+    \")\\n\",\n+    \"\\n\",\n+    \"# Create an analyzer to track results by SES group\\n\",\n+    \"class New_Infections_By_SES(ss.Analyzer):\\n\",\n+    \"    def init_results(self):\\n\",\n+    \"        self.new_cases = np.zeros((len(self), len(SES)))\\n\",\n+    \"\\n\",\n+    \"    def step(self):\\n\",\n+    \"        new_inf = self.sim.diseases.sir.ti_infected == self.ti\\n\",\n+    \"        if not new_inf.any():\\n\",\n+    \"            return\\n\",\n+    \"\\n\",\n+    \"        for ses in SES:\\n\",\n+    \"            self.new_cases[self.ti, ses] = np.count_nonzero(new_inf & (self.sim.people.ses==ses))\\n\",\n+    \"\\n\",\n+    \"az = New_Infections_By_SES()\\n\",\n+    \"\\n\",\n+    \"def seeding(self, sim, uids):\\n\",\n+    \"    p = np.zeros(len(uids))\\n\",\n+    \"    high_ses = ss.uids(sim.people.ses == SES.HIGH)\\n\",\n+    \"    p[high_ses] = 0.1 # Seed infections into 10% of SES HIGH\\n\",\n+    \"    return p\\n\",\n+    \"sir = ss.SIR(init_prev = ss.bernoulli(p=seeding)) # The probability of being selected as a seed is determined on a per-agent basis by the above 'seeding' function\\n\",\n+    \"\\n\",\n+    \"sim = ss.Sim(people=ppl, diseases=sir, networks=mps, analyzers=az, dt=1/12, dur=35, verbose=0)\\n\",\n+    \"sim.run()\\n\",\n+    \"\\n\",\n+    \"\\n\",\n+    \"fig, ax = plt.subplots()\\n\",\n+    \"new_cases = sim.analyzers[0].new_cases\\n\",\n+    \"for ses in [SES.LOW, SES.MID, SES.HIGH]:\\n\",\n+    \"    ax.plot(sim.results.timevec, new_cases[:,ses], label=ses.name)\\n\",\n+    \"ax.legend(); ax.set_xlabel('Year'); ax.set_ylabel('New Infections')\\n\",\n+    \"plt.show()\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"2ed791af\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"In the above figure, infections are seeded into the HIGH group at the beginning of the simulation, explaining the spike in new cases at that time. HIGH SES can only infect MID SES, so the MID (orange) wave follows. LOW SES can only become infected by MID SES in this example, so the blue wave follows. This example intentionally demonstrates the directional nature of mixing pools and includes strong mixing within groups and bottlenecks between groups to make the point.\"\n+   ]\n+  }\n+ ],\n+ \"metadata\": {\n+  \"kernelspec\": {\n+   \"display_name\": \"base\",\n+   \"language\": \"python\",\n+   \"name\": \"python3\"\n+  },\n+  \"language_info\": {\n+   \"codemirror_mode\": {\n+    \"name\": \"ipython\",\n+    \"version\": 3\n+   },\n+   \"file_extension\": \".py\",\n+   \"mimetype\": \"text/x-python\",\n+   \"name\": \"python\",\n+   \"nbconvert_exporter\": \"python\",\n+   \"pygments_lexer\": \"ipython3\",\n+   \"version\": \"3.12.2\"\n+  }\n+ },\n+ \"nbformat\": 4,\n+ \"nbformat_minor\": 5\n+}\ndiff --git a/pyproject.toml b/pyproject.toml\nnew file mode 100644\nindex 0000000..67d0850\n--- /dev/null\n+++ b/pyproject.toml\n@@ -0,0 +1,63 @@\n+[build-system]\n+requires = [\"setuptools\", \"setuptools-scm\"]\n+build-backend = \"setuptools.build_meta\"\n+\n+[project]\n+name = \"starsim\"\n+dynamic = [\"version\"]\n+description = \"A fast, flexible agent-based disease modeling framework\"\n+readme = \"README.rst\"\n+requires-python = \">=3.8\"\n+license = {file = \"LICENSE\"}\n+keywords = [\"agent-based model\", \"simulation\", \"disease\", \"epidemiology\"]\n+\n+authors = [\n+  { name = \"Starsim Development Team\", email = \"info@starsim.org\" },\n+  { name = \"Cliff Kerr\" },\n+  { name = \"Robyn Stuart\" },\n+  { name = \"Romesh Abeysuriya\" },\n+  { name = \"Paula Sanz-Leon\" },\n+  { name = \"Jamie Cohen\" },\n+  { name = \"Daniel Klein\" }\n+]\n+\n+classifiers = [\n+  \"Intended Audience :: Science/Research\",\n+  \"License :: OSI Approved :: MIT License\",\n+  \"Operating System :: OS Independent\",\n+  \"Programming Language :: Python\",\n+  \"Topic :: Software Development :: Libraries :: Python Modules\",\n+  \"Development Status :: 5 - Production/Stable\",\n+  \"Programming Language :: Python :: 3.10\",\n+  \"Programming Language :: Python :: 3.11\",\n+  \"Programming Language :: Python :: 3.12\"\n+]\n+\n+dependencies = [\n+    \"numpy>=1.24.0\",\n+    \"pandas>=2.0.0\",\n+    \"sciris>=3.2.0\",\n+    \"numba\",\n+    \"scipy\",\n+    \"matplotlib\",\n+    \"networkx\",\n+    \"optuna\"\n+]\n+\n+[project.optional-dependencies]\n+fastmath = [\"intel-cmplr-lib-rt\"]\n+test = [\"pytest>=7.3\", \"pytest-cov\", \"pytest-env\", \"pytest-xdist\"]\n+\n+[project.urls]\n+\"Website\" = \"https://starsim.org\"\n+\"Source\" = \"https://github.com/starsimhub/starsim/\"\n+\n+[tool.setuptools.packages.find]\n+where = [\".\"]\n+include = [\"starsim*\"]\n+\n+[tool.setuptools.package-data]\n+mypkg = [\"*.ipynb\", \"*.rst\", \"*.csv\"]\n+\n+[tool.setuptools.dynamic]\n+version = {attr = \"starsim.version.__version__\"}\n\\ No newline at end of file\ndiff --git a/setup.py b/setup.py\nindex 4d4ae2f..d7b72bd 100644\n--- a/setup.py\n+++ b/setup.py\n@@ -1,49 +1,7 @@\n-import os\n-import runpy\n-from setuptools import setup, find_packages\n+\"\"\"\n+Legacy support; see pyproject.toml for current information\n+\"\"\"\n \n-# Get version\n-cwd = os.path.abspath(os.path.dirname(__file__))\n-versionpath = os.path.join(cwd, 'starsim', 'version.py')\n-version = runpy.run_path(versionpath)['__version__']\n+import setuptools\n \n-# Get the documentation\n-with open(os.path.join(cwd, 'README.rst'), \"r\") as f:\n-    long_description = f.read()\n-\n-CLASSIFIERS = [\n-    \"Environment :: Console\",\n-    \"Intended Audience :: Science/Research\",\n-    \"License :: Other/Proprietary License\",\n-    \"Operating System :: OS Independent\",\n-    \"Programming Language :: Python\",\n-    \"Topic :: Software Development :: Libraries :: Python Modules\",\n-    \"Development Status :: 5 - Production/Stable\",\n-    \"Programming Language :: Python :: 3.9\",\n-    \"Programming Language :: Python :: 3.10\",\n-    \"Programming Language :: Python :: 3.11\",\n-    \"Programming Language :: Python :: 3.12\",\n-]\n-\n-setup(\n-    name=\"starsim\",\n-    version=version,\n-    author=\"Robyn Stuart, Cliff Kerr, Romesh Abeysuriya, Paula Sanz-Leon, Jamie Cohen, and Daniel Klein on behalf of the Starsim Collective\",\n-    description=\"Starsim\",\n-    long_description=long_description,\n-    long_description_content_type=\"text/x-rst\",\n-    keywords=[\"agent-based model\", \"simulation\", \"disease\", \"epidemiology\"],\n-    platforms=[\"OS Independent\"],\n-    classifiers=CLASSIFIERS,\n-    packages=find_packages(),\n-    include_package_data=True,\n-    install_requires=[ # NB: remember to update __init__.py if these requirements change\n-        'numpy',\n-        'scipy',\n-        'pandas>=2.0.0',\n-        'sciris>=3.1.6',\n-        'matplotlib',\n-        'numba',\n-        'networkx',\n-    ],\n-)\n+setuptools.setup()\n\\ No newline at end of file\ndiff --git a/starsim/__init__.py b/starsim/__init__.py\nindex 1e873df..6d055bc 100644\n--- a/starsim/__init__.py\n+++ b/starsim/__init__.py\n@@ -1,12 +1,24 @@\n+\"\"\"\n+Import all Starsim modules\n+\"\"\"\n+\n+# Start imports: version and settings\n from .version import __version__, __versiondate__, __license__\n-from .settings      import *\n+from .settings import dtypes, options\n+\n+# Optionally print the license\n+if options.license:\n+    print(__license__)\n+\n+# Finish imports\n from .utils         import *\n+from .arrays        import *\n+from .time          import *\n from .parameters    import *\n from .distributions import *\n-from .states        import *\n from .people        import *\n from .modules       import *\n-from .network       import *\n+from .networks      import *\n from .results       import *\n from .demographics  import *\n from .products      import *\n@@ -14,20 +26,18 @@ from .interventions import *\n from .demographics  import *\n from .disease       import *\n from .diseases      import *\n+from .loop          import *\n from .sim           import *\n from .run           import *\n+from .calibration   import *\n from .samples       import *\n \n # Assign the root folder\n import sciris as sc\n root = sc.thispath(__file__).parent\n \n-# Import the version and print the license\n-if options.verbose:\n-    print(__license__)\n-\n-# Double-check key requirements -- should match setup.py\n-reqs = ['sciris>=3.1.6', 'pandas>=2.0.0', 'scipy', 'numba', 'networkx']\n+# Double-check key requirements -- should match pyproject.toml\n+reqs = ['sciris>=3.2.0', 'pandas>=2.0.0']\n msg = f'The following dependencies for Starsim {__version__} were not met: <MISSING>.'\n sc.require(reqs, message=msg)\n-del sc, reqs, msg # Don't keep this in the module\n\\ No newline at end of file\n+del sc, reqs, msg # Don't keep this in the module\ndiff --git a/starsim/arrays.py b/starsim/arrays.py\nnew file mode 100644\nindex 0000000..7c8bc5c\n--- /dev/null\n+++ b/starsim/arrays.py\n@@ -0,0 +1,551 @@\n+\"\"\"\n+Define array-handling classes, including agent states\n+\"\"\"\n+import numpy as np\n+import sciris as sc\n+import starsim as ss\n+\n+# Shorten these for performance\n+ss_float = ss.dtypes.float\n+ss_int   = ss.dtypes.int\n+ss_bool  = ss.dtypes.bool\n+type_def = {\n+    ss_float: ('float', float, np.float64, np.float32),\n+    ss_int: ('int', int, np.int64, np.int32),\n+    ss_bool: ('bool', bool, np.bool_),\n+}\n+type_map = {v:k for k,vlist in type_def.items() for v in vlist} # Invert into a full dictionary\n+\n+__all__ = ['BaseArr', 'Arr', 'FloatArr', 'BoolArr', 'State', 'IndexArr', 'uids']\n+\n+\n+class BaseArr(np.lib.mixins.NDArrayOperatorsMixin):\n+    \"\"\"\n+    An object that acts exactly like a NumPy array, except stores the values in self.values.\n+    \"\"\"\n+    def __init__(self, values, *args, **kwargs):\n+        self.values = np.array(values, *args, **kwargs)\n+        return\n+\n+    def __getattr__(self, attr):\n+        \"\"\" Make it behave like a regular array mostly -- enables things like sum(), mean(), etc. \"\"\"\n+        if attr in ['__deepcopy__', '__getstate__', '__setstate__']:\n+            return self.__getattribute__(attr)\n+        else:\n+            return object.__getattribute__(self, 'values').__getattribute__(attr) # Be explicit to avoid possible recurison\n+\n+    # Define more base methods\n+    def __len__(self):   return self.values.__len__()\n+    def __bool__(self):  return self.values.__bool__()\n+    def __int__(self):   return self.values.__int__()\n+    def __float__(self): return self.values.__float__()\n+    def __contains__(self, key): return self.values.__contains__(key)\n+\n+    def convert(self, obj):\n+        \"\"\" Check if an object is an array, and convert if so \"\"\"\n+        if isinstance(obj, np.ndarray):\n+            return self.asnew(obj)\n+        elif isinstance(obj, BaseArr):\n+            return self.asnew(obj.values)\n+        return obj\n+\n+    @staticmethod\n+    def _arr(obj):\n+        \"\"\" Helper function to efficiently extract values from a BaseArr, or return the original object \"\"\"\n+        if isinstance(obj, BaseArr):\n+            return obj.values\n+        return obj\n+\n+    def __array_ufunc__(self, ufunc, method, *inputs, **kwargs):\n+        \"\"\" To handle all numpy operations, e.g. arr1*arr2 \"\"\"\n+        # Convert all inputs to their .values if they are BaseArr, otherwise leave unchanged\n+        inputs = [self._arr(x) for x in inputs]\n+        kwargs = {k:self._arr(v) for k,v in kwargs.items()}\n+        result = getattr(ufunc, method)(*inputs, **kwargs)\n+\n+        # If result is a tuple (e.g., for divmod or ufuncs that return multiple values), convert all results to BaseArr\n+        if isinstance(result, tuple):\n+            return tuple(self.convert(x) for x in result)\n+\n+        result = self.convert(result)\n+        return result\n+\n+    def __iter__(self):\n+        \"\"\" For iterating correctly, e.g. for sum() \"\"\"\n+        return iter(self.values)\n+\n+    def __getitem__(self, index):\n+        \"\"\" For indexing and slicing, e.g. arr[inds] \"\"\"\n+        return self.values[index]\n+\n+    def __setitem__(self, index, value):\n+        \"\"\" Assign values, e.g. arr1[inds] = arr2 \"\"\"\n+        self.values[index] = value\n+\n+    def __array__(self, *args, **kwargs):\n+        \"\"\" To ensure isinstance(arr, BaseArr) passes when creating new instances \"\"\"\n+        return np.array(self.values, *args, **kwargs)\n+\n+    def __repr__(self):\n+        return f\"{self.__class__.__name__}({self.values})\"\n+\n+    def disp(self):\n+        \"\"\" Full display of object \"\"\"\n+        return sc.pr(self)\n+\n+    def asnew(self, values=None, cls=None, **kwargs):\n+        \"\"\" Duplicate and copy (rather than link) data \"\"\"\n+        if cls is None: # Use the current class if none is provided\n+            cls = self.__class__\n+        new = object.__new__(cls) # Create a new Arr instance\n+        new.__dict__ = self.__dict__.copy() # Copy pointers\n+        new.__dict__.update(kwargs) # Update any keyword arguments provided # TODO: add validation?\n+        if values is not None:\n+            new.values = values # Replace data with new data\n+        else:\n+            new.values = sc.cp(new.values) # TODO: is this needed?\n+        return new\n+\n+    def update(self, skip_none=True, overwrite=True, force=False, **kwargs):\n+        \"\"\" Update the attributes, skipping None values and raising an error if extra keys are added \"\"\"\n+        if skip_none: # Remove None inputs\n+            kwargs = {k:v for k,v in kwargs.items() if v is not None}\n+        if not overwrite: # Don't overwrite non-None values\n+            kwargs = {k:v for k,v in kwargs.items() if getattr(self, k, None) is None}\n+        if not force: # Check if we'd be creating any new keys\n+            kw_keys = set(kwargs.keys())\n+            self_keys = set(self.__dict__.keys())\n+            diff = kw_keys - self_keys\n+            if diff:\n+                errormsg = f'Invalid arguments to {self}: {diff}'\n+                raise ValueError(errormsg)\n+        self.__dict__.update(kwargs) # Actually perform the update\n+        return self\n+\n+    def to_json(self):\n+        \"\"\" Return a dictionary representation of the Arr \"\"\"\n+        out = dict(\n+            classname = self.__class__.__name__,\n+            values = sc.jsonify(self.values),\n+        )\n+        return out\n+\n+\n+class Arr(BaseArr):\n+    \"\"\"\n+    Store a state of the agents (e.g. age, infection status, etc.) as an array.\n+\n+    In practice, ``Arr`` objects can be used interchangeably with NumPy arrays.\n+    They have two main data interfaces: ``Arr.raw`` contains the \"raw\", underlying\n+    NumPy array of the data. ``Arr.values`` contains the \"active\" values, which\n+    usually corresponds to agents who are alive.\n+\n+    By default, operations are performed on active agents only (specified by ``Arr.auids``,\n+    which is a pointer to ``sim.people.auids``). For example, ``sim.people.age.mean()``\n+    will only use the ages of active agents. Thus, ``sim.people.age.mean()``\n+    is equal to ``sim.people.age.values.mean()``, not ``sim.people.age.raw.mean()``.\n+\n+    If indexing by an int or slice, ``Arr.values`` is used. If indexing by an\n+    ``ss.uids`` object, ``Arr.raw`` is used. ``Arr`` objects can't be directly\n+    indexed by a list or array of ints, as this would be ambiguous about whether\n+    ``values`` or ``raw`` is intended. For example, if there are 1000 people in a\n+    simulation and 100 of them have died, ``sim.people.age[999]`` will return\n+    an ``IndexError`` (since ``sim.people.age[899]`` is the last active agent),\n+    whereas ``sim.people.age[ss.uids(999)]`` is valid.\n+\n+    Args:\n+        name (str): The name for the state (also used as the dictionary key, so should not have spaces etc.)\n+        dtype (class): The dtype to use for this instance (if None, infer from value)\n+        default (any): Specify default value for new agents. This can be\n+        - A scalar with the same dtype (or castable to the same dtype) as the State\n+        - A callable, with a single argument for the number of values to produce\n+        - A ``ss.Dist`` instance\n+        nan (any): the value to use to represent NaN (not a number); also used as the default value if not supplied\n+        label (str): The human-readable name for the state\n+        skip_init (bool): Whether to skip initialization with the People object (used for uid and slot states)\n+        people (ss.People): Optionally specify an initialized People object, used to construct temporary Arr instances\n+    \"\"\"\n+    def __init__(self, name=None, dtype=None, default=None, nan=None, label=None, skip_init=False, people=None):\n+        # Set attributes\n+        self.name = name\n+        self.label = label or name\n+        self.default = default\n+        self.nan = nan\n+        self.dtype = dtype\n+        self.people = people # Used solely for accessing people.auids\n+\n+        if self.people is None:\n+            # This Arr is being defined in advance (e.g., as a module state) and we want a bidirectional link\n+            # with a People instance for dynamic growth. These properties will be initialized later when the\n+            # People/Sim are initialized\n+            self.len_used = 0\n+            self.len_tot = 0\n+            self.initialized = skip_init\n+            self.raw = np.empty(0, dtype=dtype)\n+        else:\n+            # This Arr is a temporary object used for intermediate calculations when we want to index an array\n+            # by UID (e.g., inside an update() method). We allow this state to reference an existing, initialized\n+            # People object, but do not register it for dynamic growth\n+            self.len_used = self.people.uid.len_used\n+            self.len_tot = self.people.uid.len_tot\n+            self.initialized = True\n+            self.raw = np.full(self.len_tot, dtype=self.dtype, fill_value=self.nan)\n+\n+        return\n+\n+    def __repr__(self):\n+        arr_str = np.array2string(self.values, max_line_width=200)\n+        if self.name:\n+            string = f'<{self.__class__.__name__} \"{str(self.name)}\", len={len(self)}, {arr_str}>'\n+        else:\n+            string = f'<{self.__class__.__name__}, len={len(self)}, {arr_str}>'\n+        return string\n+\n+    def __len__(self):\n+        return len(self.auids)\n+\n+    def _convert_key(self, key):\n+        \"\"\"\n+        Used for getitem and setitem to determine whether the key is indexing\n+        the raw array (``raw``) or the active agents (``values``), and to convert\n+        the key to array indices if needed.\n+        \"\"\"\n+        if isinstance(key, (uids, int, ss_int)):\n+            return key\n+        elif isinstance(key, (BoolArr, IndexArr)):\n+            return key.uids\n+        elif isinstance(key, slice):\n+            return self.auids[key]\n+        elif not np.isscalar(key) and len(key) == 0: # Handle [], np.array([]), etc.\n+            return uids()\n+        else:\n+            errormsg = f'Indexing an Arr ({self.name}) by ({key}) is ambiguous or not supported. Use ss.uids() instead, or index Arr.raw or Arr.values.'\n+            raise Exception(errormsg)\n+\n+    def __getitem__(self, key):\n+        key = self._convert_key(key)\n+        return self.raw[key]\n+\n+    def __setitem__(self, key, value):\n+        key = self._convert_key(key)\n+        self.raw[key] = value\n+        return\n+\n+    def __gt__(self, other): return self.asnew(self.values > other,  cls=BoolArr)\n+    def __lt__(self, other): return self.asnew(self.values < other,  cls=BoolArr)\n+    def __ge__(self, other): return self.asnew(self.values >= other, cls=BoolArr)\n+    def __le__(self, other): return self.asnew(self.values <= other, cls=BoolArr)\n+    def __eq__(self, other): return self.asnew(self.values == other, cls=BoolArr)\n+    def __ne__(self, other): return self.asnew(self.values != other, cls=BoolArr)\n+\n+    def __and__(self, other): raise BooleanOperationError(self)\n+    def __or__(self, other):  raise BooleanOperationError(self)\n+    def __xor__(self, other): raise BooleanOperationError(self)\n+    def __invert__(self):     raise BooleanOperationError(self)\n+\n+    @property\n+    def auids(self):\n+        \"\"\" Link to the indices of active agents -- sim.people.auids \"\"\"\n+        try:\n+            return self.people.auids\n+        except:\n+            if not self.initialized:\n+                ss.warn('Trying to access non-initialized Arr object; in most cases, Arr objects need to be initialized with a Sim object, but set skip_init=True if this is intentional.')\n+            return uids(np.arange(len(self.raw)))\n+\n+    def count(self):\n+        return np.count_nonzero(self.values)\n+\n+    @property\n+    def values(self):\n+        \"\"\" Return the values of the active agents \"\"\"\n+        return self.raw[self.auids]\n+\n+    def set(self, uids, new_vals=None):\n+        \"\"\" Set the values for the specified UIDs\"\"\"\n+        if new_vals is None:\n+            if isinstance(self.default, ss.Dist):\n+                new_vals = self.default.rvs(uids)\n+            elif callable(self.default):\n+                new_vals = self.default(len(uids))\n+            elif self.default is not None:\n+                new_vals = self.default\n+            else:\n+                new_vals = self.nan\n+        self.raw[uids] = new_vals\n+        return new_vals\n+\n+    def set_nan(self, uids):\n+        \"\"\" Shortcut function to set values to NaN \"\"\"\n+        self.raw[uids] = self.nan\n+        return\n+\n+    @property\n+    def isnan(self):\n+        return self.asnew(self.values == self.nan, cls=BoolArr)\n+\n+    @property\n+    def notnan(self):\n+        return self.asnew(self.values != self.nan, cls=BoolArr)\n+\n+    def grow(self, new_uids=None, new_vals=None):\n+        \"\"\"\n+        Add new agents to an Arr\n+\n+        This method is normally only called via `People.grow()`.\n+\n+        Args:\n+            new_uids: Numpy array of UIDs for the new agents being added\n+            new_vals: If provided, assign these state values to the new UIDs\n+        \"\"\"\n+        orig_len = self.len_used\n+        n_new = len(new_uids)\n+        self.len_used += n_new  # Increase the count of the number of agents by `n` (the requested number of new agents)\n+\n+        # Physically reshape the arrays, if needed\n+        if orig_len + n_new > self.len_tot:\n+            n_grow = max(n_new, self.len_tot//2)  # Minimum 50% growth, since growing arrays is slow\n+            new_empty = np.empty(n_grow, dtype=self.dtype) # 10x faster than np.zeros()\n+            self.raw = np.concatenate([self.raw, new_empty], axis=0)\n+            self.len_tot = len(self.raw)\n+            if n_grow > n_new: # We added extra space at the end, set to NaN\n+                nan_uids = np.arange(self.len_used, self.len_tot)\n+                self.set_nan(nan_uids)\n+\n+        # Set new values, and NaN if needed\n+        self.set(new_uids, new_vals=new_vals) # Assign new default values to those agents\n+        return\n+\n+    def link_people(self, people):\n+        \"\"\" Link a People object to this state, for access auids \"\"\"\n+        self.people = people # Link the people object to this state\n+        people._link_state(self) # Ensure the state is linked to the People object as well\n+        return\n+\n+    def init_vals(self):\n+        \"\"\" Actually populate the initial values and mark as initialized; only to be used on initialization \"\"\"\n+        if self.initialized:\n+            errormsg = f'Cannot re-initialize state {self}; use set() instead'\n+            raise RuntimeError(errormsg)\n+        self.grow(self.people.uid)\n+        self.initialized = True\n+        return\n+\n+    def asnew(self, arr=None, cls=None, name=None):\n+        \"\"\" Duplicate and copy (rather than link) data, optionally resetting the array \"\"\"\n+        if cls is None:\n+            cls = self.__class__\n+        if arr is None:\n+            arr = self.values\n+        new = object.__new__(cls) # Create a new Arr instance\n+        new.__dict__ = self.__dict__.copy() # Copy pointers\n+        new.dtype = arr.dtype # Set to correct dtype\n+        new.name = name # In most cases, the asnew Arr has different values to the original Arr so the original name no longer makes sense\n+        new.raw = np.empty(new.raw.shape, dtype=new.dtype) # Copy values, breaking reference\n+        new.raw[new.auids] = arr\n+        return new\n+\n+    def true(self):\n+        \"\"\" Efficiently convert truthy values to UIDs \"\"\"\n+        return self.auids[self.values.astype(bool)]\n+\n+    def false(self):\n+        \"\"\" Reverse of true(); return UIDs of falsy values \"\"\"\n+        return self.auids[~self.values.astype(bool)]\n+\n+    def to_json(self):\n+        \"\"\" Export to JSON \"\"\"\n+        out = dict(\n+            classname = self.__class__.__name__,\n+            name = self.name,\n+            label = self.label,\n+            default = self.default,\n+            nan = self.nan,\n+            dtype = self.dtype,\n+            values = sc.jsonify(self.values),\n+        )\n+        return out\n+\n+\n+class FloatArr(Arr):\n+    \"\"\"\n+    Subclass of Arr with defaults for floats and ints.\n+\n+    Note: Starsim does not support integer arrays by default since they introduce\n+    ambiguity in dealing with NaNs, and float arrays are suitable for most purposes.\n+    If you really want an integer array, you can use the default Arr class instead.\n+    \"\"\"\n+    def __init__(self, name=None, nan=np.nan, **kwargs):\n+        super().__init__(name=name, dtype=ss_float, nan=nan, **kwargs)\n+        return\n+\n+    @property\n+    def isnan(self):\n+        \"\"\" Return BoolArr for NaN values \"\"\"\n+        return self.asnew(np.isnan(self.values), cls=BoolArr)\n+\n+    @property\n+    def notnan(self):\n+        \"\"\" Return BoolArr for non-NaN values \"\"\"\n+        return self.asnew(~np.isnan(self.values), cls=BoolArr)\n+\n+    @property\n+    def notnanvals(self):\n+        \"\"\" Return values that are not-NaN \"\"\"\n+        vals = self.values # Shorten and avoid double indexing\n+        out = vals[np.nonzero(~np.isnan(vals))[0]]\n+        return out\n+\n+\n+class BoolArr(Arr):\n+    \"\"\" Subclass of Arr with defaults for booleans \"\"\"\n+    def __init__(self, name=None, nan=False, **kwargs): # No good NaN equivalent for bool arrays\n+        super().__init__(name=name, dtype=ss_bool, nan=nan, **kwargs)\n+        return\n+\n+    def __and__(self, other): return self.asnew(self.values & other)\n+    def __or__(self, other):  return self.asnew(self.values | other)\n+    def __xor__(self, other): return self.asnew(self.values ^ other)\n+    def __invert__(self):     return self.asnew(~self.values)\n+\n+    # BoolArr cannot store NaNs so report all entries as being not-NaN\n+    @property\n+    def isnan(self):\n+        return self.asnew(np.full_like(self.values, fill_value=False), cls=BoolArr)\n+\n+    @property\n+    def notnan(self):\n+        return self.asnew(np.full_like(self.values, fill_value=True), cls=BoolArr)\n+\n+    @property\n+    def uids(self):\n+        \"\"\" Alias to Arr.true \"\"\"\n+        return self.true()\n+\n+    def split(self):\n+        \"\"\" Return UIDs of values that are true and false as separate arrays \"\"\"\n+        t_uids = self.true()\n+        f_uids = self.false()\n+        return t_uids, f_uids\n+\n+\n+class State(BoolArr):\n+    \"\"\"\n+    A boolean array being used as a state.\n+\n+    Although functionally identical to BoolArr, a State is handled differently in\n+    terms of automation: specifically, results are automatically generated from a\n+    State (but not a BoolArr).\n+\n+    States are typically used to keep track of externally-facing variables (e.g.\n+    disease.susceptible), while BoolArrs can be used to keep track of internal\n+    ones (e.g. disease.has_immunity).\n+    \"\"\"\n+    pass\n+\n+\n+class IndexArr(Arr):\n+    \"\"\" A special class of Arr used for UIDs and RNG IDs; not to be used as an integer array (for that, use FloatArr) \"\"\"\n+    def __init__(self, name=None, label=None):\n+        super().__init__(name=name, dtype=ss_int, default=None, nan=-1, label=label, skip_init=True)\n+        self.raw = uids(self.raw)\n+        return\n+\n+    @property\n+    def uids(self):\n+        \"\"\" Alias to self.values, to allow Arr.uids like BoolArr \"\"\"\n+        return self.values\n+\n+    def grow(self, new_uids=None, new_vals=None):\n+        \"\"\" Change the size of the array \"\"\"\n+        if new_uids is None and new_vals is not None: # Used as a shortcut to avoid needing to supply twice\n+            new_uids = new_vals\n+        super().grow(new_uids=new_uids, new_vals=new_vals)\n+        self.raw = uids(self.raw)\n+        return\n+\n+\n+class uids(np.ndarray):\n+    \"\"\"\n+    Class to specify that integers should be interpreted as UIDs.\n+\n+    For all practical purposes, behaves like a NumPy integer array. However,\n+    has additional methods ``uids.concat()`` (instance method), ``ss.uids.cat()``\n+    (class method), ``uids.remove()``, and ``uids.intersect()`` to simplify common\n+    UID operations.\n+    \"\"\"\n+    def __new__(cls, arr=None):\n+        if isinstance(arr, np.ndarray): # Shortcut to typical use case, where the input is an array\n+            return arr.astype(ss_int).view(cls)\n+        elif isinstance(arr, BoolArr): # Shortcut for arr.uids\n+            return arr.uids\n+        elif isinstance(arr, set):\n+            return np.fromiter(arr, dtype=ss_int).view(cls)\n+        elif arr is None: # Shortcut to return empty\n+            return np.empty(0, dtype=ss_int).view(cls)\n+        elif isinstance(arr, int): # Convert e.g. ss.uids(0) to ss.uids([0])\n+            arr = [arr]\n+        return np.asarray(arr, dtype=ss_int).view(cls) # Handle everything else\n+\n+    def concat(self, other, **kw): # Class and instance methods can't share a name\n+        \"\"\" Equivalent to np.concatenate(), but return correct type \"\"\"\n+        return np.concatenate([self, other], **kw).view(self.__class__)\n+\n+    @classmethod\n+    def cat(cls, *args, **kw):\n+        \"\"\" Equivalent to np.concatenate(), but return correct type \"\"\"\n+        if len(args) == 0 or (len(args) == 1 and (args[0] is None or not len(args[0]))):\n+            return uids()\n+        arrs = args[0] if len(args) == 1 else args # TODO: handle one-array case\n+        return np.concatenate(arrs, **kw).view(cls)\n+\n+    def remove(self, other, **kw):\n+        \"\"\" Remove provided UIDs from current array\"\"\"\n+        if isinstance(other, BoolArr):\n+            other = other.uids\n+        return np.setdiff1d(self, other, **kw).view(self.__class__)\n+\n+    def intersect(self, other, **kw):\n+        \"\"\" Keep only UIDs that are also present in the other array \"\"\"\n+        if isinstance(other, BoolArr):\n+            other = other.uids\n+        return np.intersect1d(self, other, **kw).view(self.__class__)\n+\n+    def union(self, other, **kw):\n+        \"\"\" Return all UIDs present in both arrays \"\"\"\n+        if isinstance(other, BoolArr):\n+            other = other.uids\n+        return np.union1d(self, other, **kw).view(self.__class__)\n+\n+    def xor(self, other, **kw):\n+        \"\"\" Return UIDs present in only one of the arrays \"\"\"\n+        if isinstance(other, BoolArr):\n+            other = other.uids\n+        return np.setxor1d(self, other, **kw).view(self.__class__)\n+\n+    def to_numpy(self):\n+        \"\"\" Return a view as a standard NumPy array \"\"\"\n+        return self.view(np.ndarray)\n+\n+    def unique(self, return_index=False):\n+        \"\"\" Return unique UIDs; equivalent to np.unique() \"\"\"\n+        if return_index:\n+            arr, index = np.unique(self, return_index=True)\n+            return arr.view(self.__class__), index\n+        else:\n+            arr = np.unique(self).view(self.__class__)\n+            return arr\n+\n+    # Implement collection of operators\n+    def __and__(self, other): return self.intersect(other)\n+    def __or__(self, other) : return self.union(other)\n+    def __sub__(self, other): return self.remove(other)\n+    def __xor__(self, other): return self.xor(other)\n+    def __invert__(self)    : raise Exception(f\"Cannot invert an instance of {self.__class__.__name__}. One possible cause is attempting `~x.uids` - use `x.false()` or `(~x).uids` instead\")\n+\n+\n+class BooleanOperationError(NotImplementedError):\n+    \"\"\" Raised when a logical operation is performed on a non-logical array \"\"\"\n+    def __init__(self, arr):\n+        msg = f'Logical operations are only valid on Boolean arrays, not {arr.dtype}'\n+        super().__init__(msg)\ndiff --git a/starsim/calibration.py b/starsim/calibration.py\nnew file mode 100644\nindex 0000000..8c3a86d\n--- /dev/null\n+++ b/starsim/calibration.py\n@@ -0,0 +1,573 @@\n+\"\"\"\n+Define the calibration class\n+\"\"\"\n+import os\n+import numpy as np\n+import pandas as pd\n+import sciris as sc\n+import optuna as op\n+import matplotlib.pyplot as plt\n+import starsim as ss\n+\n+\n+__all__ = ['Calibration', 'compute_gof']\n+\n+\n+def compute_gof(actual, predicted, normalize=True, use_frac=False, use_squared=False,\n+                as_scalar='none', eps=1e-9, skestimator=None, estimator=None, **kwargs):\n+    \"\"\"\n+    Calculate the goodness of fit. By default use normalized absolute error, but\n+    highly customizable. For example, mean squared error is equivalent to\n+    setting normalize=False, use_squared=True, as_scalar='mean'.\n+\n+    Args:\n+        actual      (arr):   array of actual (data) points\n+        predicted   (arr):   corresponding array of predicted (model) points\n+        normalize   (bool):  whether to divide the values by the largest value in either series\n+        use_frac    (bool):  convert to fractional mismatches rather than absolute\n+        use_squared (bool):  square the mismatches\n+        as_scalar   (str):   return as a scalar instead of a time series: choices are sum, mean, median\n+        eps         (float): to avoid divide-by-zero\n+        skestimator (str):   if provided, use this scikit-learn estimator instead\n+        estimator   (func):  if provided, use this custom estimator instead\n+        kwargs      (dict):  passed to the scikit-learn or custom estimator\n+\n+    Returns:\n+        gofs (arr): array of goodness-of-fit values, or a single value if as_scalar is True\n+\n+    **Examples**::\n+\n+        x1 = np.cumsum(np.random.random(100))\n+        x2 = np.cumsum(np.random.random(100))\n+\n+        e1 = compute_gof(x1, x2) # Default, normalized absolute error\n+        e2 = compute_gof(x1, x2, normalize=False, use_frac=False) # Fractional error\n+        e3 = compute_gof(x1, x2, normalize=False, use_squared=True, as_scalar='mean') # Mean squared error\n+        e4 = compute_gof(x1, x2, skestimator='mean_squared_error') # Scikit-learn's MSE method\n+        e5 = compute_gof(x1, x2, as_scalar='median') # Normalized median absolute error -- highly robust\n+    \"\"\"\n+\n+    # Handle inputs\n+    actual    = np.array(sc.dcp(actual), dtype=float)\n+    predicted = np.array(sc.dcp(predicted), dtype=float)\n+\n+    # Scikit-learn estimator is supplied: use that\n+    if skestimator is not None: # pragma: no cover\n+        try:\n+            import sklearn.metrics as sm\n+            sklearn_gof = getattr(sm, skestimator) # Shortcut to e.g. sklearn.metrics.max_error\n+        except ImportError as E:\n+            errormsg = f'You must have scikit-learn >=0.22.2 installed: {str(E)}'\n+            raise ImportError(errormsg) from E\n+        except AttributeError as E:\n+            errormsg = f'Estimator {skestimator} is not available; see https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter for options'\n+            raise AttributeError(errormsg) from E\n+        gof = sklearn_gof(actual, predicted, **kwargs)\n+        return gof\n+\n+    # Custom estimator is supplied: use that\n+    if estimator is not None: # pragma: no cover\n+        try:\n+            gof = estimator(actual, predicted, **kwargs)\n+        except Exception as E:\n+            errormsg = f'Custom estimator \"{estimator}\" must be a callable function that accepts actual and predicted arrays, plus optional kwargs'\n+            raise RuntimeError(errormsg) from E\n+        return gof\n+\n+    # Default case: calculate it manually\n+    else:\n+        # Key step -- calculate the mismatch!\n+        gofs = abs(np.array(actual) - np.array(predicted))\n+\n+        if normalize and not use_frac:\n+            actual_max = abs(actual).max()\n+            if actual_max > 0:\n+                gofs /= actual_max\n+\n+        if use_frac:\n+            if (actual<0).any() or (predicted<0).any():\n+                print('Warning: Calculating fractional errors for non-positive quantities is ill-advised!')\n+            else:\n+                maxvals = np.maximum(actual, predicted) + eps\n+                gofs /= maxvals\n+\n+        if use_squared:\n+            gofs = gofs**2\n+\n+        if as_scalar == 'sum':\n+            gofs = np.sum(gofs)\n+        elif as_scalar == 'mean':\n+            gofs = np.mean(gofs)\n+        elif as_scalar == 'median':\n+            gofs = np.median(gofs)\n+\n+        return gofs\n+\n+\n+class Calibration(sc.prettyobj): # pragma: no cover\n+    \"\"\"\n+    A class to handle calibration of Starsim simulations. Uses the Optuna hyperparameter\n+    optimization library (optuna.org).\n+\n+    Args:\n+        sim          (Sim)  : the simulation to calibrate\n+        data         (df)   : pandas dataframe (or dataframe-compatible dict) of the data to calibrate to\n+        calib_pars   (dict) : a dictionary of the parameters to calibrate of the format dict(key1=[best, low, high])\n+        n_trials     (int)  : the number of trials per worker\n+        n_workers    (int)  : the number of parallel workers (default: maximum number of available CPUs)\n+        total_trials (int)  : if n_trials is not supplied, calculate by dividing this number by n_workers\n+        reseed       (bool) : whether to generate new random seeds for each trial\n+        weights      (dict) : the relative weights of each data source\n+        fit_args     (dict) : a dictionary of options that are passed to sim.compute_fit() to calculate the goodness-of-fit\n+        sep          (str)  : the separate between different types of results, e.g. 'hiv.deaths' vs 'hiv_deaths'\n+        name         (str)  : the name of the database (default: 'starsim_calibration')\n+        db_name      (str)  : the name of the database file (default: 'starsim_calibration.db')\n+        keep_db      (bool) : whether to keep the database after calibration (default: false)\n+        storage      (str)  : the location of the database (default: sqlite)\n+        rand_seed    (int)  : if provided, use this random seed to initialize Optuna runs (for reproducibility)\n+        label        (str)  : a label for this calibration object\n+        die          (bool) : whether to stop if an exception is encountered (default: false)\n+        debug        (bool) : if True, do not run in parallel\n+        verbose      (bool) : whether to print details of the calibration\n+\n+    Returns:\n+        A Calibration object\n+    \"\"\"\n+    def __init__(self, sim, data, calib_pars, n_trials=None, n_workers=None, total_trials=None, reseed=True,\n+                 weights=None, fit_args=None, sep='.', name=None, db_name=None, keep_db=None, storage=None,\n+                 rand_seed=None, sampler=None, label=None, die=False, debug=False, verbose=True, save_results=False):\n+\n+        # Handle run arguments\n+        if n_trials  is None: n_trials  = 20\n+        if n_workers is None: n_workers = sc.cpu_count()\n+        if name      is None: name      = 'starsim_calibration'\n+        if db_name   is None: db_name   = f'{name}.db'\n+        if keep_db   is None: keep_db   = False\n+        if storage   is None: storage   = f'sqlite:///{db_name}'\n+        if total_trials is not None: n_trials = int(np.ceil(total_trials/n_workers))\n+        kw = dict(n_trials=int(n_trials), n_workers=int(n_workers), debug=debug, name=name, db_name=db_name,\n+                  keep_db=keep_db, storage=storage, rand_seed=rand_seed, sampler=sampler)\n+        self.run_args = sc.objdict(kw)\n+\n+        # Handle other inputs\n+        self.label      = label\n+        self.sim        = sim\n+        self.calib_pars = calib_pars\n+        self.reseed     = reseed\n+        self.sep        = sep\n+        self.weights    = sc.mergedicts(weights)\n+        self.fit_args   = sc.mergedicts(fit_args)\n+        self.die        = die\n+        self.verbose    = verbose\n+        self.save_results = save_results\n+        self.calibrated = False\n+        self.before_sim = None\n+        self.after_sim  = None\n+\n+        # Load data -- this is expecting a dataframe with a column for 'time' and other columns for to sim results\n+        self.data = ss.validate_sim_data(data, die=True)\n+\n+        # Temporarily store a filename\n+        self.tmp_filename = 'tmp_calibration_%05i.obj'\n+\n+        # Initialize sim\n+        if not self.sim.initialized:\n+            self.sim.init()\n+\n+        # Figure out which sim results to get\n+        self.sim_result_list = self.data.cols\n+\n+        return\n+\n+    def run_sim(self, calib_pars=None, label=None):\n+        \"\"\" Create and run a simulation \"\"\"\n+        sim = sc.dcp(self.sim)\n+        if label: sim.label = label\n+\n+        sim = self.translate_pars(sim, calib_pars=calib_pars)\n+\n+        # Run the sim\n+        try:\n+            sim.run()\n+            return sim\n+\n+        except Exception as E:\n+            if self.die:\n+                raise E\n+            else:\n+                print(f'Encountered error running sim!\\nParameters:\\n{calib_pars}\\nTraceback:\\n{sc.traceback()}')\n+                output = None\n+                return output\n+\n+    @staticmethod\n+    def translate_pars(sim=None, calib_pars=None):\n+        \"\"\" Take the nested dict of calibration pars and modify the sim \"\"\"\n+\n+        if 'rand_seed' in calib_pars:\n+            sim.pars['rand_seed'] = calib_pars['rand_seed']\n+\n+        for parname, spec in calib_pars.items():\n+            if parname == 'rand_seed':\n+                continue\n+\n+            if 'path' not in spec:\n+                raise ValueError(f'Cannot map {parname} because \"path\" is missing from the parameter configuration.')\n+\n+            p = spec['path']\n+\n+            if len(p) != 3:\n+                raise ValueError(f'Cannot map {parname} because \"path\" must be a tuple of length 3.')\n+\n+            modtype = p[0]\n+            dkey = p[1]\n+            dparkey = p[2]\n+            dparval = spec['value']\n+            targetpar = sim[modtype][dkey].pars[dparkey]\n+\n+            if sc.isnumber(targetpar):\n+                sim[modtype][dkey].pars[dparkey] = dparval\n+            elif isinstance(targetpar, ss.Dist):\n+                sim[modtype][dkey].pars[dparkey].set(dparval)\n+            else:\n+                errormsg = 'Type not implemented'\n+                raise ValueError(errormsg)\n+\n+        return sim\n+\n+    def trial_to_sim_pars(self, pardict=None, trial=None):\n+        \"\"\"\n+        Take in an optuna trial and sample from pars, after extracting them from the structure they're provided in\n+\n+        Different use cases:\n+            - pardict is self.calib_pars, i.e. {'diseases':{'hiv':{'art_efficacy':[0.96, 0.9, 0.99]}}}, need to sample\n+            - pardict is self.initial_pars, i.e. {'diseases':{'hiv':{'art_efficacy':[0.96, 0.9, 0.99]}}}, pull 1st vals\n+            - pardict is self.best_pars, i.e. {'diseases':{'hiv':{'art_efficacy':0.96786}}}, pull single vals\n+        \"\"\"\n+        pars = sc.dcp(pardict)\n+        for parname, spec in pars.items():\n+\n+            if 'value' in spec:\n+                # Already have a value, likely running initial or final values as part of checking the fit\n+                continue\n+\n+            if 'sampler' in spec:\n+                sampler = spec.pop('sampler')\n+                sampler_fn = getattr(trial, sampler)\n+            else:\n+                sampler_fn = trial.suggest_float\n+\n+            path = spec.pop('path', None) # remove path\n+            guess = spec.pop('guess', None) # remove guess\n+            spec['value'] = sampler_fn(name=parname, **spec) # Sample!\n+            spec['path'] = path\n+            spec['guess'] = guess\n+\n+        return pars\n+\n+    @staticmethod\n+    def sim_to_df(sim): # TODO: remove this method\n+        \"\"\" Convert a sim to the expected dataframe type \"\"\"\n+        df_res = sim.to_df(sep='.')\n+        df_res['t'] = df_res['timevec']\n+        df_res = df_res.set_index('t')\n+        df_res['time'] = np.floor(np.round(df_res.index, 1)).astype(int)\n+        return df_res\n+\n+    def run_trial(self, trial):\n+        \"\"\" Define the objective for Optuna \"\"\"\n+        if self.calib_pars is not None:\n+            calib_pars = self.trial_to_sim_pars(self.calib_pars, trial)\n+        else:\n+            calib_pars = None\n+\n+        if self.reseed:\n+            calib_pars['rand_seed'] = trial.suggest_int('rand_seed', 0, 1_000_000) # Choose a random rand_seed\n+\n+        sim = self.run_sim(calib_pars)\n+\n+        # Export results # TODO: make more robust\n+        df_res = self.sim_to_df(sim)\n+        sim_results = sc.objdict()\n+\n+        for skey in self.sim_result_list:\n+            if 'prevalence' in skey or skey.startswith('n_'):\n+                model_output = df_res.groupby(by='time')[skey].mean()\n+            else:\n+                model_output = df_res.groupby(by='time')[skey].sum()\n+            sim_results[skey] = model_output.values\n+\n+        sim_results['time'] = model_output.index.values\n+        # Store results in temporary files\n+        if self.save_results:\n+            filename = self.tmp_filename % trial.number\n+            sc.save(filename, sim_results)\n+\n+        # Compute fit\n+        fit = self.compute_fit(df_res=df_res)\n+        return fit\n+\n+    def compute_fit(self, sim=None, df_res=None):\n+        \"\"\" Compute goodness-of-fit \"\"\"\n+        fit = 0\n+\n+        # TODO: reduce duplication with above\n+        if df_res is None:\n+            df_res = self.sim_to_df(sim)\n+        for skey in self.sim_result_list:\n+            if 'prevalence' in skey or skey.startswith('n_'):\n+                model_output = df_res.groupby(by='time')[skey].mean()\n+            else:\n+                model_output = df_res.groupby(by='time')[skey].sum()\n+\n+            data = self.data[skey]\n+            combined = pd.merge(data, model_output, how='left', on='time')\n+            combined['diffs'] = combined[skey+'_x'] - combined[skey+'_y']\n+            gofs = compute_gof(combined.dropna()[skey+'_x'], combined.dropna()[skey+'_y'])\n+\n+            losses = gofs  #* self.weights[skey]\n+            mismatch = losses.sum()\n+            fit += mismatch\n+\n+        return fit\n+\n+    def worker(self):\n+        \"\"\" Run a single worker \"\"\"\n+        if self.verbose:\n+            op.logging.set_verbosity(op.logging.DEBUG)\n+        else:\n+            op.logging.set_verbosity(op.logging.ERROR)\n+        study = op.load_study(storage=self.run_args.storage, study_name=self.run_args.name, sampler = self.run_args.sampler)\n+        output = study.optimize(self.run_trial, n_trials=self.run_args.n_trials, callbacks=None)\n+        return output\n+\n+    def run_workers(self):\n+        \"\"\" Run multiple workers in parallel \"\"\"\n+        if self.run_args.n_workers > 1 and not self.run_args.debug: # Normal use case: run in parallel\n+            output = sc.parallelize(self.worker, iterarg=self.run_args.n_workers)\n+        else: # Special case: just run one\n+            output = [self.worker()]\n+        return output\n+\n+    def remove_db(self):\n+        \"\"\" Remove the database file if keep_db is false and the path exists \"\"\"\n+        try:\n+            if 'sqlite' in self.run_args.storage:\n+                # Delete the file from disk\n+                if os.path.exists(self.run_args.db_name):\n+                    os.remove(self.run_args.db_name)\n+                if self.verbose: print(f'Removed existing calibration file {self.run_args.db_name}')\n+            else:\n+                # Delete the study from the database e.g., mysql\n+                op.delete_study(study_name=self.run_args.name, storage=self.run_args.storage)\n+                if self.verbose: print(f'Deleted study {self.run_args.name} in {self.run_args.storage}')\n+        except Exception as E:\n+            if self.verbose:\n+                print('Could not delete study, skipping...')\n+                print(str(E))\n+        return\n+\n+    def make_study(self):\n+        \"\"\" Make a study, deleting one if it already exists \"\"\"\n+        if not self.run_args.keep_db:\n+            self.remove_db()\n+        if self.run_args.rand_seed is not None:\n+            sampler = op.samplers.RandomSampler(self.run_args.rand_seed)\n+            sampler.reseed_rng()\n+            raise NotImplementedError('Implemented but does not work')\n+        else:\n+            sampler = None\n+        if self.verbose: print(self.run_args.storage)\n+        output = op.create_study(storage=self.run_args.storage, study_name=self.run_args.name, sampler=sampler)\n+        return output\n+\n+    def calibrate(self, calib_pars=None, confirm_fit=False, load=False, tidyup=True, **kwargs):\n+        \"\"\"\n+        Perform calibration.\n+\n+        Args:\n+            calib_pars (dict): if supplied, overwrite stored calib_pars\n+            confirm_fit (bool): if True, run simulations with parameters from before and after calibration\n+            load (bool): whether to load existing trials from the database (if rerunning the same calibration)\n+            tidyup (bool): whether to delete temporary files from trial runs\n+            verbose (bool): whether to print output from each trial\n+            kwargs (dict): if supplied, overwrite stored run_args (n_trials, n_workers, etc.)\n+        \"\"\"\n+        # Load and validate calibration parameters\n+        if calib_pars is not None:\n+            self.calib_pars = calib_pars\n+        self.run_args.update(kwargs) # Update optuna settings\n+\n+        # Run the optimization\n+        t0 = sc.tic()\n+        self.make_study()\n+        self.run_workers()\n+        study = op.load_study(storage=self.run_args.storage, study_name=self.run_args.name, sampler = self.run_args.sampler)\n+        self.best_pars = sc.objdict(study.best_params)\n+        self.elapsed = sc.toc(t0, output=True)\n+\n+        self.sim_results = []\n+        if load:\n+            if self.verbose: print('Loading saved results...')\n+            for trial in study.trials:\n+                n = trial.number\n+                try:\n+                    filename = self.tmp_filename % trial.number\n+                    results = sc.load(filename)\n+                    self.sim_results.append(results)\n+                    if tidyup:\n+                        try:\n+                            os.remove(filename)\n+                            if self.verbose: print(f'    Removed temporary file {filename}')\n+                        except Exception as E:\n+                            errormsg = f'Could not remove {filename}: {str(E)}'\n+                            if self.verbose: print(errormsg)\n+                    if self.verbose: print(f'  Loaded trial {n}')\n+                except Exception as E:\n+                    errormsg = f'Warning, could not load trial {n}: {str(E)}'\n+                    if self.verbose: print(errormsg)\n+\n+        # Compare the results\n+        self.parse_study(study)\n+\n+        if self.verbose: print('Best pars:', self.best_pars)\n+\n+        # Tidy up\n+        self.calibrated = True\n+        if not self.run_args.keep_db:\n+            self.remove_db()\n+\n+        # Optionally compute the sims before and after the fit\n+        if confirm_fit:\n+            self.confirm_fit()\n+\n+        return self\n+\n+    def confirm_fit(self):\n+        \"\"\" Run before and after simulations to validate the fit \"\"\"\n+\n+        if self.verbose: print('\\nConfirming fit...')\n+\n+        before_pars = sc.dcp(self.calib_pars)\n+        for spec in before_pars.values():\n+            spec['value'] = spec['guess'] # Use guess values\n+\n+        after_pars = sc.dcp(self.calib_pars)\n+        for parname, spec in after_pars.items():\n+            spec['value'] = self.best_pars[parname]\n+\n+        self.before_sim = self.run_sim(calib_pars=before_pars, label='Before calibration')\n+        self.after_sim  = self.run_sim(calib_pars=after_pars, label='After calibration')\n+        self.before_fit = self.compute_fit(self.before_sim)\n+        self.after_fit  = self.compute_fit(self.after_sim)\n+\n+        # Add the data to the sims\n+        for sim in [self.before_sim, self.after_sim]:\n+            sim.init_data(self.data)\n+\n+        print(f'Fit with original pars: {self.before_fit:n}')\n+        print(f'Fit with best-fit pars: {self.after_fit:n}')\n+        if self.after_fit <= self.before_fit:\n+            print('✓ Calibration improved fit')\n+        else:\n+            print('✗ Calibration did not improve fit, but this sometimes happens stochastically and is not necessarily an error')\n+\n+        return self.before_fit, self.after_fit\n+\n+    def parse_study(self, study):\n+        \"\"\"Parse the study into a data frame -- called automatically \"\"\"\n+        best = study.best_params\n+        self.best_pars = best\n+\n+        if self.verbose: print('Making results structure...')\n+        results = []\n+        n_trials = len(study.trials)\n+        failed_trials = []\n+        for trial in study.trials:\n+            data = {'index':trial.number, 'mismatch': trial.value}\n+            for key,val in trial.params.items():\n+                data[key] = val\n+            if data['mismatch'] is None:\n+                failed_trials.append(data['index'])\n+            else:\n+                results.append(data)\n+        if self.verbose: print(f'Processed {n_trials} trials; {len(failed_trials)} failed')\n+\n+        keys = ['index', 'mismatch'] + list(best.keys())\n+        data = sc.objdict().make(keys=keys, vals=[])\n+        for i,r in enumerate(results):\n+            for key in keys:\n+                if key not in r:\n+                    warnmsg = f'Key {key} is missing from trial {i}, replacing with default'\n+                    print(warnmsg)\n+                    r[key] = best[key]\n+                data[key].append(r[key])\n+        self.study_data = data\n+        self.df = sc.dataframe.from_dict(data)\n+        self.df = self.df.sort_values(by=['mismatch']) # Sort\n+        return\n+\n+    def to_json(self, filename=None, indent=2, **kwargs):\n+        \"\"\" Convert the results to JSON \"\"\"\n+        order = np.argsort(self.df['mismatch'])\n+        json = []\n+        for o in order:\n+            row = self.df.iloc[o,:].to_dict()\n+            rowdict = dict(index=row.pop('index'), mismatch=row.pop('mismatch'), pars={})\n+            for key,val in row.items():\n+                rowdict['pars'][key] = val\n+            json.append(rowdict)\n+        self.json = json\n+        if filename:\n+            return sc.savejson(filename, json, indent=indent, **kwargs)\n+        else:\n+            return json\n+\n+    def plot_sims(self, **kwargs):\n+        \"\"\"\n+        Plot sims, before and after calibration.\n+\n+        Args:\n+            kwargs (dict): passed to MultiSim.plot()\n+        \"\"\"\n+        if self.before_sim is None:\n+            self.confirm_fit()\n+        msim = ss.MultiSim([self.before_sim, self.after_sim])\n+        fig = msim.plot(**kwargs)\n+        return ss.return_fig(fig)\n+\n+    def plot_trend(self, best_thresh=None, fig_kw=None):\n+        \"\"\"\n+        Plot the trend in best mismatch over time.\n+\n+        Args:\n+            best_thresh (int): Define the threshold for the \"best\" fits, relative to the lowest mismatch value (if None, show all)\n+            fig_kw (dict): passed to plt.figure()\n+        \"\"\"\n+        df = self.df.sort_values('index') # Make a copy of the dataframe, sorted by trial number\n+        mismatch = sc.dcp(df['mismatch'].values)\n+        best_mismatch = np.zeros(len(mismatch))\n+        for i in range(len(mismatch)):\n+            best_mismatch[i] = mismatch[:i+1].min()\n+        smoothed_mismatch = sc.smooth(mismatch)\n+        fig = plt.figure(**sc.mergedicts(fig_kw))\n+\n+        ax1 = plt.subplot(2,1,1)\n+        plt.plot(mismatch, alpha=0.2, label='Original')\n+        plt.plot(smoothed_mismatch, lw=3, label='Smoothed')\n+        plt.plot(best_mismatch, lw=3, label='Best')\n+\n+        ax2 = plt.subplot(2,1,2)\n+        max_mismatch = mismatch.min()*best_thresh if best_thresh is not None else np.inf\n+        inds = sc.findinds(mismatch<=max_mismatch)\n+        plt.plot(best_mismatch, lw=3, label='Best')\n+        plt.scatter(inds, mismatch[inds], c=mismatch[inds], label='Trials')\n+        for ax in [ax1, ax2]:\n+            plt.sca(ax)\n+            plt.grid(True)\n+            plt.legend()\n+            sc.setylim()\n+            sc.setxlim()\n+            plt.xlabel('Trial number')\n+            plt.ylabel('Mismatch')\n+        sc.figlayout()\n+        return ss.return_fig(fig)\n\\ No newline at end of file\ndiff --git a/starsim/demographics.py b/starsim/demographics.py\nindex 56af1f8..fd981c0 100644\n--- a/starsim/demographics.py\n+++ b/starsim/demographics.py\n@@ -1,12 +1,14 @@\n \"\"\"\n Define pregnancy, deaths, migration, etc.\n \"\"\"\n-\n import numpy as np\n import starsim as ss\n import sciris as sc\n import pandas as pd\n \n+ss_float_ = ss.dtypes.float\n+ss_int_ = ss.dtypes.int\n+\n __all__ = ['Demographics', 'Births', 'Deaths', 'Pregnancy']\n \n \n@@ -16,35 +18,24 @@ class Demographics(ss.Module):\n     place at the start of the timestep, before networks are updated and before\n     any disease modules are executed.\n     \"\"\"\n-    def init_pre(self, sim):\n-        super().init_pre(sim)\n-        self.init_results()\n-        return\n-\n-    def init_results(self):\n-        pass\n-\n-    def update(self):\n-        pass\n-\n-    def update_results(self):\n-        pass\n+    pass\n \n \n class Births(Demographics):\n     \"\"\" Create births based on rates, rather than based on pregnancy \"\"\"\n     def __init__(self, pars=None, metadata=None, **kwargs):\n         super().__init__()\n-        self.default_pars(\n-            birth_rate = 30,\n+        self.define_pars(\n+            unit = 'year',\n+            birth_rate = ss.peryear(20),\n             rel_birth = 1,\n-            units = 1e-3,  # assumes birth rates are per 1000. If using percentages, switch this to 1\n+            rate_units = 1e-3,  # assumes birth rates are per 1000. If using percentages, switch this to 1\n         )\n         self.update_pars(pars, **kwargs)\n \n         # Process metadata. Defaults here are the labels used by UN data\n         self.metadata = sc.mergedicts(\n-            sc.objdict(data_cols=dict(year='Year', cbr='CBR')),\n+            sc.objdict(data_cols=dict(year='Year', value='CBR')),\n             metadata,\n         )\n \n@@ -60,45 +51,56 @@ class Births(Demographics):\n         if isinstance(self.pars.birth_rate, pd.DataFrame):\n             br_year = self.pars.birth_rate[self.metadata.data_cols['year']]\n             br_val = self.pars.birth_rate[self.metadata.data_cols['cbr']]\n-            all_birth_rates = np.interp(sim.yearvec, br_year, br_val)\n+            all_birth_rates = np.interp(self.timevec, br_year, br_val) # This assumes a year timestep -- probably ok?\n             self.pars.birth_rate = all_birth_rates\n         return\n \n     def standardize_birth_data(self):\n         \"\"\" Standardize/validate birth rates - handled in an external file due to shared functionality \"\"\"\n         birth_rate = ss.standardize_data(data=self.pars.birth_rate, metadata=self.metadata)\n+        if isinstance(birth_rate, (pd.Series, pd.DataFrame)):\n+            return birth_rate.xs(0,level='age')\n         return birth_rate\n \n     def init_results(self):\n-        npts = self.sim.npts\n-        self.results += [\n-            ss.Result(self.name, 'new', npts, dtype=int, scale=True),\n-            ss.Result(self.name, 'cumulative', npts, dtype=int, scale=True),\n-            ss.Result(self.name, 'cbr', npts, dtype=int, scale=False),\n-        ]\n+        super().init_results()\n+        self.define_results(\n+            ss.Result('new',        dtype=int,   scale=True,  label='New births'),\n+            ss.Result('cumulative', dtype=int,   scale=True,  label='Cumulative births'),\n+            ss.Result('cbr',        dtype=float, scale=False, label='Crude birth rate'),\n+        )\n         return\n \n-    def update(self):\n-        new_uids = self.add_births()\n-        self.n_births = len(new_uids)\n-        return new_uids\n-\n     def get_births(self):\n         \"\"\"\n         Extract the right birth rates to use and translate it into a number of people to add.\n         \"\"\"\n         sim = self.sim\n         p = self.pars\n-        if sc.isnumber(p.birth_rate):\n+\n+        if isinstance(p.birth_rate, (pd.Series, pd.DataFrame)):\n+            available_years = p.birth_rate.index\n+            year_ind = sc.findnearest(available_years, sim.t.now('year'))\n+            nearest_year = available_years[year_ind]\n+            this_birth_rate = p.birth_rate.loc[nearest_year]\n+        else:\n             this_birth_rate = p.birth_rate\n-        elif sc.checktype(p.birth_rate, 'arraylike'):\n-            this_birth_rate = p.birth_rate[sim.ti]\n \n-        scaled_birth_prob = this_birth_rate * p.units * p.rel_birth * sim.pars.dt\n+        if isinstance(this_birth_rate, ss.TimePar):\n+            factor = 1.0\n+        else:\n+            factor = ss.time_ratio(unit1=self.t.unit, dt1=self.t.dt, unit2='year', dt2=1.0)\n+\n+        scaled_birth_prob = this_birth_rate * p.rate_units * p.rel_birth * factor\n         scaled_birth_prob = np.clip(scaled_birth_prob, a_min=0, a_max=1)\n-        n_new = int(np.floor(sim.people.alive.count() * scaled_birth_prob))\n+        n_new = int(sc.randround(sim.people.alive.count() * scaled_birth_prob))\n         return n_new\n \n+    def step(self):\n+        new_uids = self.add_births()\n+        self.n_births = len(new_uids)\n+        return new_uids\n+\n     def add_births(self):\n         \"\"\" Add n_new births to each state in the sim \"\"\"\n         people = self.sim.people\n@@ -108,14 +110,19 @@ class Births(Demographics):\n         return new_uids\n \n     def update_results(self):\n-        self.results['new'][self.sim.ti] = self.n_births\n+        # New births -- already calculated\n+        self.results.new[self.ti] = self.n_births\n+\n+        # Calculate crude birth rate (CBR)\n+        inv_rate_units = 1.0/self.pars.rate_units\n+        births_per_year = self.n_births/self.sim.t.dt_year\n+        denom = self.sim.people.alive.sum()\n+        self.results.cbr[self.ti] = inv_rate_units*births_per_year/denom\n         return\n \n     def finalize(self):\n         super().finalize()\n-        res = self.sim.results\n-        self.results.cumulative = np.cumsum(self.results.new)\n-        self.results.cbr = 1/self.pars.units*np.divide(self.results.new/self.sim.dt, res.n_alive, where=res.n_alive>0)\n+        self.results.cumulative[:] = np.cumsum(self.results.new)\n         return\n \n \n@@ -142,17 +149,18 @@ class Deaths(Demographics):\n             pars: dict with arguments including:\n                 rel_death: constant used to scale all death rates\n                 death_rate: float, dict, or pandas dataframe/series containing mortality data\n-                units: units for death rates (see in-line comment on par dict below)\n+                rate_units: units for death rates (see in-line comment on par dict below)\n \n             metadata: data about the data contained within the data input.\n                 \"data_cols\" is is a dictionary mapping standard keys, like \"year\" to the\n                 corresponding column name in data. Similar for \"sex_keys\". Finally,\n         \"\"\"\n         super().__init__()\n-        self.default_pars(\n+        self.define_pars(\n+            unit = 'year',\n             rel_death = 1,\n-            death_rate = 20,  # Default = a fixed rate of 2%/year, overwritten if data provided\n-            units = 1e-3,  # assumes death rates are per 1000. If using percentages, switch this to 1\n+            death_rate = ss.peryear(20),  # Default = a fixed rate of 2%/year, overwritten if data provided\n+            rate_units = 1e-3,  # assumes death rates are per 1000. If using percentages, switch this to 1\n         )\n         self.update_pars(pars, **kwargs)\n \n@@ -160,7 +168,7 @@ class Deaths(Demographics):\n         self.metadata = sc.mergedicts(\n             sc.objdict(\n                 data_cols = dict(year='Time', sex='Sex', age='AgeGrpStart', value='mx'),\n-                sex_keys = dict(f='Female', m='Male'),\n+                sex_keys = {'Female':'f', 'Male':'m'},\n             ),\n             metadata\n         )\n@@ -171,86 +179,86 @@ class Deaths(Demographics):\n         self.pars.death_rate = ss.bernoulli(p=self.make_death_prob_fn)\n         self.n_deaths = 0 # For results tracking\n         return\n-    \n+\n     def standardize_death_data(self):\n         \"\"\" Standardize/validate death rates - handled in an external file due to shared functionality \"\"\"\n         death_rate = ss.standardize_data(data=self.pars.death_rate, metadata=self.metadata)\n+        if isinstance(death_rate, (pd.Series, pd.DataFrame)):\n+            death_rate = death_rate.unstack(level='age')\n+            assert not death_rate.isna().any(axis=None) # For efficiency, we assume that the age bins are the same for all years in the input dataset\n         return death_rate\n \n     @staticmethod # Needs to be static since called externally, although it sure looks like a class method!\n     def make_death_prob_fn(self, sim, uids):\n         \"\"\" Take in the module, sim, and uids, and return the probability of death for each UID on this timestep \"\"\"\n-\n         drd = self.death_rate_data\n-        if sc.isnumber(drd) or isinstance(drd, ss.Dist):\n+        if sc.isnumber(drd) or isinstance(drd, ss.TimePar):\n             death_rate = drd\n \n+        # Process data\n         else:\n             ppl = sim.people\n-            data_cols = sc.objdict(self.metadata.data_cols)\n-            year_label = data_cols.year\n-            age_label  = data_cols.age\n-            sex_label  = data_cols.sex\n-            val_label  = data_cols.value\n-            sex_keys = self.metadata.sex_keys\n-\n-            available_years = self.death_rate_data[year_label].unique()\n-            year_ind = sc.findnearest(available_years, sim.year)\n-            nearest_year = available_years[year_ind]\n \n-            df = self.death_rate_data.loc[self.death_rate_data[year_label] == nearest_year]\n-            age_bins = df[age_label].unique()\n+            # Performance optimization - the Deaths module checks for deaths for all agents\n+            # Therefore the UIDs requested should match all UIDs\n+            assert len(uids) == len(ppl.auids)\n \n-            f_arr = df[val_label].loc[df[sex_label] == sex_keys['f']].values\n-            m_arr = df[val_label].loc[df[sex_label] == sex_keys['m']].values\n+            available_years = drd.index.get_level_values('year')\n+            year_ind = sc.findnearest(available_years, sim.t.now('year')) # TODO: make work with different timesteps\n+            nearest_year = available_years[year_ind]\n \n-            # Initialize\n-            death_rate_df = pd.Series(index=uids)\n-            f_uids = uids.intersect(ppl.female.uids) # TODO: reduce duplication\n-            m_uids = uids.intersect(ppl.male.uids)\n-            f_age_inds = np.digitize(ppl.age[f_uids], age_bins) - 1\n-            m_age_inds = np.digitize(ppl.age[m_uids], age_bins) - 1\n-            death_rate_df[f_uids] = f_arr[f_age_inds]\n-            death_rate_df[m_uids] = m_arr[m_age_inds]\n-            unborn_inds = uids.intersect((sim.people.age < 0).uids)\n-            death_rate_df[unborn_inds] = 0  # Don't use background death rates for unborn babies\n+            death_rate = np.empty(uids.shape, dtype=ss_float_)\n \n-            death_rate = death_rate_df.values\n+            if 'sex' in drd.index.names:\n+                s = drd.loc[nearest_year, 'f']\n+                binned_ages = np.digitize(ppl.age[ppl.female], s.index)-1 # Negative ages will be in the first bin - do *not* subtract 1 so that this bin is 0\n+                death_rate[ppl.female] = s.values[binned_ages]\n+                s = drd.loc[nearest_year, 'm']\n+                binned_ages = np.digitize(ppl.age[ppl.male], s.index)-1 # Negative ages will be in the first bin - do *not* subtract 1 so that this bin is 0\n+                death_rate[ppl.male] = s.values[binned_ages]\n+            else:\n+                s = drd.loc[nearest_year]\n+                binned_ages = np.digitize(ppl.age, s.index)-1 # Negative ages will be in the first bin - do *not* subtract 1 so that this bin is 0\n+                death_rate[:] = s.values[binned_ages]\n \n         # Scale from rate to probability. Consider an exponential here.\n-        death_prob = death_rate * (self.pars.units * self.pars.rel_death * sim.pars.dt)\n+        if isinstance(death_rate, ss.TimePar):\n+            factor = self.t.dt # TODO: figure out why this isn't 1.0\n+        else:\n+            factor = ss.time_ratio(unit1=self.t.unit, dt1=self.t.dt, unit2='year', dt2=1.0)\n+        death_prob = death_rate * self.pars.rate_units * self.pars.rel_death * factor\n         death_prob = np.clip(death_prob, a_min=0, a_max=1)\n \n         return death_prob\n \n     def init_results(self):\n-        npts = self.sim.npts\n-        self.results += [\n-            ss.Result(self.name, 'new', npts, dtype=int, scale=True),\n-            ss.Result(self.name, 'cumulative', npts, dtype=int, scale=True),\n-            ss.Result(self.name, 'cmr', npts, dtype=int, scale=False),\n-        ]\n-        return\n-\n-    def update(self):\n-        self.n_deaths = self.apply_deaths()\n+        super().init_results()\n+        self.define_results(\n+            ss.Result('new',        dtype=int,   scale=True,  label='Deaths', auto_plot=False), # Use sim deaths instead\n+            ss.Result('cumulative', dtype=int,   scale=True,  label='Cumulative deaths', auto_plot=False),\n+            ss.Result('cmr',        dtype=float, scale=False, label='Crude mortality rate'),\n+        )\n         return\n \n-    def apply_deaths(self):\n+    def step(self):\n         \"\"\" Select people to die \"\"\"\n         death_uids = self.pars.death_rate.filter()\n         self.sim.people.request_death(death_uids)\n-        return len(death_uids)\n+        self.n_deaths = len(death_uids)\n+        return self.n_deaths\n \n     def update_results(self):\n-        self.results['new'][self.sim.ti] = self.n_deaths\n+        self.results['new'][self.ti] = self.n_deaths\n         return\n \n     def finalize(self):\n         super().finalize()\n-        n_alive = self.sim.results.n_alive\n-        self.results.cumulative = np.cumsum(self.results.new)\n-        self.results.cmr = 1/self.pars.units*np.divide(self.results.new / self.sim.dt, n_alive, where=n_alive>0)\n+        self.results.cumulative[:] = np.cumsum(self.results.new)\n+        units = self.pars.rate_units*self.sim.t.dt_year\n+        inds = self.match_time_inds()\n+        n_alive = self.sim.results.n_alive[inds]\n+        deaths = np.divide(self.results.new, n_alive, where=n_alive>0)\n+        self.results.cmr[:] = deaths/units\n         return\n \n \n@@ -258,30 +266,37 @@ class Pregnancy(Demographics):\n     \"\"\" Create births via pregnancies \"\"\"\n     def __init__(self, pars=None, metadata=None, **kwargs):\n         super().__init__()\n-        self.default_pars(\n-            dur_pregnancy = 0.75,   # Duration for pre-natal transmission\n-            dur_postpartum = ss.lognorm_ex(0.5, 0.5),   # Duration for post-natal transmission (e.g. via breastfeeding)\n-            fertility_rate = 0,     # See make_fertility_prob_function\n+        self.define_pars(\n+            unit = 'year',\n+            dur_pregnancy = ss.years(0.75), # Duration for pre-natal transmission\n+            dur_postpartum = ss.lognorm_ex(mean=ss.years(0.5), std=ss.years(0.5)), # Duration for post-natal transmission (e.g. via breastfeeding)\n+            fertility_rate = 0, # Can be a number of Pandas DataFrame\n             rel_fertility = 1,\n-            maternal_death_prob = ss.bernoulli(0),\n+            p_maternal_death = ss.bernoulli(0),\n+            p_neonatal_death = ss.bernoulli(0),\n             sex_ratio = ss.bernoulli(0.5), # Ratio of babies born female\n             min_age = 15, # Minimum age to become pregnant\n             max_age = 50, # Maximum age to become pregnant\n-            units = 1e-3, # Assumes fertility rates are per 1000. If using percentages, switch this to 1\n+            rate_units = 1e-3, # Assumes fertility rates are per 1000. If using percentages, switch this to 1\n+            burnin = True, # Should we seed pregnancies that would have happened before the start of the simulation?\n+            slot_scale = 5, # Random slots will be assigned to newborn agents between min=n_agents and max=slot_scale*n_agents\n+            min_slots  = 100, # Minimum number of slots, useful if the population size is very small\n         )\n         self.update_pars(pars, **kwargs)\n-        \n+\n+        self.pars.p_fertility = ss.bernoulli(p=0) # Placeholder, see make_fertility_prob_fn\n+\n         # Other, e.g. postpartum, on contraception...\n-        self.add_states(\n-            ss.BoolArr('infertile'),  # Applies to girls and women outside the fertility window\n-            ss.BoolArr('fecund', default=True),  # Applies to girls and women inside the fertility window\n-            ss.BoolArr('pregnant'),  # Currently pregnant\n-            ss.BoolArr('postpartum'),  # Currently post-partum\n-            ss.FloatArr('dur_postpartum'),  # Duration of postpartum phase\n-            ss.FloatArr('ti_pregnant'),  # Time pregnancy begins\n-            ss.FloatArr('ti_delivery'),  # Time of delivery\n-            ss.FloatArr('ti_postpartum'),  # Time postpartum ends\n-            ss.FloatArr('ti_dead'),  # Maternal mortality\n+        self.define_states(\n+            ss.State('fecund', default=True, label='Female of childbearing age'),\n+            ss.State('pregnant', label='Pregnant'),  # Currently pregnant\n+            ss.State('postpartum', label=\"Post-partum\"),  # Currently post-partum\n+            ss.FloatArr('child_uid', label='UID of children, from embryo through postpartum'),\n+            ss.FloatArr('dur_postpartum', label='Post-partum duration'),  # Duration of postpartum phase\n+            ss.FloatArr('ti_pregnant', label='Time of pregnancy'),  # Time pregnancy begins\n+            ss.FloatArr('ti_delivery', label='Time of delivery'),  # Time of delivery\n+            ss.FloatArr('ti_postpartum', label='Time post-partum ends'),  # Time postpartum ends\n+            ss.FloatArr('ti_dead', label='Time of maternal death'),  # Maternal mortality\n         )\n \n         # Process metadata. Defaults here are the labels used by UN data\n@@ -289,12 +304,7 @@ class Pregnancy(Demographics):\n             sc.objdict(data_cols=dict(year='Time', age='AgeGrp', value='ASFR')),\n             metadata,\n         )\n-        self.choose_slots = None # Distribution for choosing slots; set in self.initialize()\n-\n-        # Process data, which may be provided as a number, dict, dataframe, or series\n-        # If it's a number it's left as-is; otherwise it's converted to a dataframe\n-        self.fertility_rate_data = self.standardize_fertility_data()\n-        self.pars.fertility_rate = ss.bernoulli(self.make_fertility_prob_fn)\n+        self.choose_slots = None # Distribution for choosing slots; set in self.init()\n \n         # For results tracking\n         self.n_pregnancies = 0\n@@ -305,64 +315,75 @@ class Pregnancy(Demographics):\n     def make_fertility_prob_fn(self, sim, uids):\n         \"\"\" Take in the module, sim, and uids, and return the conception probability for each UID on this timestep \"\"\"\n \n-        if sc.isnumber(self.fertility_rate_data):\n-            fertility_rate = pd.Series(index=uids, data=self.fertility_rate_data)\n+        age = sim.people.age[uids]\n+\n+        frd = self.fertility_rate_data\n+        fertility_rate = np.zeros(len(sim.people.uid.raw), dtype=ss_float_)\n \n+        time_factor = ss.time_ratio(unit1=self.t.unit, dt1=self.t.dt, unit2='year', dt2=1.0)\n+        if sc.isnumber(frd):\n+            fertility_rate[uids] = self.fertility_rate_data\n+            if isinstance(frd, ss.TimePar):\n+                time_factor = 1 # Time conversion performed automatically by TimePar\n         else:\n-            # Abbreviate key variables\n-            data_cols = sc.objdict(self.metadata.data_cols)\n-            year_label = data_cols.year\n-            age_label  = data_cols.age\n-            val_label  = data_cols.value\n-\n-            available_years = self.fertility_rate_data[year_label].unique()\n-            year_ind = sc.findnearest(available_years, sim.year-self.pars.dur_pregnancy)\n-            nearest_year = available_years[year_ind]\n+            year_ind = sc.findnearest(frd.index, self.t.now('year')-self.pars.dur_pregnancy.to('year')) # TODO: make time-unit-aware\n+            nearest_year = frd.index[year_ind]\n+\n+            # Assign agents to age bins\n+            age_bins = self.fertility_rate_data.columns.values\n+            age_bin_all = np.digitize(age, age_bins) - 1\n+            new_rate = self.fertility_rate_data.loc[nearest_year].values.copy()  # Initialize array with new rates\n \n-            df = self.fertility_rate_data.loc[self.fertility_rate_data[year_label] == nearest_year]\n-            df_arr = df[val_label].values  # Pull out dataframe values\n-            df_arr = np.append(df_arr, 0)  # Add zeros for those outside data range\n-\n-            # Process age data\n-            age_bins = df[age_label].unique()\n-            age_bins = np.append(age_bins, age_bins[-1]+1) # WARNING: Assumes one year age bins! TODO: More robust handling.\n-            age_inds = np.digitize(sim.people.age[uids], age_bins) - 1\n-            age_inds[age_inds == len(age_bins)-1] = -1  # This ensures women outside the data range will get a value of 0\n-\n-            # Adjust rates: rates are based on the entire population, but we need to remove\n-            # anyone already pregnant and then inflate the rates for the remainder\n-            pregnant_uids = self.pregnant.uids # Find agents who are already pregnant\n-            pregnant_age_counts, _ = np.histogram(sim.people.age[pregnant_uids], age_bins)  # Count them by age\n-            age_counts, _ = np.histogram(sim.people.age[uids], age_bins)  # Count overall number per age bin\n-            new_denom = age_counts - pregnant_age_counts  # New denominator for rates\n-            num_to_make = df_arr[:-1]*age_counts  # Number that we need to make pregnant\n-            new_percent = sc.dcp(df_arr)  # Initialize array with new rates\n-            inds_to_rescale = new_denom > 0  # Rescale any non-zero age bins\n-            new_percent[:-1][inds_to_rescale] = num_to_make[inds_to_rescale] / new_denom[inds_to_rescale]  # New rates\n-\n-            # Make array of fertility rates\n-            fertility_rate = pd.Series(index=uids)\n-            fertility_rate[uids] = new_percent[age_inds]\n+            if (~self.fecund).any():\n+                # Scale the new rate to convert the denominator from all women to fecund women\n+                v, c = np.unique(age_bin_all, return_counts=True)\n+                age_counts = np.zeros(len(age_bins))\n+                age_counts[v] = c\n+\n+                age_bin_infecund = np.digitize(sim.people.age[~self.fecund], age_bins) - 1\n+                v, c = np.unique(age_bin_infecund, return_counts=True)\n+                infecund_age_counts = np.zeros(len(age_bins))\n+                infecund_age_counts[v] = c\n+\n+                num_to_make = new_rate * age_counts  # Number that we need to make pregnant\n+                new_denom = age_counts - infecund_age_counts  # New denominator for rates\n+                np.divide(num_to_make, new_denom, where=new_denom>0, out=new_rate)\n+\n+            fertility_rate[uids] = new_rate[age_bin_all]\n \n         # Scale from rate to probability\n-        age = self.sim.people.age[uids]\n         invalid_age = (age < self.pars.min_age) | (age > self.pars.max_age)\n-        fertility_prob = fertility_rate * (self.pars.units * self.pars.rel_fertility * sim.pars.dt)\n-        fertility_prob[self.pregnant.uids] = 0 # Currently pregnant women cannot become pregnant again\n+        fertility_prob = fertility_rate * (self.pars.rate_units * self.pars.rel_fertility) * time_factor\n+        fertility_prob[(~self.fecund).uids] = 0 # Currently infecund women cannot become pregnant\n         fertility_prob[uids[invalid_age]] = 0 # Women too young or old cannot become pregnant\n-        fertility_prob = np.clip(fertility_prob, a_min=0, a_max=1)\n-\n+        fertility_prob = np.clip(fertility_prob[uids], a_min=0, a_max=1)\n         return fertility_prob\n \n     def standardize_fertility_data(self):\n-        \"\"\" Standardize/validate fertility rates - handled in an external file due to shared functionality \"\"\"\n+        \"\"\"\n+        Standardize/validate fertility rates\n+        \"\"\"\n         fertility_rate = ss.standardize_data(data=self.pars.fertility_rate, metadata=self.metadata)\n+        if isinstance(fertility_rate, (pd.Series, pd.DataFrame)):\n+            fertility_rate = fertility_rate.unstack()\n+            # Interpolate to 1 year increments\n+            fertility_rate = fertility_rate.reindex(np.arange(fertility_rate.index.min(), fertility_rate.index.max() + 1)).interpolate()\n+            max_age = fertility_rate.columns.max()\n+            fertility_rate[max_age + 1] = 0\n+            assert not fertility_rate.isna().any(axis=None) # For efficiency, we assume that the age bins are the same for all years in the input dataset\n         return fertility_rate\n \n     def init_pre(self, sim):\n         super().init_pre(sim)\n+\n+        # Process data, which may be provided as a number, dict, dataframe, or series\n+        # If it's a number it's left as-is; otherwise it's converted to a dataframe\n+        self.fertility_rate_data = self.standardize_fertility_data()\n+        self.pars.p_fertility.set(p=self.make_fertility_prob_fn)\n+\n         low = sim.pars.n_agents + 1\n-        high = int(sim.pars.slot_scale*sim.pars.n_agents)\n+        high = int(self.pars.slot_scale*sim.pars.n_agents)\n+        high = np.maximum(high, self.pars.min_slots) # Make sure there are at least min_slots slots to avoid artifacts related to small populations\n         self.choose_slots = ss.randint(low=low, high=high, sim=sim, module=self)\n         return\n \n@@ -372,26 +393,36 @@ class Pregnancy(Demographics):\n         Still unclear whether this logic should live in the pregnancy module, the\n         individual disease modules, the connectors, or the sim.\n         \"\"\"\n-        npts = self.sim.npts\n-        self.results += [\n-            ss.Result(self.name, 'pregnancies', npts, dtype=int, scale=True),\n-            ss.Result(self.name, 'births', npts, dtype=int, scale=True),\n-            ss.Result(self.name, 'cbr', npts, dtype=int, scale=False),\n-        ]\n+        super().init_results()\n+        self.define_results(\n+            ss.Result('pregnancies', dtype=int,   scale=True,  label='New pregnancies'),\n+            ss.Result('births',      dtype=int,   scale=True,  label='New births'),\n+            ss.Result('cbr',         dtype=float, scale=False, label='Crude birth rate'),\n+        )\n         return\n \n-    def update(self):\n+    def step(self):\n+        if self.ti == 0 and self.pars.burnin: # TODO: refactor\n+            dtis = np.arange(np.ceil(-1 * self.pars.dur_pregnancy), 0, 1).astype(int)\n+            for dti in dtis:\n+                self.t.ti = dti\n+                self.do_step()\n+            self.t.ti = 0\n+        new_uids = self.do_step()\n+        return new_uids\n+\n+    def do_step(self):\n         \"\"\" Perform all updates \"\"\"\n         self.update_states()\n         conceive_uids = self.make_pregnancies()\n-        self.n_pregnancies = len(conceive_uids)\n-        self.make_embryos(conceive_uids)\n-        return\n+        self.n_pregnancies += len(conceive_uids) # += to handle burn-in\n+        new_uids = self.make_embryos(conceive_uids)\n+        return new_uids\n \n     def update_states(self):\n         \"\"\" Update states \"\"\"\n         # Check for new deliveries\n-        ti = self.sim.ti\n+        ti = self.ti\n         deliveries = self.pregnant & (self.ti_delivery <= ti)\n         self.n_births = np.count_nonzero(deliveries)\n         self.pregnant[deliveries] = False\n@@ -407,27 +438,28 @@ class Pregnancy(Demographics):\n                 prenatalnet = [nw for nw in self.sim.networks.values() if nw.prenatal][0]\n \n                 # Find the prenatal connections that are ending\n-                prenatal_ending = prenatalnet.edges.end<=self.sim.ti\n+                prenatal_ending = prenatalnet.edges.end <= ti\n                 new_mother_uids = prenatalnet.edges.p1[prenatal_ending]\n                 new_infant_uids = prenatalnet.edges.p2[prenatal_ending]\n \n                 # Validation\n-                if not np.array_equal(new_mother_uids, deliveries.uids):\n-                    errormsg = f'IDs of new mothers do not match IDs of new deliveries.'\n+                if not set(new_mother_uids) == set(deliveries.uids): # Not sure why sometimes out of order\n+                    errormsg = 'IDs of new mothers do not match IDs of new deliveries'\n                     raise ValueError(errormsg)\n \n                 # Create durations and start dates, and add connections\n                 durs = self.dur_postpartum[new_mother_uids]\n-                start = np.full(self.n_births, fill_value=self.sim.ti)\n+                start = np.full(self.n_births, fill_value=ti)\n \n                 # # Remove pairs from prenatal network and add to postnatal\n                 prenatalnet.end_pairs()\n                 layer.add_pairs(new_mother_uids, new_infant_uids, dur=durs, start=start)\n \n         # Check for new women emerging from post-partum\n-        postpartum = ~self.pregnant & (self.ti_postpartum <= ti)\n+        postpartum = self.postpartum & (self.ti_postpartum <= ti)\n         self.postpartum[postpartum] = False\n         self.fecund[postpartum] = True\n+        self.child_uid[postpartum] = np.nan\n \n         # Maternal deaths\n         maternal_deaths = (self.ti_dead <= ti).uids\n@@ -439,17 +471,19 @@ class Pregnancy(Demographics):\n         # People eligible to become pregnant. We don't remove pregnant people here, these\n         # are instead handled in the fertility_dist logic as the rates need to be adjusted\n         eligible_uids = self.sim.people.female.uids\n-        conceive_uids = self.pars.fertility_rate.filter(eligible_uids)\n+        conceive_uids = self.pars.p_fertility.filter(eligible_uids)\n+\n+        if len(conceive_uids) == 0:\n+            return ss.uids()\n \n         # Validation\n         if np.any(self.pregnant[conceive_uids]):\n             which_uids = conceive_uids[self.pregnant[conceive_uids]]\n-            errormsg = f'New conceptions registered in {len(which_uids)} pregnant agent(s) at timestep {self.sim.ti}.'\n+            errormsg = f'New conceptions registered in {len(which_uids)} pregnant agent(s) at timestep {self.ti}.'\n             raise ValueError(errormsg)\n \n         # Set prognoses for the pregnancies\n-        if len(conceive_uids) > 0:\n-            self.set_prognoses(conceive_uids)\n+        self.set_prognoses(conceive_uids)\n         return conceive_uids\n \n     def make_embryos(self, conceive_uids):\n@@ -465,17 +499,22 @@ class Pregnancy(Demographics):\n \n             # Grow the arrays and set properties for the unborn agents\n             new_uids = people.grow(len(new_slots), new_slots)\n-            people.age[new_uids] = -self.pars.dur_pregnancy\n+            people.age[new_uids] = -self.pars.dur_pregnancy.to('year')\n             people.slot[new_uids] = new_slots  # Before sampling female_dist\n             people.female[new_uids] = self.pars.sex_ratio.rvs(conceive_uids)\n+            people.parent[new_uids] = conceive_uids\n+            self.child_uid[conceive_uids] = new_uids\n \n             # Add connections to any prenatal transmission layers\n             for lkey, layer in self.sim.networks.items():\n                 if layer.prenatal:\n                     durs = np.full(n_unborn, fill_value=self.pars.dur_pregnancy)\n-                    start = np.full(n_unborn, fill_value=self.sim.ti)\n+                    start = np.full(n_unborn, fill_value=self.ti)\n                     layer.add_pairs(conceive_uids, new_uids, dur=durs, start=start)\n \n+        if self.ti < 0:\n+            people.age[new_uids] += -self.ti * self.sim.t.dt_year # Age to ti=0\n+\n         return new_uids\n \n     def set_prognoses(self, uids):\n@@ -487,32 +526,66 @@ class Pregnancy(Demographics):\n         \"\"\"\n \n         # Change states for the newly pregnant woman\n-        ti = self.sim.ti\n-        dt = self.sim.dt\n+        ti = self.ti\n         self.fecund[uids] = False\n         self.pregnant[uids] = True\n         self.ti_pregnant[uids] = ti\n \n         # Outcomes for pregnancies\n-        dur_preg = np.full(len(uids), self.pars.dur_pregnancy)  # Duration in years\n+        dur_preg = np.ones(len(uids))*self.pars.dur_pregnancy\n         dur_postpartum = self.pars.dur_postpartum.rvs(uids)\n-        dead = self.pars.maternal_death_prob.rvs(uids)\n-        self.ti_delivery[uids] = ti + dur_preg/dt # Currently assumes maternal deaths still result in a live baby\n-        self.ti_postpartum[uids] = self.ti_delivery[uids] + dur_postpartum/dt\n+        dead = self.pars.p_maternal_death.rvs(uids)\n+        self.ti_delivery[uids] = ti + dur_preg # Currently assumes maternal deaths still result in a live baby\n+        self.ti_postpartum[uids] = self.ti_delivery[uids] + dur_postpartum\n         self.dur_postpartum[uids] = dur_postpartum\n \n         if np.any(dead): # NB: 100x faster than np.sum(), 10x faster than np.count_nonzero()\n             self.ti_dead[uids[dead]] = ti + dur_preg[dead]\n         return\n \n+    def finish_step(self):\n+        super().finish_step()\n+        death_uids = ss.uids(self.sim.people.ti_dead <= self.ti)\n+        if len(death_uids) == 0:\n+            return\n+\n+        # Any pregnant? Consider death of the neonate\n+        mother_death_uids = death_uids[self.pregnant[death_uids]]\n+        if len(mother_death_uids):\n+            neonate_uids = ss.uids(self.child_uid[mother_death_uids])\n+            neonatal_death_uids = self.pars.p_neonatal_death.filter(neonate_uids)\n+            if len(neonatal_death_uids):\n+                self.sim.people.request_death(neonatal_death_uids)\n+\n+        # Any prenatal? Handle changes to pregnancy\n+        is_prenatal = self.sim.people.age[death_uids] < 0\n+        prenatal_death_uids = death_uids[is_prenatal]\n+        if len(prenatal_death_uids):\n+            mother_uids = self.sim.people.parent[prenatal_death_uids]\n+            self.pregnant[mother_uids] = False # Baby lost, mother no longer pregnant\n+            self.fecund[mother_uids] = True # Or wait?\n+            self.postpartum[mother_uids] = False\n+            self.child_uid[mother_uids] = np.nan\n+            self.ti_delivery[mother_uids] = np.nan\n+            self.ti_postpartum[mother_uids] = np.nan\n+        return\n+\n     def update_results(self):\n-        ti = self.sim.ti\n+        ti = self.ti\n         self.results['pregnancies'][ti] = self.n_pregnancies\n         self.results['births'][ti] = self.n_births\n+\n+        # Reset for the next step\n+        self.n_pregnancies = 0\n+        self.n_births = 0\n+\n         return\n \n     def finalize(self):\n         super().finalize()\n-        n_alive = self.sim.results.n_alive\n-        self.results['cbr'] = 1/self.pars.units * np.divide(self.results['births'] / self.sim.dt, n_alive, where=n_alive>0)\n+        units = self.pars.rate_units*self.sim.t.dt_year\n+        inds = self.match_time_inds()\n+        n_alive = self.sim.results.n_alive[inds]\n+        births = np.divide(self.results['births'], n_alive, where=n_alive>0)\n+        self.results['cbr'][:] = births/units\n         return\ndiff --git a/starsim/disease.py b/starsim/disease.py\nindex 21fd504..e340b34 100644\n--- a/starsim/disease.py\n+++ b/starsim/disease.py\n@@ -1,7 +1,6 @@\n \"\"\"\n Base classes for diseases\n \"\"\"\n-\n import numpy as np\n import sciris as sc\n import starsim as ss\n@@ -9,56 +8,67 @@ import networkx as nx\n from operator import itemgetter\n import pandas as pd\n \n+ss_int_ = ss.dtypes.int\n+\n __all__ = ['Disease', 'Infection', 'InfectionLog']\n \n \n class Disease(ss.Module):\n     \"\"\" Base module class for diseases \"\"\"\n \n-    def __init__(self, log=True, *args, **kwargs):\n+    def __init__(self, pars=None, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n+        self.define_pars(\n+            log = False,\n+        )\n+        self.update_pars(pars, **kwargs)\n         self.results = ss.Results(self.name)\n-        self.log = InfectionLog() if log else None  # See below for definition\n         return\n \n     @property\n-    def _boolean_states(self):\n+    def _disease_states(self):\n         \"\"\"\n-        Iterator over states with boolean type\n+        Iterator over disease states with boolean type\n \n         For diseases, these states typically represent attributes like 'susceptible',\n-        'infectious', 'diagnosed' etc. These variables are typically useful to\n+        'infectious', 'diagnosed' etc. These variables are typically useful to store\n+        results for.\n         \"\"\"\n         for state in self.states:\n-            if state.dtype == bool:\n+            if isinstance(state, ss.State):\n                 yield state\n         return\n \n     def init_pre(self, sim):\n         \"\"\" Link the disease to the sim, create objects, and initialize results; see Module.init_pre() for details \"\"\"\n         super().init_pre(sim)\n-        self.init_results()\n+        if self.pars.log:\n+            self.log = InfectionLog()\n         return\n \n     def init_results(self):\n         \"\"\"\n         Initialize results\n \n-        By default, diseases all report on counts for any boolean states e.g., if\n+        By default, diseases all report on counts for any explicitly defined \"States\", e.g. if\n         a disease contains a boolean state 'susceptible' it will automatically contain a\n-        Result for 'n_susceptible'\n+        Result for 'n_susceptible'.\n         \"\"\"\n-        for state in self._boolean_states:\n-            self.results += ss.Result(self.name, f'n_{state.name}', self.sim.npts, dtype=int, scale=True)\n+        super().init_results()\n+        results = sc.autolist()\n+        for state in self._disease_states:\n+            results += ss.Result(f'n_{state.name}', dtype=int, scale=True, label=state.label)\n+        self.define_results(*results)\n         return\n \n-    def update_pre(self):\n+    def step_state(self):\n         \"\"\"\n-        Carry out autonomous updates at the start of the timestep (prior to transmission)\n+        Carry out updates at the start of the timestep (prior to transmission);\n+        these are typically state changes\n         \"\"\"\n         pass\n \n-    def update_death(self, uids):\n+    def step_die(self, uids):\n         \"\"\"\n         Carry out state changes upon death\n \n@@ -70,14 +80,18 @@ class Disease(ss.Module):\n         to undo any state changes that have already been applied (because they only run via this\n         function if the death actually occurs).\n \n+        Unlike other methods during the integration loop, this method is not called directly\n+        by the sim; instead, it is called by people.step_die(), which reconciles the UIDs of\n+        the agents who will die.\n+\n         Depending on the module and the results it produces, it may or may not be necessary\n         to implement this.\n         \"\"\"\n         pass\n \n-    def make_new_cases(self):\n+    def step(self):\n         \"\"\"\n-        Add new cases of the disease\n+        Handle the main disease updates, e.g. add new cases\n \n         This method is agnostic as to the mechanism by which new cases occur. This\n         could be through transmission (parametrized in different ways, which may or\n@@ -89,16 +103,17 @@ class Disease(ss.Module):\n         \"\"\"\n         pass\n \n-    def set_prognoses(self, uids, source_uids=None):\n+    def set_prognoses(self, uids, sources=None):\n         \"\"\"\n         Set prognoses upon infection/acquisition\n \n         This function assigns state values upon infection or acquisition of\n         the disease. It would normally be called somewhere towards the end of\n-        `Disease.make_new_cases()`. Infections will automatically be added to\n-        the log as part of this operation.\n+        `Disease.make_new_cases()`. Infections will optionally be added to\n+        the log as part of this operation if logging is enabled (in the\n+        `Disease` parameters)\n \n-        The from_uids are relevant for infectious diseases, but would be left\n+        The `sources` are relevant for infectious diseases, but would be left\n         as `None` for NCDs.\n \n         Args:\n@@ -106,14 +121,13 @@ class Disease(ss.Module):\n             uids (array): UIDs for agents to assign disease progoses to\n             from_uids (array): Optionally specify the infecting agent\n         \"\"\"\n-        if self.log is not None:\n-            sim = self.sim\n-            if source_uids is None:\n-                for target in uids:\n-                    self.log.append(np.nan, target, sim.year)\n-            else:\n-                for target, source in zip(uids, source_uids):\n-                    self.log.append(source, target, sim.year)\n+        # Track infections\n+        if self.pars.log:\n+            self.log_infections(uids, sources)\n+        return\n+\n+    def log_infections(self, uids, sources=None):\n+        self.log.add_entries(uids, sources, self.now)\n         return\n \n     def update_results(self):\n@@ -124,9 +138,8 @@ class Disease(ss.Module):\n         This allows result updates at this point to capture outcomes dependent on multiple\n         modules, where relevant.\n         \"\"\"\n-        sim = self.sim\n-        for state in self._boolean_states:\n-            self.results[f'n_{state.name}'][sim.ti] = np.count_nonzero(state & sim.people.alive)\n+        for state in self._disease_states:\n+            self.results[f'n_{state.name}'][self.ti] = state.sum()\n         return\n \n \n@@ -139,47 +152,28 @@ class Infection(Disease):\n     operate on to capture co-infection\n     \"\"\"\n \n-    def __init__(self, *args, **kwargs):\n+    def __init__(self, pars=None, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n-        self.add_states(\n-            ss.BoolArr('susceptible', default=True),\n-            ss.BoolArr('infected'),\n-            ss.FloatArr('rel_sus', default=1.0),\n-            ss.FloatArr('rel_trans', default=1.0),\n-            ss.FloatArr('ti_infected'),\n+        self.define_states(\n+            ss.State('susceptible', default=True, label='Susceptible'),\n+            ss.State('infected', label='Infectious'),\n+            ss.FloatArr('rel_sus', default=1.0, label='Relative susceptibility'),\n+            ss.FloatArr('rel_trans', default=1.0, label='Relative transmission'),\n+            ss.FloatArr('ti_infected', label='Time of infection' ),\n+        )\n+\n+        self.define_pars(\n+            init_prev = None, # Replace None with a ss.bernoulli to seed infections\n         )\n+        self.update_pars(pars, **kwargs)\n \n-        # Define random number generators for make_new_cases\n-        self.rng_target = ss.random(name='target')\n-        self.rng_source = ss.random(name='source')\n+        # Define random number generator for determining transmission\n+        self.trans_rng = ss.multi_random('source', 'target')\n         return\n-    \n+\n     def init_pre(self, sim):\n         super().init_pre(sim)\n-        self.validate_beta()\n-        return\n-    \n-    def validate_beta(self):\n-        \"\"\"\n-        Perform any parameter validation\n-        \"\"\"\n-        networks = self.sim.networks\n-        if networks is not None and len(networks) > 0:\n-            \n-            if 'beta' not in self.pars:\n-                errormsg = f'Disease {self.name} is missing beta; pars are: {sc.strjoin(self.pars.keys())}'\n-                raise sc.KeyNotFoundError(errormsg)\n-\n-            # If beta is a scalar, apply this bi-directionally to all networks\n-            if sc.isnumber(self.pars.beta):\n-                β = self.pars.beta\n-                self.pars.beta = sc.objdict({k:[β,β] for k in networks.keys()})\n-\n-            # If beta is a dict, check all entries are bi-directional\n-            elif isinstance(self.pars.beta, dict):\n-                for k,β in self.pars.beta.items():\n-                    if sc.isnumber(β):\n-                        self.pars.beta[k] = [β,β]\n+        self.validate_beta(run_checks=True)\n         return\n \n     @property\n@@ -197,127 +191,163 @@ class Infection(Disease):\n         i.e., creating their dynamic array, linking them to a People instance. That should have already\n         taken place by the time this method is called.\n         \"\"\"\n+        super().init_post()\n         if self.pars.init_prev is None:\n             return\n \n         initial_cases = self.pars.init_prev.filter()\n-        self.set_prognoses(initial_cases)  # TODO: sentinel value to indicate seeds?\n-        return\n+        if len(initial_cases):\n+            self.set_prognoses(initial_cases)  # TODO: sentinel value to indicate seeds?\n+\n+        # Exclude initial cases from results -- disabling for now since it disrupts counting of new infections, e.g. test_diseases.py\n+        # self.ti_infected[self.ti_infected == self.ti] = -1\n+        return initial_cases\n \n     def init_results(self):\n         \"\"\"\n         Initialize results\n         \"\"\"\n         super().init_results()\n-        sim = self.sim\n-        self.results += [\n-            ss.Result(self.name, 'prevalence',     sim.npts, dtype=float, scale=False),\n-            ss.Result(self.name, 'new_infections', sim.npts, dtype=int, scale=True),\n-            ss.Result(self.name, 'cum_infections', sim.npts, dtype=int, scale=True),\n-        ]\n+        self.define_results(\n+            ss.Result('prevalence',     dtype=float, scale=False, label='Prevalence'),\n+            ss.Result('new_infections', dtype=int,   scale=True,  label='New infections'),\n+            ss.Result('cum_infections', dtype=int,   scale=True,  label='Cumulative infections'),\n+        )\n         return\n \n-    def _check_betas(self):\n-        \"\"\" Check that there's a network for each beta key \"\"\"\n-        # Ensure keys are lowercase\n-        if isinstance(self.pars.beta, dict): # TODO: check if needed\n-            self.pars.beta = {k.lower(): v for k, v in self.pars.beta.items()}\n-\n-        # Create a mapping between beta and networks, and populate it\n-        betapars = self.pars.beta\n-        betamap = sc.objdict()\n-        netkeys = list(self.sim.networks.keys())\n-        if netkeys: # Skip if no networks\n-            for bkey in betapars.keys():\n-                orig_bkey = bkey[:]\n-                if bkey in netkeys: # TODO: CK: could tidy up logic\n-                    betamap[bkey] = betapars[orig_bkey]\n+    def validate_beta(self, run_checks=False):\n+        \"\"\" Validate beta and return as a map to match the networks \"\"\"\n+        sim = self.sim\n+        β = self.pars.beta\n+\n+        def scalar_beta(β):\n+            return isinstance(β, ss.TimePar) or sc.isnumber(β)\n+\n+        if run_checks:\n+            scalar_warn = f'Beta is defined as a number ({β}); convert it to a rate to handle timestep conversions'\n+\n+            if 'beta' not in self.pars:\n+                errormsg = f'Disease {self.name} is missing beta; pars are: {sc.strjoin(self.pars.keys())}'\n+                raise sc.KeyNotFoundError(errormsg)\n+\n+            if sc.isnumber(β):\n+                ss.warn(scalar_warn)\n+            elif isinstance(β, dict):\n+                for netbeta in β.values():\n+                    if sc.isnumber(netbeta):\n+                        ss.warn(scalar_warn)\n+                    elif isinstance(netbeta, (list, tuple)):\n+                        for thisbeta in netbeta:\n+                            if sc.isnumber(netbeta):\n+                                ss.warn(scalar_warn)\n+\n+        # If beta is a scalar, apply this bi-directionally to all networks\n+        if scalar_beta(β):\n+            betamap = {ss.standardize_netkey(k):[β,β] for k in sim.networks.keys()}\n+\n+        # If beta is a dict, check all entries are bi-directional\n+        elif isinstance(β, dict):\n+            betamap = dict()\n+            for k,thisbeta in β.items():\n+                nkey = ss.standardize_netkey(k)\n+                if scalar_beta(thisbeta):\n+                    betamap[nkey] = [thisbeta, thisbeta]\n                 else:\n-                    if 'net' not in bkey:\n-                        bkey += 'net'  # Add 'net' suffix if not already there\n-                    if bkey in netkeys:\n-                        betamap[bkey] = betapars[orig_bkey]\n-                    else:\n-                        errormsg = f'No network for beta parameter \"{bkey}\"; your beta should match network keys:\\n{sc.newlinejoin(netkeys)}'\n-                        raise ValueError(errormsg)\n+                    betamap[nkey] = thisbeta\n+\n+        else:\n+            errormsg = f'Invalid type {type(β)} for beta'\n+            raise TypeError(errormsg)\n+\n+        # Check that it matches the network\n+        netkeys = [ss.standardize_netkey(k) for k in list(sim.networks.keys())]\n+        if set(betamap.keys()) != set(netkeys):\n+            errormsg = f'Network keys ({netkeys}) and beta keys ({betamap.keys()}) do not match'\n+            raise ValueError(errormsg)\n+\n         return betamap\n \n-    def make_new_cases(self):\n+    def step(self):\n         \"\"\"\n-        Add new cases of module, through transmission, incidence, etc.\n-        \n-        Common-random-number-safe transmission code works by mapping edges onto\n-        slots.\n+        Perform key infection updates, including infection and setting prognoses\n         \"\"\"\n+        # Create new cases\n+        new_cases, sources, networks = self.infect() # TODO: store outputs in self or use objdict rather than 3 returns\n+\n+        # Set prognoses\n+        if len(new_cases):\n+            self.set_outcomes(new_cases, sources)\n+\n+        return new_cases, sources, networks\n+\n+    @staticmethod # In future, consider: @nb.njit(fastmath=True, parallel=True, cache=True), but no faster it seems\n+    def compute_transmission(src, trg, rel_trans, rel_sus, beta_per_dt, randvals):\n+        \"\"\" Compute the probability of a->b transmission \"\"\"\n+        p_transmit = rel_trans[src] * rel_sus[trg] * beta_per_dt\n+        transmitted = p_transmit > randvals\n+        target_uids = trg[transmitted]\n+        source_uids = src[transmitted]\n+        return target_uids, source_uids\n+\n+    def infect(self):\n+        \"\"\" Determine who gets infected on this timestep via transmission on the network \"\"\"\n         new_cases = []\n         sources = []\n-        betamap = self._check_betas()\n-\n-        for nkey,net in self.sim.networks.items():\n-            if not len(net):\n-                break\n-\n-            nbetas = betamap[nkey]\n-            edges = net.edges\n-\n-            rel_trans = self.rel_trans.asnew(self.infectious * self.rel_trans)\n-            rel_sus   = self.rel_sus.asnew(self.susceptible * self.rel_sus)\n-            p1p2b0 = [edges.p1, edges.p2, nbetas[0]]\n-            p2p1b1 = [edges.p2, edges.p1, nbetas[1]]\n-            for src, trg, beta in [p1p2b0, p2p1b1]:\n-\n-                # Skip networks with no transmission\n-                if beta == 0:\n-                    continue\n-\n-                # Calculate probability of a->b transmission.\n-                beta_per_dt = net.beta_per_dt(disease_beta=beta, dt=self.sim.dt)\n-                p_transmit = rel_trans[src] * rel_sus[trg] * beta_per_dt\n-\n-                # Generate a new random number based on the two other random numbers -- 3x faster than `rvs = np.remainder(rvs_s + rvs_t, 1)`\n-                rvs_s = self.rng_source.rvs(src)\n-                rvs_t = self.rng_target.rvs(trg)\n-                rvs = rvs_s + rvs_t\n-                inds = np.where(rvs>1.0)[0]\n-                rvs[inds] -= 1\n-                \n-                new_cases_bool = rvs < p_transmit\n-                new_cases.append(trg[new_cases_bool])\n-                sources.append(src[new_cases_bool])\n-                \n-        # Tidy up\n+        networks = []\n+        betamap = self.validate_beta()\n+\n+        rel_trans = self.rel_trans.asnew(self.infectious * self.rel_trans)\n+        rel_sus   = self.rel_sus.asnew(self.susceptible * self.rel_sus)\n+\n+        for i, (nkey,net) in enumerate(self.sim.networks.items()):\n+            nk = ss.standardize_netkey(nkey)\n+            if isinstance(net, ss.Network) and len(net): # Skip networks with no edges\n+                edges = net.edges\n+                p1p2b0 = [edges.p1, edges.p2, betamap[nk][0]] # Person 1, person 2, beta 0\n+                p2p1b1 = [edges.p2, edges.p1, betamap[nk][1]] # Person 2, person 1, beta 1\n+                for src, trg, beta in [p1p2b0, p2p1b1]:\n+                    if beta: # Skip networks with no transmission\n+                        beta_per_dt = net.net_beta(disease_beta=beta) # Compute beta for this network and timestep\n+                        randvals = self.trans_rng.rvs(src, trg) # Generate a new random number based on the two other random numbers\n+                        args = (src, trg, rel_trans, rel_sus, beta_per_dt, randvals) # Set up the arguments to calculate transmission\n+                        target_uids, source_uids = self.compute_transmission(*args) # Actually calculate it\n+                        new_cases.append(target_uids)\n+                        sources.append(source_uids)\n+                        networks.append(np.full(len(target_uids), dtype=ss_int_, fill_value=i))\n+\n+        # Finalize\n         if len(new_cases) and len(sources):\n             new_cases = ss.uids.cat(new_cases)\n-            sources = ss.uids.cat(sources)\n+            new_cases, inds = new_cases.unique(return_index=True)\n+            sources = ss.uids.cat(sources)[inds]\n+            networks = np.concatenate(networks)[inds]\n         else:\n-            new_cases = np.empty(0, dtype=int)\n-            sources = np.empty(0, dtype=int)\n-            \n-        if len(new_cases):\n-            self._set_cases(new_cases, sources)\n-            \n-        return new_cases, sources\n+            new_cases = ss.uids()\n+            sources = ss.uids()\n+            networks = np.empty(0, dtype=ss_int_)\n+\n+        return new_cases, sources, networks\n \n-    def _set_cases(self, target_uids, source_uids=None):\n+    def set_outcomes(self, uids, sources=None):\n         sim = self.sim\n-        congenital = sim.people.age[target_uids] <= 0\n+        congenital = sim.people.age[uids] <= 0\n         if np.count_nonzero(congenital):\n-            src_c = source_uids[congenital] if source_uids is not None else None\n-            self.set_congenital(target_uids[congenital], src_c)\n-        src_p = source_uids[~congenital] if source_uids is not None else None\n-        self.set_prognoses(target_uids[~congenital], src_p)\n+            src_c = sources[congenital] if sources is not None else None\n+            self.set_congenital(uids[congenital], src_c)\n+        src_p = sources[~congenital] if sources is not None else None\n+        self.set_prognoses(uids[~congenital], src_p)\n         return\n \n-    def set_congenital(self, target_uids, source_uids=None):\n+    def set_congenital(self, uids, sources=None):\n         pass\n \n     def update_results(self):\n         super().update_results()\n         res = self.results\n-        ti = self.sim.ti\n+        ti = self.ti\n         res.prevalence[ti] = res.n_infected[ti] / np.count_nonzero(self.sim.people.alive)\n         res.new_infections[ti] = np.count_nonzero(self.ti_infected == ti)\n-        res.cum_infections[ti] = np.sum(res['new_infections'][:ti+1])\n+        res.cum_infections[ti] = np.sum(res['new_infections'][:ti+1]) # TODO: can compute at end\n         return\n \n \n@@ -349,9 +379,14 @@ class InfectionLog(nx.MultiDiGraph):\n \n     A table of outcomes can be returned using `InfectionLog.line_list()`\n     \"\"\"\n-\n-    # Add entries\n-    # Add items to the most recent infection for an agent\n+    def add_entries(self, uids, sources=None, time=np.nan):\n+        if sources is None:\n+            for target in uids:\n+                self.append(np.nan, target, time)\n+        else:\n+            for target, source in zip(uids, sources):\n+                self.append(source, target, time)\n+        return\n \n     def add_data(self, uids, **kwargs):\n         \"\"\"\n@@ -360,21 +395,19 @@ class InfectionLog(nx.MultiDiGraph):\n         This method can be used to add data to an existing transmission event.\n         The most recent transmission event will be used\n \n-        :param uid: The UID of the target node (the agent that was infected)\n-        :param kwargs: Remaining arguments are stored as edge data\n+        Args:\n+            uid: The UID of the target node (the agent that was infected)\n+            kwargs: Remaining arguments are stored as edge data\n         \"\"\"\n-        for uid in sc.promotetoarray(uids):\n-            source, target, key = max(self.in_edges(uid, keys=True),\n-                                      key=itemgetter(2, 0))  # itemgetter twice as fast as lambda apparently\n+        for uid in sc.toarray(uids):\n+            source, target, key = max(self.in_edges(uid, keys=True), key=itemgetter(2, 0))  # itemgetter twice as fast as lambda apparently\n             self[source][target][key].update(**kwargs)\n-\n         return\n \n     def append(self, source, target, t, **kwargs):\n         self.add_edge(source, target, key=t, **kwargs)\n         return\n \n-    @property\n     def line_list(self):\n         \"\"\"\n         Return a tabular representation of the log\ndiff --git a/starsim/diseases/cholera.py b/starsim/diseases/cholera.py\nindex 8f897bd..ccaf251 100644\n--- a/starsim/diseases/cholera.py\n+++ b/starsim/diseases/cholera.py\n@@ -17,41 +17,41 @@ class Cholera(ss.Infection):\n     def __init__(self, pars=None, *args, **kwargs):\n         \"\"\" Initialize with parameters \"\"\"\n         super().__init__()\n-        self.default_pars(\n+        self.define_pars(\n             # Initial conditions and beta\n-            beta = 1.0, # Placeholder value\n+            beta = ss.beta(1.0), # Placeholder value\n             init_prev = ss.bernoulli(0.005),\n-            \n+\n             # Natural history parameters, all specified in days\n-            dur_exp2inf   = ss.lognorm_ex(mean=2.772, stdev=4.737), # Calculated from Azman et al. estimates https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3677557/\n-            dur_asymp2rec = ss.uniform(low=1, high=10), # From WHO cholera fact sheet, asymptomatic individuals shed bacteria for 1-10 days (https://www.who.int/news-room/fact-sheets/detail/cholera)\n-            dur_symp2rec  = ss.lognorm_ex(mean=5, stdev=1.8), # According to Fung most modelling studies assume 5 days of symptoms (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3926264/), but found a range of 2.9-14 days. Distribution approximately fit to these values\n-            dur_symp2dead = ss.lognorm_ex(mean=1, stdev=0.5), # There does not appear to be differences in timing/duration of mild vs severe disease, but death from severe disease happens rapidly https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5767916/\n+            dur_exp2inf   = ss.days(ss.lognorm_ex(mean=2.772, std=4.737)), # Calculated from Azman et al. estimates https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3677557/\n+            dur_asymp2rec = ss.days(ss.uniform(low=1, high=10)), # From WHO cholera fact sheet, asymptomatic individuals shed bacteria for 1-10 days (https://www.who.int/news-room/fact-sheets/detail/cholera)\n+            dur_symp2rec  = ss.days(ss.lognorm_ex(mean=5, std=1.8)), # According to Fung most modelling studies assume 5 days of symptoms (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3926264/), but found a range of 2.9-14 days. Distribution approximately fit to these values\n+            dur_symp2dead = ss.days(ss.lognorm_ex(mean=1, std=0.5)), # There does not appear to be differences in timing/duration of mild vs severe disease, but death from severe disease happens rapidly https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5767916/\n             p_death       = ss.bernoulli(p=0.005), # Probability of death is typically less than 1% when treated\n             p_symp        = ss.bernoulli(p=0.5), # Proportion of infected which are symptomatic, mid range of ~25% and 57% estimates from Jaclson et al (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3795095/) and Nelson et al (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3842031/), respectively\n             asymp_trans   = 0.01, # Reduction in transmission probability for asymptomatic infection, asymptomatic carriers shed 100-1000 times less bacteria than symptomatic carriers (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3084143/ and https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3842031/). Previous models assume a 10% relative transmissibility (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4238032/)\n \n             # Environmental parameters\n-            beta_env = 0.5 / 3, # Scaling factor for transmission from environment,\n+            beta_env = ss.beta(0.5 / 3), # Scaling factor for transmission from environment,\n             half_sat_rate = 1_000_000, # Infectious dose in water sufficient to produce infection in 50% of  exposed, from Mukandavire et al. (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3102413/)\n-            shedding_rate = 10, # Rate at which infectious people shed bacteria to the environment (per day), from Mukandavire et al. (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3102413/)\n-            decay_rate = 0.033, # Rate at which bacteria in the environment dies (per day), from Chao et al. and Mukandavire et al. citing https://pubmed.ncbi.nlm.nih.gov/8882180/\n+            shedding_rate = ss.rate(10, unit='day'), # Rate at which infectious people shed bacteria to the environment (per day), from Mukandavire et al. (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3102413/)\n+            decay_rate = ss.rate(0.033, unit='day'), # Rate at which bacteria in the environment dies (per day), from Chao et al. and Mukandavire et al. citing https://pubmed.ncbi.nlm.nih.gov/8882180/\n             p_env_transmit = ss.bernoulli(p=0), # Probability of environmental transmission - filled out later\n         )\n         self.update_pars(pars, **kwargs)\n \n         # Boolean states\n-        self.add_states(\n+        self.define_states(\n             # Susceptible & infected are added automatically, here we add the rest\n-            ss.BoolArr('exposed'),\n-            ss.BoolArr('symptomatic'),\n-            ss.BoolArr('recovered'),\n-    \n+            ss.State('exposed', label='Exposed'),\n+            ss.State('symptomatic', label='Symptomatic'),\n+            ss.State('recovered', label='Recovered'),\n+\n             # Timepoint states\n-            ss.FloatArr('ti_exposed'),\n-            ss.FloatArr('ti_symptomatic'),\n-            ss.FloatArr('ti_recovered'),\n-            ss.FloatArr('ti_dead'),\n+            ss.FloatArr('ti_exposed', label='Time of exposure'),\n+            ss.FloatArr('ti_symptomatic', label='Time of symptoms'),\n+            ss.FloatArr('ti_recovered', label='Time of recovery'),\n+            ss.FloatArr('ti_dead', label='Time of death'),\n         )\n         return\n \n@@ -64,26 +64,23 @@ class Cholera(ss.Infection):\n         return self.infected & ~self.symptomatic\n \n     def init_results(self):\n-        \"\"\"\n-        Initialize results\n-        \"\"\"\n+        \"\"\" Initialize results \"\"\"\n         super().init_results()\n-        npts = self.sim.npts\n-        self.results += [\n-            ss.Result(self.name, 'new_deaths', npts, dtype=int),\n-            ss.Result(self.name, 'cum_deaths', npts, dtype=int),\n-            ss.Result(self.name, 'env_prev', npts, dtype=float),\n-            ss.Result(self.name, 'env_conc', npts, dtype=float),\n-        ]\n+        self.define_results(\n+            ss.Result('new_deaths', dtype=int,   label='Deaths'),\n+            ss.Result('cum_deaths', dtype=int,   label='Cumulative deaths'),\n+            ss.Result('env_prev',   dtype=float, label='Environmental prevalence'),\n+            ss.Result('env_conc',   dtype=float, label='Environmental concentration'),\n+        )\n         return\n \n-    def update_pre(self):\n+    def step_state(self):\n         \"\"\"\n         Adapted from https://github.com/optimamodel/gavi-outbreaks/blob/main/stisim/gavi/cholera.py\n         Original version by Dom Delport\n         \"\"\"\n         # Progress exposed -> infected\n-        ti = self.sim.ti\n+        ti = self.ti\n         infected = (self.exposed & (self.ti_infected <= ti)).uids\n         self.infected[infected] = True\n \n@@ -114,7 +111,7 @@ class Cholera(ss.Infection):\n         \"\"\"\n         p = self.pars\n         r = self.results\n-        ti = self.sim.ti\n+        ti = self.ti\n \n         n_symptomatic = self.symptomatic.sum()\n         n_asymptomatic = self.asymptomatic.sum()\n@@ -127,11 +124,10 @@ class Cholera(ss.Infection):\n         r.env_conc[ti] = r.env_prev[ti] / (r.env_prev[ti] + p.half_sat_rate)\n         return\n \n-    def set_prognoses(self, uids, source_uids=None):\n+    def set_prognoses(self, uids, sources=None):\n         \"\"\" Set prognoses for those who get infected \"\"\"\n-        super().set_prognoses(uids, source_uids)\n-        ti = self.sim.ti\n-        dt = self.sim.dt\n+        super().set_prognoses(uids, sources)\n+        ti = self.ti\n \n         self.susceptible[uids] = False\n         self.exposed[uids] = True\n@@ -140,7 +136,7 @@ class Cholera(ss.Infection):\n         p = self.pars\n \n         # Determine when exposed become infected\n-        self.ti_infected[uids] = ti + p.dur_exp2inf.rvs(uids) / dt\n+        self.ti_infected[uids] = ti + p.dur_exp2inf.rvs(uids)\n \n         # Determine who becomes symptomatic and when\n         symp_uids = p.p_symp.filter(uids)\n@@ -148,13 +144,13 @@ class Cholera(ss.Infection):\n \n         # Determine who dies and when\n         dead_uids = p.p_death.filter(symp_uids)\n-        self.ti_dead[dead_uids] = self.ti_symptomatic[dead_uids] + p.dur_symp2dead.rvs(dead_uids) / dt\n+        self.ti_dead[dead_uids] = self.ti_symptomatic[dead_uids] + p.dur_symp2dead.rvs(dead_uids)\n         symp_rev_uids = np.setdiff1d(symp_uids, dead_uids)\n         asymp_uids = np.setdiff1d(uids, symp_uids)\n \n         # Determine when agents recover\n-        self.ti_recovered[symp_rev_uids] = self.ti_exposed[symp_rev_uids] + p.dur_symp2rec.rvs(symp_rev_uids) / dt\n-        self.ti_recovered[asymp_uids] = self.ti_exposed[asymp_uids] + p.dur_asymp2rec.rvs(asymp_uids) / dt\n+        self.ti_recovered[symp_rev_uids] = self.ti_exposed[symp_rev_uids] + p.dur_symp2rec.rvs(symp_rev_uids)\n+        self.ti_recovered[asymp_uids] = self.ti_exposed[asymp_uids] + p.dur_asymp2rec.rvs(asymp_uids)\n \n         return\n \n@@ -162,18 +158,18 @@ class Cholera(ss.Infection):\n         \"\"\" Add indirect transmission \"\"\"\n         # Make new cases via direct transmission\n         super().make_new_cases()\n-        \n+\n         # Make new cases via indirect transmission\n         pars = self.pars\n         res = self.results\n-        p_transmit = res.env_conc[self.sim.ti] * pars.beta_env\n+        p_transmit = res.env_conc[self.ti] * pars.beta_env\n         pars.p_env_transmit.set(p=p_transmit)\n         new_cases = pars.p_env_transmit.filter(self.sim.people.uid[self.susceptible]) # TODO: make syntax nicer\n         if new_cases.any():\n             self.set_prognoses(new_cases, source_uids=None)\n         return\n \n-    def update_death(self, uids):\n+    def step_die(self, uids):\n         \"\"\" Reset infected/recovered flags for dead agents \"\"\"\n         for state in ['susceptible', 'exposed', 'infected', 'symptomatic', 'recovered']:\n             self.statesdict[state][uids] = False\n@@ -182,7 +178,7 @@ class Cholera(ss.Infection):\n     def update_results(self):\n         super().update_results()\n         res = self.results\n-        ti = self.sim.ti\n+        ti = self.ti\n         res.new_deaths[ti] = np.count_nonzero(self.ti_dead == ti)\n         res.cum_deaths[ti] = np.sum(res.new_deaths[:ti+1])\n         return\ndiff --git a/starsim/diseases/ebola.py b/starsim/diseases/ebola.py\nindex eeb3c01..ffc9181 100644\n--- a/starsim/diseases/ebola.py\n+++ b/starsim/diseases/ebola.py\n@@ -16,40 +16,40 @@ class Ebola(SIR):\n     def __init__(self, pars=None, *args, **kwargs):\n         \"\"\" Initialize with parameters \"\"\"\n         super().__init__()\n-        self.default_pars(\n+        self.define_pars(\n             # Initial conditions and beta\n             init_prev       = ss.bernoulli(p=0.005),\n-            beta            = 1.0, # Placeholder value\n+            beta            = ss.beta(1.0), # Placeholder value\n             sev_factor      = 2.2,\n             unburied_factor = 2.1,\n-            \n+\n             # Natural history parameters, all specified in days\n-            dur_exp2symp    = ss.lognorm_ex(mean=12.7), # Add source\n-            dur_symp2sev    = ss.lognorm_ex(mean=6), # Add source\n-            dur_sev2dead    = ss.lognorm_ex(mean=1.5), # Add source\n-            dur_dead2buried = ss.lognorm_ex(mean=2), # Add source\n-            dur_symp2rec    = ss.lognorm_ex(mean=10), # Add source\n-            dur_sev2rec     = ss.lognorm_ex(mean=10.4), # Add source\n+            dur_exp2symp    = ss.lognorm_ex(mean=ss.days(12.7)), # Add source\n+            dur_symp2sev    = ss.lognorm_ex(mean=ss.days(6)), # Add source\n+            dur_sev2dead    = ss.lognorm_ex(mean=ss.days(1.5)), # Add source\n+            dur_dead2buried = ss.lognorm_ex(mean=ss.days(2)), # Add source\n+            dur_symp2rec    = ss.lognorm_ex(mean=ss.days(10)), # Add source\n+            dur_sev2rec     = ss.lognorm_ex(mean=ss.days(10.4)), # Add source\n             p_sev           = ss.bernoulli(p=0.7), # Add source\n             p_death         = ss.bernoulli(p=0.55), # Add source\n             p_safe_bury     = ss.bernoulli(p=0.25), # Probability of a safe burial - should be linked to diagnoses\n         )\n         self.update_pars(pars=pars, **kwargs)\n-        \n+\n         # Boolean states\n-        self.add_states(\n+        self.define_states(\n             # SIR are added automatically, here we add E\n-            ss.BoolArr('exposed'),\n-            ss.BoolArr('severe'),\n-            ss.BoolArr('recovered'),\n-            ss.BoolArr('buried'),\n-    \n+            ss.State('exposed', label='Exposed'),\n+            ss.State('severe', label='Severe'),\n+            ss.State('recovered', label='Recovered'),\n+            ss.State('buried', label='Buried'),\n+\n             # Timepoint states\n-            ss.FloatArr('ti_exposed'),\n-            ss.FloatArr('ti_severe'),\n-            ss.FloatArr('ti_recovered'),\n-            ss.FloatArr('ti_dead'),\n-            ss.FloatArr('ti_buried'),\n+            ss.FloatArr('ti_exposed', label='Time of exposure'),\n+            ss.FloatArr('ti_severe', label='Time of severe symptoms'),\n+            ss.FloatArr('ti_recovered', label='Time of recovery'),\n+            ss.FloatArr('ti_dead', label='Time of death'),\n+            ss.FloatArr('ti_buried', label='Time of burial'),\n         )\n         return\n \n@@ -57,10 +57,10 @@ class Ebola(SIR):\n     def infectious(self):\n         return self.infected | self.exposed\n \n-    def update_pre(self):\n+    def step_state(self):\n \n         # Progress exposed -> infected\n-        ti = self.sim.ti\n+        ti = self.ti\n         infected = (self.exposed & (self.ti_infected <= ti)).uids\n         self.exposed[infected] = False\n         self.infected[infected] = True\n@@ -87,7 +87,7 @@ class Ebola(SIR):\n         # Progress dead -> buried\n         buried = (self.ti_buried <= ti).uids\n         self.buried[buried] = True\n-        \n+\n         return\n \n     def set_prognoses(self, uids, source_uids=None):\n@@ -95,8 +95,7 @@ class Ebola(SIR):\n         # Do not call set_prognoses on the parent\n         #super().set_prognoses(sim, uids, source_uids)\n \n-        ti = self.sim.ti\n-        dt = self.sim.dt\n+        ti = self.ti\n         self.susceptible[uids] = False\n         self.exposed[uids] = True\n         self.ti_exposed[uids] = ti\n@@ -104,25 +103,25 @@ class Ebola(SIR):\n         p = self.pars\n \n         # Determine when exposed become infected\n-        self.ti_infected[uids] = ti + p.dur_exp2symp.rvs(uids) / dt\n+        self.ti_infected[uids] = ti + p.dur_exp2symp.rvs(uids)\n \n         # Determine who progresses to sever and when\n         sev_uids = p.p_sev.filter(uids)\n-        self.ti_severe[sev_uids] = self.ti_infected[sev_uids] + p.dur_symp2sev.rvs(sev_uids) / dt\n+        self.ti_severe[sev_uids] = self.ti_infected[sev_uids] + p.dur_symp2sev.rvs(sev_uids)\n \n         # Determine who dies and who recovers and when\n         dead_uids = p.p_death.filter(sev_uids)\n-        self.ti_dead[dead_uids] = self.ti_severe[dead_uids] + p.dur_sev2dead.rvs(dead_uids) / dt\n+        self.ti_dead[dead_uids] = self.ti_severe[dead_uids] + p.dur_sev2dead.rvs(dead_uids)\n         rec_sev_uids = np.setdiff1d(sev_uids, dead_uids)\n-        self.ti_recovered[rec_sev_uids] = self.ti_severe[rec_sev_uids] + p.dur_sev2rec.rvs(rec_sev_uids) / dt\n+        self.ti_recovered[rec_sev_uids] = self.ti_severe[rec_sev_uids] + p.dur_sev2rec.rvs(rec_sev_uids)\n         rec_symp_uids = np.setdiff1d(uids, sev_uids)\n-        self.ti_recovered[rec_symp_uids] = self.ti_infected[rec_symp_uids] + p.dur_symp2rec.rvs(rec_symp_uids) / dt\n+        self.ti_recovered[rec_symp_uids] = self.ti_infected[rec_symp_uids] + p.dur_symp2rec.rvs(rec_symp_uids)\n \n         # Determine time of burial - either immediate (safe burials) or after a delay (unsafe)\n         safe_buried = p.p_safe_bury.filter(dead_uids)\n         unsafe_buried = np.setdiff1d(dead_uids, safe_buried)\n         self.ti_buried[safe_buried] = self.ti_dead[safe_buried]\n-        self.ti_buried[unsafe_buried] = self.ti_dead[unsafe_buried] + p.dur_dead2buried.rvs(unsafe_buried) / dt\n+        self.ti_buried[unsafe_buried] = self.ti_dead[unsafe_buried] + p.dur_dead2buried.rvs(unsafe_buried)\n \n         # Change rel_trans values\n         self.rel_trans[self.infectious] = 1\n@@ -131,7 +130,7 @@ class Ebola(SIR):\n         self.rel_trans[unburied_uids] = self.pars['unburied_factor']  # Change for unburied\n         return\n \n-    def update_death(self, uids):\n+    def step_die(self, uids):\n         # Reset infected/recovered flags for dead agents\n         for state in ['susceptible', 'exposed', 'infected', 'severe', 'recovered']:\n             self.statesdict[state][uids] = False\ndiff --git a/starsim/diseases/gonorrhea.py b/starsim/diseases/gonorrhea.py\nindex fb63f9e..31c2d8a 100644\n--- a/starsim/diseases/gonorrhea.py\n+++ b/starsim/diseases/gonorrhea.py\n@@ -13,53 +13,55 @@ class Gonorrhea(ss.Infection):\n     def __init__(self, pars=None, *args, **kwargs):\n         # Parameters\n         super().__init__()\n-        self.default_pars(\n-            beta = 1.0, # Placeholder value\n-            dur_inf_in_days = ss.lognorm_ex(mean=10, stdev=0.6),  # median of 10 days (IQR 7–15 days) https://sti.bmj.com/content/96/8/556\n+        self.define_pars(\n+            beta = ss.beta(1.0), # Placeholder value\n+            dur_inf_in_days = ss.lognorm_ex(mean=ss.days(10), std=ss.days(0.6)),  # median of 10 days (IQR 7–15 days) https://sti.bmj.com/content/96/8/556\n             p_symp    = ss.bernoulli(p=0.5),  # Share of infections that are symptomatic. Placeholder value\n             p_clear   = ss.bernoulli(p=0.2),  # Share of infections that spontaneously clear: https://sti.bmj.com/content/96/8/556\n             init_prev = ss.bernoulli(p=0.1),\n         )\n         self.update_pars(pars=pars, **kwargs)\n-        \n+\n         # States additional to the default disease states (see base class)\n         # Additional states dependent on parameter values, e.g. self.p_symp?\n         # These might be useful for connectors to target, e.g. if HIV reduces p_clear\n-        self.add_states(\n-            ss.BoolArr('symptomatic'),\n-            ss.FloatArr('ti_clearance'),\n-            ss.FloatArr('p_symp', default=1),\n+        self.define_states(\n+            ss.State('symptomatic', label='Symptomatic'),\n+            ss.FloatArr('ti_clearance', label='Time of clearance'),\n+            ss.FloatArr('p_symp', default=1, label='Probability of symptoms'),\n         )\n-        \n+\n         return\n \n     def init_results(self):\n         \"\"\" Initialize results \"\"\"\n         super().init_results()\n-        self.results += ss.Result(self.name, 'new_clearances', self.sim.npts, dtype=int)\n+        self.define_results(\n+            ss.Result('new_clearances', dtype=int, label='New clearances')\n+        )\n         return\n \n     def update_results(self):\n         super().update_results()\n-        ti = self.sim.ti\n+        ti = self.ti\n         self.results.n_symptomatic[ti] = self.symptomatic.count()\n         self.results.new_clearances[ti] = np.count_nonzero(self.ti_clearance == ti)\n         return\n \n-    def update_pre(self):\n+    def step_state(self):\n         \"\"\" Natural clearance \"\"\"\n-        clearances = self.ti_clearance <= self.sim.ti\n+        clearances = self.ti_clearance <= self.ti\n         self.susceptible[clearances] = True\n         self.infected[clearances] = False\n         self.symptomatic[clearances] = False\n-        self.ti_clearance[clearances] = self.sim.ti\n+        self.ti_clearance[clearances] = self.ti\n \n         return\n \n-    def set_prognoses(self, uids, source_uids=None):\n+    def set_prognoses(self, uids, sources=None):\n         \"\"\" Natural history of gonorrhea for adult infection \"\"\"\n-        super().set_prognoses(uids, source_uids)\n-        ti = self.sim.ti\n+        super().set_prognoses(uids, sources)\n+        ti = self.ti\n \n         # Set infection status\n         self.susceptible[uids] = False\n@@ -72,6 +74,6 @@ class Gonorrhea(ss.Infection):\n \n         # Set natural clearance\n         clear_uids = self.pars.p_clear.filter(uids)\n-        dur = ti + self.pars.dur_inf_in_days.rvs(clear_uids)/365/self.sim.dt # Convert from days to years and then adjust for dt\n+        dur = ti + self.pars.dur_inf_in_days.rvs(clear_uids) # Convert from days to years and then adjust for dt automatically # TODO: check!\n         self.ti_clearance[clear_uids] = dur\n         return\n\\ No newline at end of file\ndiff --git a/starsim/diseases/hiv.py b/starsim/diseases/hiv.py\nindex bf45197..caac68f 100644\n--- a/starsim/diseases/hiv.py\n+++ b/starsim/diseases/hiv.py\n@@ -13,8 +13,9 @@ class HIV(ss.Infection):\n \n     def __init__(self, pars=None, *args, **kwargs):\n         super().__init__()\n-        self.default_pars(\n-            beta = 1.0, # Placeholder value\n+        self.define_pars(\n+            unit = 'year',\n+            beta = ss.beta(1.0), # Placeholder value\n             cd4_min = 100,\n             cd4_max = 500,\n             cd4_rate = 5,\n@@ -22,27 +23,27 @@ class HIV(ss.Infection):\n             art_efficacy = 0.96,\n             init_prev = ss.bernoulli(p=0.05),\n             death_dist = ss.bernoulli(p=self.death_prob_func), # Uses p_death by default, modulated by CD4\n-            p_death = 0.05,\n+            p_death = ss.rate(0.05), # NB: this is death per unit time, not death per infection\n         )\n         self.update_pars(pars=pars, **kwargs)\n \n         # States\n-        self.add_states(\n-            ss.BoolArr('on_art'),\n-            ss.FloatArr('ti_art'),\n-            ss.FloatArr('ti_dead'), # Time of HIV-cause death\n-            ss.FloatArr('cd4', default=500),\n+        self.define_states(\n+            ss.State('on_art', label='On ART'),\n+            ss.FloatArr('ti_art', label='Time of ART initiation'),\n+            ss.FloatArr('ti_dead', label='Time of death'), # Time of HIV-caused death\n+            ss.FloatArr('cd4', default=500, label='CD4 count'),\n         )\n         return\n \n     @staticmethod\n     def death_prob_func(module, sim, uids):\n         p = module.pars\n-        out = sim.dt * p.p_death / (p.cd4_min - p.cd4_max)**2 *  (module.cd4[uids] - p.cd4_max)**2\n+        out = p.p_death / (p.cd4_min - p.cd4_max)**2 *  (module.cd4[uids] - p.cd4_max)**2\n         out = np.array(out)\n         return out\n \n-    def update_pre(self):\n+    def step_state(self):\n         \"\"\" Update CD4 \"\"\"\n         people = self.sim.people\n         self.cd4[people.alive & self.infected & self.on_art] += (self.pars.cd4_max - self.cd4[people.alive & self.infected & self.on_art])/self.pars.cd4_rate\n@@ -52,28 +53,30 @@ class HIV(ss.Infection):\n \n         can_die = people.hiv.infected.uids\n         hiv_deaths = self.pars.death_dist.filter(can_die)\n-        \n+\n         people.request_death(hiv_deaths)\n-        self.ti_dead[hiv_deaths] = self.sim.ti\n+        self.ti_dead[hiv_deaths] = self.ti\n         return\n \n     def init_results(self):\n         \"\"\" Initialize results \"\"\"\n         super().init_results()\n-        self.results += ss.Result(self.name, 'new_deaths', self.sim.npts, dtype=int)\n+        self.define_results(\n+            ss.Result('new_deaths', dtype=int, label='Deaths')\n+        )\n         return\n \n     def update_results(self):\n         super().update_results()\n-        ti = self.sim.ti\n+        ti = self.ti\n         self.results['new_deaths'][ti] = np.count_nonzero(self.ti_dead == ti)\n-        return \n+        return\n \n     def set_prognoses(self, uids, source_uids=None):\n         super().set_prognoses(uids, source_uids)\n         self.susceptible[uids] = False\n         self.infected[uids] = True\n-        self.ti_infected[uids] = self.sim.ti\n+        self.ti_infected[uids] = self.ti\n         return\n \n     def set_congenital(self, uids, source_uids):\n@@ -84,38 +87,49 @@ class HIV(ss.Infection):\n \n class ART(ss.Intervention):\n \n-    def __init__(self, year: np.array, coverage: np.array, **kwargs):\n+    def __init__(self, year, coverage, pars=None, **kwargs):\n         self.requires = HIV\n-        self.year = sc.promotetoarray(year)\n-        self.coverage = sc.promotetoarray(coverage)\n-\n-        super().__init__(**kwargs)\n+        self.year = sc.toarray(year)\n+        self.coverage = sc.toarray(coverage)\n+        super().__init__()\n+        self.define_pars(\n+            art_delay = ss.constant(v=ss.years(1.0)) # Value in years\n+        )\n+        self.update_pars(pars=pars, **kwargs)\n \n-        self.prob_art_at_infection = ss.bernoulli(p=lambda self, sim, uids: np.interp(sim.year, self.year, self.coverage))\n+        prob_art = lambda self, sim, uids: np.interp(sim.year, self.year, self.coverage)\n+        self.prob_art_at_infection = ss.bernoulli(p=prob_art)\n         return\n \n     def init_pre(self, sim):\n         super().init_pre(sim)\n-        self.results += ss.Result(self.name, 'n_art', sim.npts, dtype=int)\n         self.initialized = True\n         return\n \n-    def apply(self, sim):\n+    def init_results(self):\n+        super().init_results()\n+        self.define_results(ss.Result('n_art', dtype=int, label='Number on ART'))\n+        return\n+\n+    def step(self):\n+        sim = self.sim\n         if sim.year < self.year[0]:\n             return\n \n-        ti_delay = 1 # 1 time step delay TODO\n-        recently_infected = ss.true((sim.people.hiv.ti_infected == sim.ti-ti_delay) & sim.people.alive)\n+        hiv = sim.people.hiv\n+        infected = hiv.infected.uids\n+        ti_delay = np.round(self.pars.art_delay.rvs(infected)).astype(int)\n+        recently_infected = infected[hiv.ti_infected[infected] == sim.ti-ti_delay]\n \n         n_added = 0\n         if len(recently_infected) > 0:\n             inds = self.prob_art_at_infection.filter(recently_infected)\n-            sim.people.hiv.on_art[inds] = True\n-            sim.people.hiv.ti_art[inds] = sim.ti\n+            hiv.on_art[inds] = True\n+            hiv.ti_art[inds] = sim.ti\n             n_added = len(inds)\n \n         # Add result\n-        self.results['n_art'][sim.ti] = np.count_nonzero(sim.people.alive & sim.people.hiv.on_art)\n+        self.results['n_art'][sim.ti] = np.count_nonzero(hiv.on_art)\n \n         return n_added\n \n@@ -131,9 +145,10 @@ class CD4_analyzer(ss.Analyzer):\n \n     def init_pre(self, sim):\n         super().init_pre(sim)\n-        self.cd4 = np.zeros((sim.npts, sim.people.n), dtype=int)\n+        self.cd4 = np.zeros((self.npts, sim.people.n), dtype=int)\n         return\n \n-    def apply(self, sim):\n+    def step(self):\n+        sim = self.sim\n         self.cd4[sim.t] = sim.people.hiv.cd4\n         return\ndiff --git a/starsim/diseases/measles.py b/starsim/diseases/measles.py\nindex e3f058b..3fa3821 100644\n--- a/starsim/diseases/measles.py\n+++ b/starsim/diseases/measles.py\n@@ -15,22 +15,22 @@ class Measles(SIR):\n     def __init__(self, pars=None, *args, **kwargs):\n         \"\"\" Initialize with parameters \"\"\"\n         super().__init__()\n-        self.default_pars(\n+        self.define_pars(\n             # Initial conditions and beta\n             beta = 1.0, # Placeholder value\n             init_prev = ss.bernoulli(p=0.005),\n-            \n+\n             # Natural history parameters, all specified in days\n-            dur_exp = ss.normal(loc=8),        # (days) - source: US CDC\n-            dur_inf = ss.normal(loc=11),       # (days) - source: US CDC\n+            dur_exp = ss.normal(loc=ss.days(8)),        # (days) - source: US CDC\n+            dur_inf = ss.normal(loc=ss.days(11)),       # (days) - source: US CDC\n             p_death = ss.bernoulli(p=0.005), # Probability of death\n         )\n         self.update_pars(pars=pars, **kwargs)\n \n         # SIR are added automatically, here we add E\n-        self.add_states(\n-            ss.BoolArr('exposed'),\n-            ss.FloatArr('ti_exposed'),\n+        self.define_states(\n+            ss.State('exposed', label='Exposed'),\n+            ss.FloatArr('ti_exposed', label='Time of exposure'),\n         )\n \n         return\n@@ -39,9 +39,9 @@ class Measles(SIR):\n     def infectious(self):\n         return self.infected | self.exposed\n \n-    def update_pre(self):\n+    def step_state(self):\n         # Progress exposed -> infected\n-        ti = self.sim.ti\n+        ti = self.ti\n         infected = (self.exposed & (self.ti_infected <= ti)).uids\n         self.exposed[infected] = False\n         self.infected[infected] = True\n@@ -60,8 +60,7 @@ class Measles(SIR):\n     def set_prognoses(self, uids, source_uids=None):\n         \"\"\" Set prognoses for those who get infected \"\"\"\n         super().set_prognoses(uids, source_uids)\n-        ti = self.sim.ti\n-        dt = self.sim.dt\n+        ti = self.ti\n \n         self.susceptible[uids] = False\n         self.exposed[uids] = True\n@@ -70,7 +69,7 @@ class Measles(SIR):\n         p = self.pars\n \n         # Determine when exposed become infected\n-        self.ti_infected[uids] = ti + p.dur_exp.rvs(uids) / dt\n+        self.ti_infected[uids] = ti + p.dur_exp.rvs(uids)\n \n         # Sample duration of infection, being careful to only sample from the\n         # distribution once per timestep.\n@@ -80,12 +79,12 @@ class Measles(SIR):\n         will_die = p.p_death.rvs(uids)\n         dead_uids = uids[will_die]\n         rec_uids = uids[~will_die]\n-        self.ti_dead[dead_uids] = self.ti_infected[dead_uids] + dur_inf[will_die] / dt\n-        self.ti_recovered[rec_uids] = self.ti_infected[rec_uids] + dur_inf[~will_die] / dt\n+        self.ti_dead[dead_uids] = self.ti_infected[dead_uids] + dur_inf[will_die]\n+        self.ti_recovered[rec_uids] = self.ti_infected[rec_uids] + dur_inf[~will_die]\n \n         return\n \n-    def update_death(self, uids):\n+    def step_die(self, uids):\n         # Reset infected/recovered flags for dead agents\n         for state in ['susceptible', 'exposed', 'infected', 'recovered']:\n             self.statesdict[state][uids] = False\ndiff --git a/starsim/diseases/ncd.py b/starsim/diseases/ncd.py\nindex daa9bd2..5f32867 100644\n--- a/starsim/diseases/ncd.py\n+++ b/starsim/diseases/ncd.py\n@@ -19,18 +19,18 @@ class NCD(ss.Disease):\n     \"\"\"\n     def __init__(self, pars=None, **kwargs):\n         super().__init__()\n-        self.default_pars(\n+        self.define_pars(\n             initial_risk = ss.bernoulli(p=0.3), # Initial prevalence of risk factors\n-            dur_risk = ss.expon(scale=10),\n-            prognosis = ss.weibull(c=2, scale=5), # Time in years between first becoming affected and death\n+            dur_risk = ss.expon(scale=ss.dur(10)),\n+            prognosis = ss.weibull(c=ss.years(2), scale=5), # Time in years between first becoming affected and death\n         )\n         self.update_pars(pars=pars, **kwargs)\n-        \n-        self.add_states(\n-            ss.BoolArr('at_risk'),\n-            ss.BoolArr('affected'),\n-            ss.FloatArr('ti_affected'),\n-            ss.FloatArr('ti_dead'),\n+\n+        self.define_states(\n+            ss.State('at_risk', label='At risk'),\n+            ss.State('affected', label='Affected'),\n+            ss.FloatArr('ti_affected', label='Time of becoming affected'),\n+            ss.FloatArr('ti_dead', label='Time of death'),\n         )\n         return\n \n@@ -48,23 +48,24 @@ class NCD(ss.Disease):\n         super().init_post()\n         initial_risk = self.pars['initial_risk'].filter()\n         self.at_risk[initial_risk] = True\n-        self.ti_affected[initial_risk] = self.sim.ti + sc.randround(self.pars['dur_risk'].rvs(initial_risk) / self.sim.dt)\n+        self.ti_affected[initial_risk] = self.ti + sc.randround(self.pars['dur_risk'].rvs(initial_risk))\n         return initial_risk\n \n-    def update_pre(self):\n-        ti = self.sim.ti\n+    def step_state(self):\n+        ti = self.ti\n         deaths = (self.ti_dead == ti).uids\n         self.sim.people.request_death(deaths)\n-        self.log.add_data(deaths, died=True)\n+        if self.pars.log:\n+            self.log.add_data(deaths, died=True)\n         self.results.new_deaths[ti] = len(deaths) # Log deaths attributable to this module\n         return\n \n-    def make_new_cases(self):\n-        ti = self.sim.ti\n+    def step(self):\n+        ti = self.ti\n         new_cases = (self.ti_affected == ti).uids\n         self.affected[new_cases] = True\n         prog_years = self.pars.prognosis.rvs(new_cases)\n-        self.ti_dead[new_cases] = ti + sc.randround(prog_years / self.sim.dt)\n+        self.ti_dead[new_cases] = ti + sc.randround(prog_years / self.t.dt) # TODO: update to allow non-year units\n         super().set_prognoses(new_cases)\n         return new_cases\n \n@@ -73,17 +74,16 @@ class NCD(ss.Disease):\n         Initialize results\n         \"\"\"\n         super().init_results()\n-        npts = self.sim.npts\n-        self.results += [\n-            ss.Result(self.name, 'n_not_at_risk', npts, dtype=int),\n-            ss.Result(self.name, 'prevalence', npts, dtype=float),\n-            ss.Result(self.name, 'new_deaths', npts, dtype=int),\n-        ]\n+        self.define_results(\n+            ss.Result('n_not_at_risk', dtype=int,   label='Not at risk'),\n+            ss.Result('prevalence',    dtype=float, label='Prevalence'),\n+            ss.Result('new_deaths',    dtype=int,   label='Deaths'),\n+        )\n         return\n \n     def update_results(self):\n         super().update_results()\n-        ti = self.sim.ti\n+        ti = self.ti\n         self.results.n_not_at_risk[ti] = np.count_nonzero(self.not_at_risk)\n         self.results.prevalence[ti]    = np.count_nonzero(self.affected)/len(self.sim.people)\n         self.results.new_deaths[ti]    = np.count_nonzero(self.ti_dead == ti)\ndiff --git a/starsim/diseases/sir.py b/starsim/diseases/sir.py\nindex a21c40c..ad938a1 100644\n--- a/starsim/diseases/sir.py\n+++ b/starsim/diseases/sir.py\n@@ -3,7 +3,8 @@ Define SIR and SIS disease modules\n \"\"\"\n \n import numpy as np\n-import matplotlib.pyplot as pl\n+import sciris as sc\n+import matplotlib.pyplot as plt\n import starsim as ss\n \n \n@@ -19,22 +20,27 @@ class SIR(ss.Infection):\n     \"\"\"\n     def __init__(self, pars=None, **kwargs):\n         super().__init__()\n-        self.default_pars(\n-            beta = 0.1,\n+        self.define_pars(\n+            beta = ss.beta(0.1),\n             init_prev = ss.bernoulli(p=0.01),\n-            dur_inf = ss.lognorm_ex(mean=6),\n+            dur_inf = ss.lognorm_ex(mean=ss.dur(6)),\n             p_death = ss.bernoulli(p=0.01),\n         )\n         self.update_pars(pars, **kwargs)\n \n-        self.add_states(\n-            ss.BoolArr('recovered'),\n-            ss.FloatArr('ti_recovered'),\n-            ss.FloatArr('ti_dead'),\n+        self.define_states(\n+            ss.State('susceptible', default=True, label='Susceptible'),\n+            ss.State('infected', label='Infectious'),\n+            ss.State('recovered', label='Recovered'),\n+            ss.FloatArr('ti_infected', label='Time of infection'),\n+            ss.FloatArr('ti_recovered', label='Time of recovery'),\n+            ss.FloatArr('ti_dead', label='Time of death'),\n+            ss.FloatArr('rel_sus', default=1.0, label='Relative susceptibility'),\n+            ss.FloatArr('rel_trans', default=1.0, label='Relative transmission'),\n         )\n         return\n \n-    def update_pre(self):\n+    def step_state(self):\n         # Progress infectious -> recovered\n         sim = self.sim\n         recovered = (self.infected & (self.ti_recovered <= sim.ti)).uids\n@@ -47,11 +53,10 @@ class SIR(ss.Infection):\n             sim.people.request_death(deaths)\n         return\n \n-    def set_prognoses(self, uids, source_uids=None):\n+    def set_prognoses(self, uids, sources=None):\n         \"\"\" Set prognoses \"\"\"\n-        super().set_prognoses(uids, source_uids)\n-        ti = self.sim.ti\n-        dt = self.sim.dt\n+        super().set_prognoses(uids, sources)\n+        ti = self.t.ti\n         self.susceptible[uids] = False\n         self.infected[uids] = True\n         self.ti_infected[uids] = ti\n@@ -66,25 +71,32 @@ class SIR(ss.Infection):\n         will_die = p.p_death.rvs(uids)\n         dead_uids = uids[will_die]\n         rec_uids = uids[~will_die]\n-        self.ti_dead[dead_uids] = ti + dur_inf[will_die] / dt # Consider rand round, but not CRN safe\n-        self.ti_recovered[rec_uids] = ti + dur_inf[~will_die] / dt\n+        self.ti_dead[dead_uids] = ti + dur_inf[will_die] # Consider rand round, but not CRN safe\n+        self.ti_recovered[rec_uids] = ti + dur_inf[~will_die]\n         return\n \n-    def update_death(self, uids):\n+    def step_die(self, uids):\n         \"\"\" Reset infected/recovered flags for dead agents \"\"\"\n         self.susceptible[uids] = False\n         self.infected[uids] = False\n         self.recovered[uids] = False\n         return\n \n-    def plot(self):\n+    def plot(self, **kwargs):\n         \"\"\" Default plot for SIR model \"\"\"\n-        fig = pl.figure()\n-        for rkey in ['susceptible', 'infected', 'recovered']:\n-            pl.plot(self.results['n_'+rkey], label=rkey.title())\n-        pl.legend()\n-        return fig\n-    \n+        fig = plt.figure()\n+        kw = sc.mergedicts(dict(lw=2, alpha=0.8), kwargs)\n+        res = self.results\n+        for rkey in ['n_susceptible', 'n_infected', 'n_recovered']:\n+            plt.plot(res.timevec, res[rkey], label=res[rkey].label, **kw)\n+        plt.legend(frameon=False)\n+        plt.xlabel('Time')\n+        plt.ylabel('Number of people')\n+        plt.ylim(bottom=0)\n+        sc.boxoff()\n+        sc.commaticks()\n+        return ss.return_fig(fig)\n+\n \n class SIS(ss.Infection):\n     \"\"\"\n@@ -96,70 +108,79 @@ class SIS(ss.Infection):\n     \"\"\"\n     def __init__(self, pars=None, *args, **kwargs):\n         super().__init__()\n-        self.default_pars(\n-            beta = 0.05,\n+        self.define_pars(\n+            beta = ss.beta(0.05),\n             init_prev = ss.bernoulli(p=0.01),\n-            dur_inf = ss.lognorm_ex(mean=10),\n-            waning = 0.05,\n+            dur_inf = ss.lognorm_ex(mean=ss.dur(10)),\n+            waning = ss.rate(0.05),\n             imm_boost = 1.0,\n         )\n         self.update_pars(pars=pars, *args, **kwargs)\n \n-        self.add_states(\n+        self.define_states(\n             ss.FloatArr('ti_recovered'),\n             ss.FloatArr('immunity', default=0.0),\n         )\n         return\n \n-    def update_pre(self):\n+    def step_state(self):\n         \"\"\" Progress infectious -> recovered \"\"\"\n-        recovered = (self.infected & (self.ti_recovered <= self.sim.ti)).uids\n+        recovered = (self.infected & (self.ti_recovered <= self.ti)).uids\n         self.infected[recovered] = False\n         self.susceptible[recovered] = True\n         self.update_immunity()\n         return\n-    \n+\n     def update_immunity(self):\n         has_imm = (self.immunity > 0).uids\n-        self.immunity[has_imm] = (self.immunity[has_imm])*(1 - self.pars.waning*self.sim.dt)\n+        self.immunity[has_imm] = (self.immunity[has_imm])*(1 - self.pars.waning)\n         self.rel_sus[has_imm] = np.maximum(0, 1 - self.immunity[has_imm])\n         return\n \n-    def set_prognoses(self, uids, source_uids=None):\n+    def set_prognoses(self, uids, sources=None):\n         \"\"\" Set prognoses \"\"\"\n-        super().set_prognoses(uids, source_uids)\n+        super().set_prognoses(uids, sources)\n         self.susceptible[uids] = False\n         self.infected[uids] = True\n-        self.ti_infected[uids] = self.sim.ti\n+        self.ti_infected[uids] = self.ti\n         self.immunity[uids] += self.pars.imm_boost\n \n         # Sample duration of infection\n         dur_inf = self.pars.dur_inf.rvs(uids)\n \n         # Determine when people recover\n-        self.ti_recovered[uids] = self.sim.ti + dur_inf / self.sim.dt\n+        self.ti_recovered[uids] = self.ti + dur_inf\n \n         return\n-    \n+\n     def init_results(self):\n         \"\"\" Initialize results \"\"\"\n         super().init_results()\n-        self.results += ss.Result(self.name, 'rel_sus', self.sim.npts, dtype=float)\n+        self.define_results(\n+            ss.Result('rel_sus', dtype=float, label='Relative susceptibility')\n+        )\n         return\n \n     def update_results(self):\n         \"\"\" Store the population immunity (susceptibility) \"\"\"\n         super().update_results()\n-        self.results['rel_sus'][self.sim.ti] = self.rel_sus.mean()\n-        return \n+        self.results['rel_sus'][self.ti] = self.rel_sus.mean()\n+        return\n \n-    def plot(self):\n+    def plot(self, **kwargs):\n         \"\"\" Default plot for SIS model \"\"\"\n-        fig = pl.figure()\n-        for rkey in ['susceptible', 'infected']:\n-            pl.plot(self.results['n_'+rkey], label=rkey.title())\n-        pl.legend()\n-        return fig\n+        fig = plt.figure()\n+        kw = sc.mergedicts(dict(lw=2, alpha=0.8), kwargs)\n+        res = self.results\n+        for rkey in ['n_susceptible', 'n_infected']:\n+            plt.plot(res.timevec, res[rkey], label=res[rkey].label, **kw)\n+        plt.legend(frameon=False)\n+        plt.xlabel('Time')\n+        plt.ylabel('Number of people')\n+        plt.ylim(bottom=0)\n+        sc.boxoff()\n+        sc.commaticks()\n+        return ss.return_fig(fig)\n \n \n # %% Interventions\n@@ -169,27 +190,27 @@ __all__ += ['sir_vaccine']\n class sir_vaccine(ss.Vx):\n     \"\"\"\n     Create a vaccine product that affects the probability of infection.\n-    \n-    The vaccine can be either \"leaky\", in which everyone who receives the vaccine \n-    receives the same amount of protection (specified by the efficacy parameter) \n+\n+    The vaccine can be either \"leaky\", in which everyone who receives the vaccine\n+    receives the same amount of protection (specified by the efficacy parameter)\n     each time they are exposed to an infection. The alternative (leaky=False) is\n     that the efficacy is the probability that the vaccine \"takes\", in which case\n     that person is 100% protected (and the remaining people are 0% protected).\n-    \n+\n     Args:\n         efficacy (float): efficacy of the vaccine (0<=efficacy<=1)\n         leaky (bool): see above\n     \"\"\"\n     def __init__(self, pars=None, *args, **kwargs):\n         super().__init__()\n-        self.default_pars(\n+        self.define_pars(\n             efficacy = 0.9,\n             leaky = True\n         )\n         self.update_pars(pars, **kwargs)\n         return\n \n-    def administer(self, people, uids):        \n+    def administer(self, people, uids):\n         if self.pars.leaky:\n             people.sir.rel_sus[uids] *= 1-self.pars.efficacy\n         else:\ndiff --git a/starsim/diseases/syphilis.py b/starsim/diseases/syphilis.py\nindex b75b80b..c7b503c 100644\n--- a/starsim/diseases/syphilis.py\n+++ b/starsim/diseases/syphilis.py\n@@ -4,8 +4,8 @@ Define default syphilis disease module\n \n import numpy as np\n import sciris as sc\n-from sciris import randround as rr # Since used frequently\n import starsim as ss\n+rr = sc.randround # Since used frequently\n \n \n __all__ = ['Syphilis']\n@@ -15,17 +15,17 @@ class Syphilis(ss.Infection):\n     def __init__(self, pars=None, **kwargs):\n         # Parameters\n         super().__init__()\n-        self.default_pars(\n+        self.define_pars(\n             # Initial conditions\n             beta = 1.0, # Placeholder\n             init_prev = ss.bernoulli(p=0.03),\n-            \n+\n             # Adult syphilis natural history, all specified in years\n-            dur_exposed = ss.lognorm_ex(mean=1 / 12, stdev=1 / 36),  # https://pubmed.ncbi.nlm.nih.gov/9101629/\n-            dur_primary = ss.lognorm_ex(mean=1.5 / 12, stdev=1 / 36),  # https://pubmed.ncbi.nlm.nih.gov/9101629/\n+            dur_exposed = ss.lognorm_ex(mean=1 / 12, std=1 / 36),  # https://pubmed.ncbi.nlm.nih.gov/9101629/\n+            dur_primary = ss.lognorm_ex(mean=1.5 / 12, std=1 / 36),  # https://pubmed.ncbi.nlm.nih.gov/9101629/\n             dur_secondary = ss.normal(loc=3.6 / 12, scale=1.5 / 12),  # https://pubmed.ncbi.nlm.nih.gov/9101629/\n-            dur_latent_temp = ss.lognorm_ex(mean=1, stdev=6 / 12),  # https://pubmed.ncbi.nlm.nih.gov/9101629/\n-            dur_latent_long = ss.lognorm_ex(mean=20, stdev=8),  # https://pubmed.ncbi.nlm.nih.gov/9101629/\n+            dur_latent_temp = ss.lognorm_ex(mean=1, std=6 / 12),  # https://pubmed.ncbi.nlm.nih.gov/9101629/\n+            dur_latent_long = ss.lognorm_ex(mean=20, std=8),  # https://pubmed.ncbi.nlm.nih.gov/9101629/\n             p_latent_temp = ss.bernoulli(p=0.25),  # https://pubmed.ncbi.nlm.nih.gov/9101629/\n             p_tertiary = ss.bernoulli(p=0.35),  # https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4917057/\n \n@@ -54,30 +54,30 @@ class Syphilis(ss.Infection):\n         )\n         self.update_pars(pars, **kwargs)\n \n-        self.add_states(\n+        self.define_states(\n             # Adult syphilis states\n-            ss.BoolArr('exposed'),  # AKA incubating. Free of symptoms, not transmissible\n-            ss.BoolArr('primary'),  # Primary chancres\n-            ss.BoolArr('secondary'),  # Inclusive of those who may still have primary chancres\n-            ss.BoolArr('latent_temp'),  # Relapses to secondary (~1y)\n-            ss.BoolArr('latent_long'),  # Can progress to tertiary or remain here\n-            ss.BoolArr('tertiary'),  # Includes complications (cardio/neuro/disfigurement)\n-            ss.BoolArr('immune'),  # After effective treatment people may acquire temp immunity\n-            ss.BoolArr('ever_exposed'),  # Anyone ever exposed - stays true after treatment\n-            ss.BoolArr('congenital'),  # Congenital syphilis states\n-    \n+            ss.State('exposed', label='Exposed'),  # AKA incubating. Free of symptoms, not transmissible\n+            ss.State('primary', label='Primary'),  # Primary chancres\n+            ss.State('secondary', label=\"Secondary\"),  # Inclusive of those who may still have primary chancres\n+            ss.State('latent_temp', label=\"Latent temporary\"),  # Relapses to secondary (~1y)\n+            ss.State('latent_long', label=\"Latent long\"),  # Can progress to tertiary or remain here\n+            ss.State('tertiary', label=\"Tertiary\"),  # Includes complications (cardio/neuro/disfigurement)\n+            ss.State('immune', label=\"Immune\"),  # After effective treatment people may acquire temp immunity\n+            ss.State('ever_exposed', label=\"Ever exposed\"),  # Anyone ever exposed - stays true after treatment\n+            ss.State('congenital', label=\"Congenital\"),  # Congenital syphilis states\n+\n             # Timestep of state changes\n-            ss.FloatArr('ti_exposed'),\n-            ss.FloatArr('ti_primary'),\n-            ss.FloatArr('ti_secondary'),\n-            ss.FloatArr('ti_latent_temp'),\n-            ss.FloatArr('ti_latent_long'),\n-            ss.FloatArr('ti_tertiary'),\n-            ss.FloatArr('ti_immune'),\n-            ss.FloatArr('ti_miscarriage'),\n-            ss.FloatArr('ti_nnd'),\n-            ss.FloatArr('ti_stillborn'),\n-            ss.FloatArr('ti_congenital'),\n+            ss.FloatArr('ti_exposed', label='Time of exposure'),\n+            ss.FloatArr('ti_primary', label='Time of primary'),\n+            ss.FloatArr('ti_secondary', label='Time of secondary'),\n+            ss.FloatArr('ti_latent_temp', label='Time of latent_temp'),\n+            ss.FloatArr('ti_latent_long', label='Time of latent_long'),\n+            ss.FloatArr('ti_tertiary', label='Time of tertiary'),\n+            ss.FloatArr('ti_immune', label='Time of immunity'),\n+            ss.FloatArr('ti_miscarriage', label='Time of miscarriage'),\n+            ss.FloatArr('ti_nnd', label='Time of neonatal death'),\n+            ss.FloatArr('ti_stillborn', label='Time of stillborn'),\n+            ss.FloatArr('ti_congenital', label='Time of congenital syphilis'),\n         )\n \n         return\n@@ -110,19 +110,18 @@ class Syphilis(ss.Infection):\n     def init_results(self):\n         \"\"\" Initialize results \"\"\"\n         super().init_results()\n-        npts = self.sim.npts\n-        self.results += [\n-            ss.Result(self.name, 'new_nnds',       npts, dtype=int, scale=True),\n-            ss.Result(self.name, 'new_stillborns', npts, dtype=int, scale=True),\n-            ss.Result(self.name, 'new_congenital', npts, dtype=int, scale=True),\n-        ]\n+        self.define_results(\n+            ss.Result('new_nnds',       dtype=int, label='New neonatal deaths'),\n+            ss.Result('new_stillborns', dtype=int, label='New stillborns'),\n+            ss.Result('new_congenital', dtype=int, label='New congenital syphilis'),\n+        )\n         return\n \n-    def update_pre(self):\n+    def step_state(self):\n         \"\"\" Updates prior to interventions \"\"\"\n \n         # Primary\n-        ti = self.sim.ti\n+        ti = self.ti\n         primary = self.exposed & (self.ti_primary <= ti)\n         self.primary[primary] = True\n         self.exposed[primary] = False\n@@ -136,10 +135,6 @@ class Syphilis(ss.Infection):\n             self.set_secondary_prognoses(secondary_from_primary)\n             self.rel_trans[secondary_from_primary] = self.pars.rel_trans['secondary']\n \n-        # Hack to reset the MultiRNGs in set_secondary_prognoses so that they can be called again in this timestep. TODO: Refactor\n-        self.pars.p_latent_temp.jump(ti+1)\n-        self.pars.dur_secondary.jump(ti+1)\n-\n         # Secondary reactivation from latent\n         secondary_from_latent = (self.latent_temp & (self.ti_secondary <= ti)).uids\n         if len(secondary_from_latent) > 0:\n@@ -185,7 +180,7 @@ class Syphilis(ss.Infection):\n \n     def update_results(self):\n         super().update_results()\n-        ti = self.sim.ti\n+        ti = self.ti\n         self.results.new_nnds[ti]       = np.count_nonzero(self.ti_nnd == ti)\n         self.results.new_stillborns[ti] = np.count_nonzero(self.ti_stillborn == ti)\n         self.results.new_congenital[ti] = np.count_nonzero(self.ti_congenital == ti)\n@@ -195,10 +190,8 @@ class Syphilis(ss.Infection):\n         \"\"\"\n         Set initial prognoses for adults newly infected with syphilis\n         \"\"\"\n-        super().set_prognoses(uids, source_uids)\n-        \n-        ti = self.sim.ti\n-        dt = self.sim.dt\n+\n+        ti = self.ti\n \n         self.susceptible[uids] = False\n         self.ever_exposed[uids] = True\n@@ -210,17 +203,16 @@ class Syphilis(ss.Infection):\n         # Set future dates and probabilities\n         # Exposed to primary\n         dur_exposed = self.pars.dur_exposed.rvs(uids)\n-        self.ti_primary[uids] = ti + rr(dur_exposed / dt)\n+        self.ti_primary[uids] = ti + rr(dur_exposed)\n \n         # Primary to secondary\n         dur_primary = self.pars.dur_primary.rvs(uids)\n-        self.ti_secondary[uids] = self.ti_primary[uids] + rr(dur_primary / dt)\n+        self.ti_secondary[uids] = self.ti_primary[uids] + rr(dur_primary)\n         return\n \n     def set_secondary_prognoses(self, uids):\n         \"\"\" Set prognoses for people who have just progressed to secondary infection \"\"\"\n \n-        dt = self.sim.dt\n         dur_secondary = self.pars.dur_secondary.rvs(uids)\n \n         # Secondary to latent_temp or latent_long\n@@ -229,42 +221,41 @@ class Syphilis(ss.Infection):\n         latent_long_uids = uids[~latent_temp]\n \n         dur_secondary_temp = dur_secondary[latent_temp]\n-        self.ti_latent_temp[latent_temp_uids] = self.ti_secondary[latent_temp_uids] + rr(dur_secondary_temp / dt)\n+        self.ti_latent_temp[latent_temp_uids] = self.ti_secondary[latent_temp_uids] + rr(dur_secondary_temp)\n \n         dur_secondary_long = dur_secondary[~latent_temp]\n-        self.ti_latent_long[latent_long_uids] = self.ti_secondary[latent_long_uids] + rr(dur_secondary_long / dt)\n+        self.ti_latent_long[latent_long_uids] = self.ti_secondary[latent_long_uids] + rr(dur_secondary_long)\n \n         return\n \n     def set_latent_temp_prognoses(self, uids):\n         # Primary to secondary\n         dur_latent_temp = self.pars.dur_latent_temp.rvs(uids)\n-        self.ti_secondary[uids] = self.ti_latent_temp[uids] + rr(dur_latent_temp / self.sim.dt)\n+        self.ti_secondary[uids] = self.ti_latent_temp[uids] + rr(dur_latent_temp)\n         return\n \n     def set_latent_long_prognoses(self, uids):\n-        dt = self.sim.dt\n         dur_latent = self.pars.dur_latent_long.rvs(uids)\n \n         # Primary to secondary\n         dur_latent_long = dur_latent\n-        self.ti_secondary[uids] = self.ti_latent_temp[uids] + rr(dur_latent_long / dt)\n+        self.ti_secondary[uids] = self.ti_latent_temp[uids] + rr(dur_latent_long)\n \n         # Latent_long to tertiary\n         tertiary = self.pars.p_tertiary.rvs(uids)\n         tertiary_uids = uids[tertiary]\n-        self.ti_tertiary[tertiary_uids] = self.ti_latent_long[tertiary_uids] + rr(dur_latent_long[tertiary] / dt)\n+        self.ti_tertiary[tertiary_uids] = self.ti_latent_long[tertiary_uids] + rr(dur_latent_long[tertiary])\n \n         return\n \n-    def set_congenital(self, uids, source_uids=None):\n+    def set_congenital(self, uids, sources=None):\n         \"\"\" Natural history of syphilis for congenital infection \"\"\"\n         sim = self.sim\n \n         # Determine outcomes\n         for state in ['active', 'latent']:\n \n-            source_state_inds = getattr(self, state)[source_uids].nonzero()[0]\n+            source_state_inds = getattr(self, state)[sources].nonzero()[0]\n             state_uids = uids[source_state_inds]\n \n             if len(state_uids) > 0:\n@@ -275,12 +266,13 @@ class Syphilis(ss.Infection):\n                 time_to_birth = -sim.people.age.raw # TODO: make nicer\n \n                 # Schedule events\n+                ratio = ss.time_ratio(unit1='year', dt1=1.0, unit2=self.t.unit, dt2=self.t.dt) # TODO: think about simplifying\n                 for oi, outcome in enumerate(self.pars.birth_outcome_keys):\n                     o_uids = state_uids[assigned_outcomes == oi]\n                     if len(o_uids) > 0:\n                         ti_outcome = f'ti_{outcome}'\n                         vals = getattr(self, ti_outcome)\n-                        vals[o_uids] = sim.ti + rr(time_to_birth[o_uids] / sim.dt)\n+                        vals[o_uids] = sim.ti + rr(time_to_birth[o_uids] * ratio)\n                         setattr(self, ti_outcome, vals)\n \n         return\n@@ -334,23 +326,24 @@ class syph_screening(ss.routine_screening):\n         else:\n             return products[product]\n \n-    def check_eligibility(self, sim):\n+    def check_eligibility(self):\n         \"\"\"\n         Return an array of indices of agents eligible for screening at time t, i.e. sexually active\n         females in age range, plus any additional user-defined eligibility\n         \"\"\"\n+        sim = self.sim\n         if self.eligibility is not None:\n             is_eligible = self.eligibility(sim)\n         else:\n             is_eligible = sim.people.auids  # Probably not required\n         return is_eligible\n \n-    def init_pre(self, sim):\n-        super().init_pre(sim)\n-        self.results += [\n-            ss.Result('syphilis', 'n_screened', sim.npts, dtype=int, scale=True),\n-            ss.Result('syphilis', 'n_dx', sim.npts, dtype=int, scale=True),\n-        ]\n+    def init_results(self):\n+        super().init_results()\n+        self.define_results(\n+            ss.Result('n_screened', dtype=int, label='Number screened'),\n+            ss.Result('n_dx',       dtype=int, label='Number diagnosed'),\n+        )\n         return\n \n \n@@ -369,12 +362,15 @@ class syph_treatment(ss.treat_num):\n         else:\n             return products[product]\n \n-    def init_pre(self, sim):\n-        super().init_pre(sim)\n-        self.results += ss.Result('syphilis', 'n_tx', sim.npts, dtype=int, scale=True)\n+    def init_results(self):\n+        super().init_results()\n+        self.define_results(\n+            ss.Result('n_tx', dtype=int, label='Number treated')\n+        )\n         return\n \n-    def apply(self, sim):\n-        treat_inds = super().apply(sim)\n+    def step(self):\n+        sim = self.sim\n+        treat_inds = super().step()\n         sim.people.syphilis.infected[treat_inds] = False\n         self.results['n_tx'][sim.ti] += len(treat_inds)\ndiff --git a/starsim/distributions.py b/starsim/distributions.py\nindex 2d65c0a..759fd0e 100644\n--- a/starsim/distributions.py\n+++ b/starsim/distributions.py\n@@ -1,49 +1,39 @@\n \"\"\"\n Define random-number-safe distributions.\n \"\"\"\n-\n-import numpy as np\n import sciris as sc\n+import numpy as np\n+import numba as nb\n import scipy.stats as sps\n import starsim as ss\n-import matplotlib.pyplot as pl\n+import matplotlib.pyplot as plt\n \n-__all__ = ['find_dists', 'link_dists', 'make_dist', 'dist_list', 'Dists', 'Dist']\n+__all__ = ['link_dists', 'make_dist', 'dist_list', 'Dists', 'Dist']\n \n \n-def str2int(string, modulo=1_000_000):\n+def str2int(string, modulo=1_000_000_000):\n     \"\"\"\n-    Convert a string to an int\n-    \n-    Cannot use Python's built-in hash() since it's randomized for strings, but\n-    this is almost as fast (and 5x faster than hashlib).\n-    \"\"\"\n-    return int.from_bytes(string.encode(), byteorder='big') % modulo\n-\n+    Convert a string to an int to use as a random seed; not for the user\n \n-def find_dists(obj, verbose=False, **kwargs):\n-    \"\"\" Find all Dist objects in a parent object \"\"\"\n-    out = sc.objdict()\n-    tree = sc.iterobj(obj, depthfirst=False, flatten=True, **kwargs)\n-    if verbose: print(f'Found {len(tree)} objects')\n-    for trace,val in tree.items():\n-        if isinstance(val, Dist):\n-            out[trace] = val\n-            if verbose: print(f'  {trace} is a dist ({len(out)})')\n-    return out\n+    Cannot use Python's built-in hash() since it's randomized for strings. Hashlib\n+    (sc.sha) is 5x slower than int.from_bytes(string.encode(), byteorder='big'), but should\n+    only add a couple milliseconds to a typical sim.\n+    \"\"\"\n+    integer = sc.sha(string, asint=True) # Hash the string to an integer\n+    seed = integer % modulo # Ensure a user-friendly representation user-friendly\n+    return seed\n \n \n-def link_dists(obj, sim, module=None, overwrite=False, init=False, **kwargs):\n-    \"\"\" Link distributions to the sim and the module; used in module.initialize() and people.initialize() \"\"\"\n+def link_dists(obj, sim, module=None, overwrite=False, init=False, **kwargs): # TODO: actually link the distributions to the modules! Currently this only does the opposite, but should have mod.dists as well\n+    \"\"\" Link distributions to the sim and the module; used in module.init() and people.init() \"\"\"\n     if module is None and isinstance(obj, ss.Module):\n         module = obj\n-    dists = ss.find_dists(obj, **kwargs) # Important that this comes first, before the sim is linked to the dist!\n-    for key,val in dists.items():\n-        if isinstance(val, ss.Dist):\n-            val.link_sim(sim, overwrite=overwrite)\n-            val.link_module(module, overwrite=overwrite)\n-            if init: # Usually this is false since usually these are initialized centrally by the sim\n-                val.initialize()\n+    dists = sc.search(obj, type=Dist, **kwargs)\n+    for dist in dists.values():\n+        dist.link_sim(sim, overwrite=overwrite)\n+        dist.link_module(module, overwrite=overwrite)\n+        if init: # Usually this is false since usually these are initialized centrally by the sim\n+            dist.init()\n     return\n \n \n@@ -75,10 +65,10 @@ class Dists(sc.prettyobj):\n         self.initialized = False\n         return\n \n-    def initialize(self, obj=None, base_seed=None, sim=None, force=False):\n+    def init(self, obj=None, base_seed=None, sim=None, force=False):\n         \"\"\"\n         Set the base seed, find and initialize all distributions in an object\n-        \n+\n         In practice, the object is usually a Sim, but can be anything.\n         \"\"\"\n         if base_seed:\n@@ -92,18 +82,28 @@ class Dists(sc.prettyobj):\n         if obj is None:\n             errormsg = 'Must supply a container that contains one or more Dist objects, typically the sim'\n             raise ValueError(errormsg)\n-        self.dists = find_dists(obj)\n+\n+        # Do not look for distributions in the people states, since they shadow the \"real\" states\n+        skip = dict(\n+            ids=id(sim.people._states) if sim is not None else None,\n+            keys='module',\n+        )\n+\n+        # Find and initialize the distributions\n+        self.dists = sc.search(obj, type=Dist, skip=skip, flatten=True)\n         for trace,dist in self.dists.items():\n             if not dist.initialized or force:\n-                dist.initialize(trace=trace, seed=base_seed, sim=sim, force=force)\n+                dist.init(trace=trace, seed=base_seed, sim=sim, force=force)\n+\n+        # Confirm the seeds are unique\n         self.check_seeds()\n         self.initialized = True\n         return self\n-    \n+\n     def check_seeds(self):\n         \"\"\" Check that no two distributions share the same seed \"\"\"\n         checked = dict()\n-        for trace,dist in self.dists.items():\n+        for dist in self.dists.values():\n             seed = dist.seed\n             if seed in checked.keys():\n                 raise DistSeedRepeatError(checked[seed], dist)\n@@ -111,8 +111,8 @@ class Dists(sc.prettyobj):\n                 checked[seed] = dist\n         return\n \n-    def jump(self, to=None, delta=1):\n-        \"\"\" Advance all RNGs, e.g. to timestep \"to\", by jumping \"\"\"\n+    def jump(self, to=None, delta=1, force=False):\n+        \"\"\" Advance all RNGs, e.g. to call \"to\", by jumping \"\"\"\n         out = sc.autolist()\n \n         # Do not jump if centralized\n@@ -120,7 +120,24 @@ class Dists(sc.prettyobj):\n             return out\n \n         for dist in self.dists.values():\n-            out += dist.jump(to=to, delta=delta)\n+            out += dist.jump(to=to, delta=delta, force=force)\n+        return out\n+\n+    def jump_dt(self, ti=None, force=False): # Could this be simplified with jump(), or nice to have the parallel with Dist?\n+        \"\"\"\n+        Advance all RNGs to the next timestep\n+\n+        Args:\n+            ti (int): if specified, jump to this timestep (default: current sim timestep)\n+        \"\"\"\n+        out = sc.autolist()\n+\n+        # Do not jump if centralized\n+        if ss.options._centralized:\n+            return out\n+\n+        for dist in self.dists.values():\n+            out += dist.jump_dt(ti=ti, force=force)\n         return out\n \n     def reset(self):\n@@ -130,22 +147,34 @@ class Dists(sc.prettyobj):\n             out += dist.reset()\n         return out\n \n+    def copy_to_module(self, module):\n+        \"\"\" Copy the Sim's Dists object to the specified module \"\"\"\n+        matches = {key:dist for key,dist in self.dists.items() if id(dist.module) == id(module)} # Find which dists belong to this module\n+        if len(matches):\n+            new = Dists() # Create an empty Dists object\n+            new.__dict__.update(self.__dict__) # Shallow-copy all values over\n+            new.obj = module # Replace the module\n+            new.dists = sc.objdict(matches) # Replace the dists with a shallow copy the matching dists\n+            module.dists = new # Copy to the module\n+        else:\n+            new = None\n+        return new\n \n class Dist:\n     \"\"\"\n     Base class for tracking one random number generator associated with one distribution,\n     i.e. one decision per timestep.\n-    \n+\n     See ss.dist_list for a full list of supported distributions.\n-    \n+\n     Although it's possible in theory to define a custom distribution (i.e., not\n     one from NumPy or SciPy), in practice this is difficult. The distribution needs\n-    to have both a way to return random variables (easy), as well as the probability\n+    to have both a way to return random variates (easy), as well as the probability\n     point function (inverse CDF). In addition, the distribution must be able to\n     take a NumPy RNG as its bit generator. It's easier to just use a default Dist\n-    (e.g., ss.random()), and then take its output as input (i.e., quantiles) for \n+    (e.g., ss.random()), and then take its output as input (i.e., quantiles) for\n     whatever custom distribution you want to create.\n-    \n+\n     Args:\n         dist (rv_generic): optional; a scipy.stats distribution (frozen or not) to get the ppf from\n         distname (str): the name for this class of distribution (e.g. \"uniform\")\n@@ -157,13 +186,13 @@ class Dist:\n         sim (Sim): usually determined on initialization; the sim to use as input to callable parameters\n         module (Module): usually determined on initialization; the module to use as input to callable parameters\n         kwargs (dict): parameters of the distribution\n-        \n+\n     **Examples**::\n-        \n+\n         dist = ss.Dist(sps.norm, loc=3)\n         dist.rvs(10) # Return 10 normally distributed random numbers\n     \"\"\"\n-    def __init__(self, dist=None, distname=None, name=None, seed=None, offset=None, \n+    def __init__(self, dist=None, distname=None, name=None, seed=None, offset=None,\n                  strict=True, auto=True, sim=None, module=None, debug=False, **kwargs):\n         # If a string is provided as \"dist\" but there's no distname, swap the dist and the distname\n         if isinstance(dist, str) and distname is None:\n@@ -172,7 +201,7 @@ class Dist:\n         self.dist = dist # The type of distribution\n         self.distname = distname\n         self.name = name\n-        self.pars = sc.dictobj(kwargs) # The user-defined kwargs\n+        self.pars = sc.objdict(kwargs) # The user-defined kwargs\n         self.seed = seed # Usually determined once added to the container\n         self.offset = offset\n         self.module = module\n@@ -181,8 +210,8 @@ class Dist:\n         self.strict = strict\n         self.auto = auto\n         self.debug = debug\n-        \n-        # Auto-generated \n+\n+        # Auto-generated\n         self.rvs_func = None # The default function to call in make_rvs() to generate the random numbers\n         self.dynamic_pars = None # Whether or not the distribution has array or callable parameters\n         self._pars = None # Validated and transformed (if necessary) parameters\n@@ -190,8 +219,9 @@ class Dist:\n         self._size = None # Internal variable to keep track of actual number of random variates asked for\n         self._uids = None # Internal variable to track currently-in-use UIDs\n         self._slots = None # Internal variable to track currently-in-use slots\n-        \n+\n         # History and random state\n+        self.dt_jump_size = 1000 # How much to advance the RNG for each timestep (must be larger than the number times dist is called per timestep)\n         self.rng = None # The actual RNG generator for generating random numbers\n         self.trace = None # The path of this object within the parent\n         self.ind = 0 # The index of the RNG (usually updated on each timestep)\n@@ -200,32 +230,19 @@ class Dist:\n         self.ready = True\n         self.initialized = False\n         if not strict: # Otherwise, wait for a sim\n-            self.initialize()\n+            self.init()\n         return\n-    \n+\n     def __repr__(self):\n         \"\"\" Custom display to show state of object \"\"\"\n-        tracestr = '<no trace>' if self.trace is None else f\"{self.trace}\"\n-        classname = self.__class__.__name__\n-        diststr = ''\n-        if classname == 'Dist':\n-            if self.dist is not None:\n-                try:\n-                    diststr = f'dist={self.dist.name}, '\n-                except:\n-                    try: # What is wrong with you, SciPy -- after initialization, it moves here\n-                        diststr = f'dist={self.dist.dist.name}, '\n-                    except:\n-                        diststr = f'dist={type(self.dist)}'\n-            elif self.distname is not None:\n-                diststr = f'dist={self.distname}, '\n-        string = f'ss.{classname}({tracestr}, {diststr}pars={dict(self.pars)})'\n+        j = sc.dictobj(self.to_json())\n+        string = f'ss.{j.classname}({j.tracestr}, {j.diststr}pars={j.pars})'\n         return string\n-    \n+\n     def disp(self):\n         \"\"\" Return full display of object \"\"\"\n         return sc.pr(self)\n-    \n+\n     def show_state(self, output=False):\n         \"\"\" Show the state of the object \"\"\"\n         keys = ['pars', 'trace', 'offset', 'seed', 'ind', 'called', 'ready', 'state_int']\n@@ -238,11 +255,11 @@ class Dist:\n         else:\n             print(s)\n             return\n-    \n+\n     def __call__(self, n=1):\n         \"\"\" Alias to self.rvs() \"\"\"\n         return self.rvs(n=n)\n-    \n+\n     def set(self, *args, dist=None, **kwargs):\n         \"\"\" Set (change) the distribution type, or one or more parameters of the distribution \"\"\"\n         if dist:\n@@ -265,23 +282,23 @@ class Dist:\n     def bitgen(self):\n         try:    return self.rng._bit_generator\n         except: return None\n-    \n+\n     @property\n     def state(self):\n         \"\"\" Get the current state \"\"\"\n         try:    return self.bitgen.state\n         except: return None\n-        \n+\n     @property\n     def state_int(self):\n         \"\"\" Get the integer corresponding to the current state \"\"\"\n         try:    return self.state['state']['state']\n         except: return None\n-    \n+\n     def get_state(self):\n         \"\"\" Return a copy of the state \"\"\"\n         return self.state.copy()\n-    \n+\n     def make_history(self, reset=False):\n         \"\"\" Store the current state in history \"\"\"\n         if reset:\n@@ -292,12 +309,12 @@ class Dist:\n     def reset(self, state=0):\n         \"\"\"\n         Restore state, allowing the same numbers to be resampled\n-        \n+\n         Use 0 for original state, -1 for most recent state.\n-        \n+\n         **Example**::\n-            \n-            dist = ss.random(seed=5).initialize()\n+\n+            dist = ss.random(seed=5).init()\n             r1 = dist(5)\n             r2 = dist(5)\n             dist.reset(-1)\n@@ -314,37 +331,57 @@ class Dist:\n         self.ready = True\n         return self.state\n \n-    def jump(self, to=None, delta=1):\n+    def jump(self, to=None, delta=1, force=False):\n         \"\"\" Advance the RNG, e.g. to timestep \"to\", by jumping \"\"\"\n-        \n-        # Do not jump if centralized\n+\n+        # Do not jump if centralized # TODO: remove\n         if ss.options._centralized:\n             return self.state\n \n+        # Validation\n         jumps = to if (to is not None) else self.ind + delta\n+        if self.ind >= jumps and not force:\n+            errormsg = f'You tried to jump the distribution \"{self}\" to state {jumps}, but the ' \\\n+                       f'RNG state is already at state {self.ind}, meaning you will draw the same ' \\\n+                        'random numbers twice. If you are sure you want to do this, set force=True.'\n+            raise DistSeedRepeatError(msg=errormsg)\n+\n+        # Do the jumping\n         self.ind = jumps\n         self.reset() # First reset back to the initial state (used in case of different numbers of calls)\n         if jumps: # Seems to randomize state if jumps=0\n             self.bitgen.state = self.bitgen.jumped(jumps=jumps).state # Now take \"jumps\" number of jumps\n         return self.state\n-    \n-    def initialize(self, trace=None, seed=None, module=None, sim=None, slots=None, force=False):\n+\n+    def jump_dt(self, ti=None, force=False):\n+        \"\"\"\n+        Automatically jump on the next value of dt\n+\n+        Args:\n+            ti (int): if specified, jump to this timestep (default: current module timestep plus one)\n+        \"\"\"\n+        if ti is None:\n+            ti = self.module.t.ti + 1\n+        to = self.dt_jump_size*ti\n+        return self.jump(to=to, force=force)\n+\n+    def init(self, trace=None, seed=None, module=None, sim=None, slots=None, force=False):\n         \"\"\" Calculate the starting seed and create the RNG \"\"\"\n-        \n+\n         if self.initialized is True and not force: # Don't warn if we have a partially initialized distribution\n             msg = f'Distribution {self} is already initialized, use force=True if intentional'\n             ss.warn(msg)\n-        \n+\n         # Calculate the offset (starting seed)\n         self.process_seed(trace, seed)\n-        \n+\n         # Create the actual RNG\n         if ss.options._centralized:\n             self.rng = np.random.mtrand._rand # If _centralized, return the centralized numpy random number instance\n         else:\n             self.rng = np.random.default_rng(seed=self.seed)\n         self.make_history(reset=True)\n-        \n+\n         # Handle the sim, module, and slots\n         self.link_sim(sim)\n         self.link_module(module)\n@@ -356,7 +393,7 @@ class Dist:\n                 ss.warn(warnmsg)\n         if slots is not None:\n             self.slots = slots\n-            \n+\n         # Initialize the distribution and finalize\n         self.process_dist()\n         self.process_pars(call=False)\n@@ -371,21 +408,21 @@ class Dist:\n         else:\n             self.initialized = True\n         return self\n-    \n+\n     def link_sim(self, sim=None, overwrite=False):\n-        \"\"\" Shortcut for linking the sim, only overwriting an existing one if overwrite=True \"\"\"\n+        \"\"\" Shortcut for linking the sim, only overwriting an existing one if overwrite=True; not for the user \"\"\"\n         if (not self.sim or overwrite) and sim is not None:\n             self.sim = sim\n         return\n-    \n+\n     def link_module(self, module=None, overwrite=False):\n         \"\"\" Shortcut for linking the module \"\"\"\n         if (not self.module or overwrite) and module is not None:\n             self.module = module\n         return\n-    \n+\n     def process_seed(self, trace=None, seed=None):\n-        \"\"\" Obtain the seed offset by hashing the path to this distribution; called automatically \"\"\"\n+        \"\"\" Obtain the seed offset by hashing the path to this distribution; not for the user \"\"\"\n         unique_name = trace or self.trace or self.name\n         if unique_name:\n             if not self.name:\n@@ -396,34 +433,35 @@ class Dist:\n             self.offset = self.offset or 0\n         self.seed = self.offset + (seed or self.seed or 0)\n         return\n-    \n+\n     def process_dist(self):\n-        \"\"\" Ensure the distribution works \"\"\"\n-        \n+        \"\"\" Ensure the distribution works; not for the user \"\"\"\n+\n         # Handle a SciPy distribution, if provided\n         if self.dist is not None:\n-            \n+\n             # Pull out parameters of an already-frozen distribution\n             if isinstance(self.dist, sps._distn_infrastructure.rv_frozen):\n                 if not self.initialized: # Don't do this more than once\n                     self.pars = sc.dictobj(sc.mergedicts(self.pars, self.dist.kwds))\n-            \n+\n             # Convert to a frozen distribution\n             if isinstance(self.dist, sps._distn_infrastructure.rv_generic):\n                 spars = self.process_pars(call=False)\n-                self.dist = self.dist(**spars) \n-                \n+                spars.pop('dtype', None) # Not a valid arg for SciPy distributions\n+                self.dist = self.dist(**spars)\n+\n             # Override the default random state with the correct one\n-            self.dist.random_state = self.rng \n-            \n+            self.dist.random_state = self.rng\n+\n         # Set the default function for getting the rvs\n         if self.distname is not None and hasattr(self.rng, self.distname): # Don't worry if it doesn't, it's probably being manually overridden\n             self.rvs_func = self.distname # e.g. self.rng.uniform -- can't use the actual function because can become linked to the wrong RNG\n-        \n+\n         return\n-    \n+\n     def process_size(self, n=1):\n-        \"\"\" Handle an input of either size or UIDs and calculate size, UIDs, and slots \"\"\"\n+        \"\"\" Handle an input of either size or UIDs and calculate size, UIDs, and slots; not for the user \"\"\"\n         if np.isscalar(n) or isinstance(n, tuple):  # If passing a non-scalar size, interpret as dimension rather than UIDs iff a tuple\n             uids = None\n             slots = None\n@@ -431,6 +469,9 @@ class Dist:\n         else:\n             uids = ss.uids(n)\n             if len(uids):\n+                if self.slots is None:\n+                    errormsg = f'Could not find any slots in {self}. Did you remember to initialize the distribution with the sim?'\n+                    raise ValueError(errormsg)\n                 slots = self.slots[uids]\n                 if len(slots): # Handle case where uids is boolean\n                     size = slots.max() + 1\n@@ -439,83 +480,115 @@ class Dist:\n             else:\n                 slots = np.array([])\n                 size = 0\n-        \n+\n         self._n = n\n         self._size = size\n         self._uids = uids\n         self._slots = slots\n         return size, slots\n-    \n+\n     def process_pars(self, call=True):\n-        \"\"\" Ensure the supplied dist and parameters are valid, and initialize them; called automatically \"\"\"\n+        \"\"\" Ensure the supplied dist and parameters are valid, and initialize them; not for the user \"\"\"\n+        self._timepar = None # Time rescalings need to be done after distributions are calculated; store the correction factor here\n         self._pars = sc.cp(self.pars) # The actual keywords; shallow copy, modified below for special cases\n         if call:\n             self.call_pars() # Convert from function to values if needed\n         spars = self.sync_pars() # Synchronize parameters between the NumPy and SciPy distributions\n         return spars\n-    \n+\n+    def preprocess_timepar(self, key, timepar):\n+        \"\"\" Method to handle how timepars are processed; not for the user. By default, scales the output of the distribution. \"\"\"\n+        if self._timepar is None: # Store this here for later use\n+            self._timepar = sc.dcp(timepar) # Make a copy to avoid modifying the original\n+        elif timepar.factor != self._timepar.factor:\n+            errormsg = f'Cannot have time parameters in the same distribution with inconsistent unit/dt values: {self._pars}'\n+            raise ValueError(errormsg)\n+        self._pars[key] = timepar.v # Use the raw value, since it could be anything (including a function)\n+        return timepar.v # Also use this for the rest of the loop\n+\n+    def convert_callable(self, key, val, size, uids):\n+        \"\"\" Method to handle how callable parameters are processed; not for the user \"\"\"\n+        size_par = uids if uids is not None else size\n+        out = val(self.module, self.sim, size_par)\n+        val = np.asarray(out) # Necessary since FloatArrs don't allow slicing # TODO: check if this is correct\n+        self._pars[key] = val\n+        return val\n+\n+    def call_par(self, key, val, size, uids):\n+        \"\"\" Check if this parameter needs to be called to be turned into an array; not for the user \"\"\"\n+        if isinstance(val, ss.TimePar): # If it's a time parameter, transform it to a float now\n+            val = self.preprocess_timepar(key, val)\n+        if callable(val) and not isinstance(val, type): # If the parameter is callable, then call it (types can appear as callable)\n+            val = self.convert_callable(key, val, size, uids)\n+        return val\n+\n     def call_pars(self):\n-        \"\"\" Check if any parameters need to be called to be turned into arrays \"\"\"\n-        \n+        \"\"\" Check if any parameters need to be called to be turned into arrays; not for the user \"\"\"\n+\n         # Initialize\n         size, uids = self._size, self._uids\n         if self.dynamic_pars != False: # Allow \"False\" to prevent ever using dynamic pars (used in ss.choice())\n             self.dynamic_pars = None\n-        \n+\n         # Check each parameter\n         for key,val in self._pars.items():\n-            \n-            # If the parameter is callable, then call it\n-            if callable(val): \n-                size_par = uids if uids is not None else size\n-                out = val(self.module, self.sim, size_par) # TODO: swap order to sim, module, size?\n-                val = np.asarray(out) # Necessary since UIDArrays don't allow slicing # TODO: check if this is correct\n-                self._pars[key] = val\n-            \n+            val = self.call_par(key, val, size, uids)\n+\n             # If it's iterable and UIDs are provided, then we need to use array-parameter logic\n             if self.dynamic_pars is None and np.iterable(val) and uids is not None:\n                 self.dynamic_pars = True\n         return\n-    \n+\n     def sync_pars(self):\n-        \"\"\" Perform any necessary synchronizations or transformations on distribution parameters \"\"\"\n+        \"\"\" Perform any necessary synchronizations or transformations on distribution parameters; not for the user \"\"\"\n         self.update_dist_pars()\n         return self._pars\n-    \n+\n     def update_dist_pars(self, pars=None):\n-        \"\"\" Update SciPy distribution parameters \"\"\"\n+        \"\"\" Update SciPy distribution parameters; not for the user \"\"\"\n         if self.dist is not None:\n             pars = pars if pars is not None else self._pars\n             self.dist.kwds = pars\n         return\n-    \n+\n     def rand(self, size):\n         \"\"\" Simple way to get simple random numbers \"\"\"\n-        return self.rng.random(size)\n-    \n+        return self.rng.random(size, dtype=ss.dtypes.float) # Up to 2x faster with float32\n+\n     def make_rvs(self):\n-        \"\"\" Return default random numbers for scalar parameters \"\"\"\n+        \"\"\" Return default random numbers for scalar parameters; not for the user \"\"\"\n         if self.rvs_func is not None:\n             rvs_func = getattr(self.rng, self.rvs_func) # Can't store this because then it references the wrong RNG after copy\n-            rvs = rvs_func(**self._pars, size=self._size)\n+            rvs = rvs_func(size=self._size, **self._pars)\n         elif self.dist is not None:\n             rvs = self.dist.rvs(self._size)\n         else:\n             errormsg = 'Dist.rvs() failed: no valid NumPy/SciPy function found in this Dist. Has it been created and initialized correctly?'\n             raise ValueError(errormsg)\n         return rvs\n-    \n+\n     def ppf(self, rands):\n-        \"\"\" Return default random numbers for array parameters \"\"\"\n+        \"\"\" Return default random numbers for array parameters; not for the user \"\"\"\n         rvs = self.dist.ppf(rands)\n         return rvs\n-    \n+\n+    def postprocess_timepar(self, rvs):\n+        \"\"\" Scale random variates after generation; not for the user \"\"\"\n+        timepar = self._timepar # Shorten\n+        self._timepar = None # Remove the timepar which is no longer needed\n+        timepar.v = rvs # Replace the base value with the random variates\n+        timepar.update_cached() # Recalculate the factor and values with the time scaling\n+        rvs = timepar.values # Replace the rvs with the scaled version\n+        if isinstance(rvs, np.ndarray): # This can be false when converting values for a Bernoulli distribution (in which case rvs are actually dist parameters)\n+            rvs = rvs.astype(rvs.dtype) # Replace the random variates with the scaled version, and preserve type\n+        return rvs\n+\n     def rvs(self, n=1, reset=False):\n         \"\"\"\n-        Get random variables\n-        \n+        Get random variates -- use this!\n+\n         Args:\n-            n (int/tuple/arr): if an int or tuple, return this many random variables; if an array, treat as UIDs\n+            n (int/tuple/arr): if an int or tuple, return this many random variates; if an array, treat as UIDs\n             reset (bool): whether to automatically reset the random number distribution state after being called\n         \"\"\"\n         # Check for readiness\n@@ -523,32 +596,36 @@ class Dist:\n             raise DistNotInitializedError(self)\n         if not self.ready and self.strict and not ss.options._centralized:\n             raise DistNotReadyError(self)\n-        \n+\n         # Figure out size, UIDs, and slots\n         size, slots = self.process_size(n)\n-        \n+\n         # Check if size is 0, then we can return\n         if size == 0:\n-            return np.array([], dtype=int) # int dtype allows use as index, e.g. when filtering\n+            return np.array([], dtype=ss.dtypes.int) # int dtype allows use as index, e.g. when filtering\n         elif isinstance(size, ss.uids) and self.initialized == 'partial': # This point can be reached if and only if strict=False and UIDs are used as input\n             errormsg = f'Distribution {self} is only partially initialized; cannot generate random numbers to match UIDs'\n             raise ValueError(errormsg)\n-        \n+\n         # Store the state\n         self.make_history() # Store the pre-call state\n-        \n+\n         # Check if any keywords are callable -- parameters shouldn't need to be reprocessed otherwise\n         self.process_pars()\n-        \n+\n         # Actually get the random numbers\n         if self.dynamic_pars:\n-            rands = self.rand(size)[slots] # Get random values \n+            rands = self.rand(size)[slots] # Get random values\n             rvs = self.ppf(rands) # Convert to actual values via the PPF\n         else:\n             rvs = self.make_rvs() # Or, just get regular values\n             if self._slots is not None:\n                 rvs = rvs[self._slots]\n-        \n+\n+        # Scale by time if needed\n+        if self._timepar is not None:\n+            rvs = self.postprocess_timepar(rvs)\n+\n         # Tidy up\n         self.called += 1\n         if reset:\n@@ -558,55 +635,101 @@ class Dist:\n         elif self.strict:\n             self.ready = False\n         if self.debug:\n-            simstr = f'on ti={self.sim.ti} ' if self.sim else ''\n+            tistr   = f'on ti={self.module.ti} ' if self.module else ''\n             sizestr = f'with size={self._size}, '\n             slotstr = f'Σ(slots)={self._slots.sum()}, ' if self._slots else '<no slots>, '\n-            rvstr = f'Σ(rvs)={rvs.sum():0.2f}, |rvs|={rvs.mean():0.4f}'\n+            rvstr   = f'Σ(rvs)={rvs.sum():0.2f}, |rvs|={rvs.mean():0.4f}'\n             pre_state = str(self.history[-1]['state']['state'])[-5:]\n             post_state = str(self.state_int)[-5:]\n             statestr = f\"state {pre_state}→{post_state}\"\n-            print(f'Debug: {self} called {simstr}{sizestr}{slotstr}{rvstr}, {statestr}')\n+            print(f'Debug: {self} called {tistr}{sizestr}{slotstr}{rvstr}, {statestr}')\n             assert pre_state != post_state # Always an error if the state doesn't change after drawing random numbers\n-            \n+\n         return rvs\n \n+    def to_json(self):\n+        \"\"\" Return a dictionary representation of the Dist \"\"\"\n+        tracestr = '<no trace>' if self.trace is None else f\"{self.trace}\"\n+        classname = self.__class__.__name__\n+        diststr = ''\n+        if classname == 'Dist':\n+            if self.dist is not None:\n+                try:\n+                    diststr = f'dist={self.dist.name}, '\n+                except:\n+                    try: # What is wrong with you, SciPy -- after initialization, it moves here\n+                        diststr = f'dist={self.dist.dist.name}, '\n+                    except:\n+                        diststr = f'dist={type(self.dist)}'\n+            elif self.distname is not None:\n+                diststr = f'dist={self.distname}, '\n+        out = dict(\n+            type = 'Dist',\n+            classname = classname,\n+            tracestr = tracestr,\n+            diststr = diststr,\n+            pars = dict(self.pars),\n+        )\n+        return out\n+\n \n     def plot_hist(self, n=1000, bins=None, fig_kw=None, hist_kw=None):\n         \"\"\" Plot the current state of the RNG as a histogram \"\"\"\n-        pl.figure(**sc.mergedicts(fig_kw))\n+        plt.figure(**sc.mergedicts(fig_kw))\n         rvs = self.rvs(n)\n         self.reset(-1) # As if nothing ever happened\n-        pl.hist(rvs, bins=bins, **sc.mergedicts(hist_kw))\n-        pl.title(str(self))\n-        pl.xlabel('Value')\n-        pl.ylabel(f'Count ({n} total)')\n+        plt.hist(rvs, bins=bins, **sc.mergedicts(hist_kw))\n+        plt.title(str(self))\n+        plt.xlabel('Value')\n+        plt.ylabel(f'Count ({n} total)')\n         return rvs\n-        \n+\n \n #%% Specific distributions\n \n # Add common distributions so they can be imported directly; assigned to a variable since used in help messages\n dist_list = ['random', 'uniform', 'normal', 'lognorm_ex', 'lognorm_im', 'expon',\n-             'poisson', 'weibull', 'constant', 'randint', 'bernoulli', 'choice']\n+             'poisson', 'weibull', 'gamma', 'constant', 'randint', 'rand_raw', 'bernoulli',\n+             'choice', 'histogram']\n __all__ += dist_list\n+__all__ += ['multi_random'] # Not a dist in the same sense as the others\n \n \n class random(Dist):\n-    \"\"\" Random distribution, values on interval (0,1) \"\"\"\n+    \"\"\" Random distribution, with values on the interval (0, 1) \"\"\"\n     def __init__(self, **kwargs):\n-        super().__init__(distname='random', **kwargs)\n+        super().__init__(distname='random', dtype=ss.dtypes.float, **kwargs)\n         return\n-    \n+\n     def ppf(self, rands):\n         return rands\n \n \n class uniform(Dist):\n-    \"\"\" Uniform distribution, values on interval (low, high) \"\"\"\n-    def __init__(self, low=0.0, high=1.0, **kwargs):\n+    \"\"\"\n+    Uniform distribution, values on interval (low, high)\n+\n+    Args:\n+        low (float): the lower bound of the distribution (default 0.0)\n+        high (float): the upper bound of the distribution (default 1.0)\n+    \"\"\"\n+    def __init__(self, low=None, high=None, **kwargs):\n+        if high is None and low is not None: # One argument, swap\n+            high = low\n+            low = 0.0\n+        if low is None:\n+            low = 0.0\n+        if high is None:\n+            high = 1.0\n         super().__init__(distname='uniform', low=low, high=high, **kwargs)\n         return\n-    \n+\n+    def make_rvs(self):\n+        \"\"\" Specified here because uniform() doesn't take a dtype argument \"\"\"\n+        p = self._pars\n+        rvs = self.rand(self._size) * (p.high - p.low) + p.low\n+        return rvs\n+\n     def ppf(self, rands):\n         p = self._pars\n         rvs = rands * (p.high - p.low) + p.low\n@@ -614,8 +737,15 @@ class uniform(Dist):\n \n \n class normal(Dist):\n-    \"\"\" Normal distribution, with mean=loc and stdev=scale \"\"\"\n-    def __init__(self, loc=0.0, scale=1.0, **kwargs):\n+    \"\"\"\n+    Normal distribution\n+\n+    Args:\n+        loc (float): the mean of the distribution (default 0.0)\n+        scale (float) the standard deviation of the distribution (default 1.0)\n+\n+    \"\"\"\n+    def __init__(self, loc=0.0, scale=1.0, **kwargs): # Does not accept dtype\n         super().__init__(distname='normal', dist=sps.norm, loc=loc, scale=scale, **kwargs)\n         return\n \n@@ -623,21 +753,27 @@ class normal(Dist):\n class lognorm_im(Dist):\n     \"\"\"\n     Lognormal distribution, parameterized in terms of the \"implicit\" (normal)\n-    distribution, with mean=loc and stdev=scale (see lognorm_ex for comparison).\n-    \n+    distribution, with mean=loc and std=scale (see lognorm_ex for comparison).\n+\n     Note: the \"loc\" parameter here does *not* correspond to the mean of the resulting\n     random variates!\n-    \n+\n+    Args:\n+        mean (float): the mean of the underlying normal distribution (not this distribution) (default 0.0)\n+        sigma (float): the standard deviation of the underlying normal distribution (not this distribution) (default 1.0)\n+\n     **Example**::\n-        \n-        ss.lognorm_im(mean=2, sigma=1).rvs(1000).mean() # Should be roughly 10\n+\n+        ss.lognorm_im(mean=2, sigma=1, strict=False).rvs(1000).mean() # Should be roughly 10\n     \"\"\"\n-    def __init__(self, mean=0.0, sigma=1.0, **kwargs):\n+    def __init__(self, mean=0.0, sigma=1.0, **kwargs): # Does not accept dtype\n         super().__init__(distname='lognormal', dist=sps.lognorm, mean=mean, sigma=sigma, **kwargs)\n         return\n-    \n-    def sync_pars(self):\n+\n+    def sync_pars(self, call=True):\n         \"\"\" Translate between NumPy and SciPy parameters \"\"\"\n+        if call:\n+            self.call_pars()\n         p = self._pars\n         spars = sc.dictobj()\n         spars.s = p.sigma\n@@ -645,21 +781,32 @@ class lognorm_im(Dist):\n         spars.loc = 0\n         self.update_dist_pars(spars)\n         return spars\n-    \n+\n+    def preprocess_timepar(self, key, val):\n+        \"\"\" Not valid since incorrect time units \"\"\"\n+        errormsg = f'Cannot use timepars with a lognorm_im distribution ({self}) since its units are not time. Use lognorm_ex instead.'\n+        raise NotImplementedError(errormsg)\n+\n \n class lognorm_ex(Dist):\n     \"\"\"\n     Lognormal distribution, parameterized in terms of the \"explicit\" (lognormal)\n-    distribution, with mean=mean and stdev=stdev (see lognorm_im for comparison).\n-    \n+    distribution, with mean=mean and std=std for this distribution (see lognorm_im for comparison).\n+    Note that a mean ≤ 0.0 is impossible, since this is the parameter of the distribution\n+    after the log transform.\n+\n+    Args:\n+        mean (float): the mean of this distribution (not the underlying distribution) (default 1.0)\n+        std (float): the standard deviation of this distribution (not the underlying distribution) (default 1.0)\n+\n     **Example**::\n-        \n-        ss.lognorm_ex(mean=2, stdev=1).rvs(1000).mean() # Should be close to 2\n+\n+        ss.lognorm_ex(mean=2, std=1, strict=False).rvs(1000).mean() # Should be close to 2\n     \"\"\"\n-    def __init__(self, mean=1.0, stdev=1.0, **kwargs):\n-        super().__init__(distname='lognormal', dist=sps.lognorm, mean=mean, stdev=stdev, **kwargs)\n+    def __init__(self, mean=1.0, std=1.0, **kwargs): # Does not accept dtype\n+        super().__init__(distname='lognormal', dist=sps.lognorm, mean=mean, std=std, **kwargs)\n         return\n-    \n+\n     def convert_ex_to_im(self):\n         \"\"\"\n         Lognormal distributions can be specified in terms of the mean and standard\n@@ -671,58 +818,157 @@ class lognorm_ex(Dist):\n         self.call_pars() # Since can't work with functions\n         p = self._pars\n         mean = p.pop('mean')\n-        stdev = p.pop('stdev')\n+        std = p.pop('std')\n         if np.isscalar(mean) and mean <= 0:\n             errormsg = f'Cannot create a lognorm_ex distribution with mean≤0 (mean={mean}); did you mean to use lognorm_im instead?'\n             raise ValueError(errormsg)\n-        std2 = stdev**2\n+        std2 = std**2\n         mean2 = mean**2\n-        sigma_im = np.sqrt(np.log(std2/mean2 + 1)) # Computes stdev for the underlying normal distribution\n+        sigma_im = np.sqrt(np.log(std2/mean2 + 1)) # Computes std for the underlying normal distribution\n         mean_im  = np.log(mean2 / np.sqrt(std2 + mean2)) # Computes the mean of the underlying normal distribution\n         p.mean = mean_im\n         p.sigma = sigma_im\n         return mean_im, sigma_im\n-    \n+\n     def sync_pars(self):\n         \"\"\" Convert from overlying to underlying parameters, then translate to SciPy \"\"\"\n         self.convert_ex_to_im()\n-        spars = lognorm_im.sync_pars(self) # Borrow sync_pars from lognorm_im\n+        spars = lognorm_im.sync_pars(self, call=False) # Borrow sync_pars from lognorm_im\n         return spars\n-    \n+\n \n class expon(Dist):\n-    \"\"\" Exponential distribution \"\"\"\n+    \"\"\"\n+    Exponential distribution\n+\n+    Args:\n+        scale (float): the scale of the distribution (default 1.0)\n+\n+    \"\"\"\n     def __init__(self, scale=1.0, **kwargs):\n         super().__init__(distname='exponential', dist=sps.expon, scale=scale, **kwargs)\n         return\n \n \n-class poisson(Dist):\n-    \"\"\" Exponential distribution \"\"\"\n+class poisson(Dist): # TODO: does not currently scale correctly with dt\n+    \"\"\"\n+    Poisson distribution\n+\n+    Args:\n+        lam (float): the scale of the distribution (default 1.0)\n+    \"\"\"\n     def __init__(self, lam=1.0, **kwargs):\n         super().__init__(distname='poisson', dist=sps.poisson, lam=lam, **kwargs)\n         return\n-    \n+\n     def sync_pars(self):\n         \"\"\" Translate between NumPy and SciPy parameters \"\"\"\n         spars = dict(mu=self._pars.lam)\n         self.update_dist_pars(spars)\n         return spars\n \n+    def preprocess_timepar(self, key, timepar):\n+        \"\"\" Try to update the timepar before calculating array parameters, but raise an exception if this isn't possible \"\"\"\n+        try:\n+            timepar.update_cached()\n+        except Exception as E:\n+            errormsg = f'Could not process timepar {timepar} for {self}. Note that Poisson distributions are not compatible with both callable parameters and timepars, since this would change the shape in an unknowable way.'\n+            raise ValueError(errormsg) from E\n+\n+        self._pars[key] = timepar.values # Use the raw value, since it could be anything (including a function)\n+        return timepar.values # Also use this for the rest of the loop\n+\n \n class randint(Dist):\n-    \"\"\" Random integers, values on the interval [low, high-1] (i.e. \"high\" is excluded) \"\"\"\n-    def __init__(self, low=0, high=2,  **kwargs):\n-        super().__init__(distname='integers', dist=sps.randint, low=low, high=high, **kwargs)\n+    \"\"\"\n+    Random integer distribution, on the interval [low, high)\n+\n+    Args:\n+        low (int): the lower bound of the distribution (default 0)\n+        high (int): the upper bound of the distribution (default of maximum integer size: 9,223,372,036,854,775,807)\n+        allow_time (bool): allow time parameters to be specified as high/low values (disabled by default since introduces rounding error)\n+    \"\"\"\n+    def __init__(self, *args, low=None, high=None, dtype=ss.dtypes.rand_int, allow_time=False, **kwargs):\n+        # Handle input arguments # TODO: reconcile with how this is handled in uniform()\n+        self.allow_time = allow_time\n+        if len(args):\n+            if len(args) == 1:\n+                high = args[0]\n+            elif len(args) == 2:\n+                low,high = args\n+            else:\n+                errormsg = f'ss.randint() takes one or two arguments, not {len(args)}'\n+                raise ValueError(errormsg)\n+        if low is None:\n+            low = 0\n+        if high is None:\n+            high = np.iinfo(ss.dtypes.rand_int).max\n+\n+        if ss.options._centralized: # randint because we're accessing via numpy.random\n+            super().__init__(distname='randint', low=low, high=high, dtype=dtype, **kwargs)\n+        else: # integers instead of randint because interfacing a numpy.random.Generator\n+            super().__init__(distname='integers', low=low, high=high, dtype=dtype, **kwargs)\n         return\n-    \n+\n+    def ppf(self, rands):\n+        p = self._pars\n+        rvs = rands * (p.high + 1 - p.low) + p.low\n+        rvs = rvs.astype(self.dtype)\n+        return rvs\n+\n+    def preprocess_timepar(self, key, timepar):\n+        \"\"\" Not valid due to a rounding error \"\"\"\n+        if self.allow_time:\n+            return super().preprocess_timepar(key, timepar)\n+        else:\n+            errormsg = f'Cannot use timepars with a randint distribution ({self}) since the values may be rounded incorrectly. Use uniform() instead and convert to int yourself, or set allow_time=True if you really want to do this.'\n+            raise NotImplementedError(errormsg)\n+\n+\n+class rand_raw(Dist):\n+    \"\"\"\n+    Directly sample raw integers (uint64) from the random number generator.\n+    Typicaly only used with ss.combine_rands().\n+    \"\"\"\n+    def make_rvs(self):\n+        if ss.options._centralized:\n+            return self.rng.randint(low=0, high=np.iinfo(np.uint64).max, dtype=np.uint64, size=self._size)\n+        else:\n+            return self.bitgen.random_raw(self._size) # TODO: figure out how to make accept dtype, or check speed\n+\n \n class weibull(Dist):\n-    \"\"\" Weibull distribution -- NB, uses SciPy rather than NumPy \"\"\"\n-    def __init__(self, c=1, loc=0, scale=1,  **kwargs):\n+    \"\"\"\n+    Weibull distribution (specifically, scipy.stats.weibull_min)\n+\n+    Args:\n+        c (float): the shape parameter, sometimes called k (default 1.0)\n+        loc (float): the location parameter, which shifts the position of the distribution (default 0.0)\n+        scale (float): the scale parameter, sometimes called λ (default 1.0)\n+    \"\"\"\n+    def __init__(self, c=1.0, loc=0.0, scale=1.0, **kwargs):\n         super().__init__(distname='weibull', dist=sps.weibull_min, c=c, loc=loc, scale=scale, **kwargs)\n         return\n-    \n+\n+    def make_rvs(self):\n+        \"\"\" Use SciPy rather than NumPy to include the scale parameter \"\"\"\n+        rvs = self.dist.rvs(self._size)\n+        return rvs\n+\n+\n+class gamma(Dist):\n+    \"\"\"\n+    Gamma distribution (specifically, scipy.stats.gamma)\n+\n+    Args:\n+        a (float): the shape parameter, sometimes called k (default 1.0)\n+        loc (float): the location parameter, which shifts the position of the distribution (default 0.0)\n+        scale (float): the scale parameter, sometimes called θ (default 1.0)\n+    \"\"\"\n+    def __init__(self, a=1.0, loc=0.0, scale=1.0, **kwargs):\n+        super().__init__(distname='gamma', dist=sps.gamma, a=a, loc=loc, scale=scale, **kwargs)\n+        return\n+\n     def make_rvs(self):\n         \"\"\" Use SciPy rather than NumPy to include the scale parameter \"\"\"\n         rvs = self.dist.rvs(self._size)\n@@ -730,14 +976,19 @@ class weibull(Dist):\n \n \n class constant(Dist):\n-    \"\"\" Constant (delta) distribution: equivalent to np.full() \"\"\"\n-    def __init__(self, v=0, **kwargs):\n+    \"\"\"\n+    Constant (delta) distribution: equivalent to np.full()\n+\n+    Args:\n+        v (float): the value to return\n+    \"\"\"\n+    def __init__(self, v=0.0, **kwargs):\n         super().__init__(distname='const', v=v, **kwargs)\n         return\n-    \n+\n     def make_rvs(self):\n         return np.full(self._size, self._pars.v)\n-    \n+\n     def ppf(self, rands): # NB: don't actually need to use random numbers here, but not worth the complexity of avoiding this\n         return np.full(rands.shape, self._pars.v)\n \n@@ -745,26 +996,32 @@ class constant(Dist):\n class bernoulli(Dist):\n     \"\"\"\n     Bernoulli distribution: return True or False with the specified probability (which can be an array)\n-    \n+\n     Unlike other distributions, Bernoulli distributions have a filter() method,\n     which returns elements of the array that return True.\n+\n+    Args:\n+        p (float): the probability of returning True (default 0.5)\n     \"\"\"\n     def __init__(self, p=0.5, **kwargs):\n         super().__init__(distname='bernoulli', p=p, **kwargs)\n         return\n-    \n+\n     def make_rvs(self):\n-        rvs = self.rng.random(self._size) < self._pars.p # 3x faster than using rng.binomial(1, p, size)\n+        rvs = self.rand(self._size) < self._pars.p # 3x faster than using rng.binomial(1, p, size)\n         return rvs\n-    \n+\n     def ppf(self, rands):\n         rvs = rands < self._pars.p\n         return rvs\n-    \n+\n     def filter(self, uids=None, both=False):\n         \"\"\" Return UIDs that correspond to True, or optionally return both True and False \"\"\"\n         if uids is None:\n             uids = self.sim.people.auids # All active UIDs\n+        elif isinstance(uids, (ss.BoolArr, ss.IndexArr)):\n+            uids = uids.uids\n+\n         bools = self.rvs(uids)\n         if both:\n             return uids[bools], uids[~bools]\n@@ -775,24 +1032,55 @@ class bernoulli(Dist):\n         \"\"\" Alias to filter(uids, both=True) \"\"\"\n         return self.filter(uids=uids, both=True)\n \n+    def call_par(self, key, val, size, uids):\n+        \"\"\" Reverse the usual order of processing so callable is processed first, and then the timepar conversion \"\"\"\n+        is_timepar = isinstance(val, ss.TimePar)\n+\n+        if is_timepar: # If it's a time parameter, pull out the value\n+            timepar = sc.dcp(val) # Rename to make more sense within the context of this method\n+            val = timepar.v # Pull out the base value; we'll deal with the transformation later\n+            self._timepar = timepar # This is used, then destroyed, by postprocess_timepar() below\n+            if isinstance(timepar, ss.dur): # Validation\n+                errormsg = f'Bernoulli distributions can only be used with ss.time_prob() or ss.rate(), not {timepar}'\n+                raise TypeError(errormsg)\n+\n+        # As normal: if the parameter is callable, then call it (types can appear as callable)\n+        if callable(val) and not isinstance(val, type):\n+            val = self.convert_callable(key, val, size, uids)\n+\n+        # Process as a timepar\n+        if is_timepar:\n+            val = self.postprocess_timepar(val) # Note: this is processing the parameter rather than the rvs as usual\n+\n+        # Store in the parameters and return\n+        self._pars[key] = val\n+        return val\n+\n \n class choice(Dist):\n     \"\"\"\n-    Random choice between discrete options\n-    \n+    Random choice between discrete options (note: dynamic parameters not supported)\n+\n+    Args:\n+        a (int or array): the number of choices, or the choices themselves (default 2)\n+        p (array): if supplied, the probability of each choice (default, 1/a for a choices)\n+\n     **Examples**::\n-        \n+\n         # Simulate 10 die rolls\n-        ss.choice(6)(10) + 1 \n-        \n+        ss.choice(6, strict=False)(10) + 1\n+\n         # Choose between specified options each with a specified probability (must sum to 1)\n-        ss.choice(a=[30, 70], p=[0.3, 0.7])(10)\n+        ss.choice(a=[30, 70], p=[0.3, 0.7], strict=False)(10)\n+\n+    Note: although Bernoulli trials can be generated using a=2, it is much faster\n+    to use ss.bernoulli() instead.\n     \"\"\"\n     def __init__(self, a=2, p=None, **kwargs):\n         super().__init__(distname='choice', a=a, p=p, **kwargs)\n         self.dynamic_pars = False # Set to false since array arguments don't imply dynamic pars here\n         return\n-    \n+\n     def ppf(self, rands):\n         \"\"\" Shouldn't actually be needed since dynamic pars not supported \"\"\"\n         pars = self._pars\n@@ -803,28 +1091,165 @@ class choice(Dist):\n         rvs = pars.a[inds]\n         return rvs\n \n+    def preprocess_timepar(self, key, timepar):\n+        \"\"\" Not valid since does not scale with time \"\"\"\n+        errormsg = f'Cannot use timepars with a choice distribution ({self}) since its units are not time. Convert output to time units instead.'\n+        raise NotImplementedError(errormsg)\n+\n+\n+class histogram(Dist):\n+    \"\"\"\n+    Sample from a histogram with defined bins\n+\n+    Note: unlike other distributions, the parameters of this distribution can't\n+    be modified after creation.\n+\n+    Args:\n+        values (array): the probability (or count) of each bin\n+        bins (array): the edges of each bin\n+        density (bool): treat the histogram as a density instead of counts; only matters with unequal bin widths, see numpy.histogram and scipy.stats.rv_histogram for more information\n+        data (array): if supplied, compute the values and bin edges using this data and np.histogram() instead\n+\n+    Note: if the length of bins is equal to the length of values, they will be\n+    interpreted as left bin edges, and one additional right-bin edge will be added\n+    based on the difference between the last two bins (e.g. if the last two bins are\n+    40 and 50, the final right edge will be added at 60). If no bins are supplied,\n+    then they will be created as integers matching the length of the values.\n+\n+    The values can be supplied in either normalized (sum to 1) or un-normalized\n+    format.\n+\n+    **Examples**::\n+\n+        # Sample from an age distribution\n+        age_bins = [0,    10,  20,  40,  65, 100]\n+        age_vals = [0.1, 0.1, 0.3, 0.3, 0.2]\n+        h1 = ss.histogram(values=age_vals, bins=age_bins, strict=False)\n+        h1.plot_hist()\n+\n+        # Create a histogram from data\n+        data = np.random.randn(10_000)*2+5\n+        h2 = ss.histogram(data=data, strict=False)\n+        h2.plot_hist(bins=100)\n+    \"\"\"\n+    def __init__(self, values=None, bins=None, density=False, data=None, **kwargs):\n+        if data is not None:\n+            if values is not None:\n+                errormsg = 'You can supply values or data, but not both'\n+                raise ValueError(errormsg)\n+            kw = {'bins':bins} if bins is not None else {} # Hack to not overwrite default bins value\n+            values, bins = np.histogram(data, **kw)\n+        else:\n+            if values is None:\n+                values = [1.0] # Uniform distribution\n+            values = sc.toarray(values)\n+            if bins is None:\n+                bins = np.arange(len(values)+1)\n+            bins = sc.toarray(bins)\n+        if len(bins) == len(values): # Append a final bin, if necessary\n+            delta = bins[-1] - bins[-2]\n+            bins = np.append(bins, bins[-1]+delta)\n+        vsum = values.sum()\n+        if vsum != 1.0:\n+            values = values / vsum\n+        dist = sps.rv_histogram((values, bins), density=density) # Create the SciPy distribution\n+        super().__init__(dist=dist, distname='histogram', **kwargs)\n+        self.dynamic_pars = False # Set to false since array arguments don't imply dynamic pars here\n+        return\n+\n+\n+class multi_random(sc.prettyobj):\n+    \"\"\"\n+    A class for holding two or more ss.random() distributions, and generating\n+    random numbers linked to each of them. Useful for e.g. pairwise transmission\n+    probabilities.\n+\n+    See ss.combine_rands() for the manual version; in almost all cases this class\n+    should be used instead.\n+\n+    Usage:\n+        multi = ss.multi_random('source', 'target')\n+        rvs = multi.rvs(source_uids, target_uids)\n+    \"\"\"\n+    def __init__(self, names, *args, **kwargs):\n+        names = sc.mergelists(names, args)\n+        self.dists = [ss.random(name=name, **kwargs) for name in names]\n+        return\n+\n+    def __len__(self):\n+        return len(self.dists)\n+\n+    def init(self, *args, **kwargs):\n+        \"\"\" Not usually needed since each dist will handle this automatically; for completeness only \"\"\"\n+        for dist in self.dists: dist.init(*args, **kwargs)\n+        return\n+\n+    def reset(self, *args, **kwargs):\n+        \"\"\" Not usually needed since each dist will handle this automatically; for completeness only \"\"\"\n+        for dist in self.dists: dist.reset(*args, **kwargs)\n+        return\n+\n+    def jump(self, *args, **kwargs):\n+        \"\"\" Not usually needed since each dist will handle this automatically; for completeness only \"\"\"\n+        for dist in self.dists: dist.jump(*args, **kwargs)\n+        return\n+\n+    @staticmethod\n+    @nb.njit(fastmath=True, parallel=False, cache=True) # Numba is 3x faster, but disabling parallel for efficiency\n+    def combine_rvs(rvs_list, int_type, int_max):\n+        \"\"\" Combine inputs into one number \"\"\"\n+        # Combine using bitwise-or\n+        rand_ints = rvs_list[0].view(int_type)\n+        for rand_floats in rvs_list[1:]:\n+            rand_ints2 = rand_floats.view(int_type)\n+            rand_ints = np.bitwise_xor(rand_ints*rand_ints2, rand_ints-rand_ints2)\n+\n+        # Normalize\n+        rvs = rand_ints / int_max\n+        return rvs\n+\n+    def rvs(self, *args):\n+        \"\"\" Get random variates from each of the underlying distributions and combine them efficiently \"\"\"\n+        # Validation\n+        n_args = len(args)\n+        n_dists = len(self)\n+        if n_args != len(self):\n+            errormsg = f'Number of UID lists supplied ({n_args}) does not match number of distributions ({n_dists})'\n+            raise ValueError(errormsg)\n+\n+        rvs_list = [dist.rvs(arg) for dist,arg in zip(self.dists, args)]\n+        int_type = ss.dtypes.rand_uint\n+        int_max = np.iinfo(int_type).max\n+        rvs = self.combine_rvs(rvs_list, int_type, int_max)\n+        return rvs\n+\n+\n+\n \n #%% Dist exceptions\n \n class DistNotInitializedError(RuntimeError):\n     \"\"\" Raised when Dist object is called when not initialized. \"\"\"\n-    def __init__(self, dist):\n-        msg = f'{dist} has not been initialized; please call dist.initialize()'\n+    def __init__(self, dist=None, msg=None):\n+        if msg is None:\n+            msg = f'{dist} has not been initialized; please set strict=False when creating the distribution, or call dist.init()'\n         super().__init__(msg)\n         return\n \n \n class DistNotReadyError(RuntimeError):\n     \"\"\" Raised when a Dist object is called without being ready. \"\"\"\n-    def __init__(self, dist):\n-        msg = f'{dist} is not ready. This is likely caused by calling a distribution multiple times in a single step. Call dist.jump() to reset.'\n+    def __init__(self, dist=None, msg=None):\n+        if msg is None:\n+            msg = f'{dist} is not ready. This is likely caused by calling a distribution multiple times in a single step. Call dist.jump() to reset.'\n         super().__init__(msg)\n         return\n \n \n class DistSeedRepeatError(RuntimeError):\n     \"\"\" Raised when a Dist object shares a seed with another \"\"\"\n-    def __init__(self, dist1, dist2):\n-        msg = f'A common seed was found between {dist1} and {dist2}. This is likely caused by incorrect initialization of the parent Dists object.'\n+    def __init__(self, dist1=None, dist2=None, msg=None):\n+        if msg is None:\n+            msg = f'A common seed was found between {dist1} and {dist2}. This is likely caused by incorrect initialization of the parent Dists object.'\n         super().__init__(msg)\n         return\ndiff --git a/starsim/interventions.py b/starsim/interventions.py\nindex 4c40500..5981515 100644\n--- a/starsim/interventions.py\n+++ b/starsim/interventions.py\n@@ -1,68 +1,37 @@\n \"\"\"\n-Define interventions (and analyzers)\n+Define interventions\n \"\"\"\n-\n import starsim as ss\n import sciris as sc\n import numpy as np\n \n-__all__ = ['Plugin', 'Analyzer', 'Intervention']\n+__all__ = ['Intervention']\n \n \n-class Plugin(ss.Module):\n-    \"\"\" Base class for interventions and analyzers \"\"\"\n-    def __init__(self, *args, **kwargs):\n-        super().__init__(*args, **kwargs)\n-        return\n-    \n-    def __call__(self, *args, **kwargs):\n-        return self.apply(*args, **kwargs)\n-    \n-    def init_pre(self, sim):\n-        return super().init_pre(sim)\n-    \n-    def apply(self, sim):\n-        pass\n-\n-    def finalize(self):\n-        return super().finalize()\n-    \n-    @classmethod\n-    def from_func(cls, func):\n-        \"\"\" Create an intervention or analyzer from a function \"\"\"\n-        name = func.__name__\n-        new = cls(name=name)\n-        new.apply = func\n-        return new\n-\n-\n-class Analyzer(Plugin):\n-    \"\"\"\n-    Base class for analyzers. Analyzers are used to provide more detailed information \n-    about a simulation than is available by default -- for example, pulling states \n-    out of sim.people on a particular timestep before they get updated on the next step.\n-    \n-    The key method of the analyzer is ``apply()``, which is called with the sim\n-    on each timestep.\n-    \n-    To retrieve a particular analyzer from a sim, use sim.get_analyzer().\n-    \"\"\"\n-    pass\n-\n-\n-class Intervention(Plugin):\n+class Intervention(ss.Module):\n     \"\"\"\n     Base class for interventions.\n-    \n-    The key method of the intervention is ``apply()``, which is called with the sim\n+\n+    The key method of the intervention is ``step()``, which is called with the sim\n     on each timestep.\n     \"\"\"\n \n-    def __init__(self, eligibility=None, *args, **kwargs):\n+    def __init__(self, *args, eligibility=None, **kwargs):\n         super().__init__(*args, **kwargs)\n         self.eligibility = eligibility\n         return\n \n+    @property\n+    def has_product(self):\n+        \"\"\" Check if the intervention has a product \"\"\"\n+        return hasattr(self, 'product') and self.product is not None\n+\n+    def init_pre(self, sim):\n+        super().init_pre(sim)\n+        if self.has_product:\n+            self.product.init_pre(self.sim)\n+        return\n+\n     def _parse_product(self, product):\n         \"\"\"\n         Parse the product input\n@@ -79,12 +48,12 @@ class Intervention(Plugin):\n     def _parse_product_str(self, product):\n         raise NotImplementedError\n \n-    def check_eligibility(self, sim):\n+    def check_eligibility(self):\n         \"\"\"\n         Return an array of indices of agents eligible for screening at time t\n         \"\"\"\n         if self.eligibility is not None:\n-            is_eligible = self.eligibility(sim)\n+            is_eligible = self.eligibility(self.sim)\n             if is_eligible is not None and len(is_eligible): # Only worry if non-None/nonzero length\n                 if isinstance(is_eligible, ss.BoolArr):\n                     is_eligible = is_eligible.uids\n@@ -92,7 +61,7 @@ class Intervention(Plugin):\n                     errormsg = f'Eligibility function must return BoolArr or UIDs, not {type(is_eligible)} {is_eligible}'\n                     raise TypeError(errormsg)\n         else:\n-            is_eligible = sim.people.auids # Everyone\n+            is_eligible = self.sim.people.auids # Everyone\n         return is_eligible\n \n \n@@ -105,7 +74,7 @@ class RoutineDelivery(Intervention):\n     Base class for any intervention that uses routine delivery; handles interpolation of input years.\n     \"\"\"\n \n-    def __init__(self, years=None, start_year=None, end_year=None, prob=None, annual_prob=True, *args, **kwargs):\n+    def __init__(self, *args, years=None, start_year=None, end_year=None, prob=None, annual_prob=True, **kwargs):\n         super().__init__(*args, **kwargs)\n         self.years = years\n         self.start_year = start_year\n@@ -116,6 +85,7 @@ class RoutineDelivery(Intervention):\n         return\n \n     def init_pre(self, sim):\n+        super().init_pre(sim)\n \n         # Validate inputs\n         if (self.years is not None) and (self.start_year is not None or self.end_year is not None):\n@@ -124,26 +94,29 @@ class RoutineDelivery(Intervention):\n \n         # If start_year and end_year are not provided, figure them out from the provided years or the sim\n         if self.years is None:\n-            if self.start_year is None: self.start_year = sim.pars['start']\n-            if self.end_year is None:   self.end_year = sim.pars['end']\n+            if self.start_year is None: self.start_year = sim.pars.start\n+            if self.end_year is None:   self.end_year = sim.pars.stop\n         else:\n+            self.years = sc.promotetoarray(self.years)\n             self.start_year = self.years[0]\n             self.end_year = self.years[-1]\n \n         # More validation\n-        if not(any(np.isclose(self.start_year, sim.yearvec)) and any(np.isclose(self.end_year, sim.yearvec))):\n+        yearvec = sim.t.yearvec\n+        if not(any(np.isclose(self.start_year, yearvec)) and any(np.isclose(self.end_year, yearvec))):\n             errormsg = 'Years must be within simulation start and end dates.'\n             raise ValueError(errormsg)\n \n         # Adjustment to get the right end point\n-        adj_factor = int(1 / sim.dt) - 1 if sim.dt < 1 else 1\n+        dt = sim.pars.dt # TODO: need to eventually replace with own timestep, but not initialized yet since super().init_pre() hasn't been called\n+        adj_factor = int(1/dt) - 1 if dt < 1 else 1\n \n         # Determine the timepoints at which the intervention will be applied\n-        self.start_point = sc.findfirst(sim.yearvec, self.start_year)\n-        self.end_point   = sc.findfirst(sim.yearvec, self.end_year) + adj_factor\n+        self.start_point = sc.findfirst(yearvec, self.start_year)\n+        self.end_point   = sc.findfirst(yearvec, self.end_year) + adj_factor\n         self.years       = sc.inclusiverange(self.start_year, self.end_year)\n         self.timepoints  = sc.inclusiverange(self.start_point, self.end_point)\n-        self.yearvec     = np.arange(self.start_year, self.end_year + adj_factor, sim.dt)\n+        self.yearvec     = np.arange(self.start_year, self.end_year + adj_factor, dt) # TODO: integrate with self.t\n \n         # Get the probability input into a format compatible with timepoints\n         if len(self.years) != len(self.prob):\n@@ -156,7 +129,7 @@ class RoutineDelivery(Intervention):\n             self.prob = sc.smoothinterp(self.yearvec, self.years, self.prob, smoothness=0)\n \n         # Lastly, adjust the probability by the sim's timestep, if it's an annual probability\n-        if self.annual_prob: self.prob = 1 - (1 - self.prob) ** sim.dt\n+        if self.annual_prob: self.prob = 1 - (1 - self.prob) ** dt\n \n         return\n \n@@ -166,7 +139,7 @@ class CampaignDelivery(Intervention):\n     Base class for any intervention that uses campaign delivery; handles interpolation of input years.\n     \"\"\"\n \n-    def __init__(self, years, interpolate=None, prob=None, *args, **kwargs):\n+    def __init__(self, *args, years=None, interpolate=None, prob=None, **kwargs):\n         super().__init__(*args, **kwargs)\n         self.years = sc.promotetoarray(years)\n         self.interpolate = True if interpolate is None else interpolate\n@@ -174,8 +147,10 @@ class CampaignDelivery(Intervention):\n         return\n \n     def init_pre(self, sim):\n+        super().init_pre(sim)\n+\n         # Decide whether to apply the intervention at every timepoint throughout the year, or just once.\n-        self.timepoints = sc.findnearest(sim.yearvec, self.years)\n+        self.timepoints = sc.findnearest(sim.timevec, self.years)\n \n         if len(self.prob) == 1:\n             self.prob = np.array([self.prob[0]] * len(self.timepoints))\n@@ -214,46 +189,49 @@ class BaseTest(Intervention):\n         return\n \n     def init_pre(self, sim):\n-        Intervention.init_pre(self, sim)\n+        super().init_pre(sim)\n         self.outcomes = {k: np.array([], dtype=int) for k in self.product.hierarchy}\n         return\n \n-    def deliver(self, sim):\n+    def deliver(self):\n         \"\"\"\n         Deliver the diagnostics by finding who's eligible, finding who accepts, and applying the product.\n         \"\"\"\n+        sim = self.sim\n         ti = sc.findinds(self.timepoints, sim.ti)[0]\n         prob = self.prob[ti]  # Get the proportion of people who will be tested this timestep\n-        eligible_uids = self.check_eligibility(sim)  # Check eligibility\n+        eligible_uids = self.check_eligibility()  # Check eligibility\n         self.coverage_dist.set(p=prob)\n         accept_uids = self.coverage_dist.filter(eligible_uids)\n         if len(accept_uids):\n-            self.outcomes = self.product.administer(sim, accept_uids)  # Actually administer the diagnostic\n+            self.outcomes = self.product.administer(accept_uids)  # Actually administer the diagnostic\n         return accept_uids\n \n-    def check_eligibility(self, sim):\n+    def check_eligibility(self):\n         raise NotImplementedError\n \n \n class BaseScreening(BaseTest):\n     \"\"\"\n     Base class for screening.\n+\n     Args:\n         kwargs (dict): passed to BaseTest\n     \"\"\"\n-    def check_eligibility(self, sim):\n+    def check_eligibility(self):\n         \"\"\"\n         Check eligibility\n         \"\"\"\n         raise NotImplementedError\n \n-    def apply(self, sim, module=None):\n+    def step(self):\n         \"\"\"\n         Perform screening by finding who's eligible, finding who accepts, and applying the product.\n         \"\"\"\n+        sim = self.sim\n         accept_uids = ss.uids()\n-        if sim.ti in self.timepoints:\n-            accept_uids = self.deliver(sim)\n+        if sim.ti in self.timepoints: # TODO: change to self.ti\n+            accept_uids = self.deliver()\n             self.screened[accept_uids] = True\n             self.screens[accept_uids] += 1\n             self.ti_screened[accept_uids] = sim.ti\n@@ -266,16 +244,17 @@ class BaseScreening(BaseTest):\n class BaseTriage(BaseTest):\n     \"\"\"\n     Base class for triage.\n+\n     Args:\n         kwargs (dict): passed to BaseTest\n     \"\"\"\n-    def check_eligibility(self, sim):\n-        return sc.promotetoarray(self.eligibility(sim))\n+    def check_eligibility(self):\n+        return sc.promotetoarray(self.eligibility(self.sim))\n \n-    def apply(self, sim):\n+    def step(self):\n         self.outcomes = {k: np.array([], dtype=int) for k in self.product.hierarchy}\n         accept_inds = ss.uids()\n-        if sim.t in self.timepoints: accept_inds = self.deliver(sim)\n+        if self.sim.t in self.timepoints: accept_inds = self.deliver() # TODO: not robust for timestep\n         return accept_inds\n \n \n@@ -285,21 +264,12 @@ class routine_screening(BaseScreening, RoutineDelivery):\n     See base classes for a description of input arguments.\n \n     **Examples**::\n+\n         screen1 = ss.routine_screening(product=my_prod, prob=0.02) # Screen 2% of the eligible population every year\n         screen2 = ss.routine_screening(product=my_prod, prob=0.02, start_year=2020) # Screen 2% every year starting in 2020\n         screen3 = ss.routine_screening(product=my_prod, prob=np.linspace(0.005,0.025,5), years=np.arange(2020,2025)) # Scale up screening over 5 years starting in 2020\n     \"\"\"\n-\n-    def __init__(self, product=None, prob=None, eligibility=None,\n-                 years=None, start_year=None, end_year=None, **kwargs):\n-        BaseScreening.__init__(self, product=product, eligibility=eligibility, **kwargs)\n-        RoutineDelivery.__init__(self, prob=prob, start_year=start_year, end_year=end_year, years=years)\n-        return\n-\n-    def init_pre(self, sim):\n-        RoutineDelivery.init_pre(self, sim)  # Initialize this first, as it ensures that prob is interpolated properly\n-        BaseScreening.init_pre(self, sim)  # Initialize this next\n-        return\n+    pass\n \n \n class campaign_screening(BaseScreening, CampaignDelivery):\n@@ -312,17 +282,7 @@ class campaign_screening(BaseScreening, CampaignDelivery):\n         screen1 = ss.campaign_screening(product=my_prod, prob=0.2, years=2030) # Screen 20% of the eligible population in 2020\n         screen2 = ss.campaign_screening(product=my_prod, prob=0.02, years=[2025,2030]) # Screen 20% of the eligible population in 2025 and again in 2030\n     \"\"\"\n-\n-    def __init__(self, product=None, sex=None, eligibility=None,\n-                 prob=None, years=None, interpolate=None, **kwargs):\n-        BaseScreening.__init__(self, product=product, sex=sex, eligibility=eligibility, **kwargs)\n-        CampaignDelivery.__init__(self, prob=prob, years=years, interpolate=interpolate)\n-        return\n-\n-    def init_pre(self, sim):\n-        CampaignDelivery.init_pre(self, sim)\n-        BaseScreening.init_pre(self, sim)  # Initialize this next\n-        return\n+    pass\n \n \n class routine_triage(BaseTriage, RoutineDelivery):\n@@ -332,21 +292,10 @@ class routine_triage(BaseTriage, RoutineDelivery):\n \n     **Example**:\n         # Example: Triage positive screens into confirmatory testing\n-        screened_pos = lambda sim: sim.get_intervention('screening').outcomes['positive']\n+        screened_pos = lambda sim: sim.interventions.screening.outcomes['positive']\n         triage = ss.routine_triage(product=my_triage, eligibility=screen_pos, prob=0.9, start_year=2030)\n     \"\"\"\n-\n-    def __init__(self, product=None, prob=None, eligibility=None,\n-                 years=None, start_year=None, end_year=None, annual_prob=None, **kwargs):\n-        BaseTriage.__init__(self, product=product, eligibility=eligibility, **kwargs)\n-        RoutineDelivery.__init__(self, prob=prob, start_year=start_year, end_year=end_year, years=years,\n-                                 annual_prob=annual_prob)\n-        return\n-\n-    def init_pre(self, sim):\n-        RoutineDelivery.init_pre(self, sim)  # Initialize this first, as it ensures that prob is interpolated properly\n-        BaseTriage.init_pre(self, sim)  # Initialize this next\n-        return\n+    pass\n \n \n class campaign_triage(BaseTriage, CampaignDelivery):\n@@ -356,20 +305,10 @@ class campaign_triage(BaseTriage, CampaignDelivery):\n \n     **Examples**:\n         # Example: In 2030, triage all positive screens into confirmatory testing\n-        screened_pos = lambda sim: sim.get_intervention('screening').outcomes['positive']\n+        screened_pos = lambda sim: sim.interventions.screening.outcomes['positive']\n         triage1 = ss.campaign_triage(product=my_triage, eligibility=screen_pos, prob=0.9, years=2030)\n     \"\"\"\n-\n-    def __init__(self, product=None, sex=None, eligibility=None,\n-                 prob=None, years=None, interpolate=None, annual_prob=None, **kwargs):\n-        BaseTriage.__init__(self, product=product, sex=sex, eligibility=eligibility, **kwargs)\n-        CampaignDelivery.__init__(self, prob=prob, years=years, interpolate=interpolate, annual_prob=annual_prob)\n-        return\n-\n-    def init_pre(self, sim):\n-        CampaignDelivery.init_pre(self, sim)\n-        BaseTriage.init_pre(self, sim)\n-        return\n+    pass\n \n \n #%% Treatment interventions\n@@ -395,37 +334,37 @@ class BaseTreatment(Intervention):\n         return\n \n     def init_pre(self, sim):\n-        Intervention.init_pre(self, sim)\n+        super().init_pre(sim)\n         self.outcomes = {k: np.array([], dtype=int) for k in ['unsuccessful', 'successful']} # Store outcomes on each timestep\n         return\n \n-    def get_accept_inds(self, sim):\n+    def get_accept_inds(self):\n         \"\"\"\n         Get indices of people who will acccept treatment; these people are then added to a queue or scheduled for receiving treatment\n         \"\"\"\n         accept_uids = ss.uids()\n-        eligible_uids = self.check_eligibility(sim)  # Apply eligiblity\n+        eligible_uids = self.check_eligibility()  # Apply eligiblity\n         if len(eligible_uids):\n             self.coverage_dist.set(p=self.prob[0])\n             accept_uids = self.coverage_dist.filter(eligible_uids)\n         return accept_uids\n \n-    def get_candidates(self, sim):\n+    def get_candidates(self):\n         \"\"\"\n         Get candidates for treatment on this timestep. Implemented by derived classes.\n         \"\"\"\n         raise NotImplementedError\n \n-    def apply(self, sim):\n+    def step(self):\n         \"\"\"\n         Perform treatment by getting candidates, checking their eligibility, and then treating them.\n         \"\"\"\n         # Get indices of who will get treated\n-        treat_candidates = self.get_candidates(sim)  # NB, this needs to be implemented by derived classes\n-        still_eligible = self.check_eligibility(sim)\n+        treat_candidates = self.get_candidates()  # NB, this needs to be implemented by derived classes\n+        still_eligible = self.check_eligibility()\n         treat_uids = treat_candidates.intersect(still_eligible)\n         if len(treat_uids):\n-            self.outcomes = self.product.administer(sim, treat_uids)\n+            self.outcomes = self.product.administer(treat_uids)\n         return treat_uids\n \n \n@@ -442,15 +381,15 @@ class treat_num(BaseTreatment):\n         self.max_capacity = max_capacity\n         return\n \n-    def add_to_queue(self, sim):\n+    def add_to_queue(self):\n         \"\"\"\n         Add people who are willing to accept treatment to the queue\n         \"\"\"\n-        accept_inds = self.get_accept_inds(sim)\n+        accept_inds = self.get_accept_inds()\n         if len(accept_inds): self.queue += accept_inds.tolist()\n         return\n \n-    def get_candidates(self, sim):\n+    def get_candidates(self):\n         \"\"\"\n         Get the indices of people who are candidates for treatment\n         \"\"\"\n@@ -462,13 +401,13 @@ class treat_num(BaseTreatment):\n                 treat_candidates = self.queue[:self.max_capacity]\n         return ss.uids(treat_candidates) # TODO: Check\n \n-    def apply(self, sim):\n+    def step(self):\n         \"\"\"\n         Apply treatment. On each timestep, this method will add eligible people who are willing to accept treatment to a\n         queue, and then will treat as many people in the queue as there is capacity for.\n         \"\"\"\n-        self.add_to_queue(sim)\n-        treat_inds = BaseTreatment.apply(self, sim) # Apply method from BaseTreatment class\n+        self.add_to_queue()\n+        treat_inds = BaseTreatment.step(self) # Apply method from BaseTreatment class\n         self.queue = [e for e in self.queue if e not in treat_inds] # Recreate the queue, removing people who were treated\n         return treat_inds\n \n@@ -488,8 +427,8 @@ class BaseVaccination(Intervention):\n          label          (str)           : the name of vaccination strategy\n          kwargs         (dict)          : passed to Intervention()\n     \"\"\"\n-    def __init__(self, product=None, prob=None, label=None, **kwargs):\n-        Intervention.__init__(self, **kwargs)\n+    def __init__(self, *args, product=None, prob=None, label=None, **kwargs):\n+        super().__init__(*args, **kwargs)\n         self.prob = sc.promotetoarray(prob)\n         self.label = label\n         self._parse_product(product)\n@@ -499,16 +438,17 @@ class BaseVaccination(Intervention):\n         self.coverage_dist = ss.bernoulli(p=0)  # Placeholder\n         return\n \n-    def apply(self, sim):\n+    def step(self):\n         \"\"\"\n         Deliver the diagnostics by finding who's eligible, finding who accepts, and applying the product.\n         \"\"\"\n+        sim = self.sim\n         accept_uids = np.array([])\n         if sim.ti in self.timepoints:\n \n             ti = sc.findinds(self.timepoints, sim.ti)[0]\n             prob = self.prob[ti]  # Get the proportion of people who will be tested this timestep\n-            is_eligible = self.check_eligibility(sim)  # Check eligibility\n+            is_eligible = self.check_eligibility()  # Check eligibility\n             self.coverage_dist.set(p=prob)\n             accept_uids = self.coverage_dist.filter(is_eligible)\n \n@@ -528,18 +468,7 @@ class routine_vx(BaseVaccination, RoutineDelivery):\n     Routine vaccination - an instance of base vaccination combined with routine delivery.\n     See base classes for a description of input arguments.\n     \"\"\"\n-\n-    def __init__(self, product=None, prob=None, eligibility=None,\n-                 start_year=None, end_year=None, years=None, **kwargs):\n-\n-        BaseVaccination.__init__(self, product=product, eligibility=eligibility, **kwargs)\n-        RoutineDelivery.__init__(self, prob=prob, start_year=start_year, end_year=end_year, years=years)\n-        return\n-\n-    def init_pre(self, sim):\n-        RoutineDelivery.init_pre(self, sim)  # Initialize this first, as it ensures that prob is interpolated properly\n-        BaseVaccination.init_pre(self, sim)  # Initialize this next\n-        return\n+    pass\n \n \n class campaign_vx(BaseVaccination, CampaignDelivery):\n@@ -547,15 +476,4 @@ class campaign_vx(BaseVaccination, CampaignDelivery):\n     Campaign vaccination - an instance of base vaccination combined with campaign delivery.\n     See base classes for a description of input arguments.\n     \"\"\"\n-\n-    def __init__(self, product=None, prob=None, eligibility=None,\n-                 years=None, interpolate=True, **kwargs):\n-\n-        BaseVaccination.__init__(self, product=product, eligibility=eligibility, **kwargs)\n-        CampaignDelivery.__init__(self, prob=prob, years=years, interpolate=interpolate)\n-        return\n-\n-    def init_pre(self, sim):\n-        CampaignDelivery.init_pre(self, sim) # Initialize this first, as it ensures that prob is interpolated properly\n-        BaseVaccination.init_pre(self, sim) # Initialize this next\n-        return\n+    pass\ndiff --git a/starsim/loop.py b/starsim/loop.py\nnew file mode 100644\nindex 0000000..f0569ba\n--- /dev/null\n+++ b/starsim/loop.py\n@@ -0,0 +1,336 @@\n+\"\"\"\n+Parent class for the integration loop.\n+\"\"\"\n+import time\n+import numpy as np\n+import pandas as pd\n+import sciris as sc\n+import starsim as ss\n+import matplotlib.pyplot as plt\n+\n+# What classes are externally visible\n+__all__ = ['Loop']\n+\n+\n+\n+#%% Loop class\n+\n+class Loop:\n+    \"\"\" Base class for integration loop \"\"\"\n+    def __init__(self, sim): # TODO: consider eps=1e-6 and round times to this value\n+        self.sim = sim\n+        self.funcs = None\n+        self.abs_tvecs = None\n+        self.plan = None\n+        self.index = 0 # The next function to execute\n+        self.cpu_time = [] # Store the CPU time of execution of each function\n+        self.df = None # User-friendly verison of the plan\n+        self.cpu_df = None # User-friendly time analysis\n+        self.initialized = False\n+        return\n+\n+    def init(self):\n+        \"\"\" Parse the sim into the integration plan \"\"\"\n+        self.collect_funcs()\n+        self.collect_abs_tvecs()\n+        self.make_plan()\n+        self.initialized = True\n+        return\n+\n+    def __len__(self):\n+        if self.initialized:\n+            return len(self.plan)\n+        else:\n+            return 0 # Or None?\n+\n+    def __iadd__(self, func):\n+        \"\"\" Allow functions to be added to the function list \"\"\"\n+        parent = func.__self__\n+        func_name = func.__name__\n+\n+        # Get the name if it's defined, the class otherwise; these must match abs_tvecs\n+        module = parent.name if isinstance(parent, ss.Module) else parent.__class__.__name__.lower()\n+\n+        # Create the row and append it to the function list\n+        row = dict(func_order=len(self.funcs), module=module, func_name=func_name, func=func)\n+        self.funcs.append(row)\n+        return self\n+\n+    def __repr__(self):\n+        if self.initialized:\n+            arrs = list({len(arr) for arr in self.abs_tvecs.values()})\n+            if len(arrs) == 1: arrs = arrs[0] # If all are the same, just use that\n+            string = f'Loop(n={len(self)}, funcs={len(self.funcs)}, npts={arrs}, index={self.index})'\n+        else:\n+            string = 'Loop(initialized=False)'\n+        return string\n+\n+    def disp(self):\n+        return sc.pr(self)\n+\n+    def collect_funcs(self):\n+        \"\"\" Collect all the callable functions (methods) that comprise the step \"\"\"\n+\n+        # Run the simulation step first (updates the distributions)\n+        self.funcs = [] # Reset, just in case\n+        sim = self.sim\n+\n+        # Collect the start_steps\n+        self += sim.start_step # Note special __iadd__() method above, which appends these to the funcs list\n+        for mod in sim.modules:\n+            self += mod.start_step\n+\n+        # Update demographic modules (create new agents from births/immigration, schedule non-disease deaths and emigration)\n+        for dem in sim.demographics():\n+            self += dem.step\n+\n+        # Carry out autonomous state changes in the disease modules. This allows autonomous state changes/initializations\n+        # to be applied to newly created agents\n+        for disease in sim.diseases():\n+            if isinstance(disease, ss.Disease): # Could be a connector instead -- TODO, rethink this\n+                self += disease.step_state\n+\n+        # Update connectors\n+        for connector in sim.connectors():\n+            self += connector.step\n+\n+        # Update networks - this takes place here in case autonomous state changes at this timestep\n+        # affect eligibility for contacts\n+        for network in sim.networks():\n+            self += network.step\n+\n+        # Apply interventions - new changes to contacts will be visible and so the final networks can be customized by\n+        # interventions, by running them at this point\n+        for intv in sim.interventions():\n+            self += intv.step\n+\n+        # Carry out autonomous state changes in the disease modules, including transmission (but excluding deaths)\n+        for disease in sim.diseases():\n+            self += disease.step\n+\n+        # Update people who died -- calls disease.step_die() internally\n+        self += sim.people.step_die\n+\n+        # Update results\n+        self += sim.people.update_results\n+        for mod in sim.modules:\n+            self += mod.update_results\n+\n+        # Apply analyzers\n+        for ana in sim.analyzers():\n+            self += ana.step\n+\n+        # Clean up dead agents, increment the time index, and perform other housekeeping tasks\n+        for mod in sim.modules:\n+            self += mod.finish_step\n+        self += sim.people.finish_step\n+        self += sim.finish_step\n+\n+        return self.funcs\n+\n+    def collect_abs_tvecs(self):\n+        \"\"\" Collect numerical time arrays for each module \"\"\"\n+        self.abs_tvecs = sc.objdict()\n+\n+        # Handle the sim and people first\n+        sim = self.sim\n+        for key in ['sim', 'people']:\n+            self.abs_tvecs[key] = sim.t.abstvec\n+\n+        # Handle all other modules\n+        for mod in sim.modules:\n+            self.abs_tvecs[mod.name] = mod.t.abstvec\n+\n+        return self.abs_tvecs\n+\n+    def make_plan(self):\n+        \"\"\" Combine the module ordering and the time vectors into the integration plan \"\"\"\n+\n+        # Assemble the list of dicts\n+        raw = []\n+        for func_row in self.funcs:\n+            for t in self.abs_tvecs[func_row['module']]:\n+                row = func_row.copy()\n+                row['time'] = t # Add time column\n+                raw.append(row)\n+\n+        # Turn it into a dataframe\n+        self.plan = sc.dataframe(raw)\n+\n+        # Sort it by step_order, a combination of time and function order\n+        self.plan['step_order'] = self.plan.time + ss.options.time_eps*self.plan.func_order\n+        self.plan['func_label'] = self.plan.module + '.' + self.plan.func_name\n+        col_order = ['time', 'func_order', 'step_order', 'func', 'func_label', 'module', 'func_name'] # Func in the middle to hide it\n+        self.plan = self.plan.sort_values('step_order').reset_index(drop=True)[col_order]\n+        return\n+\n+    def store_time(self):\n+        \"\"\" Store the current time in as high resolution as possible \"\"\"\n+        self.cpu_time.append(time.perf_counter())\n+        return\n+\n+    def run_one_step(self):\n+        \"\"\"\n+        Take a single step, i.e. call a single function; only used for debugging purposes.\n+\n+        Compare sim.run_one_step(), which runs a full timestep (which involves multiple function calls).\n+        \"\"\"\n+        f = self.plan.func[self.index] # Get the next function\n+        f() # Call it\n+        self.index += 1 # Increment the time\n+        return\n+\n+    def run(self, until=None, verbose=None):\n+        \"\"\" Actually run the integration loop; usually called by sim.run() \"\"\"\n+        # Loop over every function in the integration loop, e.g. disease.step()\n+        self.store_time()\n+        for f,label in zip(self.plan.func[self.index:], self.plan.func_label[self.index:]):\n+            if verbose:\n+                row = self.plan[self.index]\n+                print(f'Running t={row.time:n}, step={row.step_order}, {label}()')\n+\n+            f() # Execute the function -- this is where all of Starsim happens!!\n+\n+            # Tidy up\n+            self.index += 1 # Increment the count\n+            self.store_time()\n+            if until and self.sim.now > until: # Terminate if asked to\n+                break\n+        return\n+\n+    def manual_reset(self): # TODO: do we need this? I feel if we don't have it, people will be tempted to manually set loop.index = 0.\n+        \"\"\"\n+        Reset the loop to run again. Note, does not reset sim quantities so should\n+        only be used for debugging.\n+        \"\"\"\n+        self.index = 0\n+        self.sim.complete = False\n+        return\n+\n+    def to_df(self):\n+        \"\"\" Return a user-friendly version of the plan, omitting object columns \"\"\"\n+        # Compute the main dataframe\n+        cols = ['time', 'func_order', 'module', 'func_name', 'func_label']\n+        if self.plan is not None:\n+            df = self.plan[cols].copy() # Need to copy, otherwise it's messed up\n+        else:\n+            errormsg = f'Simulation \"{self.sim}\" needs to be initialized before exporting the Loop dataframe'\n+            raise RuntimeError(errormsg)\n+        times = np.diff(self.cpu_time)\n+        if len(times) == len(df):\n+            df['cpu_time'] = times\n+        else:\n+            df['cpu_time'] = np.nan\n+        self.df = df\n+\n+        # Compute the CPU dataframe\n+        by_func = df.groupby('func_label')\n+        method = dict(func_order='first', module='first', func_name='first', cpu_time='sum')\n+        cdf = sc.dataframe(by_func.agg(method))\n+        cdf['percent'] = cdf.cpu_time / cdf.cpu_time.sum()*100\n+        cdf.insert(cdf.cols.index('cpu_time'), 'calls', by_func.size())\n+        cdf.sort_values('cpu_time', inplace=True, ascending=False)\n+        self.cpu_df = cdf\n+        return df\n+\n+    def plot(self, simplify=False, fig_kw=None, plot_kw=None, scatter_kw=None):\n+        \"\"\"\n+        Plot a diagram of all the events\n+\n+        Args:\n+            simplify (bool): if True, skip update_results and finish_step events, which are automatically applied\n+            fig_kw (dict): passed to ``plt.figure()``\n+            plot_kw (dict): passed to ``plt.plot()``\n+            scatter_kw (dict): passed to ``plt.scatter()``\n+        \"\"\"\n+\n+        # Assemble data\n+        df = self.to_df()\n+        if simplify:\n+            filter_out = ['update_results', 'finish_step']\n+            df = df[~df.func_name.isin(filter_out)]\n+        yticks = df.func_order.unique()\n+        ylabels = df.func_label.unique()\n+        x = df.time\n+        y = df.func_order\n+\n+        # Convert module names to integers for plotting colors\n+        mod_int, _ = pd.factorize(df.module)\n+        colors = sc.gridcolors(np.unique(mod_int), asarray=True)\n+\n+        # Do the plotting\n+        plot_kw = sc.mergedicts(dict(lw=2, alpha=0.2, c='k'), plot_kw)\n+        scatter_kw = sc.mergedicts(dict(s=200, alpha=0.6), scatter_kw)\n+        fig = plt.figure(**sc.mergedicts(fig_kw))\n+        plt.plot(x, y, **plot_kw)\n+        plt.scatter(x, y, c=colors[mod_int], **scatter_kw)\n+        plt.yticks(yticks, ylabels)\n+        plt.title(f'Integration plan ({len(df)} events)')\n+        plt.xlabel(f'Time since simulation start (in {self.sim.pars.unit}s)')\n+        plt.grid(True)\n+        sc.figlayout()\n+        sc.boxoff()\n+        return ss.return_fig(fig)\n+\n+    def plot_cpu(self, bytime=True, fig_kw=None, bar_kw=None):\n+        \"\"\"\n+        Plot the CPU time spent on each event; visualization of Loop.cpu_df.\n+\n+        Args:\n+            bytime (bool): if True, order events by total time rather than actual order\n+            fig_kw (dict): passed to ``plt.figure()``\n+            plot_kw (dict): passed to ``plt.bar()``\n+        \"\"\"\n+        # Assemble data\n+        if self.cpu_df is None:\n+            self.to_df()\n+        df = self.cpu_df\n+        ylabels = df.index.values\n+        if bytime:\n+            y = np.arange(len(ylabels))\n+        else:\n+            y = df.func_order.values\n+        y = y[::-1] # Reverse order so plots from top to bottom\n+\n+        x = df.cpu_time.values\n+        pcts = df.percent.values\n+\n+        if x.max() < 1:\n+            x *= 1e3\n+            unit = 'ms'\n+        else:\n+            unit = 's'\n+\n+        # Assemble labels\n+        for i in range(len(df)):\n+            timestr = sc.sigfig(x[i], 3) + f' {unit}'\n+            pctstr = sc.sigfig(pcts[i], 3) + '%'\n+            ylabels[i] += f'()\\n{timestr}, {pctstr}'\n+\n+        # Do the plotting\n+        bar_kw = sc.mergedicts(bar_kw)\n+        fig = plt.figure(**sc.mergedicts(fig_kw))\n+        plt.barh(y, width=x, **bar_kw)\n+        plt.yticks(y, ylabels)\n+        plt.xlabel(f'CPU time ({unit})')\n+        plt.ylabel('Function call')\n+        plt.grid(True)\n+        sc.figlayout()\n+        sc.boxoff()\n+        return ss.return_fig(fig)\n+\n+    def __deepcopy__(self, memo):\n+        \"\"\" A dataframe that has functions in it doesn't copy well; convert to a dict first \"\"\"\n+        cls = self.__class__\n+        new = cls.__new__(cls)\n+        memo[id(self)] = new\n+        for k, v in self.__dict__.items():\n+            if k == 'plan' and isinstance(v, sc.dataframe):\n+                origdict = v.to_dict() # Convert to a dictionary\n+                newdict = sc.dcp(origdict, memo=memo) # Copy the dict\n+                newdf = sc.dataframe(newdict)\n+                setattr(new, k, newdf)\n+            else:\n+                setattr(new, k, sc.dcp(v, memo=memo)) # Regular deepcopy\n+        return new\n+\ndiff --git a/starsim/modules.py b/starsim/modules.py\nindex b8e2a82..6ecd6e0 100644\n--- a/starsim/modules.py\n+++ b/starsim/modules.py\n@@ -1,11 +1,14 @@\n \"\"\"\n-General module class -- base class for diseases, interventions, etc.\n+General module class -- base class for diseases, interventions, etc. Also\n+defines Analyzers and Connectors.\n \"\"\"\n-\n import sciris as sc\n import starsim as ss\n+from functools import partial\n+\n+__all__ = ['module_map', 'find_modules', 'Base', 'Module', 'Analyzer', 'Connector']\n \n-__all__ = ['module_map', 'find_modules', 'Module', 'Connector']\n+module_args = ['name', 'label'] # Define allowable module arguments\n \n \n def module_map(key=None):\n@@ -21,11 +24,11 @@ def module_map(key=None):\n     return module_map if key is None else module_map[key]\n \n \n-def find_modules(key=None):\n-    \"\"\" Find all subclasses of Module, divided by type \"\"\"\n+def find_modules(key=None, flat=False):\n+    \"\"\" Find all subclasses of Module present in Starsim, divided by type \"\"\"\n     modules = sc.objdict()\n     modmap = module_map()\n-    attrs = dir(ss)\n+    attrs = dir(ss) # Find all attributes in Starsim (note: does not parse user code)\n     for modkey, modtype in modmap.items(): # Loop over each module type\n         modules[modkey] = sc.objdict()\n         for attr in attrs: # Loop over each attribute (inefficient, but doesn't need to be optimized)\n@@ -38,124 +41,240 @@ def find_modules(key=None):\n                     modules[modkey][low_attr.removesuffix('net')] = item\n             except:\n                 pass\n+    if flat:\n+        modules = sc.objdict({k:v for vv in modules.values() for k,v in vv.items()}) # Unpack the nested dict into a flat one\n     return modules if key is None else modules[key]\n-    \n \n-class Module(sc.quickobj):\n \n-    def __init__(self, name=None, label=None, requires=None):\n-        self.set_metadata(name, label, requires) # Usually reset as part of self.update_pars()\n-        self.pars = ss.Pars() # Usually populated via self.default_pars()\n+class Base(sc.quickobj):\n+    \"\"\"\n+    The parent class for Sim and Module objects\n+    \"\"\"\n+    def __bool__(self):\n+        \"\"\" Ensure that zero-length modules (e.g. networks) are still truthy \"\"\"\n+        return True\n+\n+    def __len__(self):\n+        \"\"\" The length of a module is the number of timepoints; see also len(sim) \"\"\"\n+        try:    return self.t.npts\n+        except: return 0\n+\n+    def disp(self, output=False, **kwargs):\n+        \"\"\" Display the full object \"\"\"\n+        out = sc.prepr(self, **kwargs)\n+        if not output:\n+            print(out)\n+        else:\n+            return out\n+\n+    @property\n+    def ti(self):\n+        \"\"\" Get the current module timestep \"\"\"\n+        try:    return self.t.ti\n+        except: return None\n+\n+    @property\n+    def now(self):\n+        \"\"\" Shortcut to self.t.now() \"\"\"\n+        try:    return self.t.now()\n+        except: return None\n+\n+    @property\n+    def timevec(self):\n+        \"\"\" Shortcut to self.t.timevec \"\"\"\n+        try:    return self.t.timevec\n+        except: return None\n+\n+    def copy(self, die=True):\n+        \"\"\"\n+        Perform a deep copy of the module/sim\n+\n+        Args:\n+            die (bool): whether to raise an exception if copy fails (else, try a shallow copy)\n+        \"\"\"\n+        out = sc.dcp(self, die=die)\n+        return out\n+\n+\n+class Module(Base):\n+    \"\"\"\n+    The main base class for all Starsim modules: diseases, networks, interventions, etc.\n+\n+    Args:\n+        name (str): a short, key-like name for the module (e.g. \"randomnet\")\n+        label (str): the full, human-readable name for the module (e.g. \"Random network\")\n+        kwargs (dict): passed to ss.Time() (e.g. start, stop, unit, dt)\n+    \"\"\"\n+\n+    def __init__(self, name=None, label=None, **kwargs):\n+        # Handle parameters\n+        self.pars = ss.Pars() # Usually populated via self.define_pars()\n+        self.set_metadata(name, label) # Usually reset as part of self.update_pars()\n+        self.t = ss.Time(**kwargs, name=self.name, init=False)\n+\n+        # Properties to be added by init_pre()\n+        self.sim = None\n+        self.dists = None # Turned into a Dists object by sim.init_dists() if this module has dists\n         self.results = ss.Results(self.name)\n+\n+        # Finish initialization\n+        self.pre_initialized = False\n         self.initialized = False\n         self.finalized = False\n         return\n-    \n-    def __bool__(self):\n-        \"\"\" Ensure that zero-length modules (e.g. networks) are still truthy \"\"\"\n-        return True\n-    \n-    def set_metadata(self, name, label, requires):\n+\n+    def __call__(self, *args, **kwargs):\n+        \"\"\" Allow modules to be called like functions \"\"\"\n+        return self.step(*args, **kwargs)\n+\n+    def _reconcile(self, key, value=None, default=None):\n+        \"\"\" Reconcile module attributes, parameters, and input arguments \"\"\"\n+        parval = self.pars.get(key)\n+        attrval = getattr(self, key, parval)\n+        val = sc.ifelse(value, attrval, default)\n+        return val\n+\n+    def set_metadata(self, name=None, label=None):\n         \"\"\" Set metadata for the module \"\"\"\n-        self.name = sc.ifelse(name, getattr(self, 'name', self.__class__.__name__.lower())) # Default name is the class name\n-        self.label = sc.ifelse(label, getattr(self, 'label', self.name))\n-        self.requires = sc.mergelists(requires)\n+        # Validation\n+        for key,val in dict(name=name, label=label).items():\n+            if val is not None:\n+                if not isinstance(val, str):\n+                    errormsg = f'Invalid value for {key}: must be str, not {type(val)}: {val}'\n+                    raise TypeError(errormsg)\n+\n+        # Set values\n+        self.name = self._reconcile('name', name, self.__class__.__name__.lower())\n+        self.label = self._reconcile('label', label, self.name)\n         return\n-    \n-    def default_pars(self, inherit=False, **kwargs):\n+\n+    def define_pars(self, inherit=True, **kwargs): # TODO: think if inherit should default to true or false\n         \"\"\" Create or merge Pars objects \"\"\"\n         if inherit: # Merge with existing\n             self.pars.update(**kwargs, create=True)\n         else: # Or overwrite\n             self.pars = ss.Pars(**kwargs)\n         return self.pars\n-    \n+\n     def update_pars(self, pars, **kwargs):\n         \"\"\" Pull out recognized parameters, returning the rest \"\"\"\n         pars = sc.mergedicts(pars, kwargs)\n-        \n+\n         # Update matching module parameters\n         matches = {}\n         for key in list(pars.keys()): # Need to cast to list to avoid \"dict changed during iteration\"\n             if key in self.pars:\n                 matches[key] = pars.pop(key)\n         self.pars.update(matches)\n-                \n+\n         # Update module attributes\n-        metadata = {key:pars.pop(key, None) for key in ['name', 'label', 'requires']}\n+        metadata = {key:pars.get(key, self.pars.get(key)) for key in module_args}\n+        timepars = {key:pars.get(key, self.pars.get(key)) for key in ss.time.time_args}\n         self.set_metadata(**metadata)\n-        \n+        self.t.update(**timepars)\n+\n         # Should be no remaining pars\n-        if len(pars):\n-            errormsg = f'{len(pars)} unrecognized arguments for {self.name}: {sc.strjoin(pars.keys())}'\n+        remaining = set(pars.keys()) - set(module_args + ss.time.time_args)\n+        if len(remaining):\n+            errormsg = f'{len(pars)} unrecognized arguments for {self.name}: {sc.strjoin(remaining)}'\n             raise ValueError(errormsg)\n         return\n-    \n-    def check_requires(self, sim):\n-        \"\"\" Check that the module's requirements (of other modules) are met \"\"\"\n-        errs = sc.autolist()\n-        all_names = [m.__class__ for m in sim.modules] + [m.name for m in sim.modules if hasattr(m, 'name')]\n-        for req in self.requires:\n-            if req not in all_names:\n-                errs += req\n-        if len(errs):\n-            errormsg = f'{self.name} (label={self.label}) requires the following module(s), but the Sim does not contain them.'\n-            errormsg += sc.newlinejoin(errs)\n-            raise Exception(errormsg)\n-        return\n \n-    def init_pre(self, sim):\n+    def init_pre(self, sim, force=False):\n         \"\"\"\n         Perform initialization steps\n \n         This method is called once, as part of initializing a Sim. Note: after\n-        initialization, initialized=False until init_post() is called (which is after\n+        initialization, initialized=False until init_vals() is called (which is after\n         distributions are initialized).\n-        \n-        Note: distributions cannot be used here because they aren't initialized \n-        until after init_pre() is called. Use init_post() instead.\n         \"\"\"\n-        self.check_requires(sim)\n-        self.sim = sim # Link back to the sim object\n-        ss.link_dists(self, sim, skip=ss.Sim) # Link the distributions to sim and module\n-        sim.pars[self.name] = self.pars\n-        sim.results[self.name] = self.results\n-        sim.people.add_module(self) # Connect the states to the people\n+        if force or not self.pre_initialized:\n+            self.sim = sim # Link back to the sim object\n+            ss.link_dists(self, sim, skip=ss.Sim) # Link the distributions to sim and module\n+            sim.pars[self.name] = self.pars\n+            sim.results[self.name] = self.results\n+            sim.people.add_module(self) # Connect the states to the people\n+            self.init_time() # Initialize the modules' time parameters and link them to the sim\n+            self.init_results()\n+            self.pre_initialized = True\n+        return\n+\n+    def init_results(self):\n+        \"\"\" Initialize any results required; part of init_pre() \"\"\"\n+        self.results.timevec = self.t.timevec # Store the timevec in the results for plotting\n         return\n-    \n+\n     def init_post(self):\n-        \"\"\" Initialize the values of the states, including calling distributions; the last step of initialization \"\"\"\n+        \"\"\" Initialize the values of the states; the last step of initialization \"\"\"\n         for state in self.states:\n             if not state.initialized:\n                 state.init_vals()\n         self.initialized = True\n         return\n-    \n-    def disp(self, output=False):\n-        \"\"\" Display the full object \"\"\"\n-        out = sc.prepr(self)\n-        if not output:\n-            print(out)\n-        else:\n-            return out\n+\n+    def init_time(self, force=False):\n+        \"\"\" Initialize all time parameters by ensuring all parameters are initialized; part of init_post() \"\"\"\n+        # Update time and initialize\n+        self.t.init(sim=self.sim) # Sets the absolute sim time vector\n+\n+        # Find all time parameters in the module\n+        timepars = sc.search(self.pars, type=ss.TimePar) # Should it be self or self.pars?\n+\n+        # Initialize them with the parent module\n+        for timepar in timepars.values():\n+            if force or not timepar.initialized:\n+                timepar.init(parent=self.t, die=False) # In some cases, the values can't be initialized; that's OK here\n+        return\n+\n+    def match_time_inds(self, inds=None):\n+         \"\"\" Find the nearest matching sim time indices for the current module \"\"\"\n+         if inds is None: inds = Ellipsis\n+         self_tvec = self.t.abstvec\n+         sim_tvec = self.sim.t.abstvec\n+         if len(self_tvec) == len(sim_tvec): # Shortcut to avoid doing matching\n+             return inds\n+         else:\n+             out = sc.findnearest(sim_tvec, [inds])\n+             return out\n+\n+    def start_step(self):\n+        \"\"\" Tasks to perform at the beginning of the step \"\"\"\n+        if self.dists is not None: # Will be None if no distributions are defined\n+            self.dists.jump_dt() # Advance random number generators forward for calls on this step\n+        return\n+\n+    def step(self):\n+        \"\"\" Define how the module updates over time -- the key part of Starsim!! \"\"\"\n+        errormsg = f'Module \"{self.name}\" does not define a \"step\" method: use \"def step(self): pass\" if this is intentional'\n+        raise NotImplementedError(errormsg)\n+\n+    def finish_step(self):\n+        \"\"\" Define what should happen at the end of the step; at minimum, increment ti \"\"\"\n+        self.t.ti += 1\n+        return\n+\n+    def update_results(self):\n+        \"\"\" Perform any results updates on each timestep \"\"\"\n+        pass\n \n     def finalize(self):\n+        \"\"\" Perform any final operations, such as removing unneeded data \"\"\"\n         self.finalize_results()\n         self.finalized = True\n         return\n \n-    def finalize_results(self):\n+    def finalize_results(self): # TODO: this is confusing, needs to be not redefined by the user, or called *after* a custom finalize_results()\n         \"\"\" Finalize results \"\"\"\n         # Scale results\n         for reskey, res in self.results.items():\n             if isinstance(res, ss.Result) and res.scale:\n                 self.results[reskey] = self.results[reskey]*self.sim.pars.pop_scale\n         return\n-    \n-    def add_states(self, *args, check=True):\n+\n+    def define_states(self, *args, check=True):\n         \"\"\"\n-        Add states to the module with the same attribute name as the state\n-        \n+        Define states of the module with the same attribute name as the state\n+\n         Args:\n             args (states): list of states to add\n             check (bool): whether to check that the object being added is a state\n@@ -167,13 +286,31 @@ class Module(sc.quickobj):\n                 state = ss.State(**arg)\n             else:\n                 state = arg\n-                \n+\n             if check:\n                 assert isinstance(state, ss.Arr), f'Could not add {state}: not an Arr object'\n-                \n+\n+            # Add the state to the module\n             setattr(self, state.name, state)\n         return\n \n+    def define_results(self, *args, check=True):\n+        \"\"\" Add results to the module \"\"\"\n+        for arg in args:\n+            if isinstance(arg, (list, tuple)):\n+                result = ss.Result(*arg)\n+            elif isinstance(arg, dict):\n+                result = ss.Result(**arg)\n+            else:\n+                result = arg\n+\n+            # Update with module information\n+            result.update(module=self.name, shape=self.t.npts, timevec=self.t.timevec)\n+\n+            # Add the result to the dict of results; does automatic checking\n+            self.results += result\n+        return\n+\n     @property\n     def states(self):\n         \"\"\"\n@@ -200,6 +337,7 @@ class Module(sc.quickobj):\n     def create(cls, name, *args, **kwargs):\n         \"\"\"\n         Create a module instance by name\n+\n         Args:\n             name (str): A string with the name of the module class in lower case, e.g. 'sir'\n         \"\"\"\n@@ -208,7 +346,20 @@ class Module(sc.quickobj):\n                 return subcls(*args, **kwargs)\n         else:\n             raise KeyError(f'Module \"{name}\" did not match any known Starsim modules')\n-            \n+\n+    @classmethod\n+    def from_func(cls, func):\n+        \"\"\" Create an module from a function \"\"\"\n+        def step(mod): # TODO: see if this can be done more simply\n+            return mod.func(mod.sim)\n+        name = func.__name__\n+        mod = cls(name=name)\n+        mod.func = func\n+        mod.step = partial(step, mod)\n+        mod.step.__name__ = name # Manually add these in as for a regular class method\n+        mod.step.__self__ = mod\n+        return mod\n+\n     def to_json(self):\n         \"\"\" Export to a JSON-compatible format \"\"\"\n         out = sc.objdict()\n@@ -219,22 +370,37 @@ class Module(sc.quickobj):\n         return out\n \n     def plot(self):\n+        \"\"\" Plot all results in the module \"\"\"\n         with sc.options.with_style('fancy'):\n             flat = sc.flattendict(self.results, sep=': ')\n-            yearvec = self.sim.yearvec\n+            timevec = self.t.timevec\n             fig, axs = sc.getrowscols(len(flat), make=True)\n             for ax, (k, v) in zip(axs.flatten(), flat.items()):\n-                ax.plot(yearvec, v)\n+                ax.plot(timevec, v)\n                 ax.set_title(k)\n                 ax.set_xlabel('Year')\n-        return fig\n+        return ss.return_fig(fig)\n+\n+\n+class Analyzer(Module):\n+    \"\"\"\n+    Base class for Analyzers. Analyzers are used to provide more detailed information\n+    about a simulation than is available by default -- for example, pulling states\n+    out of sim.people on a particular timestep before they get updated on the next step.\n+\n+    The key method of the analyzer is ``step()``, which is called with the sim\n+    on each timestep.\n+\n+    To retrieve a particular analyzer from a sim, use sim.get_analyzer().\n+    \"\"\"\n+    pass\n \n \n class Connector(Module):\n     \"\"\"\n-    Define a Connector, which mediates interactions between disease modules\n-    \n+    Base class for Connectors, which mediate interactions between disease (or other) modules\n+\n     Because connectors can do anything, they have no specified structure: it is\n-    up to the user to define how they behave.    \n+    up to the user to define how they behave.\n     \"\"\"\n     pass\ndiff --git a/starsim/network.py b/starsim/networks.py\nsimilarity index 57%\nrename from starsim/network.py\nrename to starsim/networks.py\nindex a231583..5d4649a 100644\n--- a/starsim/network.py\n+++ b/starsim/networks.py\n@@ -1,7 +1,6 @@\n-'''\n+\"\"\"\n Networks that connect people within a population\n-'''\n-\n+\"\"\"\n import networkx as nx\n import numpy as np\n import numba as nb\n@@ -10,17 +9,24 @@ import starsim as ss\n import scipy.optimize as spo\n import scipy.spatial as spsp\n \n-# CK: need to remove this, but slows down the code otherwise\n+# This has a significant impact on runtime, surprisingly\n ss_float_ = ss.dtypes.float\n ss_int_ = ss.dtypes.int\n \n \n # Specify all externally visible functions this file defines; see also more definitions below\n-__all__ = ['Network', 'DynamicNetwork', 'SexualNetwork']\n+__all__ = ['Route', 'Network', 'DynamicNetwork', 'SexualNetwork']\n \n # %% General network classes\n \n-class Network(ss.Module):\n+class Route(ss.Module):\n+    \"\"\"\n+    A transmission route -- e.g., a network, mixing pool, environmental transmission, etc.\n+    \"\"\"\n+    pass\n+\n+\n+class Network(Route):\n     \"\"\"\n     A class holding a single network of contact edges (connections) between people\n     as well as methods for updating these.\n@@ -30,10 +36,8 @@ class Network(ss.Module):\n     the connection.\n \n     Args:\n-        p1 (array): an array of length N, the number of connections in the network, with the indices of people\n-                   on one side of the connection.\n-        p2 (array): an array of length N, the number of connections in the network, with the indices of people\n-                    on the other side of the connection.\n+        p1 (array): an array of length N, the number of connections in the network, with the indices of people on one side of the connection.\n+        p2 (array): an array of length N, the number of connections in the network, with the indices of people on the other side of the connection.\n         beta (array): an array representing relative transmissibility of each connection for this network - TODO, do we need this?\n         label (str): the name of the network (optional)\n         kwargs (dict): other keys copied directly into the network\n@@ -60,9 +64,9 @@ class Network(ss.Module):\n         network2 = ss.Network(**network, index=index, self_conn=self_conn, label=network.label)\n     \"\"\"\n \n-    def __init__(self, key_dict=None, prenatal=False, postnatal=False, name=None, label=None, requires=None, **kwargs):\n+    def __init__(self, key_dict=None, prenatal=False, postnatal=False, name=None, label=None, **kwargs):\n         # Initialize as a module\n-        super().__init__(name=name, label=label, requires=requires)\n+        super().__init__(name=name, label=label)\n \n         # Each relationship is characterized by these default set of keys, plus any user- or network-supplied ones\n         default_keys = sc.objdict(\n@@ -88,37 +92,50 @@ class Network(ss.Module):\n         self.participant = ss.BoolArr('participant')\n         self.validate_uids()\n         return\n-    \n+\n     @property\n     def p1(self):\n+        \"\"\" The first half of a network edge (person 1) \"\"\"\n         return self.edges['p1'] if 'p1' in self.edges else None\n-    \n+\n     @property\n     def p2(self):\n+        \"\"\" The second half of a network edge (person 2) \"\"\"\n         return self.edges['p2'] if 'p2' in self.edges else None\n \n     @property\n     def beta(self):\n+        \"\"\" Relative transmission on each network edge \"\"\"\n         return self.edges['beta'] if 'beta' in self.edges else None\n \n+    def init_results(self):\n+        \"\"\" Store network length by default \"\"\"\n+        super().init_results()\n+        self.define_results(\n+            ss.Result('n_edges', dtype=int, scale=True, label='Number of edges', auto_plot=False)\n+        )\n+        return\n+\n     def init_post(self, add_pairs=True):\n         super().init_post()\n         if add_pairs: self.add_pairs()\n         return\n \n     def __len__(self):\n-        try:\n-            return len(self.edges.p1)\n-        except:  # pragma: no cover\n-            return 0\n+        \"\"\" The length is the number of edges \"\"\"\n+        try:    return len(self.edges.p1)\n+        except: return 0\n \n     def __repr__(self, **kwargs):\n         \"\"\" Convert to a dataframe for printing \"\"\"\n-        namestr = self.name\n-        labelstr = f'\"{self.label}\"' if self.label else '<no label>'\n-        keys_str = ', '.join(self.edges.keys())\n-        output = f'{namestr}({labelstr}, {keys_str})\\n'  # e.g. Network(\"r\", p1, p2, beta)\n-        output += self.to_df().__repr__()\n+        try:\n+            namestr = self.name\n+            labelstr = f'\"{self.label}\"' if self.label else '<no label>'\n+            keys_str = ', '.join(self.edges.keys())\n+            output = f'{namestr}({labelstr}, {keys_str})\\n'  # e.g. Network(\"r\", p1, p2, beta)\n+            output += self.to_df().__repr__()\n+        except:\n+            output = sc.prepr(self, vals=False)\n         return output\n \n     def __contains__(self, item):\n@@ -149,7 +166,7 @@ class Network(ss.Module):\n         states that depend on other states.\n         \"\"\"\n         pass\n-    \n+\n     def validate_uids(self):\n         \"\"\" Ensure that p1, p2 are both UID arrays \"\"\"\n         edges = self.edges\n@@ -184,6 +201,7 @@ class Network(ss.Module):\n     def get_inds(self, inds, remove=False):\n         \"\"\"\n         Get the specified indices from the edgelist and return them as a dict.\n+\n         Args:\n             inds (int, array, slice): the indices to find\n             remove (bool): whether to remove the indices\n@@ -207,25 +225,48 @@ class Network(ss.Module):\n         popped_inds = self.get_inds(inds, remove=True)\n         return popped_inds\n \n-    def append(self, contacts=None, **kwargs):\n+    def append(self, edges=None, **kwargs):\n         \"\"\"\n-        Append contacts to the current network.\n+        Append edges to the current network.\n \n         Args:\n-            contacts (dict): a dictionary of arrays with keys p1,p2,beta, as returned from network.pop_inds()\n+            edges (dict): a dictionary of arrays with keys p1,p2,beta, as returned from network.pop_inds()\n         \"\"\"\n-        contacts = sc.mergedicts(contacts, kwargs)\n+        edges = sc.mergedicts(edges, kwargs)\n         for key in self.meta_keys():\n             curr_arr = self.edges[key]\n             try:\n-                new_arr = contacts[key]\n+                new_arr = edges[key]\n             except KeyError:\n-                errormsg = f'Cannot append contacts since required key \"{key}\" is missing'\n+                errormsg = f'Cannot append edges since required key \"{key}\" is missing'\n                 raise KeyError(errormsg)\n             self.edges[key] = np.concatenate([curr_arr, new_arr])  # Resize to make room, preserving dtype\n         self.validate_uids()\n         return\n \n+    def update_results(self):\n+        \"\"\" Store the number of edges in the network \"\"\"\n+        self.results['n_edges'][self.ti] = len(self)\n+        return\n+\n+    def to_graph(self): # pragma: no cover\n+        \"\"\"\n+        Convert to a networkx DiGraph\n+\n+        **Example**::\n+\n+            import networkx as nx\n+            sim = ss.Sim(n_agents=100, networks='mf').init()\n+            G = sim.networks.randomnet.to_graph()\n+            nx.draw(G)\n+        \"\"\"\n+        keys = [('p1', int), ('p2', int), ('beta', float)]\n+        data = [np.array(self.edges[k], dtype=dtype).tolist() for k,dtype in keys]\n+        G = nx.DiGraph()\n+        G.add_weighted_edges_from(zip(*data), weight='beta')\n+        nx.set_edge_attributes(G, self.label, name='layer')\n+        return G\n+\n     def to_dict(self):\n         \"\"\" Convert to dictionary \"\"\"\n         d = {k: self.edges[k] for k in self.meta_keys()}\n@@ -248,8 +289,8 @@ class Network(ss.Module):\n         \"\"\"\n         Find all contacts of the specified people\n \n-        For some purposes (e.g. contact tracing) it's necessary to find all the contacts\n-        associated with a subset of the people in this network. Since contacts are bidirectional\n+        For some purposes (e.g. contact tracing) it's necessary to find all the edges\n+        associated with a subset of the people in this network. Since edges are bidirectional\n         it's necessary to check both p1 and p2 for the target indices. The return type is a Set\n         so that there is no duplication of indices (otherwise if the Network has explicit\n         symmetric interactions, they could appear multiple times). This is also for performance so\n@@ -258,7 +299,7 @@ class Network(ss.Module):\n         infection, e.g. exposure risk.\n \n         Args:\n-            inds (array): indices of people whose contacts to return\n+            inds (array): indices of people whose edges to return\n             as_array (bool): if true, return as sorted array (otherwise, return as unsorted set)\n \n         Returns:\n@@ -267,7 +308,7 @@ class Network(ss.Module):\n         Example: If there were a network with\n         - p1 = [1,2,3,4]\n         - p2 = [2,3,1,4]\n-        Then find_contacts([1,3]) would return {1,2,3}\n+        Then find_edges([1,3]) would return {1,2,3}\n         \"\"\"\n \n         # Check types\n@@ -276,7 +317,7 @@ class Network(ss.Module):\n         if inds.dtype != np.int64:  # pragma: no cover # This is int64 since indices often come from utils.true(), which returns int64\n             inds = np.array(inds, dtype=np.int64)\n \n-        # Find the contacts\n+        # Find the edges\n         contact_inds = ss.find_contacts(self.edges.p1, self.edges.p2, inds)\n         if as_array:\n             contact_inds = np.fromiter(contact_inds, dtype=ss_int_)\n@@ -288,10 +329,6 @@ class Network(ss.Module):\n         \"\"\" Define how pairs of people are formed \"\"\"\n         pass\n \n-    def update(self):\n-        \"\"\" Define how pairs/connections evolve (in time) \"\"\"\n-        pass\n-\n     def remove_uids(self, uids):\n         \"\"\"\n         Remove interactions involving specified UIDs\n@@ -304,9 +341,10 @@ class Network(ss.Module):\n \n         return\n \n-    def beta_per_dt(self, disease_beta=None, dt=None, uids=None):\n-        if uids is None: uids = Ellipsis\n-        return self.edges.beta[uids] * disease_beta * dt\n+    def net_beta(self, disease_beta=None, inds=None, disease=None):\n+        \"\"\" Calculate the beta for the given disease and network \"\"\"\n+        if inds is None: inds = Ellipsis\n+        return self.edges.beta[inds] * disease_beta # Beta should already include dt if desired\n \n \n class DynamicNetwork(Network):\n@@ -316,9 +354,14 @@ class DynamicNetwork(Network):\n         super().__init__(key_dict=key_dict, **kwargs)\n         return\n \n+    def step(self):\n+        self.end_pairs()\n+        self.add_pairs()\n+        return\n+\n     def end_pairs(self):\n         people = self.sim.people\n-        self.edges.dur = self.edges.dur - self.sim.dt\n+        self.edges.dur = self.edges.dur - self.t.dt # TODO: think about whether this is right # Update: it is, if duration is *NOT* a ss.dur! Otherwise it should be -1, in timestep units\n \n         # Non-alive agents are removed\n         active = (self.edges.dur > 0) & people.alive[self.edges.p1] & people.alive[self.edges.p2]\n@@ -347,19 +390,18 @@ class SexualNetwork(DynamicNetwork):\n         # This property could also be overwritten by a NetworkConnector\n         # which could incorporate information about membership in other\n         # contact networks\n-        right_sex = people[sex]\n-        is_active = self.active(people)\n-        is_available = (right_sex & is_active).uids\n-        still_available = is_available.remove(self.members)\n-        return still_available\n+        available = people[sex] & self.active(people)\n+        available[self.edges.p1] = False\n+        available[self.edges.p2] = False\n+        return available.uids\n \n-    def beta_per_dt(self, disease_beta=None, dt=None, uids=None):\n-        if uids is None: uids = Ellipsis\n-        return self.edges.beta[uids] * (1 - (1 - disease_beta) ** (self.edges.acts[uids] * dt))\n+    def net_beta(self, disease_beta=None, inds=None, disease=None):\n+        if inds is None: inds = Ellipsis\n+        return self.edges.beta[inds] * (1 - (1 - disease_beta) ** (self.edges.acts[inds] * self.t.dt))\n \n \n # %% Specific instances of networks\n-__all__ += ['StaticNet', 'RandomNet', 'NullNet', 'MFNet', 'MSMNet', 'EmbeddingNet', 'MaternalNet', 'PrenatalNet', 'PostnatalNet']\n+__all__ += ['StaticNet', 'RandomNet', 'ErdosRenyiNet', 'DiskNet', 'NullNet', 'MFNet', 'MSMNet', 'EmbeddingNet', 'MaternalNet', 'PrenatalNet', 'PostnatalNet']\n \n \n class StaticNet(Network):\n@@ -387,7 +429,7 @@ class StaticNet(Network):\n     def __init__(self, graph=None, pars=None, **kwargs):\n         super().__init__()\n         self.graph = graph\n-        self.default_pars(seed=True, p=None, n_contacts=10)\n+        self.define_pars(seed=True, p=None, n_contacts=10)\n         self.update_pars(pars, **kwargs)\n         self.dist = ss.Dist(name='StaticNet')\n         return\n@@ -401,7 +443,7 @@ class StaticNet(Network):\n         if self.pars.p is None: # Convert from n_contacts to probability\n             self.pars.p = n_contacts/self.n_agents\n         return\n-    \n+\n     def init_post(self):\n         super().init_post()\n         if 'seed' in self.pars and self.pars.seed is True:\n@@ -413,7 +455,7 @@ class StaticNet(Network):\n                 print(f\"{str(e)}: networkx {self.graph.name} not supported. Try using ss.NullNet().\")\n                 raise e\n         self.validate_pop(self.n_agents)\n-        self.get_contacts()\n+        self.get_edges()\n         return\n \n     def validate_pop(self, n_agents):\n@@ -427,15 +469,15 @@ class StaticNet(Network):\n             errmsg = f\"The nx generator {self.graph.name} produced a graph with no edges\"\n             raise ValueError(errmsg)\n \n-    def get_contacts(self):\n+    def get_edges(self):\n         p1s = []\n         p2s = []\n         for edge in self.graph.edges():\n             p1, p2 = edge\n             p1s.append(p1)\n             p2s.append(p2)\n-        contacts = dict(p1=p1s, p2=p2s, beta=np.ones_like(p1s))\n-        self.append(contacts)\n+        edges = dict(p1=p1s, p2=p2s, beta=np.ones_like(p1s))\n+        self.append(edges)\n         return\n \n \n@@ -445,9 +487,9 @@ class RandomNet(DynamicNetwork):\n     def __init__(self, pars=None, key_dict=None, **kwargs):\n         \"\"\" Initialize \"\"\"\n         super().__init__(key_dict=key_dict)\n-        self.default_pars(\n+        self.define_pars(\n             n_contacts = ss.constant(10),\n-            dur = 0,\n+            dur = 0, # Note; network edge durations are required to have the same unit as the network\n         )\n         self.update_pars(pars, **kwargs)\n         self.dist = ss.Dist(distname='RandomNet') # Default RNG\n@@ -458,7 +500,7 @@ class RandomNet(DynamicNetwork):\n         return\n \n     @staticmethod\n-    @nb.njit(cache=True)\n+    @nb.njit(fastmath=True, parallel=False, cache=True)\n     def get_source(inds, n_contacts):\n         \"\"\" Optimized helper function for getting contacts \"\"\"\n         total_number_of_half_edges = np.sum(n_contacts)\n@@ -470,9 +512,9 @@ class RandomNet(DynamicNetwork):\n             count += n\n         return source\n \n-    def get_contacts(self, inds, n_contacts):\n+    def get_edges(self, inds, n_contacts):\n         \"\"\"\n-        Efficiently generate contacts\n+        Efficiently find edges\n \n         Note that because of the shuffling operation, each person is assigned 2N contacts\n         (i.e. if a person has 5 contacts, they appear 5 times in the 'source' array and 5\n@@ -480,7 +522,7 @@ class RandomNet(DynamicNetwork):\n         function should be HALF of the total contacts a person is expected to have, if both\n         the source and target array outputs are used (e.g. for social contacts)\n \n-        adjusted_number_of_contacts = np.round(number_of_contacts / 2).astype(cvd.default_int)\n+        adjusted_number_of_contacts = np.round(number_of_contacts / 2).astype(ss.dtype.int)\n \n         Whereas for asymmetric contacts (e.g. staff-public interactions) it might not be necessary\n \n@@ -494,36 +536,168 @@ class RandomNet(DynamicNetwork):\n         \"\"\"\n         source = self.get_source(inds, n_contacts)\n         target = self.dist.rng.permutation(source)\n-        self.dist.jump() # Reset the RNG manually # TODO, think if there's a better way\n+        self.dist.jump() # Reset the RNG manually; does not auto-jump since using rng directly above # TODO, think if there's a better way\n         return source, target\n \n-    def update(self):\n-        self.end_pairs()\n+    def add_pairs(self):\n+        \"\"\" Generate edges \"\"\"\n+        people = self.sim.people\n+        born = people.alive & (people.age > 0)\n+        if isinstance(self.pars.n_contacts, ss.Dist):\n+            number_of_contacts = self.pars.n_contacts.rvs(born.uids)  # or people.uid?\n+        else:\n+            number_of_contacts = np.ones(len(people))*self.pars.n_contacts\n+\n+        number_of_contacts = sc.randround(number_of_contacts / 2).astype(ss_int_)  # One-way contacts\n+\n+        p1, p2 = self.get_edges(born.uids, number_of_contacts)\n+        beta = np.ones(len(p1), dtype=ss_float_)\n+\n+        if isinstance(self.pars.dur, ss.Dist):\n+            dur = self.pars.dur.rvs(p1)\n+        else:\n+            dur = np.ones(len(p1))*self.pars.dur # Other option would be np.full(len(p1), self.pars.dur.x), but this is harder to read\n+\n+        self.append(p1=p1, p2=p2, beta=beta, dur=dur)\n+        return\n+\n+\n+class ErdosRenyiNet(DynamicNetwork):\n+    \"\"\"\n+    In the Erdos-Renyi network, every possible edge has a probability, p, of\n+    being created on each time step.\n+\n+    The degree of each node will have a binomial distribution, considering each\n+    of the N-1 possible edges connection this node to the others will be created\n+    with probability p.\n+\n+    Please be careful with the `dur` parameter. When set to 0, new edges will be\n+    created on each time step. If positive, edges will persist for `dur` years.\n+    Note that the existence of edges from previous time steps will not prevent\n+    or otherwise alter the creation of new edges on each time step, edges will\n+    accumulate over time.\n+    \"\"\"\n+\n+    def __init__(self, pars=None, key_dict=None, **kwargs):\n+        \"\"\" Initialize \"\"\"\n+        super().__init__(key_dict=key_dict)\n+        self.define_pars(\n+            p = 0.1, # Probability of each edge\n+            dur = 0, # Duration of zero ensures that new random edges are formed on each time step\n+        )\n+        self.update_pars(pars, **kwargs)\n+        self.randint = ss.randint(low=np.iinfo('int64').min, high=np.iinfo('int64').max, dtype=np.int64) # Used to draw a random number for each agent as part of creating edges\n+        return\n+\n+    def init_post(self):\n         self.add_pairs()\n         return\n \n     def add_pairs(self):\n         \"\"\" Generate contacts \"\"\"\n         people = self.sim.people\n-        if isinstance(self.pars.n_contacts, ss.Dist):\n-            number_of_contacts = self.pars.n_contacts.rvs(people.uid[people.alive])  # or people.uid?\n-        else:\n-            number_of_contacts = np.full(len(people), self.pars.n_contacts)\n+        born_uids = (people.age > 0).uids\n \n-        number_of_contacts = np.round(number_of_contacts / 2).astype(ss_int_)  # One-way contacts\n+        # Sample integers\n+        ints = self.randint.rvs(born_uids)\n \n-        p1, p2 = self.get_contacts(people.uid.__array__(), number_of_contacts)\n+        # All possible edges are upper triangle of complete matrix\n+        idx1, idx2 = np.triu_indices(n=len(born_uids), k=1)\n+\n+        # Use integers to create random numbers per edge\n+        i1 = ints[idx1]\n+        i2 = ints[idx2]\n+        r = ss.utils.combine_rands(i1, i2) # TODO: use ss.multi_rand()\n+        edge = r <= self.pars.p\n+\n+        p1 = idx1[edge]\n+        p2 = idx2[edge]\n         beta = np.ones(len(p1), dtype=ss_float_)\n \n         if isinstance(self.pars.dur, ss.Dist):\n             dur = self.pars.dur.rvs(p1)\n         else:\n-            dur = np.full(len(p1), self.pars.dur)\n-        \n+            dur = np.ones(len(p1))*self.pars.dur\n+\n         self.append(p1=p1, p2=p2, beta=beta, dur=dur)\n         return\n \n \n+class DiskNet(Network):\n+    \"\"\"\n+    Disk graph in which edges are made between agents located within a user-defined radius.\n+\n+    Interactions take place within a square with edge length of 1. Agents are\n+    initialized to have a random position and orientation within this square. On\n+    each time step, agents advance v*dt in the direction they are pointed. When\n+    encountering a wall, agents are reflected.\n+\n+    Edges are formed between two agents if they are within r distance of each other.\n+    \"\"\"\n+\n+    def __init__(self, pars=None, key_dict=None, **kwargs):\n+        \"\"\" Initialize \"\"\"\n+        super().__init__(key_dict=key_dict)\n+        self.define_pars(\n+            r = 0.1, # Radius\n+            v = 0.05, # Velocity\n+        )\n+        self.update_pars(pars, **kwargs)\n+        self.define_states(\n+            ss.FloatArr('x', default=ss.random(), label='X position'),\n+            ss.FloatArr('y', default=ss.random(), label='Y position'),\n+            ss.FloatArr('theta', default=ss.uniform(high=2*np.pi), label='Heading'),\n+        )\n+        return\n+\n+    def init_post(self):\n+        self.add_pairs()\n+        return\n+\n+    def step(self):\n+        # Motion step\n+        vdt = self.pars.v * self.t.dt\n+        self.x[:] = self.x + vdt * np.cos(self.theta)\n+        self.y[:] = self.y + vdt * np.sin(self.theta)\n+\n+        # Wall bounce\n+\n+        ## Right edge\n+        inds = (self.x > 1).uids\n+        self.x[inds] = 2 - self.x[inds]\n+        self.theta[inds] = np.pi - self.theta[inds]\n+\n+        ## Left edge\n+        inds = (self.x < 0).uids\n+        self.x[inds] =  -self.x[inds]\n+        self.theta[inds] = np.pi - self.theta[inds]\n+\n+        ## Top edge\n+        inds = (self.y > 1).uids\n+        self.y[inds] = 2 - self.y[inds]\n+        self.theta[inds] = - self.theta[inds]\n+\n+        ## Bottom edge\n+        inds = (self.y < 0).uids\n+        self.y[inds] = -self.y[inds]\n+        self.theta[inds] = - self.theta[inds]\n+\n+        self.add_pairs()\n+        return\n+\n+    def add_pairs(self):\n+        \"\"\" Generate contacts \"\"\"\n+        p1, p2 = np.triu_indices(n=len(self.x), k=1)\n+        d12_sq = (self.x.raw[p2]-self.x.raw[p1])**2 + (self.y.raw[p2]-self.y.raw[p1])**2\n+        edge = d12_sq < self.pars.r**2\n+\n+        self.edges['p1'] = ss.uids(p1[edge])\n+        self.edges['p2'] = ss.uids(p2[edge])\n+        self.edges['beta'] = np.ones(len(self.p1), dtype=ss_float_)\n+\n+        return\n+\n+\n class NullNet(Network):\n     \"\"\"\n     A convenience class for a network of size n that only has self-connections with a weight of 0.\n@@ -532,7 +706,7 @@ class NullNet(Network):\n \n     Guarantees there's one (1) contact per agent (themselves), and that their connection weight is zero.\n \n-    For an empty network (ie, no contacts) use\n+    For an empty network (ie, no edges) use\n     >> import starsim as ss\n     >> import networkx as nx\n     >> empty_net_static = ss.StaticNet(nx.empty_graph)\n@@ -554,14 +728,18 @@ class NullNet(Network):\n             if self.n > popsize:\n                 errormsg = f'Please ensure the size of the network ({self.n} is less than or equal to the population size ({popsize}).'\n                 raise ValueError(errormsg)\n-        self.get_contacts()\n+        self.get_edges()\n         return\n \n-    def get_contacts(self):\n+    def get_edges(self):\n         indices = np.arange(self.n)\n         self.append(dict(p1=indices, p2=indices, beta=np.zeros_like(indices)))\n         return\n \n+    def step(self):\n+        \"\"\" Not used for NullNet \"\"\"\n+        pass\n+\n \n class MFNet(SexualNetwork):\n     \"\"\"\n@@ -570,11 +748,11 @@ class MFNet(SexualNetwork):\n     \"\"\"\n     def __init__(self, pars=None, key_dict=None, **kwargs):\n         super().__init__(key_dict=key_dict)\n-        self.default_pars(\n+        self.define_pars(\n             duration = ss.lognorm_ex(mean=15),  # Can vary by age, year, and individual pair. Set scale=exp(mu) and s=sigma where mu,sigma are of the underlying normal distribution.\n             participation = ss.bernoulli(p=0.9),  # Probability of participating in this network - can vary by individual properties (age, sex, ...) using callable parameter values\n             debut = ss.normal(loc=16),  # Age of debut can vary by using callable parameter values\n-            acts = ss.poisson(lam=80),\n+            acts = ss.poisson(lam=80), # TODO: make this work with ss.rate, which it currently does not due to network initialization limitations\n             rel_part_rates = 1.0,\n         )\n         self.update_pars(pars=pars, **kwargs)\n@@ -647,9 +825,9 @@ class MFNet(SexualNetwork):\n \n         return len(p1)\n \n-    def update(self):\n+    def step(self):\n         self.end_pairs()\n-        self.set_network_states(upper_age=self.sim.dt) # TODO: looks wrong\n+        self.set_network_states(upper_age=self.t.dt) # TODO: check\n         self.add_pairs()\n         return\n \n@@ -661,32 +839,29 @@ class MSMNet(SexualNetwork):\n \n     def __init__(self, pars=None, key_dict=None, **kwargs):\n         super().__init__(key_dict=key_dict)\n-        self.default_pars(\n-            duration = ss.lognorm_ex(mean=15, stdev=15),\n+        self.define_pars(\n+            duration = ss.lognorm_ex(mean=2, std=1),\n             debut = ss.normal(loc=16, scale=2),\n-            acts = ss.lognorm_ex(mean=80, stdev=20),\n+            acts = ss.lognorm_ex(mean=80, std=20),\n             participation = ss.bernoulli(p=0.1),\n         )\n         self.update_pars(pars, **kwargs)\n         return\n \n-    def init_pre(self, sim):\n-        # Add more here in line with MF network, e.g. age of debut\n-        # Or if too much replication then perhaps both these networks\n-        # should be subclasss of a specific network type (ask LY/DK)\n-        super().init_pre(sim)\n-        self.set_network_states(sim.people)\n-        self.add_pairs(sim.people, ti=0)\n+    def init_post(self):\n+        self.set_network_states()\n+        self.add_pairs()\n         return\n \n-    def set_network_states(self, people, upper_age=None):\n+    def set_network_states(self, upper_age=None):\n         \"\"\" Set network states including age of entry into network and participation rates \"\"\"\n+        people = self.sim.people\n         if upper_age is None: uids = people.uid[people.male]\n         else: uids = people.uid[people.male & (people.age < upper_age)]\n \n         # Participation\n         self.participant[people.female] = False\n-        self.participant[uids] = self.participation.rvs(uids) # Should be CRN safe?\n+        self.participant[uids] = self.pars.participation.rvs(uids) # Should be CRN safe?\n \n         # Debut\n         self.debut[uids] = self.pars.debut.rvs(len(uids)) # Just pass len(uids) as this network is not crn safe anyway\n@@ -694,7 +869,7 @@ class MSMNet(SexualNetwork):\n \n     def add_pairs(self):\n         \"\"\" Pair all unpartnered MSM \"\"\"\n-        available_m = self.available(self.sim.people, 'm')\n+        available_m = self.available(self.sim.people, 'male')\n         n_pairs = int(len(available_m)/2)\n         p1 = available_m[:n_pairs]\n         p2 = available_m[n_pairs:n_pairs*2]\n@@ -709,13 +884,13 @@ class MSMNet(SexualNetwork):\n             act_vals = self.pars.acts.rvs(len(p1))\n \n         self.append(p1=p1, p2=p2, beta=np.ones_like(p1), dur=dur, acts=act_vals)\n-        \n+\n         return len(p1)\n \n-    def update(self):\n-        self.end_pairs(self.sim)\n-        self.set_network_states(self.sim.people, upper_age=self.sim.dt)\n-        self.add_pairs(self.sim)\n+    def step(self):\n+        self.end_pairs()\n+        self.set_network_states()\n+        self.add_pairs()\n         return\n \n \n@@ -732,7 +907,7 @@ class EmbeddingNet(MFNet):\n             male_shift is the average age that males are older than females in partnerships\n         \"\"\"\n         super().__init__()\n-        self.default_pars(\n+        self.define_pars(\n             inherit = True, # The MFNet already comes with pars, we want to keep those\n             embedding_func = ss.normal(name='EmbeddingNet', loc=self.embedding_loc, scale=2),\n             male_shift = 5,\n@@ -789,20 +964,24 @@ class MaternalNet(DynamicNetwork):\n         super().__init__(key_dict=key_dict, prenatal=prenatal, postnatal=postnatal, **kwargs)\n         return\n \n-    def update(self):\n+    def step(self):\n         \"\"\"\n         Set beta to 0 for women who complete duration of transmission\n         Keep connections for now, might want to consider removing\n+\n+        NB: add_pairs() and end_pairs() are NOT called here; this is done separately\n+        in ss.Pregnancy.update_states().\n         \"\"\"\n-        inactive = self.edges.end <= self.sim.ti\n+        inactive = self.edges.end <= self.ti\n         self.edges.beta[inactive] = 0\n         return\n \n     def end_pairs(self):\n         people = self.sim.people\n-        active = (self.edges.end > self.sim.ti) & people.alive[self.edges.p1] & people.alive[self.edges.p2]\n+        edges = self.edges\n+        active = (edges.end > self.ti) & people.alive[edges.p1] & people.alive[edges.p2]\n         for k in self.meta_keys():\n-            self.edges[k] = self.edges[k][active]\n+            edges[k] = edges[k][active]\n         return len(active)\n \n     def add_pairs(self, mother_inds=None, unborn_inds=None, dur=None, start=None):\n@@ -811,10 +990,10 @@ class MaternalNet(DynamicNetwork):\n             return 0\n         else:\n             if start is None:\n-                start = np.full_like(dur, fill_value=self.sim.ti)\n+                start = np.ones_like(dur)*self.ti\n             n = len(mother_inds)\n             beta = np.ones(n)\n-            end = start + sc.promotetoarray(dur) / self.sim.dt\n+            end = start + sc.promotetoarray(dur)\n             self.append(p1=mother_inds, p2=unborn_inds, beta=beta, dur=dur, start=start, end=end)\n             return n\n \n@@ -830,3 +1009,265 @@ class PostnatalNet(MaternalNet):\n     def __init__(self, key_dict=None, prenatal=False, postnatal=True, **kwargs):\n         super().__init__(key_dict=key_dict, prenatal=prenatal, postnatal=postnatal, **kwargs)\n         return\n+\n+\n+__all__ += ['AgeGroup', 'MixingPools', 'MixingPool']\n+\n+class AgeGroup(sc.prettyobj):\n+    \"\"\" A simple age-based filter that returns uids of agents that match the criteria \"\"\"\n+    def __init__(self, low, high, do_cache=True):\n+        self.low = low\n+        self.high = high\n+\n+        self.do_cache = do_cache\n+        self.uids = None # Cached\n+        self.ti_cache = -1\n+\n+        self.name = repr(self)\n+        return\n+\n+    def __call__(self, sim):\n+        if (not self.do_cache) or (self.ti_cache != sim.ti):\n+            in_group = sim.people.age >= self.low\n+            if self.high is not None:\n+                in_group = in_group & (sim.people.age < self.high)\n+            self.uids = ss.uids(in_group)\n+            self.ti_cache = sim.ti\n+        return self.uids\n+\n+    def __repr__(self):\n+        return f'age({self.low}-{self.high})'\n+\n+\n+class MixingPools(Route):\n+    \"\"\"\n+    A container for creating a rectangular array of MixingPool instances\n+\n+    By default, separates the population into <15 and >15 age groups.\n+\n+    Args:\n+        diseases (str): the diseases that transmit via these mixing pools\n+        src (inds): source agents; can be AgeGroup(), ss.uids(), or lambda(sim); None indicates all alive agents\n+        dst (inds): destination agents; as above\n+        beta (float): overall transmission via these mixing pools\n+        contacts (array): the relative connectivity between different mixing pools (can be float or Dist)\n+\n+    **Example**::\n+\n+        import starsim as ss\n+        mps = ss.MixingPools(\n+            diseases = 'sis',\n+            beta = 0.1,\n+            src = {'0-15': ss.AgeGroup(0, 15), '15+': ss.AgeGroup(15, None)},\n+            dst = {'0-15': ss.AgeGroup(0, 15), '15+': ss.AgeGroup(15, None)},\n+            contacts = [[2.4, 0.49], [0.91, 0.16]],\n+        )\n+        sim = ss.Sim(diseases='sis', networks=mps).run()\n+        sim.plot()\n+    \"\"\"\n+    def __init__(self, pars=None, **kwargs):\n+        super().__init__()\n+        self.define_pars(\n+            diseases = None,\n+            src = None,\n+            dst = None,\n+            beta = ss.beta(0.1),\n+            contacts = None,\n+        )\n+        self.update_pars(pars, **kwargs)\n+        self.validate_pars()\n+        self.pools = []\n+        return\n+\n+    def __len__(self):\n+        try:    return len(self.pools)\n+        except: return 0\n+\n+    def validate_pars(self):\n+        \"\"\" Check that src and dst have correct types, and contacts is the correct shape \"\"\"\n+        p = self.pars\n+\n+        # Validate src and dst\n+        if not isinstance(p.src, dict):\n+            errormsg = f'src must be a provided as a dictionary, not {type(self.pars.src)}'\n+            raise TypeError(errormsg)\n+        if not isinstance(p.dst, dict):\n+            raise TypeError(f'dst must be a provided as a dictionary, not {type(self.pars.src)}')\n+        p.src = sc.objdict(p.src)\n+        p.dst = sc.objdict(p.dst)\n+\n+        # Validate the contacts\n+        if p.contacts is None:\n+            p.contacts = np.ones((len(p.src), len(p.dst)))\n+        p.contacts = np.array(p.contacts)\n+        actual = p.contacts.shape\n+        expected = (len(p.src), len(p.dst))\n+        if actual != expected:\n+            errormsg = f'The number of source and destination groups must match the number of rows and columns in the mixing matrix, but {actual} != {expected}.'\n+            raise ValueError(errormsg)\n+\n+        return\n+\n+    def init_pre(self, sim):\n+        super().init_pre(sim)\n+        p = self.pars\n+\n+        self.pools = []\n+        for i,sk,src in p.src.enumitems():\n+            for j,dk,dst in p.dst.enumitems():\n+                contacts = p.contacts[i,j]\n+                if sc.isnumber(contacts): # If it's a number, convert to a distribution\n+                    contacts = ss.poisson(lam=contacts)\n+                name = f'pool:{sk}->{dk}'\n+                mp = MixingPool(name=name, diseases=p.diseases, beta=p.beta, contacts=contacts, src=src, dst=dst)\n+                mp.init_pre(sim) # Initialize the pool\n+                self.pools.append(mp)\n+        return\n+\n+    def init_post(self):\n+        \"\"\" Initialize each mixing pool \"\"\"\n+        for mp in self.pools:\n+            mp.init_post()\n+        return\n+\n+    def step(self):\n+        \"\"\" Step each mixing pool \"\"\"\n+        for mp in self.pools:\n+            mp.step()\n+        return\n+\n+    def remove_uids(self, uids):\n+        \"\"\" Remove UIDs from each mixing pool \"\"\"\n+        for mp in self.pools:\n+            mp.remove_uids(uids)\n+        return\n+\n+\n+class MixingPool(Route):\n+    \"\"\"\n+    Define a single mixing pool; can be used as a drop-in replacement for a network.\n+\n+    Args:\n+        diseases (str): the diseases that transmit via this mixing pool\n+        src (inds): source agents; can be AgeGroup(), ss.uids(), or lambda(sim); None indicates all alive agents\n+        dst (inds): destination agents; as above\n+        beta (float): overall transmission\n+        contacts (Dist): the number of effective contacts of the destination agents\n+\n+    **Example**::\n+\n+        import starsim as ss\n+\n+        # Set the parameters\n+        mp_pars = dict(\n+            src = lambda sim: sim.people.male, # only males are infectious\n+            dst = None, # all agents are susceptible\n+            beta = ss.beta(0.2),\n+            contacts = ss.poisson(lam=4),\n+        )\n+\n+        # Seed 5% of the male population\n+        def p_init(self, sim, uids):\n+            return 0.05*sim.people.male\n+\n+        # Create and run the sim\n+        sis = ss.SIS(init_prev=p_init)\n+        mp = ss.MixingPool(mp_pars)\n+        sim = ss.Sim(diseases=sis, networks=mp)\n+        sim.run()\n+        sim.plot()\n+    \"\"\"\n+    def __init__(self, pars=None, **kwargs):\n+        super().__init__()\n+        self.define_pars(\n+            diseases = None,\n+            src = None,\n+            dst = None, # Same as src\n+            beta = ss.beta(0.2),\n+            contacts = ss.poisson(1.0),\n+        )\n+        self.update_pars(pars, **kwargs)\n+\n+        self.define_states(\n+            ss.FloatArr('eff_contacts', default=self.pars.contacts, label='Effective number of contacts')\n+        )\n+\n+        self.pars.diseases = sc.promotetolist(self.pars.diseases)\n+        self.diseases = None\n+        self.src_uids = None\n+        self.dst_uids = None\n+\n+        self.p_acquire = ss.bernoulli(p=0) # Placeholder value\n+\n+        return\n+\n+    def __len__(self):\n+        try:\n+            return len(self.pars.dst)\n+        except:\n+            return 0\n+\n+    def init_post(self):\n+        super().init_post()\n+\n+        if len(self.pars.diseases) == 0:\n+            self.diseases = [d for d in self.sim.diseases.values() if isinstance(d, ss.Infection)] # Assume the user wants all communicable diseases\n+        else:\n+            self.diseases = []\n+            for d in self.pars.diseases:\n+                if not isinstance(d, str):\n+                    raise TypeError(f'Diseases can be specified as ss.Disease objects or strings, not {type(d)}')\n+                if d not in self.sim.diseases:\n+                    raise KeyError(f'Could not find disease with name {d} in the list of diseases.')\n+\n+                dis = self.sim.diseases[d]\n+                if not isinstance(dis, ss.Infection):\n+                    raise TypeError(f'Cannot create a mixing pool for disease {d}. Mixing pools only work for communicable diseases.')\n+                self.diseases.append(dis)\n+\n+            if len(self.diseases) == 0:\n+                raise ValueError('You must specify at least one transmissible disease to use mixing pools')\n+        return\n+\n+    def get_uids(self, func_or_array):\n+        if func_or_array is None:\n+            return self.sim.people.auids\n+        elif callable(func_or_array):\n+            return func_or_array(self.sim)\n+        elif isinstance(func_or_array, ss.uids):\n+            return func_or_array\n+        raise Exception('src must be either a callable function, e.g. lambda sim: ss.uids(sim.people.age<5), or an array of uids.')\n+\n+    def remove_uids(self, uids):\n+        \"\"\" If UIDs are supplied explicitly, remove them if people die \"\"\"\n+        for key in ['src', 'dst']:\n+            inds = self.pars[key]\n+            if isinstance(inds, ss.uids):\n+                self.pars[key] = inds.remove(uids)\n+        return\n+\n+    def step(self):\n+        self.src_uids = self.get_uids(self.pars.src)\n+        self.dst_uids = self.get_uids(self.pars.dst)\n+        beta = self.pars.beta\n+        if isinstance(beta, ss.beta):\n+            beta = beta.values # Don't use as a time probability\n+\n+        if beta == 0:\n+            return 0\n+\n+        if len(self.src_uids) == 0 or len(self.dst_uids) == 0:\n+            return 0\n+\n+        n_new_cases = 0\n+        for disease in self.diseases:\n+            trans = np.mean(disease.infectious[self.src_uids] * disease.rel_trans[self.src_uids])\n+            acq = self.eff_contacts[self.dst_uids] * disease.susceptible[self.dst_uids] * disease.rel_sus[self.dst_uids]\n+            p = beta*trans*acq\n+\n+            self.p_acquire.set(p=p)\n+            new_cases = self.p_acquire.filter(self.dst_uids)\n+            n_new_cases += len(new_cases)\n+            disease.set_prognoses(new_cases)\n+\n+        return n_new_cases\ndiff --git a/starsim/parameters.py b/starsim/parameters.py\nindex 5b7034d..cdf9ad8 100644\n--- a/starsim/parameters.py\n+++ b/starsim/parameters.py\n@@ -1,7 +1,6 @@\n \"\"\"\n Set parameters\n \"\"\"\n-\n from numbers import Number\n import numpy as np\n import pandas as pd\n@@ -17,7 +16,7 @@ atomic_classes = (str, Number, list, np.ndarray, pd.Series, pd.DataFrame, type(N\n class Pars(sc.objdict):\n     \"\"\"\n     Dict-like container of parameters\n-    \n+\n     Acts like an ``sc.objdict()``, except that adding new keys are disallowed by\n     default, and auto-updates known types.\n     \"\"\"\n@@ -30,11 +29,11 @@ class Pars(sc.objdict):\n                 raise ValueError(errormsg)\n         super().__init__(**kwargs)\n         return\n-    \n+\n     def update(self, pars=None, create=False, **kwargs):\n         \"\"\"\n         Update internal dict with new pars.\n-        \n+\n         Args:\n             pars (dict): the parameters to update (if None, do nothing)\n             create (bool): if create is False, then raise a KeyNotFoundError if the key does not already exist\n@@ -47,7 +46,7 @@ class Pars(sc.objdict):\n             return self\n         if not create: # Check if there are any mismatches, which raises an exception if there are\n             self.check_key_mismatch(pars)\n-        \n+\n         # Perform the update\n         for key,new in pars.items():\n             if key not in self.keys(): # It's a new parameter and create=True: update directly\n@@ -56,20 +55,27 @@ class Pars(sc.objdict):\n                 old = self[key] # Get the existing object we're about to update\n                 if isinstance(old, atomic_classes): # It's a number, string, etc: update directly\n                     self[key] = new\n+\n                 elif isinstance(old, Pars): # It's a Pars object: update recursively\n                     old.update(new, create=create)\n                 elif isinstance(old, ss.ndict): # Update module containers\n                     self._update_ndict(key, old, new)\n                 elif isinstance(old, ss.Module):  # Update modules\n                     self._update_module(key, old, new)\n+                elif isinstance(old, ss.TimePar):\n+                    self._update_timepar(key, old, new)\n                 elif isinstance(old, ss.Dist): # Update a distribution\n                     self._update_dist(key, old, new)\n+                elif callable(old): # It's a function: update directly\n+                    self[key] = new\n+                elif isinstance(old, dict):\n+                    self[key] = new # Take dictionaries directly, without warning the user\n                 else: # Everything else; not used currently but could be\n-                    warnmsg = 'No known mechanism for handling {type(old)} → {type(new)}; using default'\n+                    warnmsg = f'No known mechanism for handling {type(old)} → {type(new)}; using default'\n                     ss.warn(warnmsg)\n                     self[key] = new\n         return self\n-    \n+\n     def _update_ndict(self, key, old, new):\n         \"\"\" Update an ndict object in the parameters, e.g. sim.pars.diseases \"\"\"\n         if not len(old): # It's empty, just overwrite\n@@ -82,7 +88,7 @@ class Pars(sc.objdict):\n                 errormsg = f'Cannot update an ndict with {type(new)}: must be a dict to set new parameters'\n                 raise TypeError(errormsg)\n         return\n-    \n+\n     def _update_module(self, key, old, new):\n         \"\"\" Update a Module object in the parameters, e.g. sim.pars.diseases.sir \"\"\"\n         if isinstance(new, dict):\n@@ -91,25 +97,69 @@ class Pars(sc.objdict):\n             errormsg = f'Cannot update a module with {type(new)}: must be a dict to set new parameters'\n             raise TypeError(errormsg)\n         return\n-    \n+\n+    def _update_timepar(self, key, old, new):\n+        \"\"\" Update a time parameter (duration or rate) \"\"\"\n+\n+        # It's a TimePar, e.g. dur_inf = ss.dur(6); use directly\n+        if isinstance(new, ss.TimePar):\n+            self[key] = new\n+\n+        # It's a dataframe, allow the update -- used for demographics\n+        elif isinstance(new, (pd.Series, pd.DataFrame)):\n+            self[key] = new # TODO: add validation or convert to timepar\n+\n+        # It's a single number, e.g. dur_inf = 6; set parameters\n+        elif isinstance(new, Number):\n+            old.set(new)\n+\n+        # It's a list of numbers, e.g. dur_inf = [6, 2]; set parameters\n+        elif isinstance(new, list):\n+            old.set(*new)\n+\n+        # It's a dict, figure out what to do\n+        elif isinstance(new, dict):\n+            if isinstance(old, ss.beta):\n+                self[key] = new # TODO: use an actual set here\n+            else:\n+                old.set(**new)\n+\n+        # Give up\n+        else:\n+            errormsg = f'Updating timepar from {type(old)} to {type(new)} is not supported'\n+            raise TypeError(errormsg)\n+\n+        return\n+\n     def _update_dist(self, key, old, new):\n         \"\"\" Update a Dist object in the parameters, e.g. sim.pars.diseases.sir.dur_inf \"\"\"\n+\n         # It's a Dist, e.g. dur_inf = ss.normal(6,2); use directly\n-        if isinstance(new, ss.Dist): \n+        if isinstance(new, ss.Dist):\n             if isinstance(old, ss.bernoulli) and not isinstance(new, ss.bernoulli):\n                 errormsg = f\"Bernoulli distributions can't be changed to another type: {type(new)} is invalid\"\n                 raise TypeError(errormsg)\n             else:\n                 self[key] = new\n-        \n+\n         # It's a single number, e.g. dur_inf = 6; set parameters\n         elif isinstance(new, Number):\n             old.set(new)\n-        \n-        # It's a list number, e.g. dur_inf = [6, 2]; set parameters\n+\n+        # It's a list of numbers, e.g. dur_inf = [6, 2]; set parameters\n         elif isinstance(new, list):\n             old.set(*new)\n-        \n+\n+        # It's a timepar, set it like a number, e.g. dur_inf = ss.dur(6)\n+        elif isinstance(new, ss.TimePar):\n+            oldpar = old.pars[0]\n+            if isinstance(oldpar, ss.TimePar): # If changing from one timepar to another, validate\n+                dur_mismatch = isinstance(oldpar, ss.dur) != isinstance(new, ss.dur)\n+                if dur_mismatch:\n+                    errormsg = f'Cannot change a duration to a non-duration vice versa: old={type(oldpar)}, new={type(new)}'\n+                    raise TypeError(errormsg)\n+            old.set(new)\n+\n         # It's a dict, figure out what to do\n         elif isinstance(new, dict):\n             newtype = new.get('type')\n@@ -122,6 +172,12 @@ class Pars(sc.objdict):\n                 else:\n                     dist = ss.make_dist(new)\n                     self[key] = dist\n+\n+        # Give up\n+        else:\n+            errormsg = f'Updating dist from {type(old)} to {type(new)} is not supported'\n+            raise TypeError(errormsg)\n+\n         return\n \n     def check_key_mismatch(self, pars):\n@@ -133,15 +189,15 @@ class Pars(sc.objdict):\n             errormsg = f'Key(s) {mismatches} not found; available keys are {available_keys}'\n             raise sc.KeyNotFoundError(errormsg)\n         return\n-    \n+\n     def dict_update(self, *args, **kwargs):\n         \"\"\" Redefine default dict.update(), since overwritten in this class; should not usually be used \"\"\"\n         super().update(*args, **kwargs)\n         return\n-    \n+\n     def to_json(self, **kwargs):\n         \"\"\" Convert to JSON representation \"\"\"\n-        return sc.jsonify(self, **kwargs)\n+        return sc.jsonify(dict(self), **kwargs)\n \n \n class SimPars(Pars):\n@@ -152,35 +208,53 @@ class SimPars(Pars):\n     directly.\n \n     Args:\n-        kwargs (dict): any additional kwargs are interpreted as parameter names\n+        label (str): The name of the simulation\n+        n_agents (int/float): The number of agents to run (default 10,000)\n+        total_pop (int/float): If provided, scale the agents to this effective population size\n+        pop_scale (float): If provided, use this agent-to-population scale factor (total_pop = n_agents*pop_scale)\n+        unit (str): The time unit for the simulation (default 'year'; other choices are 'day', 'week', 'month')\n+        start (float/str/date): The starting date for the simulation (default 2000); can be a year or date\n+        stop (float/str/date): If provided, the ending date for the simulation (if not provided, calculate from \"dur\")\n+        dur (int): How many timesteps to simulate, if \"stop\" is not provided (default 50)\n+        dt (float): The timestep, in units of \"unit\" (default 1.0)\n+        rand_seed (int): The overall random seed for the simulation (used to set module-specific random seeds)\n+        birth_rate (float): If provided, include births with this rate (per 1000 people per year)\n+        death_rate (float): If provided, include deaths with this rate (per 1000 people per year)\n+        use_aging (bool): Specify whether agents age (by default, agents age if and only if births and/or deaths are included)\n+        people (People): If provided, use a pre-existing People object rather than creating one (in which case n_agents will be ignored)\n+        networks (str/list/Module): The network module(s); can be a string, single module (i.e. Network), or list\n+        demographics (str/list/Module): As above\n+        diseases (str/list/Module): As above\n+        connectors (str/list/Module): As above\n+        interventions (str/list/Module): As above\n+        analyzers (str/list/Module): As above\n+        verbose (float): How much detail to print (1 = every timestep, 0.1 = every 10 timesteps, etc.)\n     \"\"\"\n     def __init__(self, **kwargs):\n-        \n+\n         # General parameters\n         self.label   = '' # The label of the simulation\n         self.verbose = ss.options.verbose # Whether or not to display information during the run -- options are 0 (silent), 0.1 (some; default), 1 (default), 2 (everything)\n \n         # Population parameters\n-        self.n_agents  = 10e3  # Number of agents\n-        self.total_pop = None  # If defined, used for calculating the scale factor\n-        self.pop_scale = None  # How much to scale the population\n+        self.n_agents  = 10e3 # Number of agents\n+        self.total_pop = None # If defined, used for calculating the scale factor\n+        self.pop_scale = None # How much to scale the population\n \n         # Simulation parameters\n-        self.unit       = 'year' # The time unit to use (NOT YET IMPLEMENTED)\n-        self.start      = 2000   # Start of the simulation\n-        self.end        = None   # End of the simulation\n-        self.n_years    = 50     # Number of years to run, if end isn't specified. Note that this includes burn-in\n-        self.dt         = 1.0    # Timestep\n-        self.rand_seed  = 1      # Random seed, if None, don't reset\n-        self.slot_scale = 5      # Random slots will be assigned to newborn agents between min=n_agents and max=slot_scale*n_agents\n+        self.unit      = ''    # The time unit to use; options are 'year' (default), 'day', 'week', 'month', or 'none'\n+        self.start     = None  # Start of the simulation (default 2020)\n+        self.stop      = None  # End of the simulation\n+        self.dur       = None  # Duration of time to run, if stop isn't specified (default 50 steps of self.unit)\n+        self.dt        = 1.0   # Timestep (in units of self.unit)\n+        self.rand_seed = 1     # Random seed; if None, don't reset\n \n         # Demographic parameters\n-        self.location   = None  #  NOT CURRENTLY FUNCTIONAL - what demographics to use\n         self.birth_rate = None\n         self.death_rate = None\n         self.use_aging  = None # True if demographics, false otherwise\n \n-        # Modules: demographics, diseases, connectors, networks, analyzers, and interventions\n+        # Modules: demographics, diseases, networks, analyzers, and interventions\n         self.people = None\n         self.networks      = ss.ndict()\n         self.demographics  = ss.ndict()\n@@ -192,7 +266,7 @@ class SimPars(Pars):\n         # Update with any supplied parameter values and generate things that need to be generated\n         self.update(kwargs)\n         return\n-    \n+\n     def is_default(self, key):\n         \"\"\" Check if the provided value matches the default \"\"\"\n         default_pars = SimPars() # Create a default SimPars object\n@@ -206,16 +280,15 @@ class SimPars(Pars):\n         self.validate_sim_pars()\n         self.validate_modules()\n         return\n-    \n+\n     def validate_sim_pars(self):\n         \"\"\" Validate each of the parameter values \"\"\"\n         self.validate_verbose()\n         self.validate_agents()\n         self.validate_total_pop()\n-        self.validate_start_end()\n-        self.validate_dt()\n+        self.validate_time()\n         return\n-    \n+\n     def validate_verbose(self):\n         \"\"\" Validate verbosity \"\"\"\n         if self.verbose == 'brief':\n@@ -224,7 +297,7 @@ class SimPars(Pars):\n             errormsg = f'Verbose argument should be either \"brief\", -1, or a float, not {type(self.par.verbose)} \"{self.par.verbose}\"'\n             raise ValueError(errormsg)\n         return\n-    \n+\n     def validate_agents(self):\n         \"\"\" Check that n_agents is supplied and convert to an integer \"\"\"\n         if self.people is not None:\n@@ -239,10 +312,10 @@ class SimPars(Pars):\n             errormsg = 'Must supply n_agents, a people object, or a popdict'\n             raise ValueError(errormsg)\n         return\n-    \n+\n     def validate_total_pop(self):\n         \"\"\" Ensure one but not both of total_pop and pop_scale are defined \"\"\"\n-        if self.total_pop is not None:  # If no pop_scale has been provided, try to get it from the location\n+        if self.total_pop is not None:  # In future, if no pop_scale has been provided, try to get it from the location\n             if self.pop_scale is not None:\n                 errormsg = f'You can define total_pop ({self.total_pop}) or pop_scale ({self.pop_scale}), but not both, since one is calculated from the other'\n                 raise ValueError(errormsg)\n@@ -256,48 +329,38 @@ class SimPars(Pars):\n         if self.pop_scale is None:\n             self.pop_scale = total_pop / self.n_agents\n         return\n-    \n-    def validate_start_end(self):\n-        \"\"\" Ensure at least one of n_years and end is defined, but not both \"\"\"\n-        if self.end is not None:\n-            if self.is_default('n_years'):\n-                self.n_years = self.end - self.start\n+\n+    def validate_time(self):\n+        \"\"\" Ensure at least one of dur and stop is defined, but not both \"\"\"\n+\n+        # Handle the unit\n+        if self.unit == '':\n+            self.unit = ss.time.default_unit\n+        self.unit = ss.time.validate_unit(self.unit)\n+\n+        # Handle start\n+        if self.start is None:\n+            self.start = ss.time.default_start[self.unit]\n+\n+        # Handle stop and dur\n+        if self.stop is not None:\n+            if self.dur is None:\n+                self.dur = ss.date_diff(self.start, self.stop, self.unit)\n             else:\n-                errormsg = f'You can supply either end ({self.end}) or n_years ({self.n_years}) but not both, since one is calculated from the other'\n+                errormsg = f'You can supply either stop ({self.stop}) or dur ({self.dur}) but not both, since one is calculated from the other'\n                 raise ValueError(errormsg)\n-            if self.n_years <= 0:\n-                errormsg = f\"Number of years must be >0, but you supplied start={str(self.start)} and \" \\\n-                           f\"end={str(self.end)}, which gives n_years={self.n_years}\"\n+            if self.dur <= 0:\n+                errormsg = f\"Duration must be >0, but you supplied start={str(self.start)} and stop={str(self.stop)}, which gives dur={self.dur}\"\n                 raise ValueError(errormsg)\n         else:\n-            if self.n_years is not None:\n-                self.end = self.start + self.n_years\n-            else:\n-                errormsg = 'You must supply one of n_years and end.\"'\n-                raise ValueError(errormsg)\n+            if self.dur is None:\n+                self.dur = ss.time.default_dur\n+            self.stop = ss.date_add(self.start, self.dur, self.unit)\n         return\n \n-    def validate_dt(self):\n-        \"\"\"\n-        Check that 1/dt is an integer value, otherwise results and time vectors will have mismatching shapes.\n-        init_results explicitly makes this assumption by casting resfrequency = int(1/dt).\n-        \"\"\"\n-        if self.unit == 'year': # TODO: implement properly\n-            dt = self.dt\n-            reciprocal = 1.0 / dt  # Compute the reciprocal of dt\n-            if not reciprocal.is_integer():  # Check if reciprocal is not a whole (integer) number\n-                # Round the reciprocal\n-                reciprocal = int(reciprocal)\n-                rounded_dt = 1.0 / reciprocal\n-                self.dt = rounded_dt\n-                if self.verbose:\n-                    warnmsg = f'Warning: Provided time step dt={dt} resulted in a non-integer number of steps per year. Rounded to {rounded_dt}.'\n-                    ss.warn(warnmsg)\n-        return\n-    \n     def validate_modules(self):\n         \"\"\" Validate modules passed in pars\"\"\"\n-        \n+\n         # Do special validation on demographics (must be before modules are created)\n         self.validate_demographics()\n \n@@ -317,21 +380,32 @@ class SimPars(Pars):\n         # Do special validation on networks (must be after modules are created)\n         self.validate_networks()\n         return\n-    \n+\n     def validate_demographics(self):\n         \"\"\" Validate demographics-related input parameters\"\"\"\n-        # Allow shortcut for default demographics # TODO: think about whether we want to enable this, when we have birth_rate and death_rate\n+        # Allow shortcut for default demographics\n         if self.demographics == True:\n-            self.demographics = [ss.Births(), ss.Deaths()]\n+            self.demographics = sc.autolist()\n+            if self.birth_rate is None:\n+                self.demographics += ss.Births()\n+            if self.death_rate is None:\n+                self.demographics += ss.Deaths()\n \n         # Allow users to add vital dynamics by entering birth_rate and death_rate parameters directly to the sim\n+        valid = isinstance(self.demographics, ss.ndict) and not len(self.demographics)\n         if self.birth_rate is not None:\n+            if not valid:\n+                errormsg = 'You can only specify birth_rate together with (optionally) death_rate, not other demographics modules; add ss.Births() manually'\n+                raise ValueError(errormsg)\n             births = ss.Births(birth_rate=self.birth_rate)\n             self.demographics += births\n         if self.death_rate is not None:\n+            if not valid:\n+                errormsg = 'You can only specify death_rate together with (optionally) birth_rate, not other demographics modules; add ss.Deaths() manually'\n+                raise ValueError(errormsg)\n             background_deaths = ss.Deaths(death_rate=self.death_rate)\n             self.demographics += background_deaths\n-        \n+\n         # Decide whether to use aging based on if demographics modules are present\n         if self.use_aging is None:\n             self.use_aging = True if self.demographics else False\n@@ -340,8 +414,12 @@ class SimPars(Pars):\n     def validate_networks(self):\n         \"\"\" Validate networks \"\"\"\n         # Don't allow more than one prenatal or postnatal network\n-        prenatal_nets  = {k:nw for k,nw in self.networks.items() if nw.prenatal}\n-        postnatal_nets = {k:nw for k,nw in self.networks.items() if nw.postnatal}\n+        prenatal_nets = []\n+        postnatal_nets = []\n+        for k,nw in self.networks.items():\n+            if isinstance(nw, ss.Network):\n+                if nw.prenatal: prenatal_nets.append(k)\n+                if nw.postnatal: postnatal_nets.append(k)\n         if len(prenatal_nets) > 1:\n             errormsg = f'Starsim currently only supports one prenatal network; prenatal networks are: {prenatal_nets.keys()}'\n             raise ValueError(errormsg)\n@@ -368,7 +446,7 @@ class SimPars(Pars):\n         \"\"\"\n         modmap = ss.module_map() # List of modules and parent module classes, e.g. ss.Disease\n         modules = ss.find_modules() # Each individual module class option, e.g. ss.SIR\n-        \n+\n         for modkey,ssmoddict in modules.items():\n             moddictkeys = ssmoddict.keys()\n             moddictvals = ssmoddict.values()\n@@ -376,25 +454,25 @@ class SimPars(Pars):\n             modlist = self[modkey]\n             if isinstance(modlist, list): # Skip over ones that are already ndict format, assume they're already initialized\n                 for i,mod in enumerate(modlist):\n-                    \n+\n                     # Convert first from a string to a dict\n                     if isinstance(mod, str):\n                         mod = dict(type=mod)\n-                        \n+\n                     # Convert from class to class instance (used for interventions and analyzers only)\n                     if isinstance(mod, type) and modkey in ['interventions', 'analyzers']:\n                         mod = mod() # Call it to create a class instance\n-                    \n+\n                     # Now convert from a dict to a module\n                     if isinstance(mod, dict):\n-                        \n+\n                         # Get the module type as a string\n                         if 'type' in mod:\n                             modtype = mod.pop('type')\n                         else:\n                             errormsg = f'When specifying a {modkey} module with a dict, one of the keys must be \"type\"; you supplied {mod}'\n                             raise ValueError(errormsg)\n-                        \n+\n                         # Get the module type as a class\n                         if isinstance(modtype, str): # Usual case, a string, e.g. dict(type='sir', dur_inf=6)\n                             modtype = modtype.lower() # Because our map is in lowercase\n@@ -409,24 +487,25 @@ class SimPars(Pars):\n                             else:\n                                 errormsg = f'Invalid module class \"{modtype}\" for \"{modkey}\"; must be one of {moddictvals}'\n                                 raise TypeError(errormsg)\n-                        \n+\n                         # Create the module and store it in the list\n                         mod = modcls(**mod)\n-                    \n+\n                     # Special handling for interventions and analyzers: convert class and function to class instance\n                     if modkey in ['interventions', 'analyzers']:\n                         if isinstance(mod, type) and issubclass(mod, expected_cls):\n                             mod = mod()  # Convert from a class to an instance of a class\n                         elif not isinstance(mod, ss.Module) and callable(mod):\n                             mod = expected_cls.from_func(mod)\n-                    \n+\n                     # Do final check\n-                    if not isinstance(mod, expected_cls):\n-                        errormsg = f'Was expecting {modkey} entry {i} to be class {expected_cls}, but was {type(mod)} instead'\n+                    if not isinstance(mod, (expected_cls, ss.Module)): # TEMP: check if this check still works?\n+                        errormsg = f'Was expecting {modkey} entry {i} to be class {expected_cls} or Plugin, but was {type(mod)} instead'\n                         raise TypeError(errormsg)\n                     modlist[i] = mod\n         return\n \n \n def make_pars(**kwargs):\n+    \"\"\" Shortcut for making a new instance of SimPars \"\"\"\n     return SimPars(**kwargs)\ndiff --git a/starsim/people.py b/starsim/people.py\nindex e597f12..37e021d 100644\n--- a/starsim/people.py\n+++ b/starsim/people.py\n@@ -1,12 +1,11 @@\n \"\"\"\n Defines the People class and functions associated with making people\n \"\"\"\n-\n-# %% Imports\n import numpy as np\n import pandas as pd\n import sciris as sc\n import starsim as ss\n+from pathlib import Path\n \n __all__ = ['People', 'Person']\n \n@@ -19,9 +18,8 @@ class People(sc.prettyobj):\n     will get passed instead since it will be needed before the People object is\n     initialized.\n \n-    Note that this class handles the mechanics of updating the actual people, while\n-    ``ss.BasePeople`` takes care of housekeeping (saving, loading, exporting, etc.).\n-    Please see the BasePeople class for additional methods.\n+    Note that this class handles the mechanics of updating the actual people,\n+    as well as the additional housekeeping methods (saving, loading, exporting, etc.).\n \n     Args:\n         pars (dict): the sim parameters, e.g. sim.pars -- alternatively, if a number, interpreted as n_agents\n@@ -34,7 +32,7 @@ class People(sc.prettyobj):\n \n     def __init__(self, n_agents, age_data=None, extra_states=None):\n         \"\"\" Initialize \"\"\"\n-        \n+\n         # We internally store states in a dict keyed by the memory ID of the state, so that we can have colliding names\n         # e.g., across modules, but we will never change the size of a State multiple times in the same iteration over\n         # _states. This is a hidden variable because it is internally used to synchronize the size of all States contained\n@@ -44,23 +42,25 @@ class People(sc.prettyobj):\n         self.version = ss.__version__  # Store version info\n         self.initialized = False\n \n-        # Handle the three fundamental arrays: UIDs for tracking agents, slots for \n+        # Handle the three fundamental arrays: UIDs for tracking agents, slots for\n         # tracking random numbers, and AUIDs for tracking alive agents\n         n = int(n_agents)\n         uids = ss.uids(np.arange(n))\n         self.auids = uids.copy() # This tracks all active UIDs (in practice, agents who are alive)\n         self.uid = ss.IndexArr('uid')  # This variable tracks all UIDs\n         self.slot = ss.IndexArr('slot') # A slot is a special state managed internally\n+        self.parent = ss.IndexArr('parent', label='UID of parent')  # UID of parent, if any, IndexArray?\n         self.uid.grow(new_vals=uids)\n         self.slot.grow(new_vals=uids)\n+        self.parent.grow(new_uids=uids, new_vals=np.full(len(uids), self.parent.nan))\n         for state in [self.uid, self.slot]:\n             state.people = self # Manually link to people since we don't want to link to states\n-        \n+\n         # Handle additional states\n         extra_states = sc.promotetolist(extra_states)\n         states = [\n-            ss.BoolArr('alive', default=True),  # Time index for death\n-            ss.BoolArr('female', default=ss.bernoulli(name='female', p=0.5)),\n+            ss.State('alive', default=True),  # Time index for death\n+            ss.State('female', default=ss.bernoulli(name='female', p=0.5)),\n             ss.FloatArr('age', default=self.get_age_dist(age_data)), # NaN until conceived\n             ss.FloatArr('ti_dead'),  # Time index for death\n             ss.FloatArr('scale', default=1.0), # The scale factor for the agents (multiplied for making results)\n@@ -71,31 +71,73 @@ class People(sc.prettyobj):\n             self.states.append(state, overwrite=False)\n             setattr(self, state.name, state)\n             state.link_people(self)\n-            \n+\n         return\n \n     @staticmethod\n     def get_age_dist(age_data):\n-        \"\"\" Return an age distribution based on provided data \"\"\"\n+        \"\"\"\n+        Return an age distribution based on provided data\n+\n+        The data should be provided in the form of either an Nx2 array, a pandas series\n+        with age as the index and counts/probability as the value, or a pandas DataFrame\n+        with \"age\" and \"value\" as columns. Each of these should look like e.g.:\n+\n+            age      value\n+            0      220.548\n+            1      206.188\n+            2      195.792\n+            3      187.442\n+\n+        The ages will be interpreted as lower bin edges. An upper bin edge will\n+        automatically be added based on the final age plus the difference of the\n+        last two bins. To explicitly control the width of the upper age bin, add\n+        an extra entry to the ``age_data`` with a value of 0 and an age value\n+        corresponding to the desired upper age bound.\n+\n+        Args:\n+            age_data: An array/series/dataframe with an index corresponding to age values, and a value corresponding to histogram counts\n+                         or relative proportions. A distribution will be estimated based on the histogram. The histogram will be\n+                         assumed to correspond to probability densitiy if the sum of the histogram values is equal to 1, otherwise\n+                         it will be assumed to correspond to counts.\n+\n+        Note: age_data can also be provided as a string\n+\n+        Returns:\n+            An ``ss.Dist`` instance that returns an age for newly created agents\n+        \"\"\"\n         if age_data is None:\n             dist = ss.uniform(low=0, high=100, name='Age distribution')\n-            return dist\n-\n-        if sc.checktype(age_data, pd.DataFrame):\n-            age_bins = age_data['age'].values\n-            age_props = age_data['value'].values\n-            age_props = age_props / age_props.sum()\n-            return ss.choice(a=age_bins, p=age_props)\n+        else:\n+            # Try loading from file\n+            if isinstance(age_data, str) or isinstance(age_data, Path):\n+                age_data = pd.read_csv(age_data)\n+\n+            # Process\n+            if isinstance(age_data, np.ndarray): # TODO: accept output of np.histogram()\n+                age_bins = age_data[:,0]\n+                age_props = age_data[:,1]\n+            elif isinstance(age_data, pd.Series):\n+                age_bins = age_data.index\n+                age_props = age_data.values\n+            elif isinstance(age_data, pd.DataFrame):\n+                age_bins = age_data['age'].values\n+                age_props = age_data['value'].values\n+\n+            # Convert to a histogram\n+            dist = ss.histogram(values=age_props, bins=age_bins, name='Age distribution')\n+\n+        return dist\n \n     def link_sim(self, sim):\n         \"\"\" Initialization \"\"\"\n         if self.initialized:\n-            errormsg = 'Cannot re-initialize a People object directly; use sim.initialize(reset=True)'\n+            errormsg = 'Cannot re-initialize a People object directly; use sim.init(reset=True)'\n             raise RuntimeError(errormsg)\n         self.sim = sim # Store the sim\n         ss.link_dists(obj=self.states, sim=sim, module=self, skip=[ss.Sim, ss.Module])\n         return\n-    \n+\n     def add_module(self, module, force=False):\n         \"\"\"\n         Add a Module to the People instance\n@@ -103,7 +145,7 @@ class People(sc.prettyobj):\n         This method is used to add a module to the People. It will register any module states with this\n         people instance for dynamic resizing, and expose the states contained in the module to the user\n         via `People.states.<module_name>.<state_name>`\n-        \n+\n         The entries created below make it possible to do `sim.people.hiv.susceptible` or\n         `sim.people.states['hiv.susceptible']` and have both of them work\n         \"\"\"\n@@ -120,7 +162,7 @@ class People(sc.prettyobj):\n                 self.states[combined_name] = state # Register the state on the user-facing side using the combined name. Within the original module, it can still be referenced by its original name\n                 module_states[state.name] = state\n         return\n-    \n+\n     def init_vals(self):\n         \"\"\" Populate states with initial values, the final step of initialization \"\"\"\n         for state in self.states():\n@@ -128,19 +170,19 @@ class People(sc.prettyobj):\n                 state.init_vals()\n         self.initialized = True\n         return\n-    \n+\n     def __bool__(self):\n         \"\"\" Ensure that zero-length people are still truthy \"\"\"\n         return True\n-    \n+\n     def __len__(self):\n         \"\"\" Length of people \"\"\"\n         return len(self.auids)\n-    \n+\n     @property\n     def n_uids(self):\n         return self.uid.len_used\n-    \n+\n     def _link_state(self, state, die=True):\n         \"\"\"\n         Link a state with the People instance for dynamic resizing; usually called by\n@@ -148,7 +190,7 @@ class People(sc.prettyobj):\n \n         All states should be registered by this function for the purpose of connecting them to the\n         People's UIDs and to have them be automatically resized when the number of agents changes.\n-        This operation is normally triggered as part of initializing the state (via `State.initialize()`)\n+        This operation is normally triggered as part of initializing the state (via `State.init()`)\n         \"\"\"\n         if id(state) not in self._states:\n             self._states[id(state)] = state\n@@ -184,10 +226,12 @@ class People(sc.prettyobj):\n         new_slots = new_slots if new_slots is not None else new_uids\n         self.slot.grow(new_uids, new_vals=new_slots)\n \n+        self.parent.grow(new_uids, new_vals=self.parent.nan) # Grow parent array\n+\n         # Grow the states\n         for state in self._states.values():\n             state.grow(new_uids)\n-            \n+\n         # Finally, update the alive indices\n         self.auids = self.auids.concat(new_uids)\n         return new_uids\n@@ -221,7 +265,7 @@ class People(sc.prettyobj):\n         \"\"\"\n         state['_states'] =  {id(v):v for v in state['_states'].values()}\n         self.__dict__ = state\n-        \n+\n         return\n \n     def scale_flows(self, inds):\n@@ -235,7 +279,7 @@ class People(sc.prettyobj):\n         \"\"\" Final updates at the very end of the timestep \"\"\"\n         sim = self.sim\n         if sim.pars.use_aging:\n-            self.age[self.alive.uids] += sim.dt\n+            self.age[self.alive.uids] += sim.t.dt_year\n         return\n \n     def request_death(self, uids):\n@@ -266,28 +310,35 @@ class People(sc.prettyobj):\n         self.ti_dead[uids] = self.sim.ti\n         return\n \n-    def resolve_deaths(self):\n+    def step_die(self):\n         \"\"\" Carry out any deaths that took place this timestep \"\"\"\n         death_uids = (self.ti_dead <= self.sim.ti).uids\n         self.alive[death_uids] = False\n+\n+        # Execute deaths that took place this timestep (i.e., changing the `alive` state of the agents). This is executed\n+        # before analyzers have run so that analyzers are able to inspect and record outcomes for agents that died this timestep\n+        for disease in self.sim.diseases():\n+            if isinstance(disease, ss.Disease):\n+                disease.step_die(death_uids)\n+\n         return death_uids\n-    \n+\n     def remove_dead(self):\n         \"\"\"\n         Remove dead agents\n         \"\"\"\n         uids = self.dead.uids\n         if len(uids):\n-            \n+\n             # Remove the UIDs from the networks too\n             for network in self.sim.networks.values():\n                 network.remove_uids(uids) # TODO: only run once every nth timestep\n-                \n+\n             # Calculate the indices to keep\n-            self.auids = self.auids.remove(uids)\n+            self.auids = self.auids[np.isin(self.auids, np.unique(uids), assume_unique=True, invert=True, kind='sort')]\n \n         return\n-    \n+\n     @property\n     def dead(self):\n         \"\"\" Dead boolean \"\"\"\n@@ -305,7 +356,13 @@ class People(sc.prettyobj):\n         res.new_deaths[ti] = np.count_nonzero(self.ti_dead == ti)\n         res.cum_deaths[ti] = np.sum(res.new_deaths[:ti]) # TODO: inefficient to compute the cumulative sum on every timestep!\n         return\n-    \n+\n+    def finish_step(self):\n+        # self.update_results() # This is called separately\n+        self.remove_dead()\n+        self.update_post()\n+        return\n+\n     def person(self, ind):\n         \"\"\" Get all the properties for a single person \"\"\"\n         person = Person()\n@@ -314,12 +371,12 @@ class People(sc.prettyobj):\n         for key in self.states.keys():\n             person[key] = self.states[key][ind]\n         return person\n-            \n+\n \n class Person(sc.objdict):\n     \"\"\" A simple class to hold all attributes of a person \"\"\"\n     def to_df(self):\n         \"\"\" Convert to a dataframe \"\"\"\n-        df = sc.dataframe.from_dict(self, orient='index', columns='value')\n+        df = sc.dataframe.from_dict(self, orient='index', columns=['value'])\n         df.index.name = 'key'\n         return df\ndiff --git a/starsim/products.py b/starsim/products.py\nindex bcaea4f..145a543 100644\n--- a/starsim/products.py\n+++ b/starsim/products.py\n@@ -1,11 +1,10 @@\n \"\"\"\n Define products\n \"\"\"\n-\n import starsim as ss\n import sciris as sc\n import numpy as np\n-\n+import pandas as pd\n \n __all__ = ['Product', 'Dx', 'Tx', 'Vx']\n \n@@ -25,7 +24,7 @@ class Product(ss.Module):\n \n class Dx(Product):\n     \"\"\"\n-    Generic class for diagnostics \n+    Generic class for diagnostics\n     \"\"\"\n \n     def __init__(self, df, hierarchy=None, *args, **kwargs):\n@@ -48,10 +47,10 @@ class Dx(Product):\n     def default_value(self):\n         return len(self.hierarchy) - 1\n \n-    def administer(self, sim, uids, return_format='dict'):\n+    def administer(self, uids, return_format='dict'):\n         \"\"\"\n         Administer a testing product.\n-        \n+\n         Returns:\n \n              if return_format=='array': an array of length len(inds) with integer entries that map each person to one of the result_states\n@@ -59,11 +58,11 @@ class Dx(Product):\n         \"\"\"\n \n         # Pre-fill with the default value, which is set to be the last value in the hierarchy\n-        results = sc.dataframe({'uids': uids, 'result': self.default_value})\n+        results = pd.Series(self.default_value,index=uids)\n \n         for disease in self.diseases:\n             for state in self.health_states:\n-                this_state = getattr(sim.diseases[disease], state)\n+                this_state = getattr(self.sim.diseases[disease], state)\n                 true_uids = this_state.uids # Find people for which this state is true\n                 these_uids = true_uids.intersect(uids) # Find intersection of people in this state and the supplied UIDs\n \n@@ -71,20 +70,18 @@ class Dx(Product):\n                 df_filter = (self.df.state == state) & (self.df.disease == disease)\n                 thisdf = self.df[df_filter]  # apply filter to get the results for this state & genotype\n                 probs = [thisdf[thisdf.result == result].probability.values[0] for result in self.hierarchy]\n-                self.result_dist.pk = probs  # Overwrite distribution probabilities\n+                self.result_dist.pars['p'] = probs  # Overwrite distribution probabilities\n \n                 # Sort people into one of the possible result states and then update their overall results\n                 this_result = self.result_dist.rvs(these_uids)\n-                row_inds = sc.findinds(results.uids.isin(these_uids))\n-                results.loc[row_inds, 'result'] = np.minimum(this_result, results.loc[row_inds, 'result'])\n-\n-            if return_format == 'dict':\n-                output = {self.hierarchy[i]: results[results.result == i].uids.values for i in range(len(self.hierarchy))}\n-            elif return_format == 'array':\n-                output = results\n-\n-        return output\n+                results.loc[these_uids] = np.minimum(this_result, results.loc[these_uids])\n \n+        if return_format == 'dict':\n+            return {k: ss.uids(results.index[results == i]) for i, k in enumerate(self.hierarchy)}\n+        elif return_format == 'array':\n+            return results\n+        else:\n+            raise Exception('Unknown return format')\n \n class Tx(Product):\n     \"\"\"\n@@ -98,7 +95,7 @@ class Tx(Product):\n         self.efficacy_dist = ss.bernoulli(p=0)\n         return\n \n-    def administer(self, sim, uids, return_format='dict'):\n+    def administer(self, uids, return_format='dict'):\n         \"\"\"\n         Loop over treatment states to determine those who are successfully treated and clear infection\n         \"\"\"\n@@ -106,26 +103,20 @@ class Tx(Product):\n         tx_successful = []  # Initialize list of successfully treated individuals\n \n         for disease_name in self.diseases:\n-\n-            disease = sim.diseases[disease_name]\n+            disease = self.sim.diseases[disease_name]\n \n             for state in self.health_states:\n-\n                 pre_tx_state = getattr(disease, state)\n                 true_uids = pre_tx_state.uids # People in this state\n                 these_uids = true_uids.intersect(uids)\n \n                 if len(these_uids):\n-\n                     df_filter = (self.df.state == state) & (self.df.disease == disease_name)  # Filter by state\n                     thisdf = self.df[df_filter]  # apply filter to get the results for this state & genotype\n \n                     # Determine whether treatment is successful\n                     self.efficacy_dist.set(p=thisdf.efficacy.values[0])\n-\n-                    # HACK to reset the efficacy_dist as it is called multiple times per timestep. TODO: Refactor\n-                    self.efficacy_dist.jump(sim.ti+1)\n-                    eff_treat_inds = self.efficacy_dist.filter(these_uids)\n+                    eff_treat_inds = self.efficacy_dist.filter(these_uids) # TODO: think if there's a way of not calling this inside a loop like this\n \n                     post_tx_state_name = thisdf.post_state.values[0]\n                     post_tx_state = getattr(disease, post_tx_state_name)\ndiff --git a/starsim/regression/pars_v2.0.0.json b/starsim/regression/pars_v2.0.0.json\nnew file mode 100644\nindex 0000000..15d5dd1\n--- /dev/null\n+++ b/starsim/regression/pars_v2.0.0.json\n@@ -0,0 +1,200 @@\n+{\n+  \"pars\": {\n+    \"verbose\": 0,\n+    \"n_agents\": 10000,\n+    \"total_pop\": 10000,\n+    \"pop_scale\": 1.0,\n+    \"unit\": \"year\",\n+    \"start\": 2000,\n+    \"stop\": 2020,\n+    \"dur\": 20,\n+    \"dt\": 0.2,\n+    \"rand_seed\": 2,\n+    \"slot_scale\": 5,\n+    \"min_slots\": 100,\n+    \"birth_rate\": null,\n+    \"death_rate\": null,\n+    \"use_aging\": true,\n+    \"births\": {\n+      \"birth_rate\": 30,\n+      \"rel_birth\": 1,\n+      \"units\": 0.001\n+    },\n+    \"deaths\": {\n+      \"rel_death\": 1,\n+      \"death_rate\": {\n+        \"type\": \"Dist\",\n+        \"classname\": \"bernoulli\",\n+        \"tracestr\": \"pars_deaths_death_rate\",\n+        \"diststr\": \"\",\n+        \"pars\": {\n+          \"p\": {\n+            \"python_class\": \"<class 'function'>\"\n+          }\n+        }\n+      },\n+      \"units\": 0.001\n+    },\n+    \"randomnet\": {\n+      \"n_contacts\": {\n+        \"type\": \"Dist\",\n+        \"classname\": \"constant\",\n+        \"tracestr\": \"pars_randomnet_n_contacts\",\n+        \"diststr\": \"\",\n+        \"pars\": {\n+          \"v\": 10\n+        }\n+      },\n+      \"dur\": 0\n+    },\n+    \"mfnet\": {\n+      \"duration\": {\n+        \"type\": \"Dist\",\n+        \"classname\": \"lognorm_ex\",\n+        \"tracestr\": \"pars_mfnet_duration\",\n+        \"diststr\": \"\",\n+        \"pars\": {\n+          \"mean\": 15,\n+          \"std\": 1.0\n+        }\n+      },\n+      \"participation\": {\n+        \"type\": \"Dist\",\n+        \"classname\": \"bernoulli\",\n+        \"tracestr\": \"pars_mfnet_participation\",\n+        \"diststr\": \"\",\n+        \"pars\": {\n+          \"p\": 0.9\n+        }\n+      },\n+      \"debut\": {\n+        \"type\": \"Dist\",\n+        \"classname\": \"normal\",\n+        \"tracestr\": \"pars_mfnet_debut\",\n+        \"diststr\": \"\",\n+        \"pars\": {\n+          \"loc\": 16,\n+          \"scale\": 1.0\n+        }\n+      },\n+      \"acts\": {\n+        \"type\": \"Dist\",\n+        \"classname\": \"poisson\",\n+        \"tracestr\": \"pars_mfnet_acts\",\n+        \"diststr\": \"\",\n+        \"pars\": {\n+          \"lam\": 80\n+        }\n+      },\n+      \"rel_part_rates\": 1.0\n+    },\n+    \"maternalnet\": {},\n+    \"sir\": {\n+      \"log\": false,\n+      \"beta\": {\n+        \"classname\": \"beta\",\n+        \"v\": 0.1,\n+        \"unit\": \"year\",\n+        \"parent_unit\": \"year\",\n+        \"parent_dt\": 0.2,\n+        \"parent_name\": \"Deaths\",\n+        \"self_dt\": 1.0,\n+        \"factor\": 5.0,\n+        \"values\": 0.0208516376390232\n+      },\n+      \"init_prev\": {\n+        \"type\": \"Dist\",\n+        \"classname\": \"bernoulli\",\n+        \"tracestr\": \"pars_sir_init_prev\",\n+        \"diststr\": \"\",\n+        \"pars\": {\n+          \"p\": 0.01\n+        }\n+      },\n+      \"dur_inf\": {\n+        \"type\": \"Dist\",\n+        \"classname\": \"lognorm_ex\",\n+        \"tracestr\": \"pars_sir_dur_inf\",\n+        \"diststr\": \"\",\n+        \"pars\": {\n+          \"mean\": {\n+            \"classname\": \"dur\",\n+            \"v\": 6,\n+            \"unit\": \"year\",\n+            \"parent_unit\": \"year\",\n+            \"parent_dt\": 0.2,\n+            \"parent_name\": \"Deaths\",\n+            \"self_dt\": 1.0,\n+            \"factor\": 5.0,\n+            \"values\": 30.0\n+          },\n+          \"std\": 1.0\n+        }\n+      },\n+      \"p_death\": {\n+        \"type\": \"Dist\",\n+        \"classname\": \"bernoulli\",\n+        \"tracestr\": \"pars_sir_p_death\",\n+        \"diststr\": \"\",\n+        \"pars\": {\n+          \"p\": 0.01\n+        }\n+      }\n+    },\n+    \"sis\": {\n+      \"log\": false,\n+      \"beta\": {\n+        \"classname\": \"beta\",\n+        \"v\": 0.05,\n+        \"unit\": \"year\",\n+        \"parent_unit\": \"year\",\n+        \"parent_dt\": 0.2,\n+        \"parent_name\": \"Deaths\",\n+        \"self_dt\": 1.0,\n+        \"factor\": 5.0,\n+        \"values\": 0.010206218313011495\n+      },\n+      \"init_prev\": {\n+        \"type\": \"Dist\",\n+        \"classname\": \"bernoulli\",\n+        \"tracestr\": \"pars_sis_init_prev\",\n+        \"diststr\": \"\",\n+        \"pars\": {\n+          \"p\": 0.01\n+        }\n+      },\n+      \"dur_inf\": {\n+        \"type\": \"Dist\",\n+        \"classname\": \"lognorm_ex\",\n+        \"tracestr\": \"pars_sis_dur_inf\",\n+        \"diststr\": \"\",\n+        \"pars\": {\n+          \"mean\": {\n+            \"classname\": \"dur\",\n+            \"v\": 10,\n+            \"unit\": \"year\",\n+            \"parent_unit\": \"year\",\n+            \"parent_dt\": 0.2,\n+            \"parent_name\": \"Deaths\",\n+            \"self_dt\": 1.0,\n+            \"factor\": 5.0,\n+            \"values\": 50.0\n+          },\n+          \"std\": 1.0\n+        }\n+      },\n+      \"waning\": {\n+        \"classname\": \"rate\",\n+        \"v\": 0.05,\n+        \"unit\": \"year\",\n+        \"parent_unit\": \"year\",\n+        \"parent_dt\": 0.2,\n+        \"parent_name\": \"Deaths\",\n+        \"self_dt\": 1.0,\n+        \"factor\": 5.0,\n+        \"values\": 0.01\n+      },\n+      \"imm_boost\": 1.0\n+    }\n+  }\n+}\n\\ No newline at end of file\ndiff --git a/starsim/results.py b/starsim/results.py\nindex 001cfd7..23c4e2b 100644\n--- a/starsim/results.py\n+++ b/starsim/results.py\n@@ -1,76 +1,293 @@\n \"\"\"\n Result structures.\n \"\"\"\n-\n import numpy as np\n import sciris as sc\n import starsim as ss\n-\n+import matplotlib.pyplot as plt\n \n __all__ = ['Result', 'Results']\n \n \n-class Result(np.ndarray):\n-    \n-    def __new__(cls, module=None, name=None, shape=None, dtype=None, scale=None):\n-        arr = np.zeros(shape=shape, dtype=dtype).view(cls)\n-        arr.name = name\n-        arr.module = module\n-        arr.scale = scale\n-        return arr\n-    \n+class Result(ss.BaseArr):\n+    \"\"\"\n+    Array-like container for holding sim results.\n+\n+    Args:\n+        module (str): the name of the parent module, e.g. 'hiv'\n+        name (str): the name of this result, e.g. 'new_infections'\n+        shape (int/tuple): the shape of the result array (usually module.npts)\n+        scale (bool): whether or not the result scales by population size (e.g. a count does, a prevalence does not)\n+        auto_plot (bool): whether to include automatically in sim.plot() results\n+        label (str): a human-readable label for the result\n+        values (array): prepopulate the Result with these values\n+        timevec (array): an array of time points\n+        low (array): values for the lower bound\n+        high (array): values for the upper bound\n+\n+    In most cases, ``ss.Result`` behaves exactly like ``np.array()``, except with\n+    the additional fields listed above. To see everything contained in a result,\n+    you can use result.disp().\n+    \"\"\"\n+    def __init__(self, name=None, label=None, dtype=float, shape=None, scale=True, auto_plot=True,\n+                 module=None, values=None, timevec=None, low=None, high=None):\n+        # Copy inputs\n+        self.name = name\n+        self.label = label\n+        self.module = module\n+        self.scale = scale\n+        self.auto_plot = auto_plot\n+        self.timevec = timevec\n+        self.low = low\n+        self.high = high\n+        self.dtype = dtype\n+        self.shape = shape\n+        self.values = values\n+        self.init_values()\n+        return\n+\n     def __repr__(self):\n-        modulestr = f'{self.module}.' if (self.module is not None) else ''\n         cls_name = self.__class__.__name__\n         arrstr = super().__repr__().removeprefix(cls_name)\n-        out = f'{cls_name}({modulestr}{self.name}):\\narray{arrstr}'\n+        out = f'{cls_name}({self.key}):\\narray{arrstr}'\n         return out\n \n-    def __array_finalize__(self, obj):\n-        if obj is None:\n-            return\n-        self.name   = getattr(obj, 'name',   None)\n-        self.module = getattr(obj, 'module', None)\n-        self.scale  = getattr(obj, 'scale',  None)\n+    def __str__(self):\n+        cls_name = self.__class__.__name__\n+        try:\n+            minval = self.values.min()\n+            meanval = self.values.mean()\n+            maxval = self.values.max()\n+            valstr = f'min={minval:n}, mean={meanval:n}, max={maxval:n}'\n+        except:\n+            valstr = f'{self.values}'\n+        out = f'{cls_name}({self.key}: {valstr})'\n+        return out\n+\n+    def __getitem__(self, key):\n+        \"\"\" Allow e.g. result['low'] \"\"\"\n+        if isinstance(key, str):\n+            return getattr(self, key)\n+        else:\n+            return super().__getitem__(key)\n+\n+    @property\n+    def initialized(self):\n+        return self.values is not None\n+\n+    @property\n+    def has_dates(self):\n+        \"\"\" Check whether the time vector uses dates (rather than numbers) \"\"\"\n+        try:    return not sc.isnumber(self.timevec[0])\n+        except: return False\n+\n+    def init_values(self, values=None, dtype=None, shape=None, force=False):\n+        \"\"\" Handle values \"\"\"\n+        if not self.initialized or force:\n+            values = sc.ifelse(values, self.values)\n+            dtype = sc.ifelse(dtype, self.dtype)\n+            shape = sc.ifelse(shape, self.shape)\n+            if values is not None: # Create if values already supplied\n+                self.values = np.array(values, dtype=dtype)\n+                dtype = self.values.dtype\n+                shape = self.values.shape\n+            elif shape is not None: # Or if a shape is provided, initialize\n+                self.values = np.zeros(shape=shape, dtype=dtype)\n+            else:\n+                self.values = None\n+            self.dtype = dtype\n+            self.shape = shape\n+        return self.values\n+\n+    def update(self, *args, **kwargs):\n+        \"\"\" Update parameters, and initialize values if needed \"\"\"\n+        super().update(*args, **kwargs)\n+        self.init_values()\n         return\n \n-    def __array_wrap__(self, obj, **kwargs):\n-        if obj.shape == ():\n-            return obj[()]\n+    @property\n+    def key(self):\n+        \"\"\" Return the unique key of the result: <module>.<name>, e.g. \"hiv.new_infections\" \"\"\"\n+        modulestr = f'{self.module}.' if (self.module is not None) else ''\n+        namestr = self.name if (self.name is not None) else 'unnamed'\n+        key = modulestr + namestr\n+        return key\n+\n+    @property\n+    def full_label(self):\n+        \"\"\" Return the full label of the result: <Module>: <label>, e.g. \"HIV: New infections\" \"\"\"\n+        reslabel = sc.ifelse(self.label, self.name)\n+        if self.module == 'sim': # Don't add anything if it's the sim\n+            full = f'Sim: {reslabel}'\n         else:\n-            return super().__array_wrap__(obj, **kwargs)\n-    \n-    def to_df(self):\n-        return sc.dataframe({self.name:self})\n-    \n+            try:\n+                mod = ss.find_modules(flat=True)[self.module]\n+                modlabel = mod.__name__\n+                assert self.module == modlabel.lower(), f'Mismatch: {self.module}, {modlabel}' # Only use the class name if the module name is the default\n+            except: # Don't worry if we can't find it, just use the module name\n+                modlabel = self.module.title()\n+            full = f'{modlabel}: {reslabel}'\n+        return full\n+\n+    def to_df(self, sep='_', rename=False):\n+        \"\"\"\n+        Convert to a dataframe with timevec, value, low, and high columns\n+\n+        Args:\n+            rename (bool): if True, rename the columns with the name of the result (else value, low, high)\n+        \"\"\"\n+        data = dict()\n+        if self.timevec is not None:\n+            data['timevec'] = self.timevec\n+        valcol = self.name if rename else 'value'\n+        data[valcol] = self.values\n+        for key in ['low', 'high']:\n+            val = self[key]\n+            valcol = f'{self.name}{sep}{key}' if rename else key\n+            if val is not None:\n+                data[valcol] = val\n+        df = sc.dataframe(data)\n+        return df\n+\n+    def plot(self, fig=None, ax=None, fig_kw=None, plot_kw=None, fill_kw=None, **kwargs):\n+        \"\"\" Plot a single result; kwargs are interpreted as plot_kw \"\"\"\n+        # Prepare inputs\n+        fig_kw = sc.mergedicts(fig_kw)\n+        plot_kw = sc.mergedicts(dict(lw=3, alpha=0.8), plot_kw, kwargs)\n+        fill_kw = sc.mergedicts(dict(alpha=0.1), fill_kw)\n+        if fig is None and ax is None:\n+            fig = plt.figure(**fig_kw)\n+        if ax is None:\n+            ax = plt.subplot(111)\n+        if self.timevec is None:\n+            errormsg = f'Cannot figure out how to plot {self}: no time data associated with it'\n+            raise ValueError(errormsg)\n+\n+        # Plot bounds\n+        if self.low is not None and self.high is not None:\n+            ax.fill_between(self.timevec, self.low, self.high, **fill_kw)\n+\n+        # Plot results\n+        plt.plot(self.timevec, self.values, **plot_kw)\n+        plt.title(self.full_label)\n+        plt.xlabel('Time')\n+        sc.commaticks(ax)\n+        if self.has_dates:\n+            sc.dateformatter(ax)\n+        if (self.values.min() >= 0) and (plt.ylim()[0]<0): # Don't allow axis to go negative if results don't\n+            plt.ylim(bottom=0)\n+        return ss.return_fig(fig)\n+\n \n class Results(ss.ndict):\n-    \n-    def __init__(self, module, strict=True, *args, **kwargs):\n-        super().__init__(type=Result, strict=strict)\n+    \"\"\" Container for storing results \"\"\"\n+    def __init__(self, module, *args, strict=True, **kwargs):\n         if hasattr(module, 'name'):\n             module = module.name\n         self.setattribute('_module', module)\n+        super().__init__(type=Result, strict=strict, *args, **kwargs)\n+        return\n+\n+    def __repr__(self, indent=2, **kwargs): # kwargs are not used, but are needed for disp() to work\n+        string = f'Results({self._module})\\n'\n+        for i,k,v in self.enumitems():\n+            if k != 'timevec':\n+                entry = f'{v}'\n+                if '\\n' in entry: # Check if the string is multi-line\n+                    lines = entry.splitlines()\n+                    entry = f'{i}. {lines[0]}\\n'\n+                    entry += '\\n'.join(' '*indent + f'{i}.' + line for line in lines[1:])\n+                    string += entry + '\\n'\n+                else:\n+                    string += f'{i}. {v}\\n'\n+        string = string.rstrip()\n+        return string\n+\n+    def disp(self, *args, **kwargs):\n+        print(super().__repr__(*args, **kwargs))\n         return\n-    \n+\n     def append(self, arg, key=None):\n+        \"\"\" This is activated by adding as well, e.g. results += result \"\"\"\n         if isinstance(arg, (list, tuple)):\n             result = ss.Result(self._module, *arg)\n         elif isinstance(arg, dict):\n             result = ss.Result(self._module, **arg)\n         else:\n             result = arg\n+\n+        if not isinstance(result, Result):\n+            warnmsg = f'You are adding a result of type {type(result)} to Results, which is inadvisable.'\n+            ss.warn(warnmsg)\n+\n         if result.module != self._module:\n+            if result.module:\n+                warnmsg = f'You are adding a result from module {result.module} to module {self._module}; check that this is intentional.'\n+                ss.warn(warnmsg)\n             result.module = self._module\n-        \n+\n         super().append(result, key=key)\n         return\n-    \n-    def to_df(self):\n-        pass\n-    \n-    def __repr__(self, *args, **kwargs): # TODO: replace with dataframe summary\n-        return super().__repr__(*args, **kwargs)\n-        \n-    def plot(self):\n-        pass\n+\n+    @property\n+    def all_results(self):\n+        \"\"\" Iterator over all results, skipping any nested values \"\"\"\n+        return iter(res for res in self.values() if isinstance(res, Result))\n+\n+    @property\n+    def equal_len(self):\n+        \"\"\" Check if all results are equal length \"\"\"\n+        lengths = [len(res) for res in self.flatten().values()]\n+        return len(set(lengths)) == 1\n+\n+    def flatten(self, sep='_', only_results=True):\n+        \"\"\" Turn from a nested dictionary into a flat dictionary, keeping only results by default \"\"\"\n+        out = sc.flattendict(self, sep=sep)\n+        if only_results:\n+            out = sc.objdict({k:v for k,v in out.items() if isinstance(v, Result)})\n+        return out\n+\n+    def to_df(self, sep='_', descend=False):\n+        \"\"\" Merge all results dataframes into one \"\"\"\n+        if not descend:\n+            dfs = [res.to_df(sep=sep, rename=True) for res in self.all_results]\n+            if len(dfs):\n+                df = dfs[0]\n+                for df2 in dfs[1:]:\n+                    df = df.merge(df2)\n+            else:\n+                df = None\n+        else:\n+            if self.equal_len:\n+                flat = self.flatten(sep=sep, only_results=True)\n+                flat = dict(timevec=self.timevec) | flat # Prepend the timevec\n+                df = sc.dataframe.from_dict(flat)\n+            else:\n+                df = sc.objdict() # For non-equal lengths, actually return an objdict rather than a dataframe\n+                df.sim = self.to_df(sep=sep, descend=False)\n+                for k,v in self.items():\n+                    if isinstance(v, Results):\n+                        thisdf = v.to_df(sep=sep, descend=False) # Only allow one level of nesting\n+                        if thisdf is not None:\n+                            df[k] = thisdf\n+        return df\n+\n+    def plot(self, style='fancy', fig_kw=None, plot_kw=None):\n+        \"\"\" Plot all the results \"\"\"\n+        # Prepare the inputs\n+        fig_kw = sc.mergedicts(fig_kw)\n+        plot_kw = sc.mergedicts(plot_kw)\n+        results = list(self.all_results)\n+        nrows,ncols = sc.getrowscols(len(results))\n+\n+        # Do the plotting\n+        with sc.options.with_style(style):\n+            fig = plt.figure(**fig_kw)\n+            for i,res in enumerate(results):\n+                ax = plt.subplot(nrows, ncols, i+1)\n+                res.plot(ax=ax, **plot_kw)\n+            sc.figlayout()\n+        return ss.return_fig(fig)\n+\n+\n+\ndiff --git a/starsim/run.py b/starsim/run.py\nindex 9d9b6c2..718f705 100644\n--- a/starsim/run.py\n+++ b/starsim/run.py\n@@ -1,23 +1,32 @@\n \"\"\"\n Utilities for running in parallel\n \"\"\"\n-\n import numpy as np\n import sciris as sc\n+import matplotlib.pyplot as plt\n import starsim as ss\n \n __all__ = ['MultiSim', 'single_run', 'multi_run', 'parallel']\n \n \n-class MultiSim(sc.prettyobj):\n+class MultiSim:\n     \"\"\"\n     Class for running multiple copies of a simulation.\n-    \"\"\"\n-\n-    def __init__(self, sims=None, base_sim=None, label=None, initialize=False, *args, **kwargs):\n \n+    Args:\n+        sims (Sim/list): a single sim or a list of sims\n+        base_sim (Sim): the sim used for shared properties; if not supplied, the first of the sims provided\n+        label (str): the name of the multisim\n+        n_runs (int): if a single sim is provided, the number of replicates (default 4)\n+        initialize (bool): whether or not to initialize the sims (otherwise, initialize them during run)\n+        inplace (bool): whether to modify the sims in-place (default True); else return new sims\n+        debug (bool): if True, run in serial\n+        kwargs (dict): stored in run_args and passed to run()\n+    \"\"\"\n+    def __init__(self, sims=None, base_sim=None, label=None, n_runs=4, initialize=False,\n+                 inplace=True, debug=False, **kwargs):\n         # Handle inputs\n-        super().__init__(*args, **kwargs)\n+        super().__init__(**kwargs)\n         if base_sim is None:\n             if isinstance(sims, ss.Sim):\n                 base_sim = sims\n@@ -33,9 +42,11 @@ class MultiSim(sc.prettyobj):\n         self.sims = sims\n         self.base_sim = base_sim\n         self.label = base_sim.label if (label is None and base_sim is not None) else label\n-        self.run_args = sc.mergedicts(kwargs)\n+        self.run_args = sc.mergedicts(dict(n_runs=n_runs, inplace=inplace, debug=debug), kwargs)\n         self.results = None\n+        self.summary = None\n         self.which = None  # Whether the multisim is to be reduced, combined, etc.\n+        self.timer = sc.timer() # Create a timer\n \n         # Optionally initialize\n         if initialize:\n@@ -44,7 +55,60 @@ class MultiSim(sc.prettyobj):\n         return\n \n     def __len__(self):\n-        return len(self.sims)\n+        \"\"\" The length of a MultiSim is how many sims it contains \"\"\"\n+        try:\n+            return len(self.sims)\n+        except:\n+            return 0\n+\n+    def __repr__(self):\n+        \"\"\" Return a brief description of a multisim; see multisim.disp() for the more detailed version. \"\"\"\n+        try:\n+            labelstr = f'\"{self.label}\"; ' if self.label else ''\n+            string   = f'MultiSim({labelstr}n_sims: {len(self)}; base: {self.base_sim})'\n+        except Exception as E:\n+            string = sc.objectid(self)\n+            string += f'Warning, multisim appears to be malformed:\\n{str(E)}'\n+        return string\n+\n+    def brief(self):\n+        \"\"\" A single-line display of the MultiSim; same as print(multisim) \"\"\"\n+        print(self)\n+        return\n+\n+    def show(self, output=False):\n+        \"\"\"\n+        Print a moderate length summary of the MultiSim. See also multisim.disp()\n+        (detailed output) and multisim.brief() (short output).\n+\n+        Args:\n+            output (bool): if true, return a string instead of printing output\n+\n+        **Example**::\n+\n+            msim = ss.MultiSim(ss.demo(run=False), label='Example multisim')\n+            msim.run()\n+            msim.show() # Prints moderate length output\n+        \"\"\"\n+        labelstr = f' \"{self.label}\"' if self.label else ''\n+        simlenstr = f'{len(self)}'\n+        string  = f'MultiSim{labelstr} summary:\\n'\n+        string += f'  Number of sims: {simlenstr}\\n'\n+        string += f'  Reduced/combined: {self.which}\\n'\n+        string += f'  Base: {self.base_sim}\\n'\n+        if self.sims:\n+            string += '  Sims:\\n'\n+            for s,sim in enumerate(self.sims):\n+                string += f'    {s}: {sim}\\n'\n+        if not output:\n+            print(string)\n+            return\n+        else:\n+            return string\n+\n+    def disp(self):\n+        \"\"\" Display the full object \"\"\"\n+        return sc.pr(self)\n \n     def init_sims(self, **kwargs):\n         \"\"\"\n@@ -59,17 +123,20 @@ class MultiSim(sc.prettyobj):\n \n         # Initialize the sims but don't run them\n         kwargs = sc.mergedicts(self.run_args, kwargs, {'do_run': False})  # Never run, that's the point!\n+        kwargs.pop('inplace', None)\n+        kwargs.pop('debug', None)\n         self.sims = multi_run(sims, **kwargs)\n \n         return\n \n-    def run(self, reduce=False, **kwargs):\n+    def run(self, **kwargs):\n         \"\"\"\n-        Run the sims\n+        Run the sims; see ``ss.multi_run()`` for additional arguments\n \n         Args:\n-            reduce  (bool): whether to reduce after running (see reduce())\n-            kwargs  (dict): passed to multi_run(); use run_args to pass arguments to sim.run()\n+            n_runs (int): how many replicates of each sim to run (if a list of sims is not provided)\n+            inplace (bool): whether to modify the sims in place (otherwise return copies)\n+            kwargs (dict): passed to multi_run(); use run_args to pass arguments to sim.run()\n \n         Returns:\n             None (modifies MultiSim object in place)\n@@ -87,12 +154,21 @@ class MultiSim(sc.prettyobj):\n                     sim.label = f'Sim {s}'\n \n         # Run\n+        self.timer.start()\n         kwargs = sc.mergedicts(self.run_args, kwargs)\n-        self.sims = multi_run(sims, **kwargs)\n-\n-        # Reduce\n-        if reduce:\n-            self.reduce()\n+        inplace = kwargs.pop('inplace', True)\n+        debug = kwargs.pop('debug', False)\n+        if debug:\n+            run_sims = [single_run(sim, **kwargs) for sim in sims]\n+        else: # The next line does all the work!\n+            run_sims = multi_run(sims, **kwargs) # Output sims are copies due to the pickling during parallelization\n+\n+        # Handle output\n+        if inplace and isinstance(self.sims, list) and len(run_sims) == len(self.sims): # Validation\n+            for old,new in zip(self.sims, run_sims):\n+                old.__dict__.update(new.__dict__) # Update the same object with the new results\n+        self.sims = run_sims # Just overwrite references\n+        self.timer.stop()\n \n         return self\n \n@@ -149,7 +225,6 @@ class MultiSim(sc.prettyobj):\n             msim.reduce()\n             msim.summarize()\n         \"\"\"\n-\n         if use_mean:\n             if bounds is None:\n                 bounds = 2\n@@ -162,7 +237,7 @@ class MultiSim(sc.prettyobj):\n                 except Exception as E:\n                     errormsg = (f'Could not figure out how to convert {quantiles} into a quantiles object:'\n                                 f' must be a dict with keys low, high or a 2-element array ({str(E)})')\n-                    raise ValueError(errormsg)\n+                    raise ValueError(errormsg) from E\n \n         # Store information on the sims\n         n_runs = len(self)\n@@ -170,35 +245,35 @@ class MultiSim(sc.prettyobj):\n         reduced_sim.metadata = dict(parallelized=True, combined=False, n_runs=n_runs, quantiles=quantiles,\n                                     use_mean=use_mean, bounds=bounds)  # Store how this was parallelized\n \n-        # Perform the statistics\n+        # Calculate the statistics\n         raw = {}\n \n-        rkeys = reduced_sim.results.keys()\n-\n+        rflat = reduced_sim.results.flatten()\n+        rkeys = list(rflat.keys())\n         for rkey in rkeys:\n-            raw[rkey] = np.zeros((reduced_sim.res_npts, len(self.sims)))\n+            raw[rkey] = np.zeros((len(reduced_sim), len(self.sims)))\n             for s, sim in enumerate(self.sims):\n-                vals = sim.results[rkey].values\n-                raw[rkey][:, s] = vals\n+                flat = sim.results.flatten()\n+                raw[rkey][:, s] = flat[rkey]\n \n         for rkey in rkeys:\n-            results = reduced_sim.results\n+            res = rflat[rkey]\n             if use_mean:\n                 r_mean = np.mean(raw[rkey], axis=1)\n                 r_std = np.std(raw[rkey], axis=1)\n-                results[rkey].values[:] = r_mean\n-                results[rkey].low = r_mean - bounds * r_std\n-                results[rkey].high = r_mean + bounds * r_std\n+                res[:] = r_mean\n+                res.low = r_mean - bounds * r_std\n+                res.high = r_mean + bounds * r_std\n             else:\n-                results[rkey].values[:] = np.quantile(raw[rkey], q=0.5, axis=1)\n-                results[rkey].low = np.quantile(raw[rkey], q=quantiles['low'], axis=1)\n-                results[rkey].high = np.quantile(raw[rkey], q=quantiles['high'], axis=1)\n+                res[:] = np.quantile(raw[rkey], q=0.5, axis=1)\n+                res.low = np.quantile(raw[rkey], q=quantiles['low'], axis=1)\n+                res.high = np.quantile(raw[rkey], q=quantiles['high'], axis=1)\n \n         # Compute and store final results\n-        reduced_sim.compute_summary()\n+        reduced_sim.summarize()\n         self.orig_base_sim = self.base_sim\n         self.base_sim = reduced_sim\n-        self.results = reduced_sim.results\n+        self.results = ss.Results('MultiSim').merge(rflat) # Create the dictionary and merge it\n         self.summary = reduced_sim.summary\n         self.which = 'reduced'\n \n@@ -227,8 +302,93 @@ class MultiSim(sc.prettyobj):\n         \"\"\"\n         return self.reduce(use_mean=False, quantiles=quantiles, **kwargs)\n \n+    def summarize(self, method='mean', quantiles=None, how='default'):\n+        \"\"\"\n+        Summarize the simulations statistically.\n \n-def single_run(sim, ind=0, reseed=True, keep_people=False, run_args=None, sim_args=None,\n+        Args:\n+            method (str): one of 'mean' (default: [mean, 2*std]), 'median' ([median, min, max]), or 'all' (all results)\n+            quantiles (dict): if method='median', use these quantiles\n+            how (str): passed to sim.summarize()\n+        \"\"\"\n+\n+        # Compute the summaries\n+        summaries = []\n+        for sim in self.sims:\n+            summaries.append(sim.summarize(how=how))\n+\n+        summary = sc.dcp(summaries[0]) # Use the first one as a template\n+        for k in summary.keys():\n+            arr = np.array([s[k] for s in summaries])\n+            if method == 'all':\n+                summary[k] = arr\n+            elif method == 'mean':\n+                summary[k] = sc.objdict({'mean':arr.mean(), 'std':arr.std(), 'sem':sc.sem(arr)})\n+            elif method == 'median':\n+                if quantiles is None:\n+                    quantiles = sc.objdict({'median':0.5, 'min':0, 'max':1, 'q25':0.25, 'q75':0.75})\n+                elif isinstance(quantiles, list):\n+                    quantiles = {q:q for q in quantiles}\n+                summary[k] = {q:v for q,v in zip(quantiles, np.quantile(arr, quantiles))}\n+\n+        self.summary = summary # Could reconcile with reduce()'s summary\n+\n+        return summary\n+\n+    def plot(self, key=None, fig=None, fig_kw=None, plot_kw=None, fill_kw=None):\n+        \"\"\"\n+        Plot all results in the MultiSim object.\n+\n+        If the MultiSim object has been reduced (i.e. mean or median), then plot\n+        the best value and uncertainty bound. Otherwise, plot individual sims.\n+\n+        Args:\n+            key (str): the results key to plot (by default, all)\n+            fig (Figure): if provided, plot results into an existing figure\n+            fig_kw (dict): passed to ``plt.subplots()``\n+            plot_kw (dict): passed to ``plt.plot()``\n+            fill_kw (dict): passed to ``plt.fill_between()``\n+        \"\"\"\n+        # Has not been reduced yet, plot individual sim\n+        if self.which is None:\n+            fig = None\n+            alpha = 0.7 if len(self) < 5 else 0.5\n+            plot_kw = sc.mergedicts({'alpha':alpha}, plot_kw)\n+            with ss.options.context(jupyter=False): # Always return the figure\n+                for sim in self.sims:\n+                    fig = sim.plot(key=key, fig=fig, fig_kw=fig_kw, plot_kw=plot_kw)\n+            plt.legend()\n+\n+        # Has been reduced, plot with uncertainty bounds\n+        else:\n+            flat = self.results\n+            n_cols = np.ceil(np.sqrt(len(flat))) # TODO: remove duplication with sim.plot()\n+            default_figsize = np.array([8, 6])\n+            figsize_factor = np.clip((n_cols-3)/6+1, 1, 1.5) # Scale the default figure size based on the number of rows and columns\n+            figsize = default_figsize*figsize_factor\n+            fig_kw = sc.mergedicts({'figsize':figsize}, fig_kw)\n+            fig_kw = sc.mergedicts(fig_kw)\n+            fill_kw = sc.mergedicts({'alpha':0.2}, fill_kw)\n+            plot_kw = sc.mergedicts({'lw':2, 'alpha':0.8}, plot_kw)\n+            with sc.options.with_style('simple'):\n+                if key is not None:\n+                    flat = {k:v for k,v in flat.items() if k.startswith(key)}\n+                if fig is None:\n+                    fig, axs = sc.getrowscols(len(flat), make=True, **fig_kw)\n+                else:\n+                    axs = sc.toarray(fig.axes)\n+\n+                # Do the plotting\n+                for ax, (key, res) in zip(axs.flatten(), flat.items()):\n+                    ax.fill_between(res.timevec, res.low, res.high, **fill_kw)\n+                    ax.plot(res.timevec, res, **plot_kw)\n+                    ax.set_title(getattr(res, 'label', key))\n+                    ax.set_xlabel('Year')\n+\n+        return ss.return_fig(fig)\n+\n+\n+def single_run(sim, ind=0, reseed=True, shrink=True, run_args=None, sim_args=None,\n                verbose=None, do_run=True, **kwargs):\n     \"\"\"\n     Convenience function to perform a single simulation run. Mostly used for\n@@ -240,7 +400,7 @@ def single_run(sim, ind=0, reseed=True, keep_people=False, run_args=None, sim_ar\n         reseed      (bool)  : whether to generate a fresh seed for each run\n         noise       (float) : the amount of noise to add to each run\n         noisepar    (str)   : the name of the parameter to add noise to\n-        keep_people (bool)  : whether to keep the people after the sim run\n+        shrink      (bool)  : whether to shrink the sim after the sim run\n         run_args    (dict)  : arguments passed to sim.run()\n         sim_args    (dict)  : extra parameters to pass to the sim, e.g. 'n_infected'\n         verbose     (int)   : detail to print\n@@ -268,11 +428,7 @@ def single_run(sim, ind=0, reseed=True, keep_people=False, run_args=None, sim_ar\n \n     if reseed:\n         sim.pars['rand_seed'] += ind  # Reset the seed, otherwise no point of parallel runs\n-        ss.set_seed()\n-\n-    if verbose >= 1:\n-        verb = 'Running' if do_run else 'Creating'\n-        print(f'{verb} a simulation using seed={sim[\"rand_seed\"]}')\n+        ss.set_seed() # Note: may not be needed\n \n     # Handle additional arguments\n     for key, val in sim_args.items():\n@@ -280,7 +436,9 @@ def single_run(sim, ind=0, reseed=True, keep_people=False, run_args=None, sim_ar\n         if key in sim.pars.keys():\n             if verbose >= 1:\n                 print(f'Setting key {key} from {sim[key]} to {val}')\n-                sim[key] = val\n+            sim.pars[key] = val\n+            if key == 'rand_seed':\n+                ss.set_seed() # Note: may not be needed\n         else:\n             raise sc.KeyNotFoundError(f'Could not set key {key}: not a valid parameter name')\n \n@@ -289,24 +447,25 @@ def single_run(sim, ind=0, reseed=True, keep_people=False, run_args=None, sim_ar\n         sim.run(**run_args)\n \n     # Shrink the sim to save memory\n-    if not keep_people:\n+    if shrink:\n         sim.shrink()\n \n     return sim\n \n \n-def multi_run(sim, n_runs=4, reseed=None, iterpars=None, keep_people=None, run_args=None, sim_args=None,\n+def multi_run(sim, n_runs=4, reseed=None, iterpars=None, shrink=None, run_args=None, sim_args=None,\n               par_args=None, do_run=True, parallel=True, n_cpus=None, verbose=None, **kwargs):\n     \"\"\"\n-    For running multiple runs in parallel. If the first argument is a list of sims,\n-    exactly these will be run and most other arguments will be ignored.\n+    For running multiple sims in parallel. If the first argument is a list of sims\n+    rather than a single sim, exactly these will be run and most other arguments\n+    will be ignored.\n \n     Args:\n-        sim         (Sim)   : the sim instance to be run, or a list of sims.\n+        sim         (Sim/list): the sim instance to be run, or a list of sims.\n         n_runs      (int)   : the number of parallel runs\n         reseed      (bool)  : whether or not to generate a fresh seed for each run (default: true for single, false for list of sims)\n         iterpars    (dict)  : any other parameters to iterate over the runs; see sc.parallelize() for syntax\n-        keep_people (bool)  : whether to keep the people after the sim run (default false)\n+        shrink      (bool)  : whether to shrink the sim after the sim run\n         run_args    (dict)  : arguments passed to sim.run()\n         sim_args    (dict)  : extra parameters to pass to the sim\n         par_args    (dict)  : arguments passed to sc.parallelize()\n@@ -348,12 +507,12 @@ def multi_run(sim, n_runs=4, reseed=None, iterpars=None, keep_people=None, run_a\n         if reseed is None: reseed = True\n         iterkwargs = dict(ind=np.arange(n_runs))\n         iterkwargs.update(iterpars)\n-        kwargs = dict(sim=sim, reseed=reseed, verbose=verbose, keep_people=keep_people,\n+        kwargs = dict(sim=sim, reseed=reseed, verbose=verbose, shrink=shrink,\n                       sim_args=sim_args, run_args=run_args, do_run=do_run)\n     elif isinstance(sim, list):  # List of sims\n         if reseed is None: reseed = False\n         iterkwargs = dict(sim=sim, ind=np.arange(len(sim)))\n-        kwargs = dict(reseed=reseed, verbose=verbose, keep_people=keep_people, sim_args=sim_args, run_args=run_args,\n+        kwargs = dict(reseed=reseed, verbose=verbose, shrink=shrink, sim_args=sim_args, run_args=run_args,\n                       do_run=do_run)\n     else:\n         errormsg = f'Must be Sim object or list, not {type(sim)}'\n@@ -394,7 +553,8 @@ Alternatively, to run without multiprocessing, set parallel=False.\n             sims.append(sim)\n \n     return sims\n-                  \n+\n+\n def parallel(*args, **kwargs):\n     \"\"\"\n     A shortcut to ``ss.MultiSim()``, allowing the quick running of multiple simulations\n@@ -409,10 +569,12 @@ def parallel(*args, **kwargs):\n \n     **Examples**::\n \n-        s1 = ss.Sim(beta=0.01, label='Low')\n-        s2 = ss.Sim(beta=0.02, label='High')\n+        s1 = ss.Sim(n_agents=1000, label='Small', diseases='sis', networks='random')\n+        s2 = ss.Sim(n_agents=2000, label='Large', diseases='sis', networks='random')\n         ss.parallel(s1, s2).plot()\n-        msim = ss.parallel([s1, s2], keep_people=True)\n+        msim = ss.parallel([s1, s2], shrink=False)\n     \"\"\"\n     sims = sc.mergelists(*args)\n-    return MultiSim(sims=sims).run(**kwargs)\n+    msim = MultiSim(sims=sims, **kwargs)\n+    msim.run()\n+    return msim\ndiff --git a/starsim/samples.py b/starsim/samples.py\nindex a8818a6..1e43f91 100644\n--- a/starsim/samples.py\n+++ b/starsim/samples.py\n@@ -6,7 +6,6 @@ Hierarchy\n - samples: collection of results with same parameters but different seeds\n - dataset: collection of samples (with different parameters)\n \"\"\"\n-\n import io\n import zipfile\n import sciris as sc\n@@ -146,7 +145,7 @@ class Samples:\n             self.preload()\n \n         return\n-        \n+\n     def copy(self):\n         \"\"\"\n         Shallow copy - shared cache, copied summary\n@@ -269,7 +268,7 @@ class Samples:\n         Returns: Array of seed values\n         \"\"\"\n         return self.index.get_level_values(\"seed\").values\n-    \n+\n     @staticmethod\n     def _seedfile(seed):\n         \"\"\" Helper function to generate a seed file name \"\"\"\n@@ -281,8 +280,7 @@ class Samples:\n         Args:\n             folder: The folder name\n             outputs: A list of tuples (df:pd.DataFrame, summary_row:dict) where the summary row as an entry 'seed' for the seed\n-            identifiers: A list of columns to use as identifiers. These should appear in the summary dataframe and should have the same\n-                         value for all samples.\n+            identifiers: A list of columns to use as identifiers. These should appear in the summary dataframe and should have the same value for all samples.\n         \"\"\"\n         zipdata = {} # Store all the data to be written as files inside the zipfile\n         summary_rows = []\n@@ -309,12 +307,12 @@ class Samples:\n         # Finish working on and write the summary\n         summary.set_index(identifiers, inplace=True)\n         zipdata[summary_file] = summary.to_csv()\n-        \n+\n         # Handle the zip file name\n         if fname is None:\n             fname = \"-\".join(str(row[x]) for x in identifiers[1:]) + \".zip\"\n         folder.mkdir(parents=True, exist_ok=True)\n-        \n+\n         # Save the zip file\n         sc.savezip(folder/fname, data=zipdata, tobytes=False)\n \n@@ -349,7 +347,7 @@ class Samples:\n         \"\"\"\n         for seed in self.seeds:\n             yield seed, self.get(seed)\n-            \n+\n     def __getitem__(self, item):\n         \"\"\"\n         Overload getitem for convenience\n@@ -401,8 +399,8 @@ class Samples:\n \n         Args:\n             fcn: A function to apply. It should take in a dataframe\n-            *args: Additional arguments for ``fcn``\n-            **kwargs: Additional arguments for ``fcn``\n+            args: Additional arguments for ``fcn``\n+            kwargs: Additional arguments for ``fcn``\n \n         Returns: A list with the output of ``fcn``\n         \"\"\"\ndiff --git a/starsim/settings.py b/starsim/settings.py\nindex 1bccd52..70bb3ef 100644\n--- a/starsim/settings.py\n+++ b/starsim/settings.py\n@@ -4,20 +4,19 @@ All options should be set using set() or directly, e.g.::\n \n     ss.options(verbose=False)\n \"\"\"\n-\n-import os\n import numpy as np\n import sciris as sc\n \n __all__ = ['dtypes', 'options']\n \n # Define Starsim-default data types\n-dtypes = sc.objdict(\n-    bool = bool,\n-    int = np.int64,\n-    float = np.float64,\n-    result_float = np.float64,\n-)\n+class dtypes:\n+    bool = bool\n+    int = np.int64\n+    rand_int = np.int32\n+    rand_uint = np.uint32\n+    float = np.float32\n+    result_float = np.float64\n \n \n # Not public to avoid confusion with ss.options\n@@ -51,7 +50,7 @@ class Options(sc.objdict):\n         self.setattribute('optdesc', optdesc)  # Set the description as an attribute, not a dict entry\n         self.setattribute('orig_options', sc.dcp(options))  # Copy the default options\n         return\n-    \n+\n     @staticmethod\n     def get_orig_options():\n         \"\"\"\n@@ -64,27 +63,42 @@ class Options(sc.objdict):\n         options = sc.objdict()  # The options\n \n         optdesc.verbose = 'Set default level of verbosity (i.e. logging detail): e.g., 0.1 is an update every 10 simulated timesteps.'\n-        options.verbose = float(os.getenv('STARSIM_VERBOSE', 0.1))\n+        options.verbose = sc.parse_env('STARSIM_VERBOSE', 0.1, 'float')\n+\n+        optdesc.license = 'Whether to print the license on import'\n+        options.license = sc.parse_env('STARSIM_LICENSE', False, 'bool')\n \n         optdesc.warnings = 'How warnings are handled: options are \"warn\" (default), \"print\", and \"error\"'\n-        options.warnings = str(os.getenv('STARSIM_WARNINGS', 'warn'))\n+        options.warnings = sc.parse_env('STARSIM_WARNINGS', 'warn', 'str')\n+\n+        optdesc.time_eps = 'Set size of smallest possible time unit (in units of sim time, e.g. \"year\" or \"day\")'\n+        options.time_eps = sc.parse_env('STARSIM_TIME_EPS', 1e-6, 'float') # If unit = 'year', corresponds to ~30 seconds\n \n         optdesc.sep = 'Set thousands seperator for text output'\n-        options.sep = str(os.getenv('STARSIM_SEP', ','))\n+        options.sep = sc.parse_env('STARSIM_SEP', ',', 'str')\n+\n+        optdesc.date_sep = 'Set seperator for dates'\n+        options.date_sep = sc.parse_env('STARSIM_DATE_SEP', '.', 'str')\n+\n+        optdesc.jupyter = 'Set whether to use Jupyter settings: -1=auto, 0=False, 1=True'\n+        options.jupyter = sc.parse_env('STARSIM_JUPYTER', -1, 'int')\n \n-        optdesc.precision = 'Set arithmetic precision -- 32-bit by default for efficiency'\n-        options.precision = int(os.getenv('STARSIM_PRECISION', 64))\n+        optdesc.precision = 'Set arithmetic precision'\n+        options.precision = sc.parse_env('STARSIM_PRECISION', 64, 'int')\n \n         optdesc._centralized = 'If True, revert to centralized random number generation (NOT ADVISED).'\n-        options._centralized = False\n+        options._centralized = sc.parse_env('STARSIM_CENTRALIZED', False, 'bool')\n \n         return optdesc, options\n \n     def __call__(self, *args, **kwargs):\n         \"\"\"Allow ``ss.options(dpi=150)`` instead of ``ss.options.set(dpi=150)`` \"\"\"\n-\n         return self.set(*args, **kwargs)\n \n+    def to_dict(self):\n+        ''' Pull out only the settings from the options object '''\n+        return {k:v for k,v in self.items()}\n+\n     def __repr__(self):\n         \"\"\" Brief representation \"\"\"\n         output = sc.objectid(self)\n@@ -143,7 +157,7 @@ class Options(sc.objdict):\n         # Handle other keys\n         elif key is not None:\n             kwargs = sc.mergedicts(kwargs, {key: value})\n-        \n+\n         # Reset options\n         for key, value in kwargs.items():\n             if key not in self:\n@@ -155,7 +169,7 @@ class Options(sc.objdict):\n                 if value in [None, 'default']:\n                     value = self.orig_options[key]\n                 self[key] = value\n-                \n+\n                 # Handle special cases\n                 if key == 'precision':\n                     self.reset_precision()\n@@ -174,7 +188,7 @@ class Options(sc.objdict):\n \n             # Convert warnings to errors\n             with ss.options.context(warnings='error'):\n-                ss.Sim(location='not a location').initialize()\n+                ss.Sim(location='not a location').init()\n \n             # Use with_style(), not context(), for plotting options\n             with ss.options.with_style(dpi=50):\n@@ -199,7 +213,7 @@ class Options(sc.objdict):\n             return self[key] != self.orig_options[key]\n         else:\n             return None\n-    \n+\n     def set_precision(self):\n         if self.precision == 32:\n             dtypes.int = np.int32\ndiff --git a/starsim/sim.py b/starsim/sim.py\nindex a717f7a..125bb13 100644\n--- a/starsim/sim.py\n+++ b/starsim/sim.py\n@@ -1,101 +1,159 @@\n \"\"\"\n Define core Sim classes\n \"\"\"\n-\n-# Imports\n import itertools\n import numpy as np\n import sciris as sc\n import starsim as ss\n-import matplotlib.pyplot as pl\n+import matplotlib as mpl\n+import matplotlib.pyplot as plt\n \n __all__ = ['Sim', 'AlreadyRunError', 'demo', 'diff_sims', 'check_sims_match']\n \n \n-class Sim(sc.prettyobj):\n+class Sim(ss.Base):\n+    \"\"\"\n+    The Sim object\n \n-    def __init__(self, pars=None, label=None, people=None, demographics=None, diseases=None, networks=None,\n-                 interventions=None, analyzers=None, connectors=None, copy_inputs=True, **kwargs):\n+    All Starsim simulations run via the Sim class. It is responsible for initializing\n+    and running all modules and generating results.\n+\n+    Args:\n+        pars (SimPars/dict): either an ss.SimPars object, or a nested dictionary; can include all other arguments\n+        label (str): the human-readable name of the simulation\n+        people (People): if provided, use this ss.People object\n+        demographics (str/Demographics/list): a string naming the demographics module to use, the module itself, or a list\n+        diseases (str/Disease/list): as above, for diseases\n+        networks (str/Network/list): as above, for networks\n+        interventions (str/Intervention/list): as above, for interventions\n+        analyzers (str/Analyzer/list): as above, for analyzers\n+        connectors (str/Connector/list): as above, for connectors\n+        copy_inputs (bool): if True, copy modules as they're inserted into the sim (allowing reuse in other sims, but meaning they won't be updated)\n+        data (df): a dataframe (or dict) of data, with a column \"time\" plus data of the form \"module.result\", e.g. \"hiv.new_infections\" (used for plotting only)\n+        kwargs (dict): merged with pars; see ss.SimPars for all parameter values\n+\n+    **Examples**::\n \n-        # Make default parameters (using values from parameters.py)\n-        self.pars = ss.make_pars() # Start with default pars\n-        args = dict(label=label, people=people, demographics=demographics, diseases=diseases, networks=networks, \n+        sim = ss.Sim(diseases='sir', networks='random') # Simplest Starsim sim; equivalent to ss.demo()\n+        sim = ss.Sim(diseases=ss.SIR(), networks=ss.RandomNet()) # Equivalent using objects instead of strings\n+        sim = ss.Sim(diseases=['sir', ss.SIS()], networks=['random', 'mf']) # Example using list inputs; can mix and match types\n+    \"\"\"\n+    def __init__(self, pars=None, label=None, people=None, demographics=None, diseases=None, networks=None,\n+                 interventions=None, analyzers=None, connectors=None, copy_inputs=True, data=None, **kwargs):\n+        self.pars = ss.make_pars() # Make default parameters (using values from parameters.py)\n+        args = dict(label=label, people=people, demographics=demographics, diseases=diseases, networks=networks,\n                     interventions=interventions, analyzers=analyzers, connectors=connectors)\n         args = {key:val for key,val in args.items() if val is not None} # Remove None inputs\n-        self.pars.update(sc.mergedicts(pars, args, kwargs, _copy=copy_inputs))  # Update the parameters\n-        \n-        # Set attributes\n+        input_pars = sc.mergedicts(pars, args, kwargs, _copy=copy_inputs)\n+        self.pars.update(input_pars)  # Update the parameters\n+\n+        # Set attributes; see also sim.init() for more\n         self.label = label # Usually overwritten during initialization by the parameters\n         self.created = sc.now()  # The datetime the sim was created\n-        self.initialized = False  # Whether initialization is complete\n-        self.complete = False  # Whether a simulation has completed running # TODO: replace with finalized?\n-        self.results_ready = False  # Whether results are ready\n+        self.version = ss.__version__ # The Starsim version\n+        self.metadata = sc.metadata(version=self.version, pipfreeze=False)\n         self.dists = ss.Dists(obj=self) # Initialize the random number generator container\n+        self.loop = ss.Loop(self) # Initialize the integration loop\n         self.results = ss.Results(module='sim')  # For storing results\n+        self.data = data # For storing input data\n+        self.initialized = False  # Whether initialization is complete\n+        self.complete = False  # Whether a simulation has completed running\n+        self.results_ready = False  # Whether results are ready\n+        self.elapsed = None # The time required to run\n         self.summary = None  # For storing a summary of the results\n         self.filename = None # Store the filename, if saved\n         return\n-    \n+\n     def __getitem__(self, key):\n         \"\"\" Allow dict-like access, e.g. sim['diseases'] \"\"\"\n         return getattr(self, key)\n-    \n+\n     def __setitem__(self, key, value):\n         \"\"\" Allow dict-like access, e.g. sim['created'] = sc.now() \"\"\"\n         return setattr(self, key, value)\n-    \n-    def initialize(self, **kwargs):\n-        \"\"\" Perform all initializations for the sim; most heavy lifting is done by the parameters \"\"\"\n-        # Validation and initialization\n-        ss.set_seed(self.pars.rand_seed) # Reset the seed before the population is created -- shouldn't matter if only using Dist objects\n-        \n-        # Validate parameters\n-        self.pars.validate()\n-\n-        # Initialize time\n-        self.init_time_attrs()\n-        \n-        # Initialize the people\n-        self.init_people(**kwargs)  # Create all the people\n-        \n-        # # Initialize the modules within the parameters\n-        # self.pars.validate_modules(self)\n-        \n-        # Move initialized modules to the sim\n-        keys = ['label', 'demographics', 'networks', 'diseases', 'interventions', 'analyzers', 'connectors']\n-        for key in keys:\n-            setattr(self, key, self.pars.pop(key))\n-            \n-        # Initialize all the modules with the sim\n-        for mod in self.modules:\n-            mod.init_pre(self)\n \n-        # Initialize products # TODO: think about simplifying\n-        for mod in self.interventions:\n-            if hasattr(mod, 'product') and isinstance(mod.product, ss.Product):\n-                mod.product.init_pre(self)\n-        \n-        # Initialize all distributions now that everything else is in place, then set states\n-        self.dists.initialize(obj=self, base_seed=self.pars.rand_seed, force=True)\n-        \n-        # Initialize the values in all of the states and networks\n-        self.init_vals()\n-        \n-        # Initialize the results\n-        self.init_results()\n+    def __repr__(self):\n+        \"\"\" Show a quick version of the sim \"\"\"\n+        # Try a more custom repr first\n+        try:\n+            labelstr = f'{self.label}; ' if self.label else ''\n+            n = int(self.pars.n_agents)\n+            timestr = f'{self.pars.start}—{self.pars.stop}'\n+\n+            moddict = {}\n+            for modkey in ss.module_map().keys():\n+                if hasattr(self, modkey):\n+                    thismodtype = self[modkey]\n+                elif modkey in self.pars:\n+                    thismodtype = self.pars[modkey]\n+                else:\n+                    thismodtype = {}\n+\n+                if isinstance(thismodtype, dict) and len(thismodtype):\n+                    moddict[modkey] = sc.strjoin(thismodtype.keys())\n+                elif isinstance(thismodtype, str):\n+                    moddict[modkey] = thismodtype\n+\n+            if len(moddict):\n+                modulestr = ''\n+                for k,mstr in moddict.items():\n+                    modulestr += f'; {k}={mstr}'\n+            else:\n+                modulestr = ''\n+            if not self.initialized:\n+                modulestr += '; not initialized'\n+\n+            string = f'Sim({labelstr}n={n:n}; {timestr}{modulestr})'\n+\n+        # Or just use default\n+        except Exception as E:\n+            ss.warn(f'Error displaying custom sim repr, falling back to default: {E}')\n+            string = sc.prepr(self, vals=False)\n+\n+        return string\n+\n+    @property\n+    def modules(self):\n+        \"\"\" Return iterator over all Module instances (stored in standard places) in the Sim \"\"\"\n+        return itertools.chain(\n+            self.demographics(),\n+            self.networks(),\n+            self.diseases(),\n+            self.connectors(),\n+            self.interventions(),\n+            [intv.product for intv in self.interventions() if hasattr(intv, 'product') and intv.product is not None], # TODO: simplify\n+            self.analyzers(),\n+        )\n+\n+    def init(self, **kwargs):\n+        \"\"\" Perform all initializations for the sim \"\"\"\n+\n+        # Validation and initialization -- this is \"pre\"\n+        ss.set_seed(self.pars.rand_seed) # Reset the seed before the population is created -- shouldn't matter if only using Dist objects\n+        self.pars.validate() # Validate parameters\n+        self.init_time() # Initialize time\n+        self.init_people(**kwargs) # Initialize the people\n+        self.init_sim_attrs()\n+        self.init_mods_pre()\n+\n+        # Final initializations -- this is \"post\"\n+        self.init_dists() # Initialize distributions\n+        self.init_people_vals() # Initialize the values in all the states and networks\n+        self.init_mod_vals() # Initialize the module values\n+        self.init_results() # Initialize the results\n+        self.init_data() # Initialize the data\n+        self.loop.init() # Initialize the integration loop\n+        self.timer = sc.timer() # Store a timer for keeping track of how long the run takes\n+        self.verbose = self.pars.verbose # Store a run-specific value of verbose\n \n         # It's initialized\n         self.initialized = True\n         return self\n-    \n-    def init_time_attrs(self):\n+\n+    def init_time(self):\n         \"\"\" Time indexing; derived values live in the sim rather than in the pars \"\"\"\n-        self.dt = self.pars.dt # Shortcut to dt since used a lot\n-        self.yearvec = np.arange(start=self.pars.start, stop=self.pars.end + self.pars.dt, step=self.pars.dt) # The time points of the sim\n-        self.results.yearvec = self.yearvec # Store the yearvec in the results for plotting\n-        self.npts = len(self.yearvec) # The number of points in the sim\n-        self.tivec = np.arange(self.npts) # The vector of time indices\n-        self.ti = 0  # The time index, e.g. 0, 1, 2\n+        self.t = ss.Time(pars=self.pars, name='sim', sim=True)\n+        self.results.timevec = self.timevec # Store the timevec in the results for plotting\n         return\n \n     def init_people(self, verbose=None, **kwargs):\n@@ -103,7 +161,7 @@ class Sim(sc.prettyobj):\n         Initialize people within the sim\n         Sometimes the people are provided, in which case this just adds a few sim properties to them.\n         Other time people are not provided and this method makes them.\n-        \n+\n         Args:\n             verbose (int):  detail to print\n             kwargs  (dict): passed to ss.make_people()\n@@ -124,166 +182,135 @@ class Sim(sc.prettyobj):\n         self.people = people\n         self.people.link_sim(self)\n         return self.people\n-    \n-    def init_vals(self):\n-        \"\"\" Initialize the states and other objects with values \"\"\"\n-        \n-        # Initialize values in people\n+\n+    def init_sim_attrs(self):\n+        \"\"\" Move initialized modules to the sim \"\"\"\n+        keys = ['label', 'demographics', 'networks', 'diseases', 'interventions', 'analyzers', 'connectors']\n+        for key in keys:\n+            setattr(self, key, self.pars.pop(key))\n+        return\n+\n+    def init_mods_pre(self):\n+        \"\"\" Initialize all the modules with the sim \"\"\"\n+        for mod in self.modules:\n+            mod.init_pre(self)\n+        return\n+\n+    def init_dists(self):\n+        \"\"\" Initialize the distributions \"\"\"\n+        # Initialize all distributions now that everything else is in place\n+        self.dists.init(obj=self, base_seed=self.pars.rand_seed, force=True)\n+\n+        # Copy relevant dists to each module\n+        for mod in self.modules:\n+            self.dists.copy_to_module(mod)\n+        return\n+\n+    def init_people_vals(self):\n+        \"\"\" Initialize the People states with actual values \"\"\"\n         self.people.init_vals()\n-        \n-        # Initialize values in other modules, including networks\n+        return\n+\n+    def init_mod_vals(self):\n+        \"\"\" Initialize values in other modules, including networks and time parameters \"\"\"\n         for mod in self.modules:\n             mod.init_post()\n         return\n-    \n+\n+    def reset_time_pars(self, force=True):\n+        \"\"\" Reset the time parameters in the modules; used for imposing the sim's timestep on the modules \"\"\"\n+        for mod in self.modules:\n+            mod.init_time_pars(force=force)\n+        return\n+\n     def init_results(self):\n         \"\"\" Create initial results that are present in all simulations \"\"\"\n-        self.results += [ # TODO: refactor with self.add_results()\n-            ss.Result(None, 'n_alive',    self.npts, ss.dtypes.int, scale=True),\n-            ss.Result(None, 'new_deaths', self.npts, ss.dtypes.int, scale=True),\n-            ss.Result(None, 'cum_deaths', self.npts, ss.dtypes.int, scale=True),\n+        kw = dict(shape=self.t.npts, timevec=self.t.timevec, dtype=int, scale=True)\n+        self.results += [\n+            ss.Result('n_alive',    label='Number alive', **kw),\n+            ss.Result('new_deaths', label='Deaths', **kw),\n+            ss.Result('cum_deaths', label='Cumulative deaths', **kw),\n         ]\n         return\n \n-    @property\n-    def modules(self):\n-        # Return iterator over all Module instances (stored in standard places) in the Sim\n-        products = [intv.product for intv in self.interventions.values() if\n-                    hasattr(intv, 'product') and isinstance(intv.product, ss.Product)]\n-        return itertools.chain(\n-            self.demographics.values(),\n-            self.networks.values(),\n-            self.diseases.values(),\n-            self.connectors.values(),\n-            self.interventions.values(),\n-            products,\n-            self.analyzers.values(),\n-        )\n-    \n-    @property\n-    def year(self):\n-        return self.yearvec[self.ti]\n+    def init_data(self, data=None):\n+        \"\"\" Initialize or add data to the sim \"\"\"\n+        data = data if data is not None else self.data\n+        self.data = ss.validate_sim_data(data)\n+        return\n \n-    def step(self):\n-        \"\"\" Step through time and update values \"\"\"\n+    def start_step(self):\n+        \"\"\" Start the step -- only print progress; all actual changes happen in the modules \"\"\"\n \n         # Set the time and if we have reached the end of the simulation, then do nothing\n         if self.complete:\n-            raise AlreadyRunError('Simulation already complete (call sim.initialize() to re-run)')\n-\n-        # Advance random number generators forward to prepare for any random number calls that may be necessary on this step\n-        self.dists.jump(to=self.ti+1)  # +1 offset because ti=0 is used on initialization\n-\n-        # Update demographic modules (create new agents from births/immigration, schedule non-disease deaths and emigration)\n-        for dem_mod in self.demographics():\n-            dem_mod.update()\n-\n-        # Carry out autonomous state changes in the disease modules. This allows autonomous state changes/initializations\n-        # to be applied to newly created agents\n-        for disease in self.diseases():\n-            disease.update_pre()\n-\n-        # Update connectors -- TBC where this appears in the ordering\n-        for connector in self.connectors():\n-            connector.update()\n-\n-        # Update networks - this takes place here in case autonomous state changes at this timestep affect eligibility for contacts\n-        for network in self.networks():\n-            network.update()\n-\n-        # Apply interventions - new changes to contacts will be visible and so the final networks can be customized by\n-        # interventions, by running them at this point\n-        for intervention in self.interventions():\n-            intervention(self)\n-\n-        # Carry out transmission/new cases\n-        for disease in self.diseases():\n-            disease.make_new_cases()\n-\n-        # Execute deaths that took place this timestep (i.e., changing the `alive` state of the agents). This is executed\n-        # before analyzers have run so that analyzers are able to inspect and record outcomes for agents that died this timestep\n-        uids = self.people.resolve_deaths()\n-        for disease in self.diseases():\n-            disease.update_death(uids)\n-\n-        # Update results\n-        self.people.update_results()\n-\n-        for dem_mod in self.demographics():\n-            dem_mod.update_results()\n+            errormsg = 'Simulation already complete (call sim.init() to re-run)'\n+            raise AlreadyRunError(errormsg)\n \n-        for disease in self.diseases():\n-            disease.update_results()\n+        # Print out progress if needed\n+        self.elapsed = self.timer.toc(output=True)\n+        if self.verbose: # Print progress\n+            t = self.t\n+            simlabel = f'\"{self.label}\": ' if self.label else ''\n+            string = f'  Running {simlabel}{t.now(\"str\")} ({t.ti:2.0f}/{t.npts}) ({self.elapsed:0.2f} s) '\n+            if self.verbose >= 1:\n+                sc.heading(string)\n+            elif self.verbose > 0:\n+                if not (t.ti % int(1.0 / self.verbose)):\n+                    sc.progressbar(t.ti + 1, t.npts, label=string, length=20, newline=True)\n+        return\n \n-        for analyzer in self.analyzers():\n-            analyzer(self)\n-            \n-        # Clean up dead agents\n-        self.people.remove_dead()\n+    def finish_step(self):\n+        \"\"\" Finish the simulation timestep \"\"\"\n+        self.t.ti += 1\n+        return\n \n-        # Tidy up\n-        self.ti += 1\n-        self.people.ti = self.ti\n-        self.people.update_post()\n+    def run_one_step(self, verbose=None):\n+        \"\"\"\n+        Run a single sim step; only used for debugging purposes.\n \n-        if self.ti == self.npts:\n-            self.complete = True\n+        Note: sim.run_one_step() runs a single simulation timestep, which involves\n+        multiple function calls. In contrast, loop.run_one_step() runs a single\n+        function call.\n \n-        return\n+        Note: the verbose here is only for the Loop object, not the sim.\n+        \"\"\"\n+        self.loop.run(self.t.now(), verbose)\n+        return self\n \n     def run(self, until=None, verbose=None):\n         \"\"\" Run the model once \"\"\"\n \n         # Initialization steps\n-        T = sc.timer()\n-        if not self.initialized:\n-            self.initialize()\n-            self._orig_pars = sc.dcp(self.pars)  # Create a copy of the parameters to restore after the run\n-\n-        if verbose is None:\n-            verbose = self.pars.verbose\n+        if not self.initialized: self.init()\n+        self.verbose = sc.ifelse(verbose, self.pars.verbose)\n+        self.timer.start()\n \n         # Check for AlreadyRun errors\n         errormsg = None\n-        if until is None: until = self.npts\n-        if until > self.npts:\n-            errormsg = f'Requested to run until t={until} but the simulation end is ti={self.npts}'\n-        if self.ti >= until:  # NB. At the start, self.t is None so this check must occur after initialization\n-            errormsg = f'Simulation is currently at t={self.ti}, requested to run until ti={until} which has already been reached'\n         if self.complete:\n-            errormsg = 'Simulation is already complete (call sim.initialize() to re-run)'\n+            errormsg = 'Simulation is already complete (call sim.init() to re-run)'\n         if errormsg:\n             raise AlreadyRunError(errormsg)\n \n-        # Main simulation loop\n-        while self.ti < until:\n-\n-            # Check if we were asked to stop\n-            elapsed = T.toc(output=True)\n-\n-            # Print progress\n-            if verbose:\n-                simlabel = f'\"{self.label}\": ' if self.label else ''\n-                string = f'  Running {simlabel}{self.yearvec[self.ti]:0.1f} ({self.ti:2.0f}/{self.npts}) ({elapsed:0.2f} s) '\n-                if verbose >= 2:\n-                    sc.heading(string)\n-                elif verbose > 0:\n-                    if not (self.ti % int(1.0 / verbose)):\n-                        sc.progressbar(self.ti + 1, self.npts, label=string, length=20, newline=True)\n+        # Main simulation loop -- just one line!!!\n+        self.loop.run(until)\n \n-            # Actually run the model\n-            self.step()\n+        # Check if the simulation is complete\n+        if self.loop.index == len(self.loop.plan):\n+            self.complete = True\n \n         # If simulation reached the end, finalize the results\n         if self.complete:\n-            self.finalize(verbose=verbose)\n-            sc.printv(f'Run finished after {elapsed:0.2f} s.\\n', 1, verbose)\n-\n-        return self\n-\n-    def finalize(self, verbose=None):\n+            self.t.ti -= 1  # During the run, this keeps track of the next step; restore this be the final day of the sim\n+            for mod in self.modules: # May not be needed, but keeps it consistent with the sim\n+                mod.t.ti -= 1\n+            self.finalize()\n+            sc.printv(f'Run finished after {self.elapsed:0.2f} s.\\n', 1, self.verbose)\n+        return self # Allows e.g. ss.Sim().run().plot()\n+\n+    def finalize(self):\n         \"\"\" Compute final results \"\"\"\n-\n         if self.results_ready:\n             # Because the results are rescaled in-place, finalizing the sim cannot be run more than once or\n             # otherwise the scale factor will be applied multiple times\n@@ -291,31 +318,30 @@ class Sim(sc.prettyobj):\n \n         # Scale the results\n         for reskey, res in self.results.items():\n-            if isinstance(res, ss.Result) and res.scale:\n+            if isinstance(res, ss.Result) and res.scale: # NB: disease-specific results are scaled in module.finalize() below\n                 self.results[reskey] = self.results[reskey] * self.pars.pop_scale\n+        self.results_ready = True # Results are ready to use\n \n+        # Finalize each module\n         for module in self.modules:\n             module.finalize()\n \n-        self.summarize()\n-        self.results_ready = True  # Set this first so self.summary() knows to print the results\n-        self.ti -= 1  # During the run, this keeps track of the next step; restore this be the final day of the sim\n+        # Generate the summary and finish up\n+        self.summarize() # Create summary\n         return\n \n     def summarize(self, how='default'):\n         \"\"\"\n-        Provide a quick summary of the sim\n-        \n+        Provide a quick summary of the sim; returns the last entry for count and\n+        cumulative results, and the mean otherwise.\n+\n         Args:\n             how (str): how to summarize: can be 'mean', 'median', 'last', or a mapping of result keys to those\n-        \n-        Returns the last entry for count and cumulative results, and the mean otherwise\n         \"\"\"\n-        \n         def get_func(key, how, default='mean'):\n             \"\"\"\n             Find the right function by matching the \"how\" key with the result key\n-            \n+\n             For example, hkey=\"cum_ \" will match result key \"cum_infections\"\n             \"\"\"\n             func = None\n@@ -326,7 +352,7 @@ class Sim(sc.prettyobj):\n             if func is None:\n                 func = default\n             return func\n-            \n+\n         def get_result(res, func):\n             \"\"\" Convert a string to the actual function to use, e.g. \"median\" maps to np.median() \"\"\"\n             if   func == 'mean':   return res.mean()\n@@ -334,30 +360,27 @@ class Sim(sc.prettyobj):\n             elif func == 'last':   return res[-1]\n             elif callable(func):   return func(res)\n             else: raise Exception(f'\"{func}\" is not a valid function')\n-        \n+\n         # Convert \"how\" from a string to a dict\n         if how == 'default':\n-            how = {'n_':'mean', 'new_':'mean', 'cum_':'last', '':'mean'}\n+            how = {'n_':'mean', 'new_':'mean', 'cum_':'last', 'timevec':'last', '':'mean'}\n         elif isinstance(how, str):\n             how = {'':how} # Match everything\n-        \n+\n         summary = sc.objdict()\n         flat = sc.flattendict(self.results, sep='_')\n         for key, res in flat.items():\n-            try:\n-                func = get_func(key, how)\n-                entry = get_result(res, func)\n-            except Exception as E:\n-                entry = f'N/A {E}'\n-            summary[key] = entry\n+            if 'timevec' not in key: # Skip module-specific time vectors\n+                try:\n+                    func = get_func(key, how)\n+                    entry = get_result(res, func)\n+                except Exception as E:\n+                    entry = f'N/A {E}'\n+                summary[key] = entry\n         self.summary = summary\n         return summary\n-    \n-    def disp(self):\n-        print(self.summary)\n-        return\n-    \n-    def shrink(self, skip_attrs=None, in_place=True):\n+\n+    def shrink(self, inplace=True, size_limit=1.0):\n         \"\"\"\n         \"Shrinks\" the simulation by removing the people and other memory-intensive\n         attributes (e.g., some interventions and analyzers), and returns a copy of\n@@ -365,151 +388,82 @@ class Sim(sc.prettyobj):\n         for saved files.\n \n         Args:\n-            skip_attrs (list): a list of attributes to skip (remove) in order to perform the shrinking; default \"people\"\n-            in_place (bool): whether to perform the shrinking in place (default), or return a shrunken copy instead\n+            inplace (bool): whether to perform the shrinking in place (default), or return a shrunken copy instead\n+            size_limit (float): print a warning if any module is larger than this size limit (set to None to disable)\n \n         Returns:\n             shrunken (Sim): a Sim object with the listed attributes removed\n         \"\"\"\n-        # By default, skip people (~90% of memory), popdict, and _orig_pars (which is just a backup)\n-        if skip_attrs is None:\n-            skip_attrs = ['people']\n-\n         # Create the new object, and copy original dict, skipping the skipped attributes\n-        if in_place:\n-            shrunken = self\n-            for attr in skip_attrs:\n-                setattr(self, attr, None)\n-        else:\n-            shrunken = object.__new__(self.__class__)\n-            shrunken.__dict__ = {k: (v if k not in skip_attrs else None) for k, v in self.__dict__.items()}\n-\n-        # Don't return if in place\n-        if in_place:\n-            return\n-        else:\n-            return shrunken\n-\n-    def _get_ia(self, which, label=None, partial=False, as_list=False, as_inds=False, die=True, first=False):\n-        \"\"\" Helper method for get_interventions() and get_analyzers(); see get_interventions() docstring \"\"\"\n-\n-        # Handle inputs\n-        if which not in ['interventions', 'analyzers']:  # pragma: no cover\n-            errormsg = f'This method is only defined for interventions and analyzers, not \"{which}\"'\n-            raise ValueError(errormsg)\n-\n-        ia_ndict = self.analyzers if which == 'analyzers' else self.interventions  # List of interventions or analyzers\n-        n_ia = len(ia_ndict)  # Number of interventions/analyzers\n-\n-        position = 0 if first else -1  # Choose either the first or last element\n-        if label is None:  # Get all interventions if no label is supplied, e.g. sim.get_interventions()\n-            label = np.arange(n_ia)\n-        if isinstance(label, np.ndarray):  # Allow arrays to be provided\n-            label = label.tolist()\n-        labels = sc.promotetolist(label)\n-\n-        # Calculate the matches\n-        matches = []\n-        match_inds = []\n-\n-        for label in labels:\n-            if sc.isnumber(label):\n-                matches.append(ia_ndict[label])\n-                label = n_ia + label if label < 0 else label  # Convert to a positive number\n-                match_inds.append(label)\n-            elif sc.isstring(label) or isinstance(label, type):\n-                for ind, ia_key, ia_obj in ia_ndict.enumitems():\n-                    if sc.isstring(label) and ia_obj.label == label or (partial and (label in str(ia_obj.label))):\n-                        matches.append(ia_obj)\n-                        match_inds.append(ind)\n-                    elif isinstance(label, type) and isinstance(ia_obj, label):\n-                        matches.append(ia_obj)\n-                        match_inds.append(ind)\n-            else:  # pragma: no cover\n-                errormsg = f'Could not interpret label type \"{type(label)}\": should be str, int, list, or {which} class'\n-                raise TypeError(errormsg)\n-\n-        # Parse the output options\n-        if as_inds:\n-            output = match_inds\n-        elif as_list:  # Used by get_interventions()\n-            output = matches\n+        if inplace:\n+            sim = self\n         else:\n-            if len(matches) == 0:  # pragma: no cover\n-                if die:\n-                    errormsg = f'No {which} matching \"{label}\" were found'\n-                    raise ValueError(errormsg)\n-                else:\n-                    output = None\n-            else:\n-                output = matches[\n-                    position]  # Return either the first or last match (usually), used by get_intervention()\n-\n-        return output\n-\n-    def get_interventions(self, label=None, partial=False, as_inds=False):\n-        \"\"\"\n-        Find the matching intervention(s) by label, index, or type. If None, return\n-        all interventions. If the label provided is \"summary\", then print a summary\n-        of the interventions (index, label, type).\n-\n-        Args:\n-            label (str, int, Intervention, list): the label, index, or type of intervention to get; if a list, iterate over one of those types\n-            partial (bool): if true, return partial matches (e.g. 'beta' will match all beta interventions)\n-            as_inds (bool): if true, return matching indices instead of the actual interventions\n-        \"\"\"\n-        return self._get_ia('interventions', label=label, partial=partial, as_inds=as_inds, as_list=True)\n-\n-    def get_intervention(self, label=None, partial=False, first=False, die=True):\n-        \"\"\"\n-        Find the matching intervention(s) by label, index, or type.\n-        If more than one intervention matches, return the last by default.\n-        If no label is provided, return the last intervention in the list.\n-\n-        Args:\n-            label (str, int, Intervention, list): the label, index, or type of intervention to get; if a list, iterate over one of those types\n-            partial (bool): if true, return partial matches\n-            first (bool): if true, return first matching intervention (otherwise, return last)\n-            die (bool): whether to raise an exception if no intervention is found\n-        \"\"\"\n-        return self._get_ia('interventions', label=label, partial=partial, first=first, die=die, as_inds=False,\n-                            as_list=False)\n-\n-    def export_df(self):\n-        \"\"\"\n-        Export results as a Pandas dataframe\n-\n-        :return:\n-\n-        \"\"\"\n+            sim = self.copy() # We need to do a deep copy to avoid modifying other objects\n+\n+        # Shrink the people and loop\n+        shrunk = ss.utils.shrink()\n+        sim.people = shrunk\n+        with sc.tryexcept():\n+            sim.loop.funcs = shrunk\n+            sim.loop.plan = shrunk\n+\n+        # Shrink the networks\n+        for network in sim.networks():\n+            with sc.tryexcept():\n+                network.edges = shrunk\n+                network.participant = shrunk\n+\n+        # Shrink the distributions\n+        for dist in sim.dists.dists.values():\n+            with sc.tryexcept():\n+                dist.slots = shrunk\n+                dist._slots = shrunk\n+                dist.module = shrunk\n+                dist._n = shrunk\n+                dist._uids = shrunk\n+                dist.history = shrunk\n+\n+        # Finally, shrink the modules\n+        for mod in sim.modules:\n+            mod.sim = shrunk\n+            for state in mod.states:\n+                with sc.tryexcept():\n+                    state.people = shrunk\n+                    state.raw = shrunk\n+\n+            # Check that the module successfully shrunk\n+        if size_limit:\n+            for mod in sim.modules:\n+                size = sc.checkmem(mod, descend=0).bytesize[0]/1e6\n+                if size > size_limit:\n+                    warnmsg = f'Module {mod.name} did not successfully shrink: {size:0.1f} MB > {size_limit:0.1f} MB'\n+                    ss.warn(warnmsg)\n+\n+        # Finally, set a flag that the sim has been shrunken\n+        sim.shrunken = True\n+        return sim\n \n+    def check_results_ready(self, errormsg=None):\n+        \"\"\" Check that results are ready \"\"\"\n+        if errormsg is None:\n+            errormsg = 'Please run the sim first'\n         if not self.results_ready:  # pragma: no cover\n-            errormsg = 'Please run the sim before exporting the results'\n             raise RuntimeError(errormsg)\n+        return\n \n-        def flatten_results(d, prefix=''):\n-            flat = {}\n-            for key, val in d.items():\n-                if isinstance(val, dict):\n-                    flat.update(flatten_results(val, prefix=prefix+key+'.'))\n-                else:\n-                    flat[prefix+key] = val\n-            return flat\n-\n-        resdict = flatten_results(self.results)\n-        resdict['t'] = self.yearvec\n-\n-        df = sc.dataframe.from_dict(resdict).set_index('t')\n+    def to_df(self, sep='_'):\n+        \"\"\" Export results as a Pandas dataframe \"\"\"\n+        self.check_results_ready('Please run the sim before exporting the results')\n+        df = self.results.to_df(sep=sep, descend=True)\n         return df\n \n-    def save(self, filename=None, keep_people=None, skip_attrs=None, **kwargs):\n+    def save(self, filename=None, shrink=None, **kwargs):\n         \"\"\"\n         Save to disk as a gzipped pickle.\n \n         Args:\n             filename (str or None): the name or path of the file to save to; if None, uses stored\n-            keep_people (bool or None): whether to keep the people\n-            skip_attrs (list): attributes to skip saving\n+            shrink (bool or None): whether to shrink the sim prior to saving (reduces size by ~99%)\n             kwargs: passed to sc.makefilepath()\n \n         Returns:\n@@ -519,13 +473,9 @@ class Sim(sc.prettyobj):\n \n             sim.save() # Saves to a .sim file\n         \"\"\"\n-\n-        # Set keep_people based on whether we're in the middle of a run\n-        if keep_people is None:\n-            if self.initialized and not self.results_ready:\n-                keep_people = True\n-            else:\n-                keep_people = False\n+        # Set shrink based on whether we're in the middle of a run\n+        if shrink is None:\n+            shrink = False if self.initialized and not self.results_ready else True\n \n         # Handle the filename\n         if filename is None:\n@@ -534,160 +484,189 @@ class Sim(sc.prettyobj):\n         self.filename = filename  # Store the actual saved filename\n \n         # Handle the shrinkage and save\n-        if skip_attrs or not keep_people:\n-            obj = self.shrink(skip_attrs=skip_attrs, in_place=False)\n-        else:\n-            obj = self\n-        sc.save(filename=filename, obj=obj)\n-\n+        sim = self.shrink(inplace=False) if shrink else self\n+        sc.save(filename=filename, obj=sim)\n         return filename\n \n     @staticmethod\n     def load(filename, *args, **kwargs):\n-        \"\"\" Load from disk from a gzipped pickle.  \"\"\"\n-\n+        \"\"\" Load from disk from a gzipped pickle \"\"\"\n         sim = sc.load(filename, *args, **kwargs)\n         if not isinstance(sim, Sim):  # pragma: no cover\n             errormsg = f'Cannot load object of {type(sim)} as a Sim object'\n             raise TypeError(errormsg)\n         return sim\n \n-    def export_pars(self, filename=None, indent=2, *args, **kwargs):\n-        '''\n-        Return parameters for JSON export -- see also to_json().\n-\n-        This method is required so that interventions can specify\n-        their JSON-friendly representation.\n-\n-        Args:\n-            filename (str): filename to save to; if None, do not save\n-            indent (int): indent (int): if writing to file, how many indents to use per nested level\n-            args (list): passed to savejson()\n-            kwargs (dict): passed to savejson()\n-\n-        Returns:\n-            pardict (dict): a dictionary containing all the parameter values\n-        '''\n-        pardict = {}\n-        for key,item in self.pars.items():\n-            if key in ss.module_map().keys():\n-                if np.iterable(item):\n-                    item = [mod.to_json() for mod in item]\n-                else:\n-                    try:\n-                        item = item.to_json()\n-                    except:\n-                        pass\n-            elif key == 'people':\n-                continue\n-            pardict[key] = item\n-        if filename is not None:\n-            sc.savejson(filename=filename, obj=pardict, indent=indent, *args, **kwargs)\n-        return pardict\n-\n-    def to_json(self, filename=None, keys=None, tostring=False, indent=2, verbose=False, *args, **kwargs):\n-        '''\n+    def to_json(self, filename=None, keys=None, tostring=False, indent=2, verbose=False, **kwargs):\n+        \"\"\"\n         Export results and parameters as JSON.\n \n         Args:\n             filename (str): if None, return string; else, write to file\n-            keys (str or list): attributes to write to json (default: results, parameters, and summary)\n-            tostring (bool): if not writing to file, whether to write to string (alternative is sanitized dictionary)\n-            indent (int): if writing to file, how many indents to use per nested level\n+            keys (str/list): attributes to write to json (choices: 'pars' and/or 'summary')\n             verbose (bool): detail to print\n-            args (list): passed to savejson()\n-            kwargs (dict): passed to savejson()\n+            kwargs (dict): passed to sc.jsonify()\n \n         Returns:\n-            A unicode string containing a JSON representation of the results,\n-            or writes the JSON file to disk\n+            A dictionary representation of the parameters and/or summary results\n+            (or write that dictionary to a file)\n \n         **Examples**::\n \n             json = sim.to_json()\n             sim.to_json('results.json')\n             sim.to_json('summary.json', keys='summary')\n-        '''\n-\n+        \"\"\"\n         # Handle keys\n         if keys is None:\n-            keys = ['results', 'pars', 'summary', 'short_summary']\n+            keys = ['pars', 'summary']\n         keys = sc.promotetolist(keys)\n \n         # Convert to JSON-compatible format\n-        d = {}\n+        d = sc.objdict()\n         for key in keys:\n-            if key == 'results':\n-                if self.results_ready:\n-                    resdict = self.export_results(for_json=True)\n-                    d['results'] = resdict\n-                else:\n-                    d['results'] = 'Results not available (Sim has not yet been run)'\n-            elif key in ['pars', 'parameters']:\n-                pardict = self.export_pars()\n-                d['parameters'] = pardict\n+            if key in ['pars', 'parameters']:\n+                pardict = self.pars.to_json()\n+                d.pars = pardict\n             elif key == 'summary':\n                 if self.results_ready:\n-                    d['summary'] = dict(sc.dcp(self.summary))\n+                    d.summary = dict(sc.dcp(self.summary))\n                 else:\n-                    d['summary'] = 'Summary not available (Sim has not yet been run)'\n-            elif key == 'short_summary':\n-                if self.results_ready:\n-                    d['short_summary'] = dict(sc.dcp(self.short_summary))\n-                else:\n-                    d['short_summary'] = 'Full summary not available (Sim has not yet been run)'\n+                    d.summary = 'Summary not available (Sim has not yet been run)'\n             else:  # pragma: no cover\n-                try:\n-                    d[key] = sc.sanitizejson(getattr(self, key))\n-                except Exception as E:\n-                    errormsg = f'Could not convert \"{key}\" to JSON: {str(E)}; continuing...'\n-                    print(errormsg)\n+                errormsg = f'Could not convert \"{key}\" to JSON; continuing...'\n+                print(errormsg)\n \n-        if filename is None:\n-            output = sc.jsonify(d, tostring=tostring, indent=indent, verbose=verbose, *args, **kwargs)\n-        else:\n-            output = sc.savejson(filename=filename, obj=d, indent=indent, *args, **kwargs)\n+        # Final conversion\n+        if filename is not None:\n+            sc.savejson(filename=filename, obj=d, **kwargs)\n+        d = sc.jsonify(d)\n+        return d\n \n-        return output\n+    def plot(self, key=None, fig=None, style='fancy', show_data=True, show_skipped=False,\n+             show_module=26, show_label=False, fig_kw=None, plot_kw=None, scatter_kw=None):\n+        \"\"\"\n+        Plot all results in the Sim object\n+\n+        Args:\n+            key (str/list): the results key to plot (by default, all); if a list, plot exactly those keys\n+            fig (Figure): if provided, plot results into an existing figure\n+            style (str): the plotting style to use (default \"fancy\"; other options are \"simple\", None, or any Matplotlib style)\n+            show_data (bool): plot the data, if available\n+            show_skipped (bool): show even results that are skipped by default\n+            show_module (bool): whether to show the module as well as the result name; if an int, show if the label is less than that length; if -1, use a newline\n+            show_label (str): if 'fig', reset the fignum; if 'title', set the figure suptitle\n+            fig_kw (dict): passed to ``plt.subplots()``\n+            plot_kw (dict): passed to ``plt.plot()``\n+            scatter_kw (dict): passed to ``plt.scatter()``, for plotting the data\n+        \"\"\"\n+        self.check_results_ready('Please run the sim before plotting')\n+\n+        # Configuration\n+        flat = self.results.flatten()\n+        if not show_skipped: # Skip plots with auto_plot set to False\n+            for k in list(flat.keys()): # NB: can't call it \"key\", shadows argument\n+                res = flat[k]\n+                if isinstance(res, ss.Result) and not res.auto_plot:\n+                    flat.pop(k)\n+\n+        # Set figure defaults\n+        n_cols = np.ceil(np.sqrt(len(flat))) # Number of columns of axes\n+        default_figsize = np.array([8, 6])\n+        figsize_factor = np.clip((n_cols-3)/6+1, 1, 1.5) # Scale the default figure size based on the number of rows and columns\n+        figsize = default_figsize*figsize_factor\n+        if show_module is True: # Set no limit for the label length\n+            show_module = 999\n+\n+        # Set plotting defaults\n+        fig_kw     = sc.mergedicts(dict(figsize=figsize), fig_kw)\n+        plot_kw    = sc.mergedicts(dict(lw=2), plot_kw)\n+        scatter_kw = sc.mergedicts(dict(alpha=0.3, color='k'), scatter_kw)\n+\n+        # Do the plotting\n+        with sc.options.with_style(style):\n \n-    def plot(self, key=None):\n-        with sc.options.with_style('fancy'):\n-            flat = sc.flattendict(self.results, sep=': ')\n-            yearvec = flat.pop('yearvec')\n             if key is not None:\n-                flat = {k:v for k,v in flat.items() if k.startswith(key)}\n-            fig, axs = sc.getrowscols(len(flat), make=True)\n-            for ax, (k, v) in zip(axs.flatten(), flat.items()):\n-                ax.plot(yearvec, v)\n-                ax.set_title(k)\n-                ax.set_xlabel('Year')\n-        return fig\n+                if isinstance(key, str):\n+                    flat = {k:v for k,v in flat.items() if (key in k)}\n+                else:\n+                    flat = {k:flat[k] for k in key}\n+\n+            # Get the figure\n+            if fig is None:\n+                if show_label in ['fig', 'fignum'] and self.label:\n+                    plotlabel = self.label\n+                    figlist = sc.autolist()\n+                    while plt.fignum_exists(plotlabel):\n+                        figlist += plotlabel\n+                        plotlabel = sc.uniquename(self.label, figlist, human=True)\n+                    fig_kw['num'] = plotlabel\n+                fig, axs = sc.getrowscols(len(flat), make=True, **fig_kw)\n+                if isinstance(axs, np.ndarray):\n+                    axs = axs.flatten()\n+            else:\n+                axs = fig.axes\n+            if not sc.isiterable(axs):\n+                axs = [axs]\n+\n+            # Do the plotting\n+            df = self.data if show_data else None # For plotting the data\n+            for ax, (key, res) in zip(axs, flat.items()):\n+\n+                # Plot data\n+                if df is not None:\n+                    mod = res.module\n+                    name = res.name\n+                    found = False\n+                    for dfkey in [f'{mod}.{name}', f'{mod}_{name}']: # Allow dot or underscore\n+                        if dfkey in df.cols:\n+                            found = True\n+                            break\n+                    if found:\n+                        ax.scatter(df.index.values, df[dfkey].values, **scatter_kw)\n+\n+                # Plot results\n+                ax.plot(res.timevec, res.values, **plot_kw, label=self.label)\n+                if show_module == -1:\n+                    label = res.full_label.replace(':', '\\n')\n+                elif len(res.full_label) > show_module:\n+                    label = res.label\n+                else:\n+                    label = res.full_label\n+\n+                ax.set_title(label)\n+                sc.commaticks(ax)\n+                if res.has_dates:\n+                    locator = mpl.dates.AutoDateLocator(minticks=2, maxticks=5) # Fewer ticks since lots of plots\n+                    sc.dateformatter(ax, locator=locator)\n+\n+        if show_label in ['title', 'suptitle'] and self.label:\n+            fig.suptitle(self.label, weight='bold')\n+\n+        sc.figlayout(fig=fig)\n+\n+        return ss.return_fig(fig)\n \n \n class AlreadyRunError(RuntimeError):\n-    \"\"\"\n-    This error is raised if a simulation is run in such a way that no timesteps\n-    will be taken. This error is a distinct type so that it can be safely caught\n-    and ignored if required, but it is anticipated that most of the time, calling\n-    :py:func:`Sim.run` and not taking any timesteps, would be an inadvertent error.\n-    \"\"\"\n+    \"\"\" Raised if trying to re-run an already-run sim without re-initializing \"\"\"\n     pass\n \n \n def demo(run=True, plot=True, summary=True, show=True, **kwargs):\n     \"\"\"\n     Create a simple demo simulation for Starsim\n-    \n+\n     Defaults to using the SIR model with a random network, but these can be configured.\n-    \n+\n     Args:\n         run (bool): whether to run the sim\n         plot (bool): whether to plot the results\n         summary (bool): whether to print a summary of the results\n         kwargs (dict): passed to ``ss.Sim()``\n-    \n+\n     **Examples**::\n-        \n+\n         ss.demo() # Run, plot, and show results\n         ss.demo(diseases='hiv', networks='mf') # Run with different defaults\n     \"\"\"\n@@ -702,7 +681,7 @@ def demo(run=True, plot=True, summary=True, show=True, **kwargs):\n             if plot:\n                 sim.plot()\n                 if show:\n-                    pl.show()\n+                    plt.show()\n     return sim\n \n \n@@ -712,8 +691,8 @@ def diff_sims(sim1, sim2, skip_key_diffs=False, skip=None, full=False, output=Fa\n     values which differ.\n \n     Args:\n-        sim1 (sim/dict): either a simulation object or the sim.summary dictionary\n-        sim2 (sim/dict): ditto\n+        sim1 (Sim/MultiSim/dict): either a simulation/MultiSim object or the sim.summary dictionary\n+        sim2 (im/dict): ditto\n         skip_key_diffs (bool): whether to skip keys that don't match between sims\n         skip (list): a list of values to skip\n         full (bool): whether to print out all values (not just those that differ)\n@@ -728,15 +707,25 @@ def diff_sims(sim1, sim2, skip_key_diffs=False, skip=None, full=False, output=Fa\n         ss.diff_sims(s1, s2)\n     '''\n \n-    if isinstance(sim1, Sim):\n+    # Convert to dict\n+    if isinstance(sim1, (Sim, ss.MultiSim)):\n         sim1 = sim1.summarize()\n-    if isinstance(sim2, Sim):\n+    if isinstance(sim2, (Sim, ss.MultiSim)):\n         sim2 = sim2.summarize()\n     for sim in [sim1, sim2]:\n         if not isinstance(sim, dict):  # pragma: no cover\n             errormsg = f'Cannot compare object of type {type(sim)}, must be a sim or a sim.summary dict'\n             raise TypeError(errormsg)\n \n+\n+    # Check if it's a multisim\n+    sim1 = sc.objdict(sim1)\n+    sim2 = sc.objdict(sim2)\n+    multi = isinstance(sim1[0], dict) # If it's a dict, then it's a multisim\n+    if multi:\n+        for sim in [sim1, sim2]:\n+            assert 'mean' in sim[0], f\"Can only compare multisims with summarize(method='mean'), but you have keys {sim[0].keys()}\"\n+\n     # Compare keys\n     keymatchmsg = ''\n     sim1_keys = set(sim1.keys())\n@@ -746,7 +735,7 @@ def diff_sims(sim1, sim2, skip_key_diffs=False, skip=None, full=False, output=Fa\n         missing = list(sim1_keys - sim2_keys)\n         extra = list(sim2_keys - sim1_keys)\n         if missing:\n-            keymatchmsg += f'  Missing sim1 keys: {missing}\\ns'\n+            keymatchmsg += f'  Missing sim1 keys: {missing}\\n'\n         if extra:\n             keymatchmsg += f'  Extra sim2 keys: {extra}\\n'\n \n@@ -757,68 +746,88 @@ def diff_sims(sim1, sim2, skip_key_diffs=False, skip=None, full=False, output=Fa\n     skip = sc.tolist(skip)\n     for key in sim2.keys():  # To ensure order\n         if key in sim1_keys and key not in skip:  # If a key is missing, don't count it as a mismatch\n-            sim1_val = sim1[key] if key in sim1 else 'not present'\n-            sim2_val = sim2[key] if key in sim2 else 'not present'\n-            mm = not np.isclose(sim1_val, sim2_val, equal_nan=True)\n+            d = sc.objdict()\n+            if multi:\n+                d.sim1 = sim1[key]['mean']\n+                d.sim2 = sim2[key]['mean']\n+                d.sim1_sem = sim1[key]['sem']\n+                d.sim2_sem = sim2[key]['sem']\n+            else:\n+                d.sim1 = sim1[key]\n+                d.sim2 = sim2[key]\n+            mm = not np.isclose(d.sim1, d.sim2, equal_nan=True)\n             n_mismatch += mm\n             if mm or full:\n-                mismatches[key] = {'sim1': sim1_val, 'sim2': sim2_val}\n+                mismatches[key] = d\n \n+    df = sc.dataframe() # Preallocate in case there were no mismatches\n     if len(mismatches):\n         valmatchmsg = '\\nThe following values differ between the two simulations:\\n' if not full else ''\n         df = sc.dataframe.from_dict(mismatches).transpose()\n         diff = []\n         ratio = []\n         change = []\n-        small_change = 1e-3  # Define a small change, e.g. a rounding error\n-        for mdict in mismatches.values():\n-            old = mdict['sim1']\n-            new = mdict['sim2']\n-            numeric = sc.isnumber(sim1_val) and sc.isnumber(sim2_val)\n+        zscore = []\n+        small_change = 1 + 1e-3  # Define a small change, e.g. a rounding error\n+        for d in mismatches.values():\n+            old = d.sim1\n+            new = d.sim2\n+            if multi:\n+                old_sem = d.sim1_sem\n+                new_sem = d.sim1_sem\n+                sem = old_sem + new_sem\n+                small_change = 1.96 # 95% CI, roughly speaking\n+\n+            numeric = sc.isnumber(old) and sc.isnumber(new) # Should all be numeric, but just in case\n             if numeric and old > 0:\n                 this_diff = new - old\n                 this_ratio = new / old\n-                abs_ratio = max(this_ratio, 1.0 / this_ratio)\n+                if multi:\n+                    abs_ratio = abs(this_diff)/sem\n+                    this_zscore = abs_ratio\n+                else:\n+                    abs_ratio = max(this_ratio, 1.0/this_ratio)\n+                    this_zscore = np.nan\n \n                 # Set the character to use\n-                if abs_ratio < small_change:\n-                    change_char = '≈'\n-                elif new > old:\n-                    change_char = '↑'\n-                elif new < old:\n-                    change_char = '↓'\n-                elif new == old:\n-                    change_char = '='\n+                approx_eq = abs_ratio < small_change\n+                if approx_eq:    change_char = '≈'\n+                elif new > old:  change_char = '↑'\n+                elif new < old:  change_char = '↓'\n+                elif new == old: change_char = '='\n                 else:\n                     errormsg = f'Could not determine relationship between sim1={old} and sim2={new}'\n                     raise ValueError(errormsg)\n \n                 # Set how many repeats it should have\n                 repeats = 1\n-                if abs_ratio == 0:\n-                    repeats = 0\n-                if abs_ratio >= 1.1:\n-                    repeats = 2\n-                if abs_ratio >= 2:\n-                    repeats = 3\n-                if abs_ratio >= 10:\n-                    repeats = 4\n-\n+                if abs_ratio == 0:   repeats = 0\n+                if abs_ratio >= 1.1: repeats = 2\n+                if abs_ratio >= 2:   repeats = 3\n+                if abs_ratio >= 10:  repeats = 4\n                 this_change = change_char * repeats\n             else:  # pragma: no cover\n-                this_diff = np.nan\n-                this_ratio = np.nan\n+                this_diff =  np.nan\n+                this_ratio  = np.nan\n                 this_change = 'N/A'\n+                this_zscore = np.nan\n \n             diff.append(this_diff)\n             ratio.append(this_ratio)\n             change.append(this_change)\n+            zscore.append(this_zscore)\n \n         df['diff'] = diff\n         df['ratio'] = ratio\n-        for col in ['sim1', 'sim2', 'diff', 'ratio']:\n+        numeric_cols = ['sim1', 'sim2', 'diff', 'ratio']\n+        if multi:\n+            numeric_cols += ['sim1_sem', 'sim2_sem']\n+        for col in numeric_cols:\n             df[col] = df[col].round(decimals=3)\n         df['change'] = change\n+        if multi:\n+            df['zscore'] = zscore\n+            df['statsig'] = df.zscore > small_change\n         valmatchmsg += str(df)\n \n     # Raise an error if mismatches were found\n@@ -838,14 +847,30 @@ def diff_sims(sim1, sim2, skip_key_diffs=False, skip=None, full=False, output=Fa\n \n \n def check_sims_match(*args, full=False):\n-    \"\"\" Shortcut to using ss.diff_sims() to check if multiple sims match \"\"\"\n-    s1 = args[0]\n+    \"\"\"\n+    Shortcut to using ss.diff_sims() to check if multiple sims match\n+\n+    Args:\n+        args (list): a list of 2 or more sims to compare\n+        full (bool): if True, return whether each sim matches the first\n+\n+    **Example**::\n+\n+        s1 = ss.Sim(diseases='sir', networks='random')\n+        s2 = ss.Sim(pars=dict(diseases='sir', networks='random'))\n+        s3 = ss.Sim(diseases=ss.SIR(), networks=ss.RandomNet())\n+        assert ss.check_sims_match(s1, s2, s3)\n+    \"\"\"\n+    if len(args) < 2:\n+        errormsg = 'Must compare at least 2 sims'\n+        raise ValueError(errormsg)\n+    base = args[0]\n     matches = []\n-    for s2 in args[1:]:\n-        diff = diff_sims(s1, s2, full=False, output=False, die=False)\n+    for other in args[1:]:\n+        diff = diff_sims(base, other, full=False, output=False, die=False)\n         matches.append(not(diff)) # Return the opposite of the diff\n     if full:\n         return matches\n     else:\n         return all(matches)\n-        \n+\ndiff --git a/starsim/states.py b/starsim/states.py\ndeleted file mode 100644\nindex 4c864ec..0000000\n--- a/starsim/states.py\n+++ /dev/null\n@@ -1,379 +0,0 @@\n-\"\"\"\n-Define array-handling classes, including agent states\n-\"\"\"\n-\n-import numpy as np\n-import starsim as ss\n-\n-# Shorten these for performance\n-ss_float = ss.dtypes.float\n-ss_int   = ss.dtypes.int\n-ss_bool  = ss.dtypes.bool\n-\n-__all__ = ['check_dtype', 'Arr', 'FloatArr', 'BoolArr', 'IndexArr', 'uids']\n-\n-\n-def check_dtype(dtype, default=None):\n-    \"\"\" Check that the supplied dtype is one of the supported options \"\"\"\n-    \n-    # Handle dtype\n-    if dtype is None:\n-        if default is None:\n-            errormsg = 'Must supply either a dtype or a default value'\n-            raise ValueError(errormsg)\n-        else:\n-            dtype = type(default)\n-    \n-    if dtype in ['float', float, np.float64, np.float32]:\n-        dtype = ss_float\n-    elif dtype in ['int', int, np.int64, np.int32]:\n-        dtype = ss_int\n-    elif dtype in ['bool', bool, np.bool_]:\n-        dtype = ss_bool\n-    else:\n-        warnmsg = f'Data type {type(default)} not a supported data type; set warn=False to suppress warning'\n-        ss.warn(warnmsg)\n-    \n-    return dtype\n-\n-\n-class Arr(np.lib.mixins.NDArrayOperatorsMixin):\n-    \"\"\"\n-    Store a state of the agents (e.g. age, infection status, etc.) as an array.\n-    \n-    In practice, ``Arr`` objects can be used interchangeably with NumPy arrays.\n-    They have two main data interfaces: ``Arr.raw`` contains the \"raw\", underlying\n-    NumPy array of the data. ``Arr.values`` contains the \"active\" values, which\n-    usually corresponds to agents who are alive.\n-    \n-    By default, operations are performed on active agents only (specified by ``Arr.auids``,\n-    which is a pointer to ``sim.people.auids``). For example, ``sim.people.age.mean()``\n-    will only use the ages of active agents. Thus, ``sim.people.age.mean()``\n-    is equal to ``sim.people.age.values.mean()``, not ``sim.people.age.raw.mean()``.\n-    \n-    If indexing by an int or slice, ``Arr.values`` is used. If indexing by an\n-    ``ss.uids`` object, ``Arr.raw`` is used. ``Arr`` objects can't be directly\n-    indexed by a list or array of ints, as this would be ambiguous about whether\n-    ``values`` or ``raw`` is intended. For example, if there are 1000 people in a \n-    simulation and 100 of them have died, ``sim.people.age[999]`` will return\n-    an ``IndexError`` (since ``sim.people.age[899]`` is the last active agent),\n-    whereas ``sim.people.age[ss.uids(999)]`` is valid.\n-\n-    Args: \n-        name (str): The name for the state (also used as the dictionary key, so should not have spaces etc.)\n-        dtype (class): The dtype to use for this instance (if None, infer from value)\n-        default (any): Specify default value for new agents. This can be\n-        - A scalar with the same dtype (or castable to the same dtype) as the State\n-        - A callable, with a single argument for the number of values to produce\n-        - A ``ss.Dist`` instance\n-        nan (any): the value to use to represent NaN (not a number); also used as the default value if not supplied\n-        raw (arr): if supplied, the raw values to use\n-        label (str): The human-readable name for the state\n-        coerce (bool): Whether to ensure the the data is one of the supported data types\n-        skip_init (bool): Whether to skip initialization with the People object (used for uid and slot states)\n-    \"\"\"\n-    def __init__(self, name, dtype=None, default=None, nan=None, raw=None, label=None, coerce=True, skip_init=False):\n-        if coerce:\n-            dtype = check_dtype(dtype, default)\n-        \n-        # Set attributes\n-        self.name = name\n-        self.label = label or name\n-        self.default = default\n-        self.nan = nan\n-        self.dtype = dtype\n-        \n-        # Properties that are initialized later\n-        self.raw = np.empty(0, dtype=dtype)\n-        self.people = None # Used solely for accessing people.auids\n-        self.len_used = 0\n-        self.len_tot = 0\n-        self.initialized = skip_init\n-        if raw is not None:\n-            self.grow(new_uids=uids(np.arange(len(raw))), new_vals=raw)\n-        return\n-    \n-    def __repr__(self):\n-        arr_str = np.array2string(self.values, max_line_width=200)\n-        string = f'<{self.__class__.__name__} \"{str(self.name)}\", len={len(self)}, {arr_str}>'\n-        return string\n-    \n-    def __len__(self):\n-        return len(self.auids)\n-    \n-    def _convert_key(self, key):\n-        \"\"\"\n-        Used for getitem and setitem to determine whether the key is indexing\n-        the raw array (``raw``) or the active agents (``values``), and to convert\n-        the key to array indices if needed.\n-        \"\"\"\n-        if isinstance(key, (uids, int)):\n-            return key\n-        elif isinstance(key, (BoolArr, IndexArr)):\n-            return key.uids\n-        elif isinstance(key, slice):\n-            return self.auids[key]\n-        elif not np.isscalar(key) and len(key) == 0: # Handle [], np.array([]), etc.\n-            return uids()\n-        else:\n-            errormsg = f'Indexing an Arr ({self.name}) by ({key}) is ambiguous or not supported. Use ss.uids() instead, or index Arr.raw or Arr.values.'\n-            raise Exception(errormsg)\n-    \n-    def __getitem__(self, key):\n-        key = self._convert_key(key)\n-        return self.raw[key]\n-    \n-    def __setitem__(self, key, value):\n-        key = self._convert_key(key)\n-        self.raw[key] = value\n-        return\n-            \n-    def __getattr__(self, attr):\n-        \"\"\" Make it behave like a regular array mostly -- enables things like sum(), mean(), etc. \"\"\"\n-        if attr in ['__deepcopy__', '__getstate__', '__setstate__']:\n-            return self.__getattribute__(attr)\n-        else:\n-            return getattr(self.values, attr)\n-        \n-    def __gt__(self, other): return self.asnew(self.values > other,  cls=BoolArr)\n-    def __lt__(self, other): return self.asnew(self.values < other,  cls=BoolArr)\n-    def __ge__(self, other): return self.asnew(self.values >= other, cls=BoolArr)\n-    def __le__(self, other): return self.asnew(self.values <= other, cls=BoolArr)\n-    def __eq__(self, other): return self.asnew(self.values == other, cls=BoolArr)\n-    def __ne__(self, other): return self.asnew(self.values != other, cls=BoolArr)\n-    \n-    def __and__(self, other): raise BooleanOperationError(self)\n-    def __or__(self, other):  raise BooleanOperationError(self)\n-    def __xor__(self, other): raise BooleanOperationError(self)\n-    def __invert__(self):     raise BooleanOperationError(self)\n-    \n-    def __array_ufunc__(self, ufunc, method, *inputs, **kwargs):\n-        \"\"\" For almost everything else, behave like a normal NumPy array on Arr.values \"\"\"\n-        inputs = [x.values if isinstance(x, Arr) else x for x in inputs]\n-        return getattr(ufunc, method)(*inputs, **kwargs)\n-    \n-    @property\n-    def auids(self):\n-        \"\"\" Link to the indices of active agents -- sim.people.auids \"\"\"\n-        try:\n-            return self.people.auids\n-        except:\n-            ss.warn('Trying to access non-initialized States object')\n-            return uids(np.arange(len(self.raw)))\n-    \n-    def count(self):\n-        return np.count_nonzero(self.values)\n-\n-    @property\n-    def values(self):\n-        \"\"\" Return the values of the active agents \"\"\"\n-        return self.raw[self.auids]\n-\n-    def set(self, uids, new_vals=None):\n-        \"\"\" Set the values for the specified UIDs\"\"\"\n-        if new_vals is None: \n-            if isinstance(self.default, ss.Dist):\n-                new_vals = self.default.rvs(uids)\n-            elif callable(self.default):\n-                new_vals = self.default(len(uids))\n-            elif self.default is not None:\n-                new_vals = self.default\n-            else:\n-                new_vals = self.nan\n-        self.raw[uids] = new_vals\n-        return new_vals\n-    \n-    def set_nan(self, uids):\n-        \"\"\" Shortcut function to set values to NaN \"\"\"\n-        self.raw[uids] = self.nan\n-        return\n-    \n-    def grow(self, new_uids=None, new_vals=None):\n-        \"\"\"\n-        Add new agents to an Arr\n-\n-        This method is normally only called via `People.grow()`.\n-\n-        Args:\n-            new_uids: Numpy array of UIDs for the new agents being added\n-            new_vals: If provided, assign these state values to the new UIDs\n-        \"\"\"\n-        if new_uids is None and new_vals is not None: # Used as a shortcut to avoid needing to supply twice\n-            new_uids = new_vals\n-        orig_len = self.len_used\n-        n_new = len(new_uids)\n-        self.len_used += n_new  # Increase the count of the number of agents by `n` (the requested number of new agents)\n-        \n-        # Physically reshape the arrays, if needed\n-        if orig_len + n_new > self.len_tot:\n-            n_grow = max(n_new, self.len_tot//2)  # Minimum 50% growth, since growing arrays is slow\n-            new_empty = np.empty(n_grow, dtype=self.dtype) # 10x faster than np.zeros()\n-            self.raw = np.concatenate([self.raw, new_empty], axis=0)\n-            self.len_tot = len(self.raw)\n-            if n_grow > n_new: # We added extra space at the end, set to NaN\n-                nan_uids = np.arange(self.len_used, self.len_tot)\n-                self.set_nan(nan_uids)\n-        \n-        # Set new values, and NaN if needed\n-        self.set(new_uids, new_vals=new_vals) # Assign new default values to those agents\n-        return\n-    \n-    def link_people(self, people):\n-        \"\"\" Link a People object to this state, for access auids \"\"\"\n-        self.people = people # Link the people object to this state\n-        people._link_state(self) # Ensure the state is linked to the People object as well\n-        return\n-    \n-    def init_vals(self):\n-        \"\"\" Actually populate the initial values and mark as initialized; only to be used on initialization \"\"\"\n-        if self.initialized:\n-            errormsg = f'Cannot re-initialize state {self}; use set() instead'\n-            raise RuntimeError(errormsg)\n-        self.grow(self.people.uid)\n-        self.initialized = True\n-        return\n-\n-    def asnew(self, arr=None, cls=None):\n-        \"\"\" Duplicate and copy (rather than link) data, optionally resetting the array \"\"\"\n-        if cls is None:\n-            cls = self.__class__\n-        if arr is None:\n-            arr = self.values\n-        new = object.__new__(cls) # Create a new Arr instance\n-        new.__dict__ = self.__dict__.copy() # Copy pointers\n-        new.dtype = arr.dtype # Set to correct dtype\n-        new.raw = np.empty_like(new.raw, dtype=new.dtype) # Copy values, breaking reference\n-        new.raw[new.auids] = arr\n-        return new\n-\n-\n-class FloatArr(Arr):\n-    \"\"\" Subclass of Arr with defaults for floats \"\"\"\n-    def __init__(self, name, default=None, nan=np.nan, label=None, skip_init=False):\n-        super().__init__(name=name, dtype=ss_float, default=default, nan=nan, label=label, coerce=False, skip_init=skip_init)\n-        return\n-    \n-    @property\n-    def isnan(self):\n-        \"\"\" Return indices that are NaN \"\"\"\n-        return np.nonzero(np.isnan(self.values))[0]\n-\n-    @property\n-    def notnan(self):\n-        \"\"\" Return indices that are not-NaN \"\"\"\n-        return np.nonzero(~np.isnan(self.values))[0]\n-    \n-    @property\n-    def notnanvals(self):\n-        \"\"\" Return values that are not-NaN \"\"\"\n-        vals = self.values # Shorten and avoid double indexing\n-        out = vals[np.nonzero(~np.isnan(vals))[0]]\n-        return out\n-\n-    \n-class BoolArr(Arr):\n-    \"\"\" Subclass of Arr with defaults for booleans \"\"\"\n-    def __init__(self, name, default=None, nan=False, label=None, skip_init=False): # No good NaN equivalent for bool arrays\n-        super().__init__(name=name, dtype=ss_bool, default=default, nan=nan, label=label, coerce=False, skip_init=skip_init)\n-        return\n-    \n-    def __and__(self, other): return self.asnew(self.values & other)\n-    def __or__(self, other):  return self.asnew(self.values | other)\n-    def __xor__(self, other): return self.asnew(self.values ^ other)\n-    def __invert__(self):     return self.asnew(~self.values)\n-    \n-    @property\n-    def uids(self):\n-        \"\"\" Efficiently convert True values to UIDs \"\"\"\n-        return self.auids[np.nonzero(self.values)[0]]\n-\n-    def true(self):\n-        \"\"\" Alias to BoolArr.uids \"\"\"\n-        return self.uids\n-\n-    def false(self):\n-        \"\"\" Reverse of true(); return UIDs of values that are false \"\"\"\n-        return self.auids[np.nonzero(~self.values)[0]]\n-\n-    def split(self):\n-        \"\"\" Return UIDs of values that are true and false as separate arrays \"\"\"\n-        t_uids = self.true()\n-        f_uids = self.false()\n-        return t_uids, f_uids\n-\n-    \n-class IndexArr(Arr):\n-    \"\"\" A special class of IndexArr used for UIDs and RNG IDs \"\"\"\n-    def __init__(self, name, label=None):\n-        super().__init__(name=name, dtype=ss_int, default=None, nan=-1, label=label, coerce=False, skip_init=True)\n-        self.raw = uids(self.raw)\n-        return\n-    \n-    @property\n-    def uids(self):\n-        \"\"\" Alias to self.values, to allow Arr.uids like BoolArr \"\"\"\n-        return self.values\n-    \n-    @property\n-    def isnan(self):\n-        return np.nonzero(self.values == self.nan)[0]\n-\n-    @property\n-    def notnan(self):\n-        return np.nonzero(self.values != self.nan)[0]\n-    \n-    def grow(self, new_uids=None, new_vals=None):\n-        \"\"\" Change the size of the array \"\"\"\n-        super().grow(new_uids=new_uids, new_vals=new_vals)\n-        self.raw = uids(self.raw)\n-        return\n-    \n-    \n-class uids(np.ndarray):\n-    \"\"\"\n-    Class to specify that integers should be interpreted as UIDs.\n-    \n-    For all practical purposes, behaves like a NumPy integer array. However,\n-    has additional methods ``uids.concat()`` (instance method), ``ss.uids.cat()``\n-    (class method), ``uids.remove()``, and ``uids.intersect()`` to simplify common\n-    UID operations.    \n-    \"\"\"\n-    def __new__(cls, arr=None):\n-        if isinstance(arr, np.ndarray): # Shortcut to typical use case, where the input is an array\n-            return arr.astype(ss_int).view(cls)\n-        elif isinstance(arr, BoolArr): # Shortcut for arr.uids\n-            return arr.uids\n-        elif arr is None: # Shortcut to return empty\n-            return np.empty(0, dtype=ss_int).view(cls)\n-        elif isinstance(arr, int): # Convert e.g. ss.uids(0) to ss.uids([0])\n-            arr = [arr]\n-        return np.asarray(arr, dtype=ss_int).view(cls) # Handle everything else\n-    \n-    def concat(self, other, **kw): # TODO: why can't they both be called cat()?\n-        \"\"\" Equivalent to np.concatenate(), but return correct type \"\"\"\n-        return np.concatenate([self, other], **kw).view(self.__class__)\n-    \n-    @classmethod\n-    def cat(cls, *args, **kw):\n-        \"\"\" Equivalent to np.concatenate(), but return correct type \"\"\"\n-        arrs = args[0] if len(args) == 1 else args\n-        return np.concatenate(arrs, **kw).view(cls)\n-    \n-    def remove(self, other, **kw):\n-        \"\"\" Remove provided UIDs from current array\"\"\"\n-        return np.setdiff1d(self, other, assume_unique=True, **kw).view(self.__class__)\n-    \n-    def intersect(self, other, **kw):\n-        \"\"\" Keep only UIDs that match other array \"\"\"\n-        return np.intersect1d(self, other, assume_unique=True, **kw).view(self.__class__)\n-    \n-    def to_numpy(self):\n-        \"\"\" Convert to a standard NumPy array \"\"\"\n-        return np.array(self)\n-    \n-\n-class BooleanOperationError(NotImplementedError):\n-    \"\"\" Raised when a logical operation is performed on a non-logical array \"\"\"\n-    def __init__(self, arr):\n-        msg = f'Logical operations are only valid on Boolean arrays, not {arr.dtype}'\n-        super().__init__(msg)\n\\ No newline at end of file\ndiff --git a/starsim/time.py b/starsim/time.py\nnew file mode 100644\nindex 0000000..6e03a52\n--- /dev/null\n+++ b/starsim/time.py\n@@ -0,0 +1,916 @@\n+\"\"\"\n+Functions and classes for handling time\n+\"\"\"\n+import sciris as sc\n+import numpy as np\n+import pandas as pd\n+import datetime as dt\n+import dateutil as du\n+import starsim as ss\n+\n+\n+#%% Helper functions\n+\n+# Classes and objects that are externally visible\n+__all__ = ['time_units', 'time_ratio', 'date_add', 'date_diff']\n+\n+# Allowable time arguments\n+time_args = ['start', 'stop', 'dt', 'unit']\n+\n+# Define available time units\n+time_units = sc.objdict(\n+    day   = 1.0,\n+    week  = 7.0,\n+    month = 30.4375, # 365.25/12\n+    year  = 365.25, # For consistency with months\n+)\n+\n+# Define defaults\n+default_dur = 50\n+default_unit = 'year'\n+default_start_year = 2000\n+default_start_date = '2000-01-01'\n+default_start = sc.objdict(\n+    {k:default_start_date for k in ['day', 'week', 'month']} |\n+    {k:default_start_year for k in ['year', 'unitless']}\n+)\n+\n+\n+def time_ratio(unit1='day', dt1=1.0, unit2='day', dt2=1.0, as_int=False):\n+    \"\"\"\n+    Calculate the relationship between two sets of time factors\n+\n+    Args:\n+        unit1 (str): units for the numerator\n+        dt1 (float): timestep for the numerator\n+        unit2 (str): units for the denominator\n+        dt2 (float): timestep for the denominator\n+        as_int (bool): round and convert to an integer\n+\n+    **Example**::\n+        ss.time_ratio(unit1='week', dt1=2, unit2='day', dt2=1, as_int=True) # Returns 14\n+    \"\"\"\n+    if dt1 == dt2:\n+        dt_ratio = 1.0\n+    else:\n+        if dt1 is None or dt2 is None:\n+            errormsg = f'Cannot convert between dt when one is None ({dt1}, {dt2})'\n+            raise ValueError(errormsg)\n+        dt_ratio = dt1/dt2\n+\n+    if unit1 == unit2:\n+        unit_ratio = 1.0\n+    else:\n+        if is_unitless(unit1) or is_unitless(unit2):\n+            errormsg = f'Cannot convert between units if only one is unitless (unit1={unit1}, unit2={unit2})'\n+            raise ValueError(errormsg)\n+        if unit1 is None or unit2 is None:\n+            errormsg = f'Cannot convert between units when only one has been initialized (unit1={unit1}, unit2={unit2})'\n+            raise ValueError(errormsg)\n+        u1 = time_units[unit1]\n+        u2 = time_units[unit2]\n+        unit_ratio = u1/u2\n+\n+    factor = dt_ratio * unit_ratio\n+    if as_int:\n+        factor = int(round(factor))\n+    return factor\n+\n+\n+def date_add(start, dur, unit):\n+    \"\"\" Add two dates (or integers) together \"\"\"\n+    if sc.isnumber(start):\n+        stop = start + dur\n+    else:\n+        if unit in time_units:\n+            ndays = int(round(time_units[unit]*dur))\n+            stop = sc.datedelta(start, days=ndays)\n+        else:\n+            errormsg = f'Unknown unit {unit}, choices are: {sc.strjoin(time_units.keys())}'\n+            raise ValueError(errormsg)\n+    return stop\n+\n+\n+def date_diff(start, stop, unit):\n+    \"\"\" Find the difference between two dates (or integers) \"\"\"\n+    if sc.isnumber(start) and sc.isnumber(stop):\n+        dur = stop - start\n+    else:\n+        if unit == 'year':\n+            dur = sc.datetoyear(stop) - sc.datetoyear(start) # TODO: allow non-integer amounts\n+        else:\n+            dur = (ss.date(stop) - ss.date(start)).days\n+            if unit != 'day':\n+                dur *= time_ratio(unit1='day', unit2=unit)\n+    return dur\n+\n+\n+def round_tvec(tvec):\n+    \"\"\" Round time vectors to a certain level of precision, to avoid floating point errors \"\"\"\n+    decimals = int(-np.log10(ss.options.time_eps))\n+    tvec = np.round(np.array(tvec), decimals=decimals)\n+    return tvec\n+\n+\n+def years_to_dates(yearvec):\n+    \"\"\" Convert a numeric year vector to a date vector \"\"\"\n+    datevec = np.array([date(sc.datetoyear(y, reverse=True)) for y in yearvec])\n+    return datevec\n+\n+\n+def dates_to_years(datevec):\n+    \"\"\" Convert a date vector to a numeric year vector\"\"\"\n+    yearvec = round_tvec([sc.datetoyear(d.date()) for d in datevec])\n+    return yearvec\n+\n+\n+def dates_to_days(datevec, start_date):\n+    \"\"\" Convert a date vector into relative days since start date \"\"\"\n+    start_date = date(start_date)\n+    dayvec = np.array([(d - start_date).days for d in datevec])\n+    return dayvec\n+\n+\n+#%% Time classes\n+\n+__all__ += ['date', 'Time']\n+\n+\n+class date(pd.Timestamp):\n+    \"\"\"\n+    Define a single date; based on ``pd.Timestamp``\n+\n+    Args:\n+        date (int/float/str/datetime): Any type of date input (ints and floats will be interpreted as years)\n+        kwargs (dict): passed to pd.Timestamp()\n+\n+    **Examples**::\n+\n+        ss.date(2020) # Returns <2020-01-01>\n+        ss.date(year=2020) # Returns <2020-01-01>\n+        ss.date(year=2024.75) # Returns <2024-10-01>\n+        ss.date('2024-04-04') # Returns <2024-04-04>\n+        ss.date(year=2024, month=4, day=4) # Returns <2024-04-04>\n+    \"\"\"\n+    def __new__(cls, *args, **kwargs):\n+        # Check if a year was supplied, and preprocess it\n+        single_year_arg = False\n+        if len(args) == 1:\n+            arg = args[0]\n+            if arg is None:\n+                return pd.Timestamp(None)\n+            elif sc.isnumber(arg):\n+                single_year_arg = True\n+            elif isinstance(arg, pd.Timedelta):\n+                return pd.Timedelta(arg)\n+        year_kwarg = len(args) == 0 and len(kwargs) == 1 and 'year' in kwargs\n+        if single_year_arg:\n+            return cls.from_year(args[0])\n+        if year_kwarg:\n+            return cls.from_year(kwargs['year'])\n+\n+        # Otherwise, proceed as normal\n+        out = super(date, cls).__new__(cls, *args, **kwargs)\n+        out = cls._reset_class(out)\n+        return out\n+\n+    @classmethod\n+    def _reset_class(cls, obj):\n+        \"\"\" Manually reset the class from pd.Timestamp to ss.date \"\"\"\n+        try:\n+            obj.__class__ = date\n+        except:\n+            warnmsg = f'Unable to convert {out} to ss.date(); proceeding with pd.Timestamp'\n+            ss.warn(warnmsg)\n+        return obj\n+\n+    def __repr__(self, bracket=True):\n+        \"\"\" Show the date in brackets, e.g. <2024.04.04> \"\"\"\n+        _ = ss.options.date_sep\n+        y = f'{self.year:04d}'\n+        m = f'{self.month:02d}'\n+        d = f'{self.day:02d}'\n+        string = y + _ + m + _ + d\n+        if bracket:\n+            string = '<' + string + '>'\n+        return string\n+\n+    def __str__(self):\n+        \"\"\" Like repr, but just the date, e.g. 2024.04.04 \"\"\"\n+        return self.__repr__(bracket=False)\n+\n+    def disp(self, **kwargs):\n+        \"\"\" Show the full object \"\"\"\n+        return sc.pr(self, **kwargs)\n+\n+    @classmethod\n+    def from_year(cls, year):\n+        \"\"\"\n+        Convert an int or float year to a date.\n+\n+        **Examples**::\n+\n+            ss.date.from_year(2020) # Returns <2020-01-01>\n+            ss.date.from_year(2024.75) # Returns <2024-10-01>\n+        \"\"\"\n+        if isinstance(year, int):\n+            return cls(year=year, month=1, day=1)\n+        else:\n+            dateobj = sc.datetoyear(year, reverse=True)\n+            return cls(dateobj)\n+\n+    def to_year(self):\n+        \"\"\"\n+        Convert a date to a floating-point year\n+\n+        **Examples**::\n+\n+            ss.date('2020-01-01').to_year() # Returns 2020.0\n+            ss.date('2024-10-01').to_year() # Returns 2024.7486\n+        \"\"\"\n+        return sc.datetoyear(self.date())\n+\n+    def to_pandas(self):\n+        \"\"\" Convert to a standard pd.Timestamp instance \"\"\"\n+        return pd.Timestamp(self.to_numpy()) # Need to convert to NumPy first or it doesn't do anything\n+\n+    @staticmethod\n+    def _convert_other(other):\n+        if isinstance(other, du.relativedelta.relativedelta):\n+            tu = ss.time.time_units\n+            days = other.days + tu.month*other.months + tu.year*other.years\n+            int_days = int(round(days))\n+            other = dt.timedelta(days=int_days)\n+        elif isinstance(other, ss.dur):\n+            factor = ss.time.time_units[other.unit]\n+            int_days = int(round(factor*other.v))\n+            other = dt.timedelta(days=int_days)\n+        return other\n+\n+    def __add__(self, other):\n+        other = self._convert_other(other)\n+        out = super().__add__(other)\n+        out = date(out)\n+        return out\n+\n+    def __sub__(self, other):\n+        other = self._convert_other(other)\n+        out = super().__sub__(other)\n+        out = date(out)\n+        return out\n+\n+    def __radd__(self, other): return self.__add__(other)\n+    def __iadd__(self, other): return self.__add__(other)\n+    def __rsub__(self, other): return self.__sub__(other) # TODO: check if this should be reversed\n+    def __isub__(self, other): return self.__sub__(other)\n+\n+\n+class Time(sc.prettyobj):\n+    \"\"\"\n+    Handle time vectors for both simulations and modules.\n+\n+    Args:\n+        start (float/str/date): the start date for the simulation/module\n+        stop (float/str/date): the end date for the simulation/module\n+        dt (float): the step size, in units of \"unit\"\n+        unit (str): the time unit; choices are \"day\", \"week\", \"month\", \"year\", or \"unitless\"\n+        pars (dict): if provided, populate parameter values from this dictionary\n+        parent (obj): if provided, populate missing parameter values from a 'parent\" ``Time`` instance\n+        name (str): if provided, name the ``Time`` object\n+        init (bool): whether or not to immediately initialize the Time object\n+        sim (bool/Sim): if True, initializes as a sim-specific ``Time`` instance; if a Sim instance, initialize the absolute time vector\n+\n+    The ``Time`` object, after initialization, has the following attributes:\n+\n+    - ``ti`` (int): the current timestep\n+    -  ``dt_year`` (float): the timestep in units of years\n+    - ``npts`` (int): the number of timesteps\n+    - ``tvec`` (array): time starting at 0, in self units (e.g. ``[0, 0.1, 0.2, ... 10.0]`` if start=0, stop=10, dt=0.1)\n+    - ``absvec`` (array): time relative to sim start, in units of sim units (e.g. ``[366, 373, 380, ...]`` if sim-start=2001, start=2002, sim-unit='day', unit='week')\n+    - ``yearvec`` (array): time represented as floating-point years (e.g. ``[2000, 2000.1, 2000.2, ... 2010.0]`` if start=2000, stop=2010, dt=0.1)\n+    - ``datevec`` (array): time represented as an array of ``ss.date`` objects (e.g. ``[<2000.01.01>, <2000.02.07>, ... <2010.01.01>]`` if start=2000, stop=2010, dt=0.1)\n+    - ``timevec`` (array): the \"native\" time vector, which always matches one of ``tvec``, ``yearvec``, or ``datevec``\n+\n+    **Examples**::\n+\n+        t1 = ss.Time(start=2000, stop=2020, dt=1.0, unit='year') # Years, numeric units\n+        t2 = ss.Time(start='2021-01-01', stop='2021-04-04', dt=2.0, unit='day') # Days, date units\n+    \"\"\"\n+    def __init__(self, start=None, stop=None, dt=None, unit=None, pars=None, parent=None,\n+                 name=None, init=True, sim=None):\n+        self.name = name\n+        self.start = start\n+        self.stop = stop\n+        self.dt = dt\n+        self.unit = unit\n+        self.ti = 0 # The time index, e.g. 0, 1, 2\n+\n+        # Prepare for later initialization\n+        self.dt_year = None\n+        self.npts    = None\n+        self.tvec    = None\n+        self.timevec = None\n+        self.datevec = None\n+        self.yearvec = None\n+        self.abstvec = None\n+        self.initialized = False\n+\n+        # Finalize\n+        self.update(pars=pars, parent=parent)\n+        if init and self.ready:\n+            self.init(sim=sim)\n+        return\n+\n+    def __bool__(self):\n+        \"\"\" Always truthy \"\"\"\n+        return True\n+\n+    def __len__(self):\n+        \"\"\" Length is the number of timepoints \"\"\"\n+        return sc.ifelse(self.npts, 0)\n+\n+    @property\n+    def ready(self):\n+        \"\"\" Check if all parameters are in place to be initialized \"\"\"\n+        return not any([getattr(self, k) is None for k in time_args])\n+\n+    @property\n+    def is_numeric(self):\n+        \"\"\" Check whether the fundamental simulation unit is numeric (as opposed to date-based) \"\"\"\n+        try:\n+            return sc.isnumber(self.start)\n+        except:\n+            return False\n+\n+    @property\n+    def is_unitless(self):\n+        return is_unitless(self.unit)\n+\n+    def __setstate__(self, state):\n+        \"\"\" Custom setstate to unpickle ss.date() instances correctly \"\"\"\n+        self.__dict__.update(state)\n+        self._convert_timestamps()\n+        return\n+\n+    def _convert_timestamps(self):\n+        \"\"\" Replace pd.Timestamp instances with ss.date(); required due to pandas limitations with pickling \"\"\"\n+        objs = [self.start, self.stop]\n+        objs += sc.tolist(self.datevec, coerce='full')\n+        objs += sc.tolist(self.timevec, coerce='full')\n+        objs = [obj for obj in objs if type(obj) == pd.Timestamp]\n+        for obj in objs:\n+            date._reset_class(obj)\n+        return\n+\n+    def update(self, pars=None, parent=None, reset=True, force=None, **kwargs):\n+        \"\"\" Reconcile different ways of supplying inputs \"\"\"\n+        pars = sc.mergedicts(pars)\n+        stale = False\n+\n+        for key in time_args:\n+            current_val = getattr(self, key, None)\n+            parent_val = getattr(parent, key, None)\n+            kw_val = kwargs.get(key)\n+            par_val = pars.get(key)\n+\n+            # Special handling for dt: don't inherit dt if the units are different\n+            if key == 'dt':\n+                if isinstance(parent, Time):\n+                    if parent.unit != self.unit:\n+                        parent_val = 1.0\n+\n+            if force is False: # Only update missing (None) values\n+                val = sc.ifelse(current_val, kw_val, par_val, parent_val)\n+            elif force is None: # Prioritize current value\n+                val = sc.ifelse(kw_val, par_val, current_val, parent_val)\n+            elif force is True: # Prioritize parent value\n+                val = sc.ifelse(kw_val, par_val, parent_val, current_val)\n+            else:\n+                errormsg = f'Invalid value {force} for force: must be False, None, or True'\n+                raise ValueError(errormsg)\n+\n+            if val != current_val:\n+                setattr(self, key, val)\n+                stale = True\n+\n+        if stale and reset and self.initialized:\n+            self.init()\n+        return\n+\n+    def init(self, sim=None):\n+        \"\"\" Initialize all vectors \"\"\"\n+        # Initial validation\n+        self.unit = validate_unit(self.unit)\n+\n+        # Copy missing values from sim\n+        if isinstance(sim, ss.Sim):\n+            self.unit = sc.ifelse(self.unit, sim.t.unit)\n+            if self.unit == sim.t.unit: # Units match, use directly\n+                sim_dt = sim.t.dt\n+                sim_start = sim.t.start\n+                sim_stop = sim.t.stop\n+            else: # Units don't match, use datevec instead\n+                sim_dt = 1.0 # Don't try to reset the dt if the units don't match\n+                sim_start = sim.t.datevec[0]\n+                sim_stop = sim.t.datevec[-1]\n+            self.dt = sc.ifelse(self.dt, sim_dt)\n+            self.start = sc.ifelse(self.start, sim_start)\n+            self.stop = sc.ifelse(self.stop, sim_stop)\n+\n+        # Handle start and stop\n+        self.start = self.start if self.is_numeric else date(self.start)\n+        self.stop  = self.stop  if self.is_numeric else date(self.stop)\n+\n+        # Convert start and stop to dates\n+        date_start = self.start\n+        date_stop = self.stop\n+        date_unit = 'year' if not has_units(self.unit) else self.unit # Use year by default\n+        dt_year = time_ratio(unit1=date_unit, dt1=self.dt, unit2='year', dt2=1.0) # Timestep in units of years\n+        offset = 0\n+        if self.is_numeric and date_start == 0:\n+            date_start = ss.date(ss.time.default_start[date_unit])\n+            date_stop = date_start + ss.dur(date_stop, unit=date_unit)\n+            offset = date_start.year\n+\n+        # If numeric, treat that as the ground truth\n+        if self.is_numeric:\n+            ratio = time_ratio(unit1=date_unit, unit2='year')\n+            timevec = round_tvec(sc.inclusiverange(self.start, self.stop, self.dt))\n+            yearvec = round_tvec((timevec-timevec[0])*ratio + offset + timevec[0]) # TODO: simplify\n+            datevec = years_to_dates(yearvec)\n+\n+        # If unitless, just use that\n+        elif self.is_unitless:\n+            timevec = round_tvec(sc.inclusiverange(self.start, self.stop, self.dt))\n+            yearvec = round_tvec(timevec)\n+            datevec = timevec\n+\n+        # If the unit is years, handle that\n+        elif date_unit == 'year': # For years, the yearvec is the most robust representation\n+            start_year = sc.datetoyear(date_start.date())\n+            stop_year = sc.datetoyear(date_stop.date())\n+            yearvec = round_tvec(sc.inclusiverange(start_year, stop_year, self.dt))\n+            datevec = years_to_dates(yearvec)\n+            timevec = datevec\n+\n+        # Otherwise, use dates as the ground truth\n+        else:\n+            if int(self.dt) == self.dt: # The step is integer-like, use exactly\n+                key = date_unit + 's' # e.g. day -> days\n+                datelist = sc.daterange(date_start, date_stop, interval={key:int(self.dt)})\n+            else: # Convert to the sim unit instead\n+                day_delta = time_ratio(unit1=date_unit, dt1=self.dt, unit2='day', dt2=1.0, as_int=True)\n+                if day_delta >= 1:\n+                    datelist = sc.daterange(date_start, date_stop, interval={'days':day_delta})\n+                else:\n+                    errormsg = f'Timestep {dt} is too small; must be at least 1 day'\n+                    raise ValueError(errormsg)\n+            datevec = np.array([ss.date(d) for d in datelist])\n+            yearvec = dates_to_years(datevec)\n+            timevec = datevec\n+\n+        # Store things\n+        self.dt_year = dt_year\n+        self.npts = len(timevec) # The number of points in the sim\n+        self.tvec = round_tvec(np.arange(self.npts)*self.dt) # Absolute time array\n+        self.timevec = timevec\n+        self.datevec = datevec\n+        self.yearvec = yearvec\n+        if sim == True: # It's the sim itself, the tvec is the absolute time vector\n+            self.abstvec = self.tvec\n+        elif sim is not None:\n+            self.make_abstvec(sim)\n+        else:\n+            self.abstvec = None # Intentionally set to None, cannot be used in the sim loop until populated\n+        self.initialized = True\n+        return\n+\n+    def make_abstvec(self, sim):\n+        \"\"\" Convert the current time vector into sim units \"\"\"\n+        # Validation\n+        if self.is_unitless != sim.t.is_unitless:\n+            errormsg = f'Cannot mix units with unitless time: sim.unit={sim.t.unit} {self.name}.unit={self.unit}'\n+            raise ValueError(errormsg)\n+\n+        # Both are unitless or numeric\n+        both_unitless = self.is_unitless and sim.t.is_unitless\n+        both_numeric = self.is_numeric and sim.t.is_numeric\n+        if both_unitless or both_numeric:\n+            abstvec = self.tvec.copy() # Start by copying the current time vector\n+            ratio = time_ratio(unit1=self.unit, dt1=1.0, unit2=sim.t.unit, dt2=1.0) # tvec has sim units, but not dt\n+            if ratio != 1.0:\n+                abstvec *= ratio # TODO: CHECK\n+            start_diff = self.start - sim.t.start\n+            if start_diff != 0.0:\n+                abstvec += start_diff\n+\n+        # The sim uses years; use yearvec\n+        elif sim.t.unit == 'year':\n+            abstvec = self.yearvec.copy()\n+            abstvec -= sim.t.yearvec[0] # Start relative to sim start\n+\n+        # Otherwise (days, weeks, months), use datevec and convert to days\n+        else:\n+            dayvec = dates_to_days(self.datevec, start_date=sim.t.datevec[0])\n+            ratio = time_ratio(unit1='day', dt1=1.0, unit2=sim.t.unit, dt2=1.0)\n+            abstvec = dayvec*ratio # Convert into sim time units\n+\n+        self.abstvec = round_tvec(abstvec) # Avoid floating point inconsistencies\n+        return\n+\n+    def now(self, key=None):\n+        \"\"\"\n+        Get the current simulation time\n+\n+        Args:\n+            which (str): which type of time to get: default (None), \"year\", \"date\", \"tvec\", or \"str\"\n+\n+        **Examples**::\n+\n+            t = ss.Time(start='2021-01-01', stop='2022-02-02', dt=1, unit='week')\n+            t.ti = 25\n+            t.now() # Returns <2021-06-25>\n+            t.now('date') # Returns <2021-06-25>\n+            t.now('year') # Returns 2021.479\n+            t.now('str') # Returns '2021-06-25'\n+        \"\"\"\n+        if key in [None, 'none', 'time', 'str']:\n+            vec = self.timevec\n+        elif key == 'tvec':\n+            vec = self.tvec\n+        elif key == 'date':\n+            vec = self.datevec\n+        elif key == 'year':\n+            vec = self.yearvec\n+        else:\n+            errormsg = f'Invalid key \"{key}\": must be None, abs, date, or year'\n+            raise ValueError(errormsg)\n+\n+        now = vec[min(self.ti, len(vec)-1)]\n+        if key == 'str':\n+            now = f'{now:0.1f}' if isinstance(now, float) else str(now)\n+        return now\n+\n+\n+#%% TimePar classes\n+\n+__all__ += ['TimePar', 'dur', 'days', 'years', 'rate', 'perday', 'peryear',\n+            'time_prob', 'beta', 'rate_prob']\n+\n+class TimePar(ss.BaseArr):\n+    \"\"\"\n+    Base class for time-aware parameters, durations and rates\n+\n+    NB, because the factor needs to be recalculated, do not set values directly.\n+    \"\"\"\n+    def __new__(cls, v=None, *args, **kwargs):\n+        \"\"\" Allow TimePars to wrap distributions and return the distributions \"\"\"\n+\n+        # Special distribution handling\n+        if isinstance(v, ss.Dist):\n+            if len(args):\n+                errormsg = f'When wrapping a distribution with a TimePar, args not allowed ({args}); use kwargs'\n+                raise ValueError(errormsg)\n+            dist = v\n+            dist.pars[0] = cls(dist.pars[0], **kwargs) # Convert the first parameter to a TimePar (the same scale is applied to all parameters)\n+            return dist\n+\n+        # Otherwise, do the usual initialization\n+        else:\n+            return super().__new__(cls)\n+\n+    def __init__(self, v, unit=None, parent_unit=None, parent_dt=None, self_dt=1.0):\n+        self.v = v\n+        self.unit = unit\n+        self.parent_unit = parent_unit\n+        self.parent_dt = parent_dt\n+        self.self_dt = self_dt\n+        self.factor = None\n+        self.values = None\n+        self.initialized = False\n+        self.validate_units()\n+        return\n+\n+    def validate_units(self):\n+        \"\"\" Check that the units entered are valid \"\"\"\n+        try:\n+            self.unit = unit_mapping[self.unit]\n+        except KeyError:\n+            errormsg = f'Invalid unit \"{self.unit}\"; must be one of: {sc.strjoin(time_units.keys())}'\n+            raise ValueError(errormsg)\n+        try:\n+            self.parent_unit = unit_mapping[self.parent_unit]\n+        except KeyError:\n+            errormsg = f'Invalid parent unit \"{self.parent_unit}\"; must be one of: {sc.strjoin(time_units.keys())}'\n+            raise ValueError(errormsg)\n+        return\n+\n+    def init(self, parent=None, parent_unit=None, parent_dt=None, update_values=True, die=True):\n+        \"\"\" Link to the sim and/or module units \"\"\"\n+        if parent is None:\n+            parent = sc.dictobj(unit=parent_unit, dt=parent_dt)\n+        else:\n+            if parent_dt is not None:\n+                errormsg = f'Cannot override parent {parent} by setting parent_dt; set in parent object instead'\n+                raise ValueError(errormsg)\n+\n+        if parent.unit is not None:\n+            self.parent_unit = parent.unit\n+\n+        if parent.dt is not None:\n+            self.parent_dt = parent.dt\n+\n+        # Set defaults if not yet set\n+        self.unit = sc.ifelse(self.unit, self.parent_unit) # If unit isn't defined but parent is, set to parent\n+        self.parent_unit = sc.ifelse(self.parent_unit, self.unit) # If parent isn't defined but unit is, set to self\n+        self.parent_dt = sc.ifelse(self.parent_dt, self.self_dt, 1.0) # If dt isn't defined, assume 1 (self_dt is defined by default)\n+\n+        # Calculate the actual conversion factor to be used in the calculations\n+        self.update_cached(update_values=update_values, die=die)\n+        self.initialized = True\n+        self.validate_units()\n+        return self\n+\n+    def __repr__(self):\n+        name = self.__class__.__name__\n+\n+        if self.initialized:\n+            if self.factor == 1.0:\n+                xstr = ''\n+            else:\n+                xstr = f', values={self.values}'\n+        else:\n+            xstr = ', initialized=False'\n+\n+        if (self.parent_unit is not None) and (self.unit != self.parent_unit):\n+            parentstr = f', parent={self.parent_unit}'\n+        else:\n+            parentstr = ''\n+\n+        default_dt = sc.ifelse(self.self_dt, 1.0) == 1.0\n+        if not default_dt:\n+            dtstr = f', self_dt={self.self_dt}'\n+        else:\n+            dtstr = ''\n+\n+        # Rather than ss.dur(3, unit='day'), dispaly as ss.days(3)\n+        prefixstr = 'ss.'\n+        key = (name, self.unit)\n+        mapping = {\n+            ('dur',  'day'):  'days',\n+            ('dur',  'year'): 'years',\n+            ('rate', 'day'):  'perday',\n+            ('rate', 'year'): 'peryear',\n+        }\n+\n+        if key in mapping and default_dt:\n+            prefixstr += mapping[key]\n+            unitstr = ''\n+        else:\n+            prefixstr += name\n+            unitstr = f', unit={self.unit}'\n+\n+        suffixstr = unitstr + parentstr + dtstr + xstr\n+\n+        return f'{prefixstr}({self.v}{suffixstr})'\n+\n+    @property\n+    def isarray(self):\n+        \"\"\" Check if the value is an array \"\"\"\n+        return isinstance(self.v, np.ndarray)\n+\n+    def set(self, v=None, unit=None, parent_unit=None, parent_dt=None, self_dt=None, force=False):\n+        \"\"\" Set the specified parameter values (ignoring None values) and update stored values \"\"\"\n+        if v           is not None: self.v           = v\n+        if unit        is not None: self.unit        = unit\n+        if parent_unit is not None: self.parent_unit = parent_unit\n+        if parent_dt   is not None: self.parent_dt   = parent_dt\n+        if self_dt     is not None: self.self_dt     = self_dt\n+        if self.initialized or force: # Don't try to set these unless it's been initialized\n+            self.update_cached()\n+        self.validate_units()\n+        return self\n+\n+    def update_cached(self, update_values=True, die=True):\n+        \"\"\" Update the cached factor and values \"\"\"\n+        try:\n+            self.update_factor()\n+            if update_values:\n+                self.update_values()\n+        except TypeError as E: # For a known error, skip silently if die=False\n+            if die:\n+                errormsg = f'Update failed for {self}. Argument v={self.v} should be a number or array; if a function, use update_values=False. Error: {E}'\n+                raise TypeError(errormsg) from E\n+        except Exception as E: # For other errors, raise a warning\n+            if die:\n+                raise E\n+            else:\n+                tb = sc.traceback(E)\n+                warnmsg = f'Uncaught error encountered while updating {self}, but die=False. Traceback:\\n{tb}'\n+                ss.warn(warnmsg)\n+\n+        return self\n+\n+    def update_factor(self):\n+        \"\"\" Set factor used to multiply the value to get the output \"\"\"\n+        self.factor = time_ratio(unit1=self.unit, dt1=self.self_dt, unit2=self.parent_unit, dt2=self.parent_dt)\n+        return\n+\n+    def update_values(self):\n+        \"\"\" Convert from self.v to self.values based on self.factor -- must be implemented by derived classes \"\"\"\n+        raise NotImplementedError\n+\n+    def to(self, unit=None, dt=None):\n+        \"\"\" Create a new timepar based on the current one but with a different unit and/or dt \"\"\"\n+        new = self.asnew()\n+        unit = sc.ifelse(unit, self.parent_unit, self.unit)\n+        parent_dt = sc.ifelse(dt, 1.0)\n+        new.factor = time_ratio(unit1=self.unit, dt1=self.self_dt, unit2=unit, dt2=parent_dt) # Calculate the new factor\n+        new.update_values() # Update values\n+        new.v = new.values # Reset the base value\n+        new.factor = 1.0 # Reset everything else to be 1\n+        new.unit = unit\n+        new.self_dt = parent_dt\n+        new.parent_unit = unit\n+        new.parent_dt = parent_dt\n+        return new\n+\n+    def to_parent(self):\n+        \"\"\" Create a new timepar with the same units as the parent \"\"\"\n+        unit = self.parent_unit\n+        dt = self.parent_dt\n+        return self.to(unit=unit, dt=dt)\n+\n+    def to_json(self):\n+        \"\"\" Export to JSON \"\"\"\n+        attrs = ['v', 'unit', 'parent_unit', 'parent_dt', 'self_dt', 'factor']\n+        out = {'classname': self.__class__.__name__}\n+        out.update({attr:getattr(self, attr) for attr in attrs})\n+        out['values'] = sc.jsonify(self.values)\n+        return out\n+\n+    # Act like a float -- TODO, add type checking\n+    def __add__(self, other): return self.values + other\n+    def __sub__(self, other): return self.values - other\n+    def __mul__(self, other): return self.asnew().set(v=self.v * other)\n+    def __pow__(self, other): return self.values ** other\n+    def __truediv__(self, other): return self.asnew().set(v=self.v / other)\n+\n+    # ...from either side\n+    def __radd__(self, other): return other + self.values\n+    def __rsub__(self, other): return other - self.values\n+    def __rmul__(self, other): return self.asnew().set(v= other * self.v)\n+    def __rpow__(self, other): return other ** self.values\n+    def __rtruediv__(self, other): return other / self.values # TODO: should be a rate?\n+\n+    # Handle modify-in-place methods\n+    def __iadd__(self, other): return self.set(v=self.v + other)\n+    def __isub__(self, other): return self.set(v=self.v - other)\n+    def __imul__(self, other): return self.set(v=self.v * other)\n+    def __itruediv__(self, other): return self.set(v=self.v / other)\n+\n+    # Other methods\n+    def __neg__(self): return self.asnew().set(v=-self.v)\n+\n+\n+class dur(TimePar):\n+    \"\"\" Any number that acts like a duration \"\"\"\n+    def update_values(self):\n+        self.values = self.v*self.factor\n+        return self.values\n+\n+\n+def days(v, parent_unit=None, parent_dt=None):\n+    \"\"\" Shortcut to ss.dur(value, units='day') \"\"\"\n+    return dur(v=v, unit='day', parent_unit=parent_unit, parent_dt=parent_dt)\n+\n+\n+def years(v, parent_unit=None, parent_dt=None):\n+    \"\"\" Shortcut to ss.dur(value, units='year') \"\"\"\n+    return dur(v=v, unit='year', parent_unit=parent_unit, parent_dt=parent_dt)\n+\n+\n+class rate(TimePar):\n+    \"\"\" Any number that acts like a rate; can be greater than 1 \"\"\"\n+    def update_values(self):\n+        self.values = self.v/self.factor\n+        return self.values\n+\n+\n+def perday(v, parent_unit=None, parent_dt=None):\n+    \"\"\" Shortcut to ss.rate(value, units='day') \"\"\"\n+    return rate(v=v, unit='day', parent_unit=parent_unit, parent_dt=parent_dt)\n+\n+\n+def peryear(v, parent_unit=None, parent_dt=None):\n+    \"\"\" Shortcut to ss.rate(value, units='year') \"\"\"\n+    return rate(v=v, unit='year', parent_unit=parent_unit, parent_dt=parent_dt)\n+\n+\n+class time_prob(TimePar):\n+    \"\"\"\n+    A probability over time (a.k.a. a cumulative hazard rate); must be >=0 and <=1.\n+\n+    Note: ``ss.time_prob()`` converts one cumulative hazard rate to another with a\n+    different time unit. ``ss.rate_prob()`` converts an exponential rate to a cumulative\n+    hazard rate.\n+    \"\"\"\n+    def update_values(self):\n+        v = self.v\n+        if self.isarray:\n+            self.values = v.copy()\n+            inds = np.logical_and(0.0 < v, v < 1.0)\n+            if inds.sum():\n+                rates = -np.log(1 - v[inds])\n+                self.values[inds] = 1 - np.exp(-rates/self.factor)\n+            invalid = np.logical_or(v < 0.0, 1.0 < v)\n+            if invalid.sum():\n+                errormsg = f'Invalid value {self.v} for {self}: must be 0-1. If using in a calculation, use .values instead.'\n+                raise ValueError(errormsg)\n+        else:\n+            if v == 0:\n+                self.values = 0\n+            elif v == 1:\n+                self.values = 1\n+            elif 0 <= v <= 1:\n+                rate = -np.log(1 - v)\n+                self.values = 1 - np.exp(-rate/self.factor)\n+            else:\n+                errormsg = f'Invalid value {self.v} for {self}: must be 0-1. If using in a calculation, use .values instead.'\n+                raise ValueError(errormsg)\n+        return self.values\n+\n+\n+class rate_prob(TimePar):\n+    \"\"\"\n+    An instantaneous rate converted to a probability; must be >=0.\n+\n+    Note: ``ss.time_prob()`` converts one cumulative hazard rate to another with a\n+    different time unit. ``ss.rate_prob()`` converts an exponential rate to a cumulative\n+    hazard rate.\n+    \"\"\"\n+    def update_values(self):\n+        v = self.v\n+        if self.isarray:\n+            self.values = v.copy()\n+            inds = v > 0.0\n+            if inds.sum():\n+                self.values[inds] = 1 - np.exp(-v[inds]/self.factor)\n+            invalid = v < 0.0\n+            if invalid.sum():\n+                errormsg = f'Invalid value {self.v} for {self}: must be >=0. If using in a calculation, use .values instead.'\n+                raise ValueError(errormsg)\n+        else:\n+            if v == 0:\n+                self.values = 0\n+            elif v > 0:\n+                self.values = 1 - np.exp(-v/self.factor)\n+            else:\n+                errormsg = f'Invalid value {self.value} for {self}: must be >=0. If using in a calculation, use .values instead.'\n+                raise ValueError(errormsg)\n+        return self.values\n+\n+\n+class beta(time_prob):\n+    \"\"\" A container for beta (i.e. the disease transmission rate) \"\"\"\n+    pass\n+\n+\n+#%% Unit handling\n+\n+# Map different units onto the time units -- placed at the end to include the functions\n+unit_mapping_reverse = {\n+    None: [None],\n+    'unitless': ['unitless', 'none'],\n+    'day': ['d', 'day', 'days', 'perday', days, perday],\n+    'year': ['y', 'yr', 'year', 'years', 'peryear', years, peryear],\n+    'week': ['w', 'wk', 'week', 'weeks'],\n+    'month': ['m', 'mo', 'month', 'months'],\n+}\n+unit_mapping = {v:k for k,vlist in unit_mapping_reverse.items() for v in vlist}\n+\n+\n+def validate_unit(unit):\n+    \"\"\" Check that the unit is valid, and convert to a standard type \"\"\"\n+    try:\n+        unit = unit_mapping[unit]\n+    except KeyError as E:\n+        errormsg = f'Invalid unit \"{unit}\". Valid units are:\\n{sc.pp(unit_mapping_reverse, output=True)}'\n+        raise sc.KeyNotFoundError(errormsg) from E\n+    return unit\n+\n+\n+def is_unitless(unit):\n+    \"\"\" Check if explicitly unitless (excludes None; use not has_units() for that) \"\"\"\n+    return unit in unit_mapping_reverse['unitless']\n+\n+\n+def has_units(unit):\n+    \"\"\" Check that the unit is valid and is not unitless or None \"\"\"\n+    unit = validate_unit(unit)\n+    if unit is None:\n+        return False\n+    elif is_unitless(unit):\n+        return False\n+    else:\n+        return True\ndiff --git a/starsim/utils.py b/starsim/utils.py\nindex 3ec4cd9..fc5972e 100644\n--- a/starsim/utils.py\n+++ b/starsim/utils.py\n@@ -1,18 +1,19 @@\n \"\"\"\n Numerical utilities\n \"\"\"\n-\n import warnings\n import numpy as np\n-import sciris as sc\n-import starsim as ss\n import numba as nb\n import pandas as pd\n+import sciris as sc\n+import matplotlib.pyplot as plt\n+import starsim as ss\n \n # %% Helper functions\n \n-# What functions are externally visible -- note, this gets populated in each section below\n-__all__ = ['ndict', 'warn', 'unique', 'find_contacts']\n+# What functions are externally visible\n+__all__ = ['ndict', 'warn', 'find_contacts', 'set_seed', 'check_requires', 'standardize_netkey',\n+           'standardize_data', 'validate_sim_data', 'return_fig']\n \n \n class ndict(sc.objdict):\n@@ -40,7 +41,7 @@ class ndict(sc.objdict):\n         self.setattribute('_overwrite', overwrite)\n         self.extend(*args, **kwargs)\n         return\n-    \n+\n     def __call__(self):\n         \"\"\" Shortcut for returning values \"\"\"\n         return self.values()\n@@ -76,8 +77,8 @@ class ndict(sc.objdict):\n         else:\n             errormsg = f'Could not interpret argument {arg}: does not have expected attribute \"{self._nameattr}\"'\n             raise TypeError(errormsg)\n-        return\n-    \n+        return self\n+\n     def _check_key(self, key, overwrite=None):\n         if overwrite is None: overwrite = self._overwrite\n         if key in self:\n@@ -88,11 +89,11 @@ class ndict(sc.objdict):\n             else:\n                 ss.warn(f'Overwriting existing ndict entry \"{key}\"')\n         return\n-    \n+\n     def _check_type(self, arg):\n         \"\"\" Check types \"\"\"\n         if self._type is not None:\n-            if not isinstance(arg, self._type):\n+            if not isinstance(arg, self._type) and not isinstance(arg, ss.Module): # Module is a valid argument anywhere\n                 errormsg = f'The following item does not have the expected type {self._type}:\\n{arg}'\n                 raise TypeError(errormsg)\n         return\n@@ -104,28 +105,35 @@ class ndict(sc.objdict):\n             self.append(arg)\n         for key, arg in kwargs.items():\n             self.append(arg, key=key)\n-        return\n+        return self\n+\n+    def merge(self, other):\n+        \"\"\" Merge another dictionary with this one \"\"\"\n+        for key, arg in other.items():\n+            self.append(arg, key=key)\n+        return self\n \n     def copy(self):\n+        \"\"\" Shallow copy \"\"\"\n         new = self.__class__.__new__(nameattr=self._nameattr, type=self._type, strict=self._strict)\n         new.update(self)\n         return new\n \n-    def __add__(self, dict2):\n+    def __add__(self, other):\n         \"\"\" Allow c = a + b \"\"\"\n         new = self.copy()\n-        if isinstance(dict2, list):\n-            new.extend(dict2)\n+        if isinstance(other, list):\n+            new.extend(other)\n         else:\n-            new.append(dict2)\n+            new.append(other)\n         return new\n \n-    def __iadd__(self, dict2):\n+    def __iadd__(self, other):\n         \"\"\" Allow a += b \"\"\"\n-        if isinstance(dict2, list):\n-            self.extend(dict2)\n+        if isinstance(other, list):\n+            self.extend(other)\n         else:\n-            self.append(dict2)\n+            self.append(other)\n         return self\n \n \n@@ -159,18 +167,6 @@ def warn(msg, category=None, verbose=None, die=None):\n     return\n \n \n-def unique(arr):\n-    \"\"\"\n-    Find the unique elements and counts in an array.\n-    Equivalent to np.unique(return_counts=True) but ~5x faster, and\n-    only works for arrays of positive integers.\n-    \"\"\"\n-    counts = np.bincount(arr.ravel())\n-    unique = np.flatnonzero(counts)\n-    counts = counts[unique]\n-    return unique, counts\n-\n-\n def find_contacts(p1, p2, inds):  # pragma: no cover\n     \"\"\"\n     Variation on Network.find_contacts() that avoids sorting.\n@@ -189,9 +185,19 @@ def find_contacts(p1, p2, inds):  # pragma: no cover\n     return pairing_partners\n \n \n-# %% Seed methods\n+def check_requires(sim, requires, *args):\n+    \"\"\" Check that the module's requirements (of other modules) are met \"\"\"\n+    errs = sc.autolist()\n+    all_classes = [m.__class__ for m in sim.modules]\n+    all_names = [m.name for m in sim.modules]\n+    for req in sc.mergelists(requires, *args):\n+        if req not in all_classes + all_names:\n+            errs += req\n+    if len(errs):\n+        errormsg = f'The following module(s) are required, but the Sim does not contain them: {sc.strjoin(errs)}'\n+        raise AttributeError(errormsg)\n+    return\n \n-__all__ += ['set_seed']\n \n def set_seed(seed=None):\n     '''\n@@ -224,74 +230,172 @@ def set_seed(seed=None):\n \n # %% Data cleaning and processing\n \n-__all__ += ['standardize_data']\n+def standardize_netkey(key):\n+    \"\"\" Networks can be upper or lowercase, and have a suffix 'net' or not; this function standardizes them \"\"\"\n+    return key.lower().removesuffix('net')\n \n \n-def standardize_data(data=None, metadata=None, max_age=120, min_year=1800):\n+def standardize_data(data=None, metadata=None, min_year=1800, out_of_range=0, default_age=0, default_year=2024):\n     \"\"\"\n+    Standardize formats of input data\n+\n+    Input data can arrive in many different forms. This function accepts a variety of data\n+    structures, and converts them into a Pandas Series containing one variable, based on\n+    specified metadata, or an ``ss.Dist`` if the data is already an ``ss.Dist`` object.\n+\n+    The metadata is a dictionary that defines columns of the dataframe or keys\n+    of the dictionary to use as indices in the output Series. It should contain:\n+\n+    - ``metadata['data_cols']['value']`` specifying the name of the column/key to draw values from\n+    - ``metadata['data_cols']['year']`` optionally specifying the column containing year values; otherwise the default year will be used\n+    - ``metadata['data_cols']['age']`` optionally specifying the column containing age values; otherwise the default age will be used\n+    - ``metadata['data_cols'][<arbitrary>]`` optionally specifying any other columns to use as indices. These will form part of the multi-index for the standardized Series output.\n+\n+    If a ``sex`` column is part of the index, the metadata can also optionally specify a string mapping to convert\n+    the sex labels in the input data into the 'm'/'f' labels used by Starsim. In that case, the metadata can contain\n+    an additional key like ``metadata['sex_keys'] = {'Female':'f','Male':'m'}`` which in this case would map the strings\n+    'Female' and 'Male' in the original data into 'm'/'f' for Starsim.\n+\n     Args:\n-        data (pandas.DataFrame, pandas.Series, dict, int, float): An associative array  or a number, with the\n-        input data to be standardized.\n-        metadata (dict): The metadata containing information about the columns of the data.\n-        max_age (float): The maximum age allowed in the data. Default is 120 years.\n-        min_year (float): The minimum year allowed in the data. Default is 1800.\n+        data (pandas.DataFrame, pandas.Series, dict, int, float): An associative array  or a number, with the input data to be standardized.\n+        metadata (dict): Dictionary specifiying index columns, the value column, and optionally mapping for sex labels\n+        min_year (float): Optionally specify a minimum year allowed in the data. Default is 1800.\n+        out_of_range (float): Value to use for negative ages - typically 0 is a reasonable choice but other values (e.g., np.inf or np.nan) may be useful depending on the calculation. This will automatically be added to the dataframe with an age of ``-np.inf``\n \n     Returns:\n-        df (pandas.DataFrame or sciris.dataframe): The standardized data\n \n-    Raises:\n-        ValueError: If the columns in `data` do not match the column names in metadata.data_cols\n-        or if the index of the data series is not understood.\n+        - A `pd.Series` for all supported formats of `data` *except* an ``ss.Dist``. This series will contain index columns for 'year'\n+          and 'age' (in that order) and then subsequent index columns for any other variables specified in the metadata, in the order\n+          they appeared in the metadata (except for year and age appearing first).\n+        - An ``ss.Dist`` instance - if the ``data`` input is an ``ss.Dist``, that same object will be returned by this function\n     \"\"\"\n-    metadata = sc.objdict(metadata)\n-\n-    if isinstance(data, pd.DataFrame):\n-        if not set(metadata.data_cols.values()).issubset(data.columns):\n-            errormsg = 'Please ensure the columns of the data match the values in metadata.data_cols.'\n-            raise ValueError(errormsg)\n-        df = data\n-\n-    elif isinstance(data, pd.Series):\n-        if metadata.data_cols.get('age'):\n-            if (data.index <= max_age).all():  # Assume index is age bins\n-                df = sc.dataframe({\n-                    metadata.data_cols['year']: 2000,\n-                    metadata.data_cols['age']: data.index.values,\n-                    metadata.data_cols['value']: data.values,\n-                })\n-            elif (data.index >= min_year).all():  # Assume index year\n-                df = sc.dataframe({\n-                    metadata.data_cols['year']: data.index.values,\n-                    metadata.data_cols['age']: 0,\n-                    metadata.data_cols['value']: data.values,\n-                })\n+    # It's a format that can be used directly: return immediately\n+    if sc.isnumber(data) or isinstance(data, (ss.Dist, ss.TimePar)):\n+        return data\n+\n+    # Convert series and dataframe inputs into dicts\n+    if isinstance(data, pd.Series) or isinstance(data, pd.DataFrame):\n+        data = data.reset_index().to_dict(orient='list')\n+\n+    # Check that the input is now a dict (scalar types have already been handled above\n+    assert isinstance(data, dict), 'Supported inputs are ss.Dict, scalar numbers, DataFrames, Series, or dictionaries'\n+\n+    # Extract the values and index columns\n+    assert 'value' in metadata['data_cols'], 'The metadata is missing a column name for \"value\", which must be provided if the input data is in the form of a DataFrame, Series, or dict'\n+    values = sc.promotetoarray(data[metadata['data_cols']['value']])\n+    index = sc.objdict()\n+    for k, col in metadata['data_cols'].items():\n+        if k != 'value':\n+            index[k] = data[col]\n+\n+    # Add defaults for year and age\n+    if 'year' not in index:\n+        index['year'] = np.full(values.shape, fill_value=default_year, dtype=ss.dtypes.float)\n+    if 'age' not in index:\n+        index['age'] = np.full(values.shape, fill_value=default_age, dtype=ss.dtypes.float)\n+\n+    # Reorder the index so that it starts with age first\n+    index.insert(0, 'age', index.pop('age'))\n+    index.insert(0, 'year', index.pop('year'))\n+\n+    # Map sex values\n+    if 'sex' in index:\n+        if 'sex_keys' in metadata:\n+            index['sex'] = [metadata['sex_keys'][x] for x in index['sex']]\n+        assert set(index['sex']) == {'f','m'}, 'If standardized data contains a \"sex\" column, it should use \"m\" and \"f\" to specify the sex.'\n+\n+    # Create the series\n+    output = pd.Series(data=values, index=pd.MultiIndex.from_arrays(index.values(), names=index.keys()))\n+\n+    # Add an entry for negative ages\n+    new_entries = output.index.set_codes([0] * len(output), level=1).set_levels([-np.inf], level=1).unique()\n+    new = pd.Series(data=out_of_range, index=new_entries)\n+    output = pd.concat([output, new])\n+\n+    # Truncate years\n+    output = output.loc[output.index.get_level_values('year')>min_year]\n+\n+    # Perform a final sort to prevent \"indexing past lexsort depth\" warnings\n+    output = output.sort_index()\n+\n+    return output\n+\n+\n+def validate_sim_data(data=None, die=None):\n+    \"\"\"\n+    Validate data intended to be compared to the sim outputs, e.g. for calibration\n+\n+    Args:\n+        data (df/dict): a dataframe (or dict) of data, with a column \"time\" plus data columns of the form \"module.result\", e.g. \"hiv.new_infections\"\n+        die (bool): whether to raise an exception if the data cannot be converted (default: die if data is not None but cannot be converted)\n+\n+    \"\"\"\n+    success = False\n+    if data is not None:\n+        # Try loading the data\n+        try:\n+            data = sc.dataframe(data) # Convert it to a dataframe\n+            timecols = ['t', 'timevec', 'tvec', 'time', 'day', 'date', 'year'] # If a time column is supplied, use it as the index\n+            found = False\n+            for timecol in timecols:\n+                if timecol in data.cols:\n+                    if found:\n+                        errormsg = f'Multiple time columns found: please ensure only one of {timecols} is present; you supplied {data.cols}.'\n+                        raise ValueError(errormsg)\n+                    data.set_index(timecol, inplace=True)\n+                    found = True\n+            success = True\n+\n+        # Data loading failed\n+        except Exception as E:\n+            errormsg = f'Failed to add data \"{data}\": expecting a dataframe-compatible object. Error:\\n{E}'\n+            if die == False:\n+                print(errormsg)\n             else:\n-                errormsg = 'Could not understand index of data series: should be age (all values less than 120) or year (all values greater than 1900).'\n                 raise ValueError(errormsg)\n-        else:\n-            df = sc.dataframe({\n-                metadata.data_cols['year']: data.index.values,\n-                metadata.data_cols['value']: data.values,\n-            })\n-\n-        if metadata.data_cols.get('sex'):\n-            df = pd.concat([df, df])\n-            df[metadata.data_cols['sex']] = np.repeat(list(metadata.sex_keys.values()), len(data))\n-\n-    elif isinstance(data, dict):\n-        if not set(metadata.data_cols.values()).issubset(data.keys()):\n-            errormsg = 'Please ensure the keys of the data dict match the values in metadata.data_cols.'\n-            raise ValueError(errormsg)\n-        new_data = dict()\n-        for sim_name, col_name in metadata.data_cols.items():\n-            new_data[sim_name] = sc.tolist(data[col_name])\n-        df = sc.dataframe(new_data)\n-\n-    elif sc.isnumber(data) or isinstance(data, ss.Dist):\n-        df = data  # Just return it as-is\n \n-    else:\n-        errormsg = f'Data type {type(data)} not understood.'\n+    # Validation\n+    if not success and die == True:\n+        errormsg = 'Data \"{data}\" could not be converted and die == True'\n         raise ValueError(errormsg)\n-        \n-    return df\n+\n+    return data\n+\n+\n+def combine_rands(a, b):\n+    \"\"\"\n+    Efficient algorithm for combining two arrays of random integers into an array\n+    of floats.\n+\n+    See ss.multi_random() for the user-facing version.\n+\n+    Args:\n+        a (array): array of random integers between 0 and np.iinfo(np.uint64).max, as from ss.rand_raw()\n+        b (array): ditto, same size as a\n+\n+    Returns:\n+        A new array of random numbers the same size as a and b\n+    \"\"\"\n+    c = np.bitwise_xor(a*b, a-b)\n+    u = c / np.iinfo(np.uint64).max\n+    return u\n+\n+\n+#%% Other helper functions\n+\n+class shrink:\n+    \"\"\" Define a class to indicate an object has been shrunken \"\"\"\n+    def __repr__(self):\n+        s = 'This object has been intentionally \"shrunken\"; it is a placeholder and has no functionality. Use the non-shrunken object instead.'\n+        return s\n+\n+\n+def return_fig(fig, **kwargs):\n+    \"\"\" Do postprocessing on the figure: by default, don't return if in Jupyter, but show instead \"\"\"\n+    is_jupyter = [False, True, sc.isjupyter()][ss.options.jupyter]\n+    if is_jupyter:\n+        print(fig)\n+        plt.show()\n+        return None\n+    else:\n+        return fig\n\\ No newline at end of file\ndiff --git a/starsim/version.py b/starsim/version.py\nindex 11c9f8e..99811c1 100644\n--- a/starsim/version.py\n+++ b/starsim/version.py\n@@ -1,9 +1,9 @@\n-'''\n+\"\"\"\n Version and license information.\n-'''\n+\"\"\"\n \n __all__ = ['__version__', '__versiondate__', '__license__']\n \n-__version__ = '0.5.2'\n-__versiondate__ = '2024-06-04'\n+__version__ = '2.1.1'\n+__versiondate__ = '2024-11-8'\n __license__ = f'Starsim {__version__} ({__versiondate__}) — © 2023-2024 by IDM'\ndiff --git a/tests/baseline.json b/tests/baseline.json\nindex 43bc42f..0e7720a 100644\n--- a/tests/baseline.json\n+++ b/tests/baseline.json\n@@ -1,26 +1,26 @@\n {\n   \"summary\": {\n-    \"yearvec\": 2010.1000000000026,\n-    \"births_new\": 65.25490196078431,\n-    \"births_cumulative\": 3262.4313725490197,\n-    \"births_cbr\": 29.713410489238804,\n-    \"deaths_new\": 44.68627450980392,\n-    \"deaths_cumulative\": 2227.549019607843,\n-    \"deaths_cmr\": 20.34315186671041,\n-    \"sir_n_susceptible\": 2429.970588235294,\n-    \"sir_n_infected\": 3579.8823529411766,\n-    \"sir_n_recovered\": 4970.764705882353,\n-    \"sir_prevalence\": 0.334889084274871,\n-    \"sir_new_infections\": 128.2156862745098,\n-    \"sir_cum_infections\": 13078.0,\n-    \"sis_n_susceptible\": 3951.1960784313724,\n-    \"sis_n_infected\": 7029.421568627451,\n-    \"sis_prevalence\": 0.627871954232106,\n-    \"sis_new_infections\": 209.7843137254902,\n-    \"sis_cum_infections\": 21398.0,\n-    \"sis_rel_sus\": 0.46047714966479397,\n-    \"n_alive\": 10980.617647058823,\n-    \"new_deaths\": 45.705882352941174,\n-    \"cum_deaths\": 4625.0\n+    \"timevec\": 2020.0,\n+    \"births_new\": 46.84158415841584,\n+    \"births_cumulative\": 2267.7425742574255,\n+    \"births_cbr\": 19.93833106141367,\n+    \"deaths_new\": 9.673267326732674,\n+    \"deaths_cumulative\": 468.5742574257426,\n+    \"deaths_cmr\": 4.118825151847284,\n+    \"sir_n_susceptible\": 2440.029702970297,\n+    \"sir_n_infected\": 3630.3960396039606,\n+    \"sir_n_recovered\": 5676.693069306931,\n+    \"sir_prevalence\": 0.32402568798505815,\n+    \"sir_new_infections\": 122.34653465346534,\n+    \"sir_cum_infections\": 12357.0,\n+    \"sis_n_susceptible\": 4784.306930693069,\n+    \"sis_n_infected\": 6973.504950495049,\n+    \"sis_prevalence\": 0.5720906510271361,\n+    \"sis_new_infections\": 193.5742574257426,\n+    \"sis_cum_infections\": 19551.0,\n+    \"sis_rel_sus\": 0.5019197711850157,\n+    \"n_alive\": 11747.118811881188,\n+    \"new_deaths\": 10.693069306930694,\n+    \"cum_deaths\": 1072.0\n   }\n }\n\\ No newline at end of file\ndiff --git a/tests/baseline_multisim.json b/tests/baseline_multisim.json\nnew file mode 100644\nindex 0000000..dfca24f\n--- /dev/null\n+++ b/tests/baseline_multisim.json\n@@ -0,0 +1,112 @@\n+{\n+  \"yearvec\": {\n+    \"mean\": 2010.1000000000026,\n+    \"std\": 0.0,\n+    \"sem\": 0.0\n+  },\n+  \"births_new\": {\n+    \"mean\": 65.42156862745097,\n+    \"std\": 0.1636403441859318,\n+    \"sem\": 0.05174762047214366\n+  },\n+  \"births_cumulative\": {\n+    \"mean\": 3268.022549019608,\n+    \"std\": 7.404566545623425,\n+    \"sem\": 2.3415295370455103\n+  },\n+  \"births_cbr\": {\n+    \"mean\": 29.722512541939885,\n+    \"std\": 0.006276951230389925,\n+    \"sem\": 0.001984946264982848\n+  },\n+  \"deaths_new\": {\n+    \"mean\": 44.380392156862754,\n+    \"std\": 0.31770757109406206,\n+    \"sem\": 0.10046795545371096\n+  },\n+  \"deaths_cumulative\": {\n+    \"mean\": 2206.050980392157,\n+    \"std\": 20.506215616069515,\n+    \"sem\": 6.484634753729258\n+  },\n+  \"deaths_cmr\": {\n+    \"mean\": 20.155330390777614,\n+    \"std\": 0.14640525779385213,\n+    \"sem\": 0.04629740760526911\n+  },\n+  \"sir_n_susceptible\": {\n+    \"mean\": 2440.7539215686274,\n+    \"std\": 28.746250762671917,\n+    \"sem\": 9.090362660039563\n+  },\n+  \"sir_n_infected\": {\n+    \"mean\": 3592.6529411764704,\n+    \"std\": 15.832047055140144,\n+    \"sem\": 5.006532871720426\n+  },\n+  \"sir_n_recovered\": {\n+    \"mean\": 4971.801960784314,\n+    \"std\": 31.176074975909064,\n+    \"sem\": 9.858740542805167\n+  },\n+  \"sir_prevalence\": {\n+    \"mean\": 0.33524628593554295,\n+    \"std\": 0.0006949779189371683,\n+    \"sem\": 0.0002197713147365318\n+  },\n+  \"sir_new_infections\": {\n+    \"mean\": 128.78137254901958,\n+    \"std\": 0.6174299338251982,\n+    \"sem\": 0.19524848864546648\n+  },\n+  \"sir_cum_infections\": {\n+    \"mean\": 13135.7,\n+    \"std\": 62.97785325017042,\n+    \"sem\": 19.915345841837645\n+  },\n+  \"sis_n_susceptible\": {\n+    \"mean\": 4016.530392156862,\n+    \"std\": 103.15173055519776,\n+    \"sem\": 32.61944131424099\n+  },\n+  \"sis_n_infected\": {\n+    \"mean\": 6988.678431372548,\n+    \"std\": 112.41894818744964,\n+    \"sem\": 35.54999284327985\n+  },\n+  \"sis_prevalence\": {\n+    \"mean\": 0.622135221279589,\n+    \"std\": 0.00994225067508044,\n+    \"sem\": 0.003144015720160086\n+  },\n+  \"sis_new_infections\": {\n+    \"mean\": 208.82450980392156,\n+    \"std\": 2.531950580258016,\n+    \"sem\": 0.8006730756600289\n+  },\n+  \"sis_cum_infections\": {\n+    \"mean\": 21300.1,\n+    \"std\": 258.2589591863175,\n+    \"sem\": 81.6686537173229\n+  },\n+  \"sis_rel_sus\": {\n+    \"mean\": 0.46661987224910195,\n+    \"std\": 0.00995264046990363,\n+    \"sem\": 0.003147301261766397\n+  },\n+  \"n_alive\": {\n+    \"mean\": 11005.20882352941,\n+    \"std\": 27.11539023756586,\n+    \"sem\": 8.574639279500229\n+  },\n+  \"new_deaths\": {\n+    \"mean\": 45.478431372549025,\n+    \"std\": 0.3597865572558359,\n+    \"sem\": 0.11377449924390214\n+  },\n+  \"cum_deaths\": {\n+    \"mean\": 4589.7,\n+    \"std\": 36.32093060481793,\n+    \"sem\": 11.485686744814172\n+  }\n+}\n\\ No newline at end of file\ndiff --git a/tests/benchmark.json b/tests/benchmark.json\nindex aefe3c2..00f78bb 100644\n--- a/tests/benchmark.json\n+++ b/tests/benchmark.json\n@@ -1,12 +1,12 @@\n {\n   \"time\": {\n-    \"initialize\": 0.015,\n-    \"run\": 1.082\n+    \"initialize\": 0.055,\n+    \"run\": 1.013\n   },\n   \"parameters\": {\n     \"n_agents\": 10000,\n-    \"n_years\": 20,\n+    \"dur\": 20,\n     \"dt\": 0.2\n   },\n-  \"cpu_performance\": 0.9927627642937098\n+  \"cpu_performance\": 0.9665005580733697\n }\n\\ No newline at end of file\ndiff --git a/tests/benchmark_full.py b/tests/benchmark_full.py\nindex 9cc54af..1286d8a 100644\n--- a/tests/benchmark_full.py\n+++ b/tests/benchmark_full.py\n@@ -10,22 +10,22 @@ import starsim as ss\n repeats = 10\n n_agents = 100_000\n pars = sc.objdict(\n-    n_years       = 100,        # Number of years to simulate\n-    dt            = 0.5,        # Timestep\n-    verbose       = 0,          # Don't print details of the run\n+    dur     = 100, # Number of years to simulate\n+    dt      = 0.5, # Timestep\n+    verbose = 0,   # Don't print details of the run\n )\n \n def make_run_sim():\n     \"\"\" Make and run a decent-sized default simulation \"\"\"\n     # Make the people\n     ppl = ss.People(n_agents=n_agents)\n-    \n+\n     # Make the components\n-    sir = ss.SIR()\n+    sir = ss.SIS()\n     hiv = ss.HIV()\n-    hiv.pars['beta'] = {'mf': [0.15, 0.10], 'maternal': [0.2, 0]}\n-    networks = [ss.MFNet(), ss.MaternalNet()]\n-    \n+    hiv.pars['beta'] = {'mf': [0.15, 0.10], 'maternal': [0.2, 0], 'random': [0,0]}\n+    networks = [ss.RandomNet(), ss.MFNet(), ss.MaternalNet()]\n+\n     # Make the sim\n     sim = ss.Sim(pars=pars, people=ppl, networks=networks, demographics=ss.Pregnancy(), diseases=[sir, hiv])\n \n@@ -36,10 +36,10 @@ def make_run_sim():\n \n \n if __name__ == '__main__':\n-    \n+\n     T = sc.timer()\n     for r in range(repeats):\n         make_run_sim()\n         T.tt(f'Trial {r+1}/{repeats}')\n-        \n+\n     sc.heading(f'Average: {T.mean()*1000:0.0f} ± {T.std()/len(T)**0.5*1000:0.0f} ms')\n\\ No newline at end of file\ndiff --git a/tests/benchmark_simple.py b/tests/benchmark_simple.py\nindex 54e2a44..b1fdee7 100644\n--- a/tests/benchmark_simple.py\n+++ b/tests/benchmark_simple.py\n@@ -1,5 +1,5 @@\n import sciris as sc\n-import matplotlib.pyplot as pl\n+import matplotlib.pyplot as plt\n import starsim as ss\n \n do_plot = False\n@@ -10,11 +10,11 @@ with sc.timer():\n \n     hiv = ss.HIV()\n     hiv.pars['beta'] = {'simple_sexual': [0.0008, 0.0004], 'maternal': [0.2, 0]}\n-    \n-    sim = ss.Sim(start=1950, end=2050, people=ppl, networks=networks, demographics=ss.Pregnancy(), diseases=hiv)\n-    sim.initialize()\n+\n+    sim = ss.Sim(start=1950, stop=2050, people=ppl, networks=networks, demographics=ss.Pregnancy(), diseases=hiv)\n+    sim.init()\n     sim.run()\n \n if do_plot:\n-    pl.plot(sim.tivec, sim.results.hiv.n_infected)\n-    pl.show()\n+    plt.plot(sim.tivec, sim.results.hiv.n_infected)\n+    plt.show()\ndiff --git a/tests/check_style b/tests/check_style\nnew file mode 100755\nindex 0000000..cd6b417\n--- /dev/null\n+++ b/tests/check_style\n@@ -0,0 +1,12 @@\n+#!/bin/bash\n+# Check code quality by running pylint\n+\n+echo 'Running pylint...'\n+cd ..\n+start=$(date +%s)\n+pylint starsim | tee tests/pylint_report.txt\n+end=$(date +%s)\n+\n+echo \n+echo \"Took $(($end - $start)) s; output saved to:\"\n+echo \"pylint_report.txt\"\ndiff --git a/tests/devtests/devtest_dem_data.py b/tests/devtests/devtest_dem_data.py\nindex 95dc3c1..7589211 100644\n--- a/tests/devtests/devtest_dem_data.py\n+++ b/tests/devtests/devtest_dem_data.py\n@@ -30,7 +30,7 @@ def test_series_death_rate():\n     ppl = ss.People(1000)\n     death_rate = ss.standardize_data(data=series_death, metadata=ss.omerge({\n         'data_cols': {'year': 'Time', 'sex': 'Sex', 'age': 'AgeGrpStart', 'value': 'mx'},\n-        'sex_keys': {'f': 'Female', 'm': 'Male'},\n+        'sex_keys': {'Female':'f', 'Male':'m'},\n     }))\n     bdm2 = ss.Deaths(pars={'death_rate': death_rate})\n     sim2 = ss.Sim(people=ppl, demographics=bdm2, label='Using age-specific data from a pandas series')\ndiff --git a/tests/devtests/devtest_rngtrans.py b/tests/devtests/devtest_rngtrans.py\nnew file mode 100644\nindex 0000000..2d3c6ac\n--- /dev/null\n+++ b/tests/devtests/devtest_rngtrans.py\n@@ -0,0 +1,166 @@\n+import networkx as nx\n+import numpy as np\n+import matplotlib.pyplot as plt\n+import pandas as pd\n+import seaborn as sns\n+from pandas.util import hash_pandas_object\n+import hashlib\n+import sciris as sc\n+\n+from starsim.utils import combine_rands\n+\n+import warnings\n+warnings.filterwarnings(\"ignore\", \"overflow encountered in scalar subtract\")\n+warnings.filterwarnings(\"ignore\", \"overflow encountered in scalar multiply\")\n+ \n+n = 8 # Number of nodes\n+n_sources = 2 # Number of sources (seed infections)\n+reps = 1_000_000\n+edge_prob = 0.7 # Edge probability\n+trans_prob = 0.4\n+seed = 1\n+\n+def hash(df):\n+    #return int(hashlib.sha256(hash_pandas_object(df, index=True).values).hexdigest(), 16)\n+    return hashlib.sha256(hash_pandas_object(df, index=True).values).hexdigest()[:6]\n+\n+def random(G):\n+    src = nx.get_node_attributes(G, 'infected')\n+    infected = []\n+    tx = []\n+\n+    # Randomize in case a node is infected multiple times\n+    el = list(G.edges())\n+    np.random.shuffle(el)\n+\n+    for (n1,n2) in el:\n+        # n1 --> n2\n+        if src[n1] and (not src[n2]) and (n2 not in infected) and (np.random.rand() < trans_prob):\n+            tx.append((n1, n2))\n+            infected.append(n2)\n+        # n2 --> n1\n+        if src[n2] and (not src[n1]) and (n1 not in infected) and (np.random.rand() < trans_prob):\n+            tx.append((n2, n1))\n+            infected.append(n1)\n+    return tx\n+\n+\n+def modulo(G):\n+    src = nx.get_node_attributes(G, 'infected')\n+    infected = []\n+    tx = []\n+    r1 = np.random.rand(n)\n+    r2 = np.random.rand(n)\n+    el = list(G.edges())\n+    np.random.shuffle(el)\n+    for (n1,n2) in el:\n+        # n1 --> n2\n+        if (src[n1]) and (not src[n2]) and (n2 not in infected) and (((r1[n1]+r2[n2])%1) < trans_prob):\n+            tx.append((n1, n2))\n+            infected.append(n2)\n+        # n2 --> n1\n+        if (src[n2]) and (not src[n1]) and (n1 not in infected) and (((r1[n2]+r2[n1])%1) < trans_prob):\n+            tx.append((n2, n1))\n+            infected.append(n1)\n+    return tx\n+\n+\n+def combine_hash(G):\n+    src = nx.get_node_attributes(G, 'infected')\n+    infected = []\n+    tx = []\n+    el = list(G.edges())\n+    r1 = np.random.randint(low=0, high=np.iinfo(np.uint64).max, dtype=np.uint64, size=n)\n+    r2 = np.random.randint(low=0, high=np.iinfo(np.uint64).max, dtype=np.uint64, size=n)\n+    np.random.shuffle(el)\n+    for (n1,n2) in el:\n+        # n1 --> n2\n+        r = combine_rands(r1[n1], r2[n2])\n+        if (src[n1]) and (not src[n2]) and (n2 not in infected) and (r < trans_prob):\n+            tx.append((n1, n2))\n+            infected.append(n2)\n+        # n2 --> n1\n+        r = combine_rands(r1[n2], r2[n1])\n+        if (src[n2]) and (not src[n1]) and (n1 not in infected) and (r < trans_prob):\n+            tx.append((n2, n1))\n+            infected.append(n1)\n+    return tx\n+\n+def roulette(G):\n+    src = nx.get_node_attributes(G, 'infected')\n+    tx = []\n+    for n2 in G.nodes():\n+        # All nodes --> n2\n+        if not src[n2]:\n+            srcs = [n for n in G.neighbors(n2) if src[n]] #[src[n] for n in G.neighbors(n2)] # Count infected neighbors\n+            cnt = len(srcs)\n+            if np.random.rand() < 1-(1-trans_prob)**cnt:\n+                n1 = np.random.choice(srcs)\n+                tx.append((n1, n2))\n+    return tx\n+ \n+\n+def transmit(G, trans_fn):\n+    # Align transmissions from tx_in if provided\n+    txs = {}\n+    counts = {}\n+ \n+    for _ in np.arange(reps):\n+        txl = trans_fn(G)\n+        tx = pd.DataFrame(txl, columns=['src', 'dst']).sort_values(['src', 'dst']).reset_index(drop=True)\n+        \n+        h = hash(tx)\n+\n+        if h not in txs:\n+            txs[h] = tx\n+\n+        counts[h] = counts.get(h, 0) + 1\n+\n+    df = pd.DataFrame(counts.values(), index=pd.Index(counts.keys(), name='Hash'), columns=['Counts'])\n+    return txs, df\n+\n+\n+# Build the graph\n+G = nx.random_graphs.erdos_renyi_graph(n=n, p=edge_prob, seed=seed)\n+\n+# Seed infections\n+infected = {i:False for i in range(n)}\n+sources = np.random.choice(a=range(n), size=n_sources, replace=False)\n+for source in sources:\n+    infected[source] = True\n+nx.set_node_attributes(G, infected, 'infected')\n+ \n+# Do transmissions via each method in parallel\n+results = sc.parallelize(transmit, iterkwargs=[{'trans_fn':random}, {'trans_fn':modulo}, {'trans_fn':combine_hash}, {'trans_fn':roulette}], kwargs={'G':G}, die=True, serial=False)\n+tx, cnt = zip(*results)\n+\n+df = pd.concat(cnt, axis=1) \\\n+    .fillna(0) \\\n+    .astype(int)\n+df.columns = ['Random', 'Modulo', 'CombineHash', 'Roulette']\n+\n+# Manipulate results\n+df.reset_index(inplace=True)\n+dfm = df.melt(id_vars='Hash', var_name='Method', value_name='Count')\n+\n+# Plot\n+g = sns.barplot(data=dfm, x='Hash', y='Count', hue='Method')\n+plt.xticks(rotation=90)\n+g.figure.tight_layout()\n+\n+txc = tx[0].copy()\n+for i in range(1, len(tx)):\n+    txc.update(tx[i])\n+for h, v in txc.items():\n+    print(f'\\nUnique transmission tree #{h}')\n+    print(v)\n+\n+plt.figure()\n+pos = nx.spring_layout(G, seed=3113794652)  # positions for all nodes\n+ec = nx.draw_networkx_edges(G, pos, alpha=0.2)\n+colors = ['red' if infected else 'blue' for infected in nx.get_node_attributes(G, 'infected').values()]\n+nc = nx.draw_networkx_nodes(G, pos, nodelist=G.nodes(), node_color=colors, node_size=100)\n+nx.draw_networkx_edges(G, pos, width=1.0, alpha=0.5)\n+nx.draw_networkx_labels(G, pos)\n+\n+plt.show()\n\\ No newline at end of file\ndiff --git a/tests/multisim_baseline.py b/tests/multisim_baseline.py\nnew file mode 100755\nindex 0000000..ede2f48\n--- /dev/null\n+++ b/tests/multisim_baseline.py\n@@ -0,0 +1,22 @@\n+#!/usr/bin/env python3\n+\n+\"\"\"\n+Run this script to save or check the multisim baseline.\n+\n+You can supply command line arguments for \"save\" and \"n_runs\" as integers, e.g.\n+    ./multisim_baseline.py 0 20\n+\"\"\"\n+\n+import sys\n+import test_baselines\n+\n+save = False\n+n_runs = 10\n+\n+if len(sys.argv) > 1:\n+    save = int(sys.argv[1])\n+    assert save in [0,1] # Avoid confusing with n_runs\n+if len(sys.argv) > 2:\n+    n_runs = int(sys.argv[2])\n+\n+test_baselines.multisim_baseline(save, n_runs)\ndiff --git a/tests/profile_sim.py b/tests/profile_sim.py\nnew file mode 100644\nindex 0000000..95051fa\n--- /dev/null\n+++ b/tests/profile_sim.py\n@@ -0,0 +1,21 @@\n+import sciris as sc\n+import starsim as ss\n+\n+kw = dict(n_agents=10e3, start=2000, dur=100, diseases='sis', networks='random', demographics=True)\n+sim = ss.Sim(**kw)\n+\n+prof = ['profile', 'cprofile', 'time'][1]\n+\n+if prof == 'profile':\n+    prf = sc.profile(run=sim.run, follow=[sim.run])\n+\n+elif prof == 'cprofile':\n+    cprf = sc.cprofile(sort='selfpct', mintime=1e-3, maxitems=None, maxfunclen=None, maxpathlen=None)\n+    with cprf:\n+        sim.run()\n+\n+else:\n+    with sc.timer() as T:\n+        sim.run()\n+\n+sim.loop.plot_cpu()\n\\ No newline at end of file\ndiff --git a/tests/quick_benchmark b/tests/quick_benchmark\nnew file mode 100755\nindex 0000000..a41c899\n--- /dev/null\n+++ b/tests/quick_benchmark\n@@ -0,0 +1,8 @@\n+#!/usr/bin/env python3\n+\"\"\"\n+Quickly check the performance benchmark\n+\"\"\"\n+\n+import test_baselines\n+\n+test_baselines.test_benchmark(do_save=False, repeats=5)\ndiff --git a/tests/requirements.txt b/tests/requirements.txt\nindex fce2743..a2bea3c 100644\n--- a/tests/requirements.txt\n+++ b/tests/requirements.txt\n@@ -1,4 +1,5 @@\n pytest>=7.3\n pytest-cov\n pytest-env\n-pytest-xdist\n\\ No newline at end of file\n+pytest-xdist\n+optuna\n\\ No newline at end of file\ndiff --git a/tests/test_baselines.py b/tests/test_baselines.py\nindex 45f8714..b51d2ea 100644\n--- a/tests/test_baselines.py\n+++ b/tests/test_baselines.py\n@@ -8,30 +8,31 @@ import sciris as sc\n import starsim as ss\n \n baseline_filename  = sc.thisdir(__file__, 'baseline.json')\n+multisim_filename  = sc.thisdir(__file__, 'baseline_multisim.json')\n benchmark_filename = sc.thisdir(__file__, 'benchmark.json')\n parameters_filename = sc.thisdir(ss.__file__, 'regression', f'pars_v{ss.__version__}.json')\n sc.options(interactive=False) # Assume not running interactively\n \n # Define the parameters\n pars = sc.objdict(\n-    n_agents   = 10e3, # Number of agents\n-    start      = 2000, # Starting year\n-    n_years    = 20,   # Number of years to simulate\n-    dt         = 0.2,  # Timestep\n-    verbose    = 0,    # Don't print details of the run\n-    rand_seed  = 2,    # Set a non-default seed\n+    n_agents  = 10e3, # Number of agents\n+    start     = 2000, # Starting year\n+    dur       = 20,   # Number of years to simulate\n+    dt        = 0.2,  # Timestep\n+    verbose   = 0,    # Don't print details of the run\n+    rand_seed = 2,    # Set a non-default seed\n )\n \n \n-def make_sim(run=False):\n+def make_sim(run=False, **kwargs):\n     \"\"\"\n-    Define a default simulation for testing the baseline. If run directly (not \n+    Define a default simulation for testing the baseline. If run directly (not\n     via pytest), also plot the sim by default.\n     \"\"\"\n     diseases = ['sir', 'sis']\n     networks = ['random', 'mf', 'maternal']\n-    sim = ss.Sim(pars=pars, networks=networks, diseases=diseases, demographics=True)\n-    \n+    sim = ss.Sim(pars=pars | kwargs, networks=networks, diseases=diseases, demographics=True)\n+\n     # Optionally run and plot\n     if run:\n         sim.run()\n@@ -53,17 +54,42 @@ def save_baseline():\n \n     # Export results\n     sim.to_json(filename=baseline_filename, keys='summary')\n-    \n-    # CK: To restore once export_pars is fixed\n-    # sim.export_pars(filename=parameters_filename) # If not different from previous version, can safely delete\n+\n+    # Save parameters\n+    sim.to_json(filename=parameters_filename, keys='pars') # If not different from previous version, can safely delete\n \n     print('Done.')\n     return\n \n \n+def multisim_baseline(save=False, n_runs=10, **kwargs):\n+    \"\"\"\n+    Check or update the multisim baseline results; not part of the integration tests\n+    \"\"\"\n+    word = 'Saving' if save else 'Checking'\n+    sc.heading(f'{word} MultiSim baseline...')\n+\n+    # Make and run sims\n+    kwargs.setdefault('verbose', ss.options.verbose/n_runs*2)\n+    sim = make_sim(**kwargs)\n+    msim = ss.MultiSim(base_sim=sim)\n+    msim.run(n_runs)\n+    summary = msim.summarize()\n+\n+    # Export results\n+    if save:\n+        sc.savejson(multisim_filename, summary)\n+        print('Done.')\n+    else:\n+        baseline = sc.loadjson(multisim_filename)\n+        ss.diff_sims(baseline, summary, die=False)\n+\n+    return\n+\n+\n def test_baseline():\n     \"\"\" Compare the current default sim against the saved baseline \"\"\"\n-    \n+\n     # Load existing baseline\n     baseline = sc.loadjson(baseline_filename)\n     old = baseline['summary']\n@@ -80,7 +106,7 @@ def test_baseline():\n \n def test_benchmark(do_save=False, repeats=1, verbose=True):\n     \"\"\" Compare benchmark performance \"\"\"\n-    \n+\n     if verbose: print('Running benchmark...')\n     try:\n         previous = sc.loadjson(benchmark_filename)\n@@ -115,13 +141,13 @@ def test_benchmark(do_save=False, repeats=1, verbose=True):\n \n     # Do the actual benchmarking\n     for r in range(repeats):\n-        \n+\n         print(f'Repeat {r}')\n-        \n+\n         # Time initialization\n         t0 = sc.tic()\n         sim = make_sim()\n-        sim.initialize()\n+        sim.init()\n         t_init = sc.toc(t0, output=True)\n \n         # Time running\n@@ -147,7 +173,7 @@ def test_benchmark(do_save=False, repeats=1, verbose=True):\n                 },\n             'parameters': {\n                 'n_agents': sim.pars.n_agents,\n-                'n_years':  sim.pars.n_years,\n+                'dur':      sim.pars.dur,\n                 'dt':       sim.pars.dt,\n                 },\n             'cpu_performance': ratio,\ndiff --git a/tests/test_calibration.py b/tests/test_calibration.py\nnew file mode 100644\nindex 0000000..2d89ebb\n--- /dev/null\n+++ b/tests/test_calibration.py\n@@ -0,0 +1,146 @@\n+\"\"\"\n+Test calibration\n+\"\"\"\n+\n+#%% Imports and settings\n+import sciris as sc\n+import starsim as ss\n+\n+do_plot = 1\n+do_save = 0\n+n_agents = 2e3\n+\n+\n+#%% Helper functions\n+\n+def make_sim():\n+    hiv = ss.HIV(\n+        beta = {'random': [0.01]*2, 'maternal': [1, 0]},\n+        init_prev = 0.15,\n+    )\n+    pregnancy = ss.Pregnancy(fertility_rate=20)\n+    death = ss.Deaths(death_rate=10)\n+    random = ss.RandomNet(n_contacts=4)\n+    maternal = ss.MaternalNet()\n+\n+    sim = ss.Sim(\n+        dt = 1,\n+        n_agents = n_agents,\n+        total_pop = 9980999,\n+        start = 1990,\n+        dur = 40,\n+        diseases = [hiv],\n+        networks = [random, maternal],\n+        demographics = [pregnancy, death],\n+    )\n+\n+    return sim\n+\n+\n+def make_data():\n+    \"\"\" Define the calibration target data \"\"\"\n+    target_data = [\n+    ['time', 'n_alive', 'hiv.prevalence', 'hiv.n_infected', 'hiv.new_infections', 'hiv.new_deaths'],\n+    [  1990,  10432409,        0.0699742,          730000 ,               210000,           25000],\n+    [  1991,  10681008,        0.0851979,          910000 ,               220000,           33000],\n+    [  1992,  10900511,        0.1009127,          1100000,               220000,           43000],\n+    [  1993,  11092775,        0.1081785,          1200000,               210000,           53000],\n+    [  1994,  11261752,        0.1154349,          1300000,               200000,           63000],\n+    [  1995,  11410721,        0.1226916,          1400000,               180000,           74000],\n+    [  1996,  11541215,        0.1299689,          1500000,               160000,           84000],\n+    [  1997,  11653254,        0.1287194,          1500000,               150000,           94000],\n+    [  1998,  11747079,        0.1362040,          1600000,               140000,           100000],\n+    [  1999,  11822722,        0.1353326,          1600000,               130000,           110000],\n+    [  2000,  11881482,        0.1346633,          1600000,               120000,           120000],\n+    [  2001,  11923906,        0.1341842,          1600000,               110000,           130000],\n+    [  2002,  11954293,        0.1254779,          1500000,               100000,           130000],\n+    [  2003,  11982219,        0.1251854,          1500000,               94000 ,           130000],\n+    [  2004,  12019911,        0.1164734,          1400000,               89000 ,           120000],\n+    [  2005,  12076697,        0.1159257,          1400000,               83000 ,           120000],\n+    [  2006,  12155496,        0.1069475,          1300000,               78000 ,           110000],\n+    [  2007,  12255920,        0.1060711,          1300000,               74000 ,           93000],\n+    [  2008,  12379553,        0.1050118,          1300000,               69000 ,           80000],\n+    [  2009,  12526964,        0.0957933,          1200000,               65000 ,           68000],\n+    [  2010,  12697728,        0.0945050,          1200000,               62000 ,           54000],\n+    [  2011,  12894323,        0.0930642,          1200000,               56000 ,           42000],\n+    [  2012,  13115149,        0.0914972,          1200000,               49000 ,           34000],\n+    [  2013,  13350378,        0.0973755,          1300000,               47000 ,           28000],\n+    [  2014,  13586710,        0.0956817,          1300000,               45000 ,           25000],\n+    [  2015,  13814642,        0.0941030,          1300000,               44000 ,           24000],\n+    [  2016,  14030338,        0.0926563,          1300000,               43000 ,           23000],\n+    [  2017,  14236599,        0.0913139,          1300000,               34000 ,           23000],\n+    [  2018,  14438812,        0.0900351,          1300000,               27000 ,           22000],\n+    [  2019,  14645473,        0.0920401,          1347971,               23000 ,           None],\n+    [  2020,  14862927,        0.0874659,          1300000,               20000 ,           None],\n+    [  2021,  15085870,        0.0861733,          1300000,               19000 ,           None],\n+    [  2022,  15312158,        0.0848998,          1300000,               17000 ,           None],\n+    ]\n+    df = sc.dataframe(target_data[1:], columns=target_data[0])\n+    return df\n+\n+#%% Define the tests\n+\n+def test_calibration(do_plot=False):\n+    sc.heading('Testing calibration')\n+\n+    # Define the calibration parameters\n+    calib_pars = dict(\n+        init_prev = dict(low=0.01, high=0.30, guess=0.15, path=('diseases', 'hiv', 'init_prev')),\n+        n_contacts = dict(low=2, high=10, guess=4, path=('networks', 'randomnet', 'n_contacts')),\n+    )\n+\n+    # Make the sim and data\n+    sim = make_sim()\n+    data = make_data()\n+\n+    # Define weights for the data\n+    weights = {\n+        'n_alive':            1.0,\n+        'hiv.prevalence':     1.0,\n+        'hiv.n_infected':     1.0,\n+        'hiv.new_infections': 1.0,\n+        'hiv.new_deaths':     1.0,\n+    }\n+\n+    # Make the calibration\n+    calib = ss.Calibration(\n+        calib_pars = calib_pars,\n+        sim = sim,\n+        data = data,\n+        weights = weights,\n+        total_trials = 8,\n+        n_workers = 2,\n+        die = True,\n+        debug = False,\n+    )\n+\n+    # Perform the calibration\n+    sc.printcyan('\\nPeforming calibration...')\n+    calib.calibrate(confirm_fit=False)\n+\n+    # Confirm\n+    sc.printcyan('\\nConfirming fit...')\n+    calib.confirm_fit()\n+    print(f'Fit with original pars: {calib.before_fit:n}')\n+    print(f'Fit with best-fit pars: {calib.after_fit:n}')\n+    if calib.after_fit <= calib.before_fit:\n+        print('✓ Calibration improved fit')\n+    else:\n+        print('✗ Calibration did not improve fit, but this sometimes happens stochastically and is not necessarily an error')\n+\n+    if do_plot:\n+        calib.plot_sims()\n+        calib.plot_trend()\n+\n+    return sim, calib\n+\n+\n+#%% Run as a script\n+if __name__ == '__main__':\n+\n+    T = sc.timer()\n+    do_plot = True\n+\n+    sim, calib = test_calibration(do_plot=do_plot)\n+\n+    T.toc()\ndiff --git a/tests/test_demographics.py b/tests/test_demographics.py\nindex bdfdd3d..4e81a3d 100644\n--- a/tests/test_demographics.py\n+++ b/tests/test_demographics.py\n@@ -1,8 +1,6 @@\n \"\"\"\n Test demographic consistency\n \"\"\"\n-\n-# %% Imports and settings\n import starsim as ss\n import pandas as pd\n import matplotlib.pyplot as plt\n@@ -10,11 +8,11 @@ import numpy as np\n import sciris as sc\n import pytest\n \n-\n sc.options(interactive=False) # Assume not running interactively\n+datadir = ss.root / 'tests/test_data'\n \n \n-def test_nigeria(which='births', dt=1, start=1995, n_years=15, do_plot=False):\n+def test_nigeria(which='births', dt=1, start=1995, dur=15, do_plot=False):\n     \"\"\"\n     Make a Nigeria sim with demographic modules\n     Switch between which='births' or 'pregnancy' to determine which demographic module to use\n@@ -25,36 +23,36 @@ def test_nigeria(which='births', dt=1, start=1995, n_years=15, do_plot=False):\n     demographics = sc.autolist()\n \n     if which == 'births':\n-        birth_rates = pd.read_csv(ss.root / 'tests/test_data/nigeria_births.csv')\n+        birth_rates = pd.read_csv(datadir/'nigeria_births.csv')\n         births = ss.Births(pars={'birth_rate': birth_rates})\n         demographics += births\n \n     elif which == 'pregnancy':\n-        fertility_rates = pd.read_csv(ss.root / 'tests/test_data/nigeria_asfr.csv')\n+        fertility_rates = pd.read_csv(datadir/'nigeria_asfr.csv')\n         pregnancy = ss.Pregnancy(pars={'fertility_rate': fertility_rates, 'rel_fertility': 1})  # 4/3\n         demographics += pregnancy\n \n-    death_rates = pd.read_csv(ss.root / 'tests/test_data/nigeria_deaths.csv')\n-    death = ss.Deaths(pars={'death_rate': death_rates, 'units': 1})\n+    death_rates = pd.read_csv(datadir/'nigeria_deaths.csv')\n+    death = ss.Deaths(pars={'death_rate': death_rates, 'rate_units': 1})\n     demographics += death\n \n     # Make people\n     n_agents = 5_000\n     nga_pop_1995 = 106819805\n-    age_data = pd.read_csv(ss.root / 'tests/test_data/nigeria_age.csv')\n+    age_data = pd.read_csv(datadir/'nigeria_age.csv')\n     ppl = ss.People(n_agents, age_data=age_data)\n \n     sim = ss.Sim(\n         dt=dt,\n         total_pop=nga_pop_1995,\n         start=start,\n-        n_years=n_years,\n+        dur=dur,\n         people=ppl,\n         demographics=demographics,\n     )\n \n     if do_plot:\n-        sim.initialize()\n+        sim.init()\n         # Plot histograms of the age distributions - simulated vs data\n         bins = np.arange(0, 101, 1)\n         init_scale = nga_pop_1995 / n_agents\n@@ -65,15 +63,15 @@ def test_nigeria(which='births', dt=1, start=1995, n_years=15, do_plot=False):\n \n     sim.run()\n \n-    end = start + n_years\n-    nigeria_popsize = pd.read_csv(ss.root / 'tests/test_data/nigeria_popsize.csv')\n-    data = nigeria_popsize[(nigeria_popsize.year >= start) & (nigeria_popsize.year <= end)]\n+    stop = start + dur\n+    nigeria_popsize = pd.read_csv(datadir/'nigeria_popsize.csv')\n+    data = nigeria_popsize[(nigeria_popsize.year >= start) & (nigeria_popsize.year <= stop)]\n \n-    nigeria_cbr = pd.read_csv(ss.root / 'tests/test_data/nigeria_births.csv')\n-    cbr_data = nigeria_cbr[(nigeria_cbr.Year >= start) & (nigeria_cbr.Year <= end)]\n+    nigeria_cbr = pd.read_csv(datadir/'nigeria_births.csv')\n+    cbr_data = nigeria_cbr[(nigeria_cbr.Year >= start) & (nigeria_cbr.Year <= stop)]\n \n-    nigeria_cmr = pd.read_csv(ss.root / 'tests/test_data/nigeria_cmr.csv')\n-    cmr_data = nigeria_cmr[(nigeria_cmr.Year >= start) & (nigeria_cmr.Year <= end)]\n+    nigeria_cmr = pd.read_csv(datadir/'nigeria_cmr.csv')\n+    cmr_data = nigeria_cmr[(nigeria_cmr.Year >= start) & (nigeria_cmr.Year <= stop)]\n \n     # Tests\n     if which == 'pregnancy':\n@@ -87,34 +85,36 @@ def test_nigeria(which='births', dt=1, start=1995, n_years=15, do_plot=False):\n             assert np.array_equal(sim.results.pregnancy.pregnancies, sim.results.pregnancy.births)\n             print('✓ (births == pregnancies)')\n \n-    print(\"Check final pop size within 5% of data\")\n-    assert np.isclose(data.n_alive.values[-1], sim.results.n_alive[-1], rtol=0.05)\n+    rtol = 0.05\n+    print(f'Check final pop size within {rtol*100:n}% of data')\n+    assert np.isclose(data.n_alive.values[-1], sim.results.n_alive[-1], rtol=rtol), f'Final population size not within {rtol*100:n}% of data'\n     print(f'✓ (simulated/data={sim.results.n_alive[-1] / data.n_alive.values[-1]:.2f})')\n \n     # Plots\n     if do_plot:\n+        tvec = sim.timevec\n         fig, ax = plt.subplots(2, 2)\n         ax = ax.ravel()\n         ax[0].scatter(data.year, data.n_alive, alpha=0.5)\n-        ax[0].plot(sim.yearvec, sim.results.n_alive, color='k')\n+        ax[0].plot(tvec, sim.results.n_alive, color='k')\n         ax[0].set_title('Population')\n \n-        ax[1].plot(sim.yearvec, 1000 * sim.results.deaths.cmr / dt, label='Simulated CMR')\n+        ax[1].plot(tvec, 1000 * sim.results.deaths.cmr, label='Simulated CMR')\n         ax[1].scatter(cmr_data.Year, cmr_data.CMR, label='Data CMR')\n         ax[1].set_title('CMR')\n         ax[1].legend()\n \n         if which == 'births':\n-            ax[2].plot(sim.yearvec, sim.results.births.cbr / dt, label='Simulated CBR')\n+            ax[2].plot(tvec, sim.results.births.cbr, label='Simulated CBR')\n         elif which == 'pregnancy':\n-            ax[2].plot(sim.yearvec, sim.results.pregnancy.cbr / dt, label='Simulated CBR')\n+            ax[2].plot(tvec, sim.results.pregnancy.cbr, label='Simulated CBR')\n         ax[2].scatter(cbr_data.Year, cbr_data.CBR, label='Data CBR')\n         ax[2].set_title('CBR')\n         ax[2].legend()\n \n         if which == 'pregnancy':\n-            ax[3].plot(sim.yearvec, sim.results.pregnancy.pregnancies / dt, label='Pregnancies')\n-            ax[3].plot(sim.yearvec, sim.results.pregnancy.births / dt, label='Births')\n+            ax[3].plot(tvec, sim.results.pregnancy.pregnancies, label='Pregnancies')\n+            ax[3].plot(tvec, sim.results.pregnancy.births, label='Births')\n             ax[3].set_title('Pregnancies and births')\n             ax[3].legend()\n \n@@ -126,7 +126,7 @@ def test_nigeria(which='births', dt=1, start=1995, n_years=15, do_plot=False):\n def test_constant_pop(do_plot=False):\n     \"\"\" Test pars for constant pop size \"\"\"\n     sc.heading('Testing constant population size')\n-    sim = ss.Sim(n_agents=10e3, birth_rate=10, death_rate=10/1010*1000, n_years=200, rand_seed=1).run()\n+    sim = ss.Sim(n_agents=10e3, birth_rate=10, death_rate=10/1010*1000, dur=200, rand_seed=1).run()\n     print(\"Check final pop size within 5% of starting pop\")\n     assert np.isclose(sim.results.n_alive[0], sim.results.n_alive[-1], rtol=0.05)\n     print(f'✓ (final pop / starting pop={sim.results.n_alive[-1] / sim.results.n_alive[0]:.2f})')\n@@ -143,7 +143,7 @@ def test_module_adding():\n     births = ss.Births(pars={'birth_rate': 10})\n     deaths = ss.Deaths(pars={'death_rate': 10})\n     demographics = [births, deaths]\n-    with pytest.raises(Exception): # CK: should be ValueError, but that fails for now, and this is OK\n+    with pytest.raises(ValueError):\n         ss.Sim(n_agents=1e3, demographics=demographics, birth_rate=10, death_rate=10).run()\n     return demographics\n \n@@ -152,27 +152,27 @@ def test_aging():\n     \"\"\" Test that aging is configured properly \"\"\"\n     sc.heading('Testing aging')\n     n_agents = int(1e3)\n-    \n+\n     # With no demograhpics, people shouldn't age\n-    s1 = ss.Sim(n_agents=n_agents).initialize()\n+    s1 = ss.Sim(n_agents=n_agents).init()\n     orig_ages = s1.people.age.raw.copy()\n     orig_age = orig_ages.mean()\n     s1.run()\n     end_age = s1.people.age.mean()\n     assert orig_age == end_age, f'By default there should be no aging, but {orig_age} != {end_age}'\n-    \n+\n     # We should be able to manually turn on aging\n     s2 = ss.Sim(n_agents=n_agents, use_aging=True).run()\n     age2 = s2.people.age.mean()\n     assert orig_age < age2, f'With aging, start age {orig_age} should be less than end age {age2}'\n-    \n+\n     # Aging should turn on automatically if we add demographics\n     s3 = ss.Sim(n_agents=n_agents, demographics=True).run()\n     agent = s3.people.auids[0] # Find first alive agent\n     orig_agent_age = orig_ages[agent]\n     age3 = s3.people.age[ss.uids(agent)]\n     assert orig_agent_age < age3, f'With demographics, original agent age {orig_agent_age} should be less than end age {age3}'\n-    \n+\n     # ...but can be turned off manually\n     s4 = ss.Sim(n_agents=n_agents, demographics=True, use_aging=False).run()\n     agent = s4.people.auids[0] # Find first alive agent\ndiff --git a/tests/test_diseases.py b/tests/test_diseases.py\nindex c88579f..3ba2c4e 100644\n--- a/tests/test_diseases.py\n+++ b/tests/test_diseases.py\n@@ -10,10 +10,12 @@ import matplotlib.pyplot as plt\n test_run = True\n n_agents = [10_000, 2_000][test_run]\n do_plot = False\n-sc.options(interactive=False) # Assume not running interactively\n+sc.options(interactive=do_plot) # Assume not running interactively\n \n \n def test_sir():\n+    sc.heading('Testing SIR dynamics')\n+\n     ppl = ss.People(n_agents)\n     network_pars = {\n         'n_contacts': ss.poisson(4), # Contacts Poisson distributed with a mean of 4\n@@ -26,7 +28,7 @@ def test_sir():\n     sir = ss.SIR(sir_pars)\n \n     # Change pars after creating the SIR instance\n-    sir.pars.beta = {'random': 0.1}\n+    sir.pars.beta = {'random': ss.rate(0.1)}\n \n     # You can also change the parameters of the default lognormal distribution directly\n     sir.pars.dur_inf.set(loc=5)\n@@ -40,7 +42,7 @@ def test_sir():\n     plt.figure()\n     res = sim.results\n     plt.stackplot(\n-        sim.yearvec,\n+        sim.timevec,\n         res.sir.n_susceptible,\n         res.sir.n_infected,\n         res.sir.n_recovered,\n@@ -54,7 +56,7 @@ def test_sir():\n \n def test_sir_epi():\n     sc.heading('Test basic epi dynamics')\n-    \n+\n     base_pars = dict(n_agents=n_agents, networks=dict(type='random'), diseases=dict(type='sir'))\n \n     # Define the parameters to vary\n@@ -103,6 +105,8 @@ def test_sir_epi():\n \n \n def test_sis(do_plot=do_plot):\n+    sc.heading('Testing SIS dynamics')\n+\n     pars = dict(\n         n_agents = n_agents,\n         diseases = 'sis',\n@@ -117,23 +121,27 @@ def test_sis(do_plot=do_plot):\n \n \n def test_ncd():\n+    sc.heading('Testing NCDs')\n+\n     ppl = ss.People(n_agents)\n-    ncd = ss.NCD()\n+    ncd = ss.NCD(pars={'log':True})\n     sim = ss.Sim(people=ppl, diseases=ncd, copy_inputs=False) # Since using ncd directly below\n     sim.run()\n \n     assert len(ncd.log.out_edges) == ncd.log.number_of_edges()\n-    df = ncd.log.line_list  # Check generation of line-list\n+    df = ncd.log.line_list()  # Check generation of line-list\n     assert df.source.isna().all()\n \n     plt.figure()\n     plt.stackplot(\n-        sim.yearvec,\n+        sim.timevec,\n         ncd.results.n_not_at_risk,\n         ncd.results.n_at_risk - ncd.results.n_affected,\n         ncd.results.n_affected,\n         sim.results.new_deaths.cumsum(),\n     )\n+    assert ncd.results.n_not_at_risk.label == 'Not at risk'\n+    assert ncd.results.n_affected.label == 'Affected'\n     plt.legend(['Not at risk', 'At risk', 'Affected', 'Dead'])\n     plt.xlabel('Year')\n     plt.title('NCD')\n@@ -141,6 +149,8 @@ def test_ncd():\n \n \n def test_gavi():\n+    sc.heading('Testing GAVI diseases')\n+\n     sims = sc.autolist()\n     for disease in ['cholera', 'measles', 'ebola']:\n         pars = dict(\n@@ -155,6 +165,8 @@ def test_gavi():\n \n \n def test_multidisease():\n+    sc.heading('Testing simulating multiple diseases')\n+\n     ppl = ss.People(n_agents)\n     sir1 = ss.SIR(name='sir1')\n     sir2 = ss.SIR(name='sir2')\n@@ -167,9 +179,9 @@ def test_multidisease():\n     sim.run()\n     return sim\n \n-def test_mtct():\n-    \"\"\" Test mother-to-child transmission routes \"\"\"\n \n+def test_mtct():\n+    sc.heading('Test mother-to-child transmission routes')\n     ppl = ss.People(n_agents)\n     sis = ss.SIS(beta={'random':[0.005, 0.001], 'prenatal':[0.1, 0], 'postnatal':[0.1, 0]})\n     networks = [ss.RandomNet(), ss.PrenatalNet(), ss.PostnatalNet()]\n@@ -178,7 +190,9 @@ def test_mtct():\n     sim.run()\n     return sim\n \n+\n if __name__ == '__main__':\n+    do_plot = True\n     sc.options(interactive=do_plot)\n     sir   = test_sir()\n     s1,s2 = test_sir_epi()\ndiff --git a/tests/test_dist.py b/tests/test_dist.py\nindex eaedd01..aebb4b4 100644\n--- a/tests/test_dist.py\n+++ b/tests/test_dist.py\n@@ -6,22 +6,23 @@ import numpy as np\n import sciris as sc\n import scipy.stats as sps\n import starsim as ss\n-import matplotlib.pyplot as pl\n+import matplotlib.pyplot as plt\n import pytest\n \n n = 1_000_000 # For testing statistical properties and performance of distributions\n m = 5 # For just testing that drawing works\n+dpy = 365.25 # Number of days per year\n sc.options(interactive=False)\n \n \n def plot_rvs(rvs, times=None, nrows=None):\n-    fig = pl.figure(figsize=(12,12))\n+    fig = plt.figure(figsize=(12,12))\n     nrows, ncols = sc.getrowscols(len(rvs), nrows=nrows)\n     for i,name,r in rvs.enumitems():\n-        pl.subplot(nrows, ncols, i+1)\n-        pl.hist(r.astype(float))\n+        plt.subplot(nrows, ncols, i+1)\n+        plt.hist(r.astype(float))\n         title = times[name] if times else name\n-        pl.title(title)\n+        plt.title(title)\n         sc.commaticks()\n     sc.figlayout()\n     return fig\n@@ -29,7 +30,7 @@ def plot_rvs(rvs, times=None, nrows=None):\n \n def make_sim():\n     \"\"\" Make a tiny sim for initializing the distributions \"\"\"\n-    sim = ss.Sim(n_agents=100).initialize() # Need an empty sim to initialize properly\n+    sim = ss.Sim(n_agents=100).init() # Need an empty sim to initialize properly\n     return sim\n \n \n@@ -38,39 +39,43 @@ def test_dist(m=m):\n     \"\"\" Test the Dist class \"\"\"\n     sc.heading('Testing the basic Dist call')\n     dist = ss.Dist(distname='random', name='test', strict=False)\n-    dist.initialize()\n+    dist.init()\n     rvs = dist(m)\n     print(rvs)\n     assert 0 < rvs.min() < 1, 'Values should be between 0 and 1'\n+\n+    # Test other options\n+    dist.show_state()\n+    dist.plot_hist()\n     return rvs\n \n \n def test_custom_dists(n=n, do_plot=False):\n     \"\"\" Test all custom dists \"\"\"\n     sc.heading('Testing all custom distributions')\n-    \n+\n     o     = sc.objdict()\n     dists = sc.objdict()\n     rvs   = sc.objdict()\n     times = sc.objdict()\n     for name in ss.dist_list:\n-        func = getattr(ss, name)\n-        dist = func(name='test', strict=False)\n-        dist.initialize()\n+        dist_class = getattr(ss, name)\n+        dist = dist_class(name='test', strict=False)\n+        dist.init()\n         dists[name] = dist\n         sc.tic()\n         rvs[name] = dist.rvs(n)\n         times[name] = sc.toc(name, unit='ms', output='message')\n         print(f'{name:10s}: mean = {rvs[name].mean():n}')\n-    \n+\n     if do_plot:\n         plot_rvs(rvs, times=times, nrows=5)\n-    \n+\n     o.dists = dists\n     o.rvs = rvs\n     o.times = times\n     return o\n-        \n+\n \n def test_dists(n=n, do_plot=False):\n     \"\"\" Test the Dists container \"\"\"\n@@ -79,14 +84,14 @@ def test_dists(n=n, do_plot=False):\n \n     # Create the objects twice\n     for i in range(2):\n-        \n+\n         # Create a complex object containing various distributions\n         obj = sc.prettyobj()\n         obj.a = sc.objdict()\n         obj.a.mylist = [ss.random(), ss.Dist(distname='uniform', low=2, high=3)]\n         obj.b = dict(d3=ss.weibull(c=2), d4=ss.constant(v=0.3))\n-        dists = ss.Dists(obj).initialize(sim=make_sim())\n-        \n+        dists = ss.Dists(obj).init(sim=make_sim())\n+\n         # Call each distribution twice\n         for j in range(2):\n             rvs = sc.objdict()\n@@ -94,15 +99,15 @@ def test_dists(n=n, do_plot=False):\n                 rvs[str(dist)] = dist(n)\n                 dist.jump() # Reset\n             testvals[i,j] = rvs[0][283] # Pick one of the random values and store it\n-    \n+\n     # Check that results are as expected\n     print(testvals)\n     assert np.all(testvals[0,:] == testvals[1,:]), 'Newly initialized objects should match'\n     assert np.all(testvals[:,0] != testvals[:,1]), 'After jumping, values should be different'\n-            \n+\n     if do_plot:\n         plot_rvs(rvs)\n-    \n+\n     o = sc.objdict()\n     o.dists = dists\n     o.rvs = rvs\n@@ -112,96 +117,101 @@ def test_dists(n=n, do_plot=False):\n def test_scipy(m=m):\n     \"\"\" Test that SciPy distributions also work \"\"\"\n     sc.heading('Testing SciPy distributions')\n-    \n+\n     # Make SciPy distributions in two different ways\n-    dist1 = ss.Dist(dist=sps.expon, name='scipy', scale=2, strict=False).initialize() # Version 1: callable\n-    dist2 = ss.Dist(dist=sps.expon(scale=2), name='scipy', strict=False).initialize() # Version 2: frozen\n+    dist1 = ss.Dist(dist=sps.expon, name='scipy', scale=2, strict=False).init() # Version 1: callable\n+    dist2 = ss.Dist(dist=sps.expon(scale=2), name='scipy', strict=False).init() # Version 2: frozen\n     rvs1 = dist1(m)\n     rvs2 = dist2(m)\n-    \n+\n     # Check that they match\n     print(rvs1)\n     assert np.array_equal(rvs1, rvs2), 'Arrays should match'\n-    \n+\n     return dist1, dist2\n \n \n def test_exceptions(m=m):\n     \"\"\" Check that exceptions are being appropriately raised \"\"\"\n     sc.heading('Testing exceptions and strict')\n-    \n+\n     # Create a strict distribution\n     dist = ss.random(strict=True, auto=False)\n     with pytest.raises(ss.distributions.DistNotInitializedError):\n         dist(m) # Check that we can't call an uninitialized\n-    \n+\n     # Initialize and check we can't call repeatedly\n-    dist.initialize(trace='test', sim=make_sim())\n+    dist.init(trace='test', sim=make_sim())\n     rvs = dist(m)\n     with pytest.raises(ss.distributions.DistNotReadyError):\n         dist(m) # Check that we can't call an already-used distribution\n-    \n+\n     # Check that we can with a non-strict Dist\n     dist2 = ss.random(strict=False)\n-    dist2.initialize(trace='test')\n+    dist2.init(trace='test')\n     rvs2 = sc.autolist()\n     for i in range(2):\n         rvs2 += dist2(m) # We should be able to call multiple times with no problem\n-    \n+\n     print(rvs)\n     print(rvs2)\n     assert np.array_equal(rvs, rvs2[0]), 'Separate dists should match'\n     assert not np.array_equal(rvs2[0], rvs2[1]), 'Multiple calls to the same dist should not match'\n-    \n+\n     return dist, dist2\n-    \n+\n \n def test_reset(m=m):\n     \"\"\" Check that reset works as expected \"\"\"\n     sc.heading('Testing reset')\n-    \n+\n     # Create and draw two sets of random numbers\n-    dist = ss.random(seed=533, strict=False).initialize()\n+    dist = ss.random(seed=533, strict=False).init()\n     r1 = dist.rvs(m)\n     r2 = dist.rvs(m)\n     assert all(r1 != r2)\n-    \n+\n     # Reset to the most recent state\n     dist.reset(-1)\n     r3 = dist.rvs(m)\n     assert all(r3 == r2)\n-    \n+\n     # Reset to the initial state\n     dist.reset(0)\n     r4 = dist.rvs(m)\n     assert all(r4 == r1)\n-    \n+\n     for r in [r1, r2, r3, r4]:\n         print(r)\n-    \n+\n     return dist\n \n \n-def test_callable(n=n):\n-    \"\"\" Test callable parameters \"\"\"\n-    sc.heading('Testing a uniform distribution with callable parameters')\n-    \n-    # Define a fake people object\n+def make_fake_sim(n=10):\n+    \"\"\" Define a fake sim object for testing slots \"\"\"\n     sim = sc.prettyobj()\n-    sim.n = 10\n+    sim.n = n\n     sim.people = sc.prettyobj()\n     sim.people.uid = np.arange(sim.n)\n     sim.people.slot = np.arange(sim.n)\n-    sim.people.age = np.random.uniform(0, 90, size=sim.n)\n+    sim.people.age = np.random.uniform(0, 100, size=sim.n)\n+    return sim\n+\n+\n+def test_callable(n=n):\n+    \"\"\" Test callable parameters \"\"\"\n+    sc.heading('Testing a uniform distribution with callable parameters')\n+\n+    sim = make_fake_sim()\n \n     # Define a parameter as a function\n     def custom_loc(module, sim, uids):\n         out = sim.people.age[uids]\n         return out\n-    \n+\n     scale = 1\n-    d1 = ss.normal(name='callable', loc=custom_loc, scale=scale).initialize(sim=sim)\n-    d2 = ss.lognorm_ex(name='callable', mean=custom_loc, stdev=scale).initialize(sim=sim)\n+    d1 = ss.normal(name='callable', loc=custom_loc, scale=scale).init(sim=sim)\n+    d2 = ss.lognorm_ex(name='callable', mean=custom_loc, std=scale).init(sim=sim)\n \n     uids = np.array([1, 3, 7, 9])\n     draws1 = d1.rvs(uids)\n@@ -212,6 +222,7 @@ def test_callable(n=n):\n     for draws in [draws1, draws2]:\n         meandiff = np.abs(sim.people.age[uids] - draws).mean()\n         assert meandiff < scale*3, 'Outputs should match ages'\n+\n     return d1\n \n \n@@ -223,7 +234,7 @@ def test_array(n=n):\n     low  = np.array([1, 100]) # Low\n     high = np.array([3, 125]) # High\n \n-    d = ss.uniform(low=low, high=high, strict=False).initialize(slots=np.arange(uids.max()+1))\n+    d = ss.uniform(low=low, high=high, strict=False).init(slots=np.arange(uids.max()+1))\n     draws = d.rvs(uids)\n     print(f'Uniform sample for uids {uids} returned {draws}')\n \n@@ -245,9 +256,9 @@ def test_repeat_slot():\n     high = low + 1\n \n     # Draw values\n-    d = ss.uniform(low=low, high=high, strict=False).initialize(slots=slots)\n+    d = ss.uniform(low=low, high=high, strict=False).init(slots=slots)\n     draws = d.rvs(uids)\n-    \n+\n     # Print and test\n     print(f'Uniform sample for slots {slots} returned {draws}')\n     assert len(draws) == len(slots)\n@@ -261,14 +272,176 @@ def test_repeat_slot():\n     return draws\n \n \n+def test_timepar_dists():\n+    \"\"\" Test interaction of distributions and timepars \"\"\"\n+    sc.heading('Test interaction of distributions and timepars')\n+\n+    # Set parameters\n+    n = int(10e3)\n+    u1 = 'day'\n+    u2 = 'year'\n+    dt_dur = 0.1\n+    dt_rate = 20.0\n+    ratio_dur  = ss.time_ratio(u1, 1.0, u2, dt_dur)\n+    ratio_rate = ss.time_ratio(u2, 1.0, u1, dt_rate)\n+\n+    # Create time parameters\n+    v = sc.objdict()\n+    v.base = 30.0\n+    v.dur = ss.dur(v.base, unit=u1, parent_unit=u2, parent_dt=dt_dur).init()\n+    v.rate = ss.rate(v.base, unit=u2, parent_unit=u1, parent_dt=dt_rate).init() # Swap units\n+\n+    # Check distributions that scale linearly with time, with the parameter we'll set\n+    print('Testing linear distributions ...')\n+    linear_dists = dict(\n+        constant   = 'v',\n+        uniform    = 'high',\n+        normal     = 'loc',\n+        lognorm_ex = 'mean',\n+        expon      = 'scale',\n+        weibull    = 'scale',\n+        gamma      = 'scale',\n+    )\n+\n+    for name,par in linear_dists.items():\n+        dist_class = getattr(ss, name)\n+\n+        # Create the dists, the first parameter of which should have time units\n+        dists = sc.objdict()\n+        for key,val in v.items():\n+            pardict = {par:val} # Convert to a tiny dictionary to insert the correct name\n+            dists[key] = dist_class(**pardict, name=key, strict=False).init()\n+\n+        # Create th erandom variates\n+        rvs = sc.objdict()\n+        for k,dist in dists.items():\n+            rvs[k] = dist.rvs(n)\n+\n+        # Check that the distributions match\n+        rtol = 0.1 # Be somewhat generous with the uncertainty\n+        expected = rvs.base.mean()\n+        expected_dur = expected*ratio_dur\n+        expected_rate = expected/ratio_rate\n+        actual_dur = rvs.dur.mean()\n+        actual_rate = rvs.rate.mean()\n+        assert np.isclose(expected_dur, actual_dur, rtol=rtol), f'Duration not close for {name}: {expected_dur:n} ≠ {actual_dur:n}'\n+        assert np.isclose(expected_rate, actual_rate, rtol=rtol), f'Rate not close for {name}: {expected_rate:n} ≠ {actual_rate:n}'\n+        sc.printgreen(f'✓ {name} passed: {expected_dur:n} ≈ {actual_dur:n}')\n+\n+    # Check that unitless distributions fail\n+    print('Testing unitless distributions ...')\n+    par = ss.dur(10)\n+    unitless_dists = ['lognorm_im', 'randint', 'choice']\n+    for name in unitless_dists:\n+        dist_class = getattr(ss, name)\n+        with pytest.raises(NotImplementedError):\n+            dist = dist_class(par, name='notimplemented', strict=False).init()\n+            dist.rvs(n)\n+        sc.printgreen(f'✓ {name} passed: raised appropriate error')\n+\n+    # Check special distributions\n+    print('Testing Poisson distribution ...')\n+    lam1 = ss.rate(dpy, 'year', parent_unit='year').init()\n+    lam2 = ss.rate(1,   'day',  parent_unit='year').init()\n+    poi1 = ss.poisson(lam=lam1, strict=False).init()\n+    poi2 = ss.poisson(lam=lam2, strict=False).init()\n+    mean1 = poi1.rvs(n).mean()\n+    mean2 = poi2.rvs(n).mean()\n+    assert np.isclose(mean1, mean2, rtol=rtol), f'Poisson values do not match for {lam1} and {lam2}: {mean1:n} ≠ {mean2:n}'\n+    sc.printgreen(f'✓ poisson passed: {mean1:n} ≈ {mean2:n}')\n+\n+    print('Testing Bernoulli distribution ...')\n+    p1 = 0.1\n+    p2 = ss.time_prob(0.01, parent_dt=10).init()\n+    ber1 = ss.bernoulli(p=p1, strict=False).init()\n+    ber2 = ss.bernoulli(p=p2, strict=False).init()\n+    mean1 = ber1.rvs(n).mean()\n+    mean2 = ber2.rvs(n).mean()\n+    assert np.isclose(mean1, mean2, rtol=rtol), f'Bernoulli values do not match for {lam1} and {lam2}: {mean1:n} ≠ {mean2:n}'\n+    sc.printgreen(f'✓ bernoulli passed: {mean1:n} ≈ {mean2:n}')\n+\n+    return ber2\n+\n+\n+def test_timepar_callable():\n+    sc.heading('Test that timepars work with (some) callable functions')\n+\n+    print('Testing callable parameters with regular-scaling distributions')\n+    sim = make_fake_sim(n=10)\n+    uids = np.array([1, 3, 7, 9])\n+\n+    def age_year(module, sim, uids):\n+        \"\"\" Extract age as a year \"\"\"\n+        out = sim.people.age[uids].copy()\n+        return out\n+\n+    def age_day(module, sim, uids):\n+        \"\"\" Extract age as a day \"\"\"\n+        out = sim.people.age[uids].copy()\n+        out *= dpy # Convert to days manually\n+        return out\n+\n+    scale = 1e-3 # Set to a very small but nonzero scale\n+    loc  = ss.dur(age_year, unit='year', parent_unit='day').init(update_values=False)\n+    mean = ss.dur(age_day,  unit='day',  parent_unit='day').init(update_values=False)\n+    d3 = ss.normal(name='callable', loc=loc, scale=scale).init(sim=sim)\n+    d4 = ss.lognorm_ex(name='callable', mean=mean, std=scale).init(sim=sim)\n+    draws3 = d3.rvs(uids)\n+    draws4 = d4.rvs(uids)\n+    age_in_days = sim.people.age[uids]*dpy\n+    draw_diff = np.abs(draws3 - draws4).mean()\n+    age_diff = np.abs(age_in_days - draws3).mean()\n+    print(f'Input ages were:\\n{sim.people.age[uids]}')\n+    print(f'Output samples were:\\n{sc.sigfiground(draws3)}\\n{sc.sigfiground(draws4)}')\n+    assert draw_diff < 1, 'Day and year outputs should match to the nearest day'\n+    assert age_diff < 1, 'Distribution outputs should match ages to the nearest day'\n+\n+    print('Testing callable parameters with Bernoulli distributions')\n+    n = 100_000\n+    sim = make_fake_sim(n=n)\n+    uids = np.random.choice(n, size=n//2, replace=False)\n+    age = sim.people.age[uids]\n+    mean = age.mean()\n+    young = sc.findinds(age<=mean)\n+    old = sc.findinds(age>mean)\n+    p_young = 0.001\n+    p_old = 0.010\n+\n+    def age_prob(module, sim, uids):\n+        out = np.zeros_like(age)\n+        out[young] = p_young\n+        out[old]   = p_old\n+        return out\n+\n+    parent_dt = 10\n+    p1 = age_prob\n+    p2 = ss.time_prob(age_prob, parent_dt=parent_dt).init(update_values=False)\n+    ber1 = ss.bernoulli(name='base', p=p1).init(sim=sim)\n+    ber2 = ss.bernoulli(name='time', p=p2).init(sim=sim)\n+    brvs1 = ber1.rvs(uids)\n+    brvs2 = ber2.rvs(uids)\n+\n+    rtol = 0.5 # We're dealing with order-of-magnitude differences but small numbers, so be generous to avoid random failures\n+    sum1 = brvs1.sum()*parent_dt\n+    sum2 = brvs2.sum()\n+    assert np.isclose(sum1, sum2, rtol=rtol), f'Callable Bernoulli sums did not match: {sum1}  ≠  {sum2}'\n+    sc.printgreen(f'✓ Callable Bernoulli sums matched: {sum1:n} ≈ {sum2:n}')\n+    for key,expected,inds in zip(['young', 'old'], [p_young, p_old], [young, old]):\n+        m1 = brvs1[inds].mean()\n+        m2 = brvs2[inds].mean()/parent_dt\n+        assert np.allclose([expected, m1], [expected, m2], rtol=rtol), f'Callable Bernoulli proportions did not match: {expected:n}  ≠  {m1:n}  ≠  {m2:n}'\n+        sc.printgreen(f'✓ Callable Bernoulli proportions matched: {expected:n}  ≈  {m1:n}  ≈  {m2:n}')\n+\n+    return\n+\n \n # %% Run as a script\n if __name__ == '__main__':\n     do_plot = True\n     sc.options(interactive=do_plot)\n-    \n+\n     T = sc.timer()\n-    \n+\n     o1 = test_dist()\n     o2 = test_custom_dists(do_plot=do_plot)\n     o3 = test_dists(do_plot=do_plot)\n@@ -278,5 +451,7 @@ if __name__ == '__main__':\n     o7 = test_callable()\n     o8 = test_array()\n     o9 = test_repeat_slot()\n-    \n+    o10 = test_timepar_dists()\n+    o10 = test_timepar_callable()\n+\n     T.toc()\ndiff --git a/tests/test_interventions.py b/tests/test_interventions.py\nindex 1f7f05e..8a1abca 100644\n--- a/tests/test_interventions.py\n+++ b/tests/test_interventions.py\n@@ -8,7 +8,7 @@ import numpy as np\n import starsim as ss\n \n \n-def run_sir_vaccine(efficacy, leaky=True):\n+def run_sir_vaccine(efficacy, leaky=True, do_plot=False):\n     # parameters\n     v_frac      = 0.5    # fraction of population vaccinated\n     total_cases = 500    # total cases at which point we check results\n@@ -16,32 +16,32 @@ def run_sir_vaccine(efficacy, leaky=True):\n \n     # create a basic SIR sim\n     sim = ss.Sim(\n-        n_agents = 1000,     \n+        n_agents = 1000,\n         pars = dict(\n-          networks = dict(     \n-                type = 'random', \n-                n_contacts = 4    \n+          networks = dict(\n+                type = 'random',\n+                n_contacts = 4\n           ),\n-          diseases = dict(      \n-                type      = 'sir',     \n-                init_prev = 0.01,  \n-                dur_inf   = 0.1,\n+          diseases = dict(\n+                type      = 'sir',\n+                init_prev = 0.01,\n+                dur_inf   = ss.dur(10),\n                 p_death   = 0,\n-                beta      = 6,       \n+                beta      = ss.beta(0.06),\n           )\n         ),\n-        n_years = 10,\n-        dt      = 0.01\n+        dur = 10,\n+        dt  = 0.01\n     )\n-    sim.initialize(verbose=False)\n-    \n+    sim.init(verbose=False)\n+\n     # work out who to vaccinate\n     in_trial = sim.people.sir.susceptible.uids\n     n_vac = round(len(in_trial) * v_frac)\n     in_vac = np.random.choice(in_trial, n_vac, replace=False)\n     in_pla = np.setdiff1d(in_trial, in_vac)\n     uids = ss.uids(in_vac)\n-    \n+\n     # create and apply the vaccination\n     vac = ss.sir_vaccine(efficacy=efficacy, leaky=leaky)\n     vac.init_pre(sim)\n@@ -62,7 +62,7 @@ def run_sir_vaccine(efficacy, leaky=True):\n     # run the simulation until sufficient cases\n     old_cases = []\n     for idx in range(1000):\n-        sim.step()\n+        sim.run_one_step()\n         susc = sim.people.sir.susceptible.uids\n         cases = np.setdiff1d(in_trial, susc)\n         if len(cases) > total_cases:\n@@ -84,20 +84,24 @@ def run_sir_vaccine(efficacy, leaky=True):\n         assert len(np.intersect1d(vac_cases, in_vac[rel_susc[in_vac] == 1.0])) == len(vac_cases), 'Not all vaccine cases amongst vaccine failures (all or nothing)'\n         assert len(np.intersect1d(vac_cases, in_vac[rel_susc[in_vac] == 0.0])) == 0, 'Vaccine cases amongst fully vaccincated (all or nothing)'\n \n+    if do_plot:\n+        sim.plot()\n+\n     return sim\n \n \n-def test_sir_vaccine_leaky():\n-    return run_sir_vaccine(0.3, False)\n+def test_sir_vaccine_leaky(do_plot=False):\n+    return run_sir_vaccine(0.3, False, do_plot=do_plot)\n \n-def test_sir_vaccine_all_or_nothing():\n-    return run_sir_vaccine(0.3, True)\n+def test_sir_vaccine_all_or_nothing(do_plot=False):\n+    return run_sir_vaccine(0.3, True, do_plot=do_plot)\n \n \n if __name__ == '__main__':\n     T = sc.timer()\n+    do_plot = True\n \n-    sir_vaccine_leaky   = test_sir_vaccine_leaky(leaky=True)\n-    sir_vaccine_a_or_n  = test_sir_vaccine_all_or_nothing(leaky=False)\n+    leaky  = test_sir_vaccine_leaky(do_plot=do_plot)\n+    a_or_n = test_sir_vaccine_all_or_nothing(do_plot=do_plot)\n \n     T.toc()\ndiff --git a/tests/test_loop.py b/tests/test_loop.py\nnew file mode 100644\nindex 0000000..d438aba\n--- /dev/null\n+++ b/tests/test_loop.py\n@@ -0,0 +1,55 @@\n+\"\"\"\n+Test the Loop class\n+\"\"\"\n+\n+# %% Imports and settings\n+import sciris as sc\n+import starsim as ss\n+\n+sc.options(interactive=False) # Assume not running interactively\n+\n+pars = sc.objdict(\n+    dur      = 20,\n+    n_agents = 1000,\n+    diseases = 'sis',\n+    networks = 'random',\n+)\n+\n+\n+def test_run_options():\n+    sc.heading('Testing run options...')\n+    s1 = ss.Sim(pars).init()\n+    s2 = ss.Sim(pars).init()\n+\n+    # Automatic run\n+    s1.run()\n+\n+    # Manual run\n+    while s2.loop.index < len(s2.loop):\n+        s2.run_one_step()\n+    s2.finalize()\n+\n+    assert s1.summary == s2.summary, 'Sims do not match'\n+\n+    return s2.loop\n+\n+\n+def test_loop_plotting():\n+    sc.heading('Testing loop plotting...')\n+    sim = ss.Sim(pars).run()\n+    sim.loop.plot()\n+    sim.loop.plot_cpu()\n+    return sim.loop\n+\n+\n+# %% Run as a script\n+if __name__ == '__main__':\n+    do_plot = True\n+    sc.options(interactive=do_plot)\n+    T = sc.timer()\n+\n+    # Run tests\n+    l1 = test_run_options()\n+    l2 = test_loop_plotting()\n+\n+    T.toc()\n\\ No newline at end of file\ndiff --git a/tests/test_mixingpools.py b/tests/test_mixingpools.py\nnew file mode 100644\nindex 0000000..43792cb\n--- /dev/null\n+++ b/tests/test_mixingpools.py\n@@ -0,0 +1,203 @@\n+\"\"\"\n+Test Sim API\n+\"\"\"\n+\n+# %% Imports and settings\n+import sys\n+import numpy as np\n+import sciris as sc\n+import matplotlib.pyplot as plt\n+import starsim as ss\n+import pytest\n+\n+n_agents = 1_000\n+do_plot = False\n+sc.options(interactive=False) # Assume not running interactively\n+\n+\n+def test_single_defaults(do_plot=do_plot):\n+    \"\"\" Test a single MixingPool using defaults \"\"\"\n+    test_name = sys._getframe().f_code.co_name\n+    sc.heading(f'Testing {test_name}...')\n+    mp = ss.MixingPool()\n+    sir = ss.SIR()\n+    sim = ss.Sim(diseases=sir, networks=mp, label=test_name)\n+    sim.run()\n+\n+    if do_plot: sim.plot()\n+\n+    assert(sim.results.sir['cum_infections'][-1] > sim.results.sir['cum_infections'][0]) # There were infections\n+    return sim\n+\n+\n+def test_single_uids(do_plot=do_plot):\n+    \"\"\" Test a single MixingPool by UIDS, pre-initialization configuration \"\"\"\n+    test_name = sys._getframe().f_code.co_name\n+    sc.heading(f'Testing {test_name}...')\n+\n+    n_agents = 10_000\n+    k = n_agents // 2\n+    mp = ss.MixingPool(\n+        src = ss.uids(np.arange(k)),\n+        dst = ss.uids(np.arange(k,n_agents))\n+    )\n+    sir = ss.SIR()\n+    sim = ss.Sim(n_agents=n_agents, diseases=sir, networks=mp, label=test_name)\n+    sim.run()\n+\n+    if do_plot: sim.plot()\n+\n+    assert sim.results.sir['cum_infections'][-1] > sim.results.sir['cum_infections'][0], 'There were no new infections in the simulation'\n+    return sim\n+\n+\n+def test_single_ncd():\n+    \"\"\" Test a single MixingPool with a ncd \"\"\"\n+    test_name = sys._getframe().f_code.co_name\n+    sc.heading(f'Testing {test_name}...')\n+    mp_pars = {\n+        'src': ss.AgeGroup(0, 15),\n+        'dst': ss.AgeGroup(15, None),\n+        'beta': ss.beta(0.15),\n+        'contacts': ss.poisson(lam=5),\n+        'diseases': 'ncd'\n+    }\n+    mp = ss.MixingPool(mp_pars)\n+\n+    ncd = ss.NCD()\n+    sim = ss.Sim(diseases=ncd, networks=mp, label=test_name)\n+    with pytest.raises(Exception):\n+        sim.run()\n+    return sim\n+\n+\n+def test_single_missing_disease():\n+    \"\"\" Test a single MixingPool with a missing disease \"\"\"\n+    test_name = sys._getframe().f_code.co_name\n+    sc.heading(f'Testing {test_name}...')\n+    mp_pars = {\n+        'src': ss.AgeGroup(0, 15),\n+        'dst': ss.AgeGroup(15, None),\n+        'beta': ss.beta(0.15),\n+        'contacts': ss.poisson(lam=5),\n+        'diseases': 'hiv'\n+    }\n+    mp = ss.MixingPool(mp_pars)\n+\n+    sir = ss.SIR()\n+    sim = ss.Sim(diseases=sir, networks=mp, label=test_name)\n+    with pytest.raises(Exception):\n+        sim.run()\n+\n+    return sim\n+\n+\n+def test_single_age(do_plot=do_plot):\n+    \"\"\" Test a single MixingPool by age \"\"\"\n+    # Incidence must decline because 0-15 --> 15+ transmission only\n+    test_name = sys._getframe().f_code.co_name\n+    sc.heading(f'Testing {test_name}...')\n+    mp_pars = {\n+        'src': ss.AgeGroup(0, 15),\n+        'dst': ss.AgeGroup(15, None),\n+        'beta': ss.beta(0.15),\n+        'contacts': ss.poisson(lam=5),\n+    }\n+    mp = ss.MixingPool(mp_pars)\n+\n+    sir = ss.SIR()\n+    sim = ss.Sim(diseases=sir, networks=mp, label=test_name)\n+    sim.run()\n+\n+    if do_plot: sim.plot()\n+\n+    assert(sim.results.sir['cum_infections'][-1] > sim.results.sir['cum_infections'][0]) # There were infections\n+    return sim\n+\n+\n+def test_single_sex(do_plot=do_plot):\n+    \"\"\" Test a single MixingPool by sex \"\"\"\n+    # Incidence must decline because M --> F transmission only\n+    test_name = sys._getframe().f_code.co_name\n+    sc.heading(f'Testing {test_name}...')\n+    mp_pars = {\n+        'src': lambda sim: sim.people.female, # female to male (only) transmission\n+        'dst': lambda sim: sim.people.male,\n+        'beta': ss.beta(0.2),\n+        'contacts': ss.poisson(lam=4),\n+    }\n+    mp = ss.MixingPool(mp_pars)\n+\n+    sir = ss.SIR(init_prev=ss.bernoulli(p=lambda self, sim, uids: 0.05*sim.people.female)) # Seed 5% of the female population\n+    sim = ss.Sim(diseases=sir, networks=mp, label=test_name)\n+    sim.run()\n+\n+    if do_plot: sim.plot()\n+\n+    assert(sim.results.sir['cum_infections'][-1] > sim.results.sir['cum_infections'][0]) # There were infections\n+    assert(sim.people.male[sim.diseases.sir.ti_infected>0].all()) # All new infections should be in men\n+    return sim\n+\n+\n+def test_multi_defaults(do_plot=do_plot):\n+    \"\"\" Test MixingPools using defaults \"\"\"\n+    test_name = sys._getframe().f_code.co_name\n+    sc.heading(f'Testing {test_name}...')\n+    mps = ss.MixingPools(src={'all':None}, dst={'all':None}, contacts=[[1]])\n+    sir = ss.SIR()\n+    sim = ss.Sim(diseases=sir, networks=mps, label=test_name)\n+    sim.run()\n+\n+    if do_plot: sim.plot()\n+\n+    assert(sim.results.sir['cum_infections'][-1] > sim.results.sir['cum_infections'][0]) # There were infections\n+    return sim\n+\n+\n+def test_multi(do_plot=do_plot):\n+    \"\"\" Test MixingPools \"\"\"\n+    test_name = sys._getframe().f_code.co_name\n+    sc.heading(f'Testing {test_name}...')\n+\n+    groups = {\n+        'Female': lambda sim: sim.people.female,\n+        'Male': lambda sim: sim.people.male,\n+    }\n+\n+    mps_pars = dict(\n+        contacts = np.array([[1.4, 0.5], [1.2, 0.7]]),\n+        beta = ss.beta(0.2),\n+        src = groups,\n+        dst = groups,\n+    )\n+    mps = ss.MixingPools(mps_pars)\n+\n+    sir = ss.SIR()\n+    sim = ss.Sim(diseases=sir, networks=mps, label=test_name)\n+    sim.run()\n+\n+    if do_plot: sim.plot()\n+\n+    assert(sim.results.sir['cum_infections'][-1] > sim.results.sir['cum_infections'][0]) # There were infections\n+    return sim\n+\n+\n+if __name__ == '__main__':\n+    do_plot = True\n+    sc.options(interactive=do_plot)\n+    T = sc.timer()\n+\n+    sim0 = test_single_defaults(do_plot)\n+    sim1 = test_single_uids(do_plot)\n+    sim2 = test_single_ncd()\n+    sim3 = test_single_missing_disease()\n+    sim4 = test_single_age(do_plot)\n+    sim5 = test_single_sex(do_plot)\n+\n+    sim6 = test_multi_defaults(do_plot)\n+    sim7 = test_multi(do_plot)\n+\n+    T.toc()\n+\n+    if do_plot:\n+        plt.show()\ndiff --git a/tests/test_networks.py b/tests/test_networks.py\nindex 085866e..7a5813a 100644\n--- a/tests/test_networks.py\n+++ b/tests/test_networks.py\n@@ -6,6 +6,7 @@ Test networks\n import sciris as sc\n import numpy as np\n import starsim as ss\n+import scipy.stats as sps\n \n sc.options(interactive=False) # Assume not running interactively\n \n@@ -27,11 +28,11 @@ def test_manual():\n \n     # Create a maternal network\n     sim = ss.Sim(n_agents=n_agents)\n-    sim.initialize()\n+    sim.init()\n     nw2 = ss.MaternalNet()\n     nw2.init_pre(sim)\n     nw2.add_pairs(mother_inds=[1, 2, 3], unborn_inds=[100, 101, 102], dur=[1, 1, 1])\n-    \n+\n     # Tidy\n     o = sc.objdict(nw1=nw1, nw2=nw2)\n     return o\n@@ -42,62 +43,187 @@ def test_random():\n \n     # Manual creation\n     nw1 = ss.RandomNet()\n-    ss.Sim(n_agents=small, networks=nw1, copy_inputs=False).initialize() # This initializes the network\n-    \n+    ss.Sim(n_agents=small, networks=nw1, copy_inputs=False).init() # This initializes the network\n+\n     # Automatic creation as part of sim\n-    s2 = ss.Sim(n_agents=small, networks='random').initialize()\n+    s2 = ss.Sim(n_agents=small, networks='random').init()\n     nw2 = s2.networks[0]\n-    \n+\n     # Increase the number of contacts\n     nwdict = dict(type='random', n_contacts=20)\n-    s3 = ss.Sim(n_agents=small, networks=nwdict).initialize()\n+    s3 = ss.Sim(n_agents=small, networks=nwdict).init()\n     nw3 = s3.networks[0]\n-    \n+\n     # Checks\n     assert np.array_equal(nw1.p2, nw2.p2), 'Implicit and explicit creation should give the same network'\n     assert len(nw3) == len(nw2)*2, 'Doubling n_contacts should produce twice as many contacts'\n-    \n+\n+    # Tidy\n+    o = sc.objdict(nw1=nw1, nw2=nw2, nw3=nw3)\n+    return o\n+\n+\n+def test_erdosrenyi():\n+    sc.heading('Testing Erdos-Renyi network')\n+\n+    def test_ER(n, p, nw, alpha=0.01):\n+        \"\"\"\n+        Because each edge exists i.i.d. with probability p, the degree\n+        distribution of an Erdos-Renyi network should be Binomally distributed.\n+        Here, we test if the observed degree distribution, f_obs, matches the\n+        expected distribution, f_exp, which comes from the binomial probabiltiy\n+        mass function from the scipy stats library.\n+\n+        Args:\n+            n (int): number of agents\n+            p (float): edge probability\n+            nw (Network): The network to test\n+            alpha (float): The test significance level\n+\n+        Returns:\n+            Chi-Squared p-value and asserts if the statistical test fails,\n+            indicating that the observed degree distribution is unlikely to come\n+            from the the correct binomial.\n+        \"\"\"\n+        p12 = np.concatenate([nw.edges['p1'], nw.edges['p2']]) # p1 and p2 are the UIDs of agents, used here to determine degree\n+        upper = sps.binom.ppf(n=n-1, p=p, q=0.999) # Figure out the 99.9th percentile expected upper bound on the degree\n+        bins = np.arange(upper+1) # Create bins\n+        counts = np.histogram(p12, bins=np.arange(n+1))[0] # Count how many times each agent is connected\n+        f_obs = np.histogram(counts, bins=bins)[0] # Form the degree distribution\n+        pp = sps.binom.pmf(bins[:-1], n=n, p=p) # Computed the theoretical probability distribution\n+        f_exp = f_obs.sum()*pp / pp.sum() # Scale\n+        p_value = sps.chisquare(f_obs, f_exp).pvalue # Compute the X2 p-value\n+        assert not p_value < alpha\n+        return p_value\n+\n+    # Manual creation\n+    p = 0.1\n+    nw1 = ss.ErdosRenyiNet(p=p)\n+    ss.Sim(n_agents=small, networks=nw1, copy_inputs=False).init() # This initializes the network\n+    test_ER(small, p, nw1)\n+\n+    # Automatic creation as part of sim\n+    s2 = ss.Sim(n_agents=small, networks='erdosrenyi').init()\n+    nw2 = s2.networks[0]\n+\n+    # Larger example with higher p\n+    p=0.6\n+    nwdict = dict(type='erdosrenyi', p=p)\n+    s3 = ss.Sim(n_agents=medium, networks=nwdict).init()\n+    nw3 = s3.networks[0]\n+    test_ER(medium, p, nw3)\n+\n+    # Checks\n+    assert np.array_equal(nw1.p2, nw2.p2), 'Implicit and explicit creation should give the same network'\n+\n     # Tidy\n     o = sc.objdict(nw1=nw1, nw2=nw2, nw3=nw3)\n     return o\n \n \n+def test_disk():\n+    sc.heading('Testing Disk network')\n+\n+    # Visualize the path of agents\n+    nw1 = ss.DiskNet()\n+    s1 = ss.Sim(n_agents=5, dur=50, networks=nw1, copy_inputs=False).init() # This initializes the network\n+\n+    if sc.options.interactive:\n+        # Visualize motion:\n+        import matplotlib.pyplot as plt\n+        import matplotlib as mpl\n+\n+        fig, ax = plt.subplots()\n+        vdt = nw1.pars.v * s1.pars.dt\n+\n+        cmap = mpl.colormaps['plasma']\n+        colors = cmap(np.linspace(0, 1, s1.pars.n_agents))\n+        ax.scatter(nw1.x, nw1.y, s=50, c=colors)\n+        for i in range(s1.pars.dur):\n+            ax.plot([0,1,1,0,0], [0,0,1,1,0], 'k-', lw=1)\n+            ax.quiver(nw1.x, nw1.y, vdt * np.cos(nw1.theta), vdt * np.sin(nw1.theta), color=colors)\n+            ax.set_aspect('equal', adjustable='box') #ax.set_xlim([0,1]); ax.set_ylim([0,1])\n+            s1.run_one_step()\n+\n+    # Simulate SIR on a DiskNet\n+    nw2 = ss.DiskNet(r=0.15, v=0.05)\n+    s2 = ss.Sim(n_agents=small, networks=nw2, diseases='sir').init() # This initializes the network\n+    s2.run()\n+\n+    if sc.options.interactive:\n+        s2.plot()\n+        plt.show()\n+\n+    return s1, s2\n+\n+\n def test_static():\n     sc.heading('Testing static networks')\n-    \n+\n     # Create with p\n     p = 0.2\n     n = 100\n     nc = p*n\n     nd1 = dict(type='static', p=p)\n-    nw1 = ss.Sim(n_agents=n, networks=nd1).initialize().networks[0]\n-    \n+    nw1 = ss.Sim(n_agents=n, networks=nd1).init().networks[0]\n+\n     # Create with n_contacts\n     nd2 = dict(type='static', n_contacts=nc)\n-    nw2 = ss.Sim(n_agents=n, networks=nd2).initialize().networks[0]\n-    \n+    nw2 = ss.Sim(n_agents=n, networks=nd2).init().networks[0]\n+\n     # Check\n     assert len(nw1) == len(nw2), 'Networks should be the same length'\n     target = n*n*p/2\n     assert target/2 < len(nw1) < target*2, f'Network should be approximately length {target}'\n-    \n+\n     # Tidy\n     o = sc.objdict(nw1=nw1, nw2=nw2)\n     return o\n \n \n+def test_null():\n+    sc.heading('Testing NullNet...')\n+    people = ss.People(n_agents=small)\n+    network = ss.NullNet()\n+    sir = ss.SIR(pars=dict(dur_inf=10, beta=0.1))\n+    sim = ss.Sim(diseases=sir, people=people, networks=network)\n+    sim.run()\n+    return sim\n+\n+\n+def test_other():\n+    sc.heading('Other network tests...')\n+\n+    print('Testing MSM network')\n+    msm = ss.MSMNet(participation=0.3)\n+    sim = ss.Sim(diseases=dict(type='sis', beta=0.5), networks=msm, copy_inputs=False)\n+    sim.run()\n+\n+    print('Testing other network methods')\n+    msm.validate()\n+    inds1 = msm.get_inds([0])\n+    contacts = msm.find_contacts(inds1['p1'])\n+    assert contacts[0] == inds1['p2']\n+    inds2 = msm.pop_inds([0])\n+    assert inds1 == inds2\n+\n+    return msm\n+\n+\n+\n # %% Run as a script\n if __name__ == '__main__':\n     do_plot = True\n     sc.options(interactive=do_plot)\n-\n-    # Start timing\n-    T = sc.tic()\n+    T = sc.timer()\n \n     # Run tests\n-    man = test_manual()\n-    rnd = test_random()\n-    sta = test_static()\n-\n-    sc.toc(T)\n-    print('Done.')\n\\ No newline at end of file\n+    man  = test_manual()\n+    rand = test_random()\n+    stat = test_static()\n+    erdo = test_erdosrenyi()\n+    disk = test_disk()\n+    null = test_null()\n+    oth  = test_other()\n+\n+    T.toc()\n\\ No newline at end of file\ndiff --git a/tests/test_other.py b/tests/test_other.py\nindex 06f673a..b0a3e6a 100644\n--- a/tests/test_other.py\n+++ b/tests/test_other.py\n@@ -1,12 +1,11 @@\n \"\"\"\n Test Starsim features not covered by other test files\n \"\"\"\n-\n-# %% Imports and settings\n import sciris as sc\n import numpy as np\n import starsim as ss\n-import matplotlib.pyplot as pl\n+import matplotlib.pyplot as plt\n+import pytest\n \n sc.options(interactive=False) # Assume not running interactively\n \n@@ -19,7 +18,7 @@ def test_people():\n     sc.heading('Testing people object')\n \n     # Base people contains only the states defined in base.base_states\n-    ppl = ss.People(small)  # BasePeople\n+    ppl = ss.People(small)\n     del ppl\n \n     # Possible to initialize people with extra states, e.g. a geolocation\n@@ -51,20 +50,21 @@ def test_microsim(do_plot=False):\n         people=ss.People(small),\n         networks=[ss.MFNet(), ss.MaternalNet()],\n         demographics=ss.Pregnancy(),\n-        diseases=hiv\n+        diseases=hiv,\n+        copy_inputs = False, # So we can reuse hiv\n     )\n-    sim.initialize()\n+    sim.init()\n     sim.run()\n \n     if do_plot:\n-        pl.figure()\n-        pl.plot(sim.tivec, sim.results.hiv.n_infected)\n-        pl.title('HIV number of infections')\n+        plt.figure()\n+        plt.plot(hiv.timevec, hiv.results.n_infected)\n+        plt.title('HIV number of infections')\n \n     return sim\n \n \n-def test_ppl_construction():\n+def test_ppl_construction(do_plot=False):\n     sc.heading('Test making people and providing them to a sim')\n \n     def init_debut(module, sim, uids):\n@@ -81,11 +81,12 @@ def test_ppl_construction():\n     gon = ss.Gonorrhea(pars=gon_pars)\n \n     sim = ss.Sim(pars=sim_pars, diseases=[gon])\n-    sim.initialize()\n+    sim.init()\n     sim.run()\n-    pl.figure()\n-    pl.plot(sim.tivec, sim.results.gonorrhea.n_infected)\n-    pl.title('Number of gonorrhea infections')\n+    if do_plot:\n+        plt.figure()\n+        plt.plot(sim.timevec, sim.results.gonorrhea.n_infected)\n+        plt.title('Number of gonorrhea infections')\n \n     return sim\n \n@@ -93,14 +94,14 @@ def test_ppl_construction():\n def test_arrs():\n     sc.heading('Testing Arr objects')\n     o = sc.objdict()\n-    \n+\n     # Create a sim with only births\n     pars = dict(n_agents=medium, diseases='sis', networks='random')\n     p1 = sc.mergedicts(pars, birth_rate=10)\n     p2 = sc.mergedicts(pars, death_rate=10)\n     s1 = ss.Sim(pars=p1).run()\n     s2 = ss.Sim(pars=p2).run()\n-    \n+\n     # Tests\n     assert len(s1.people.auids) > len(s2.people.auids), 'Should have more people with births'\n     assert np.array_equal(s1.people.age, s1.people.age.raw[s1.people.auids]), 'Different ways of indexing age should match'\n@@ -109,24 +110,25 @@ def test_arrs():\n     assert not np.all(s2.people.alive.raw), 'Some agents should not be alive when indexed like this'\n     assert np.array_equal(~s1.people.female, s1.people.male), 'Definition of men does not match'\n     assert isinstance(s1.people.age < 5, ss.BoolArr), 'Performing logical operations should return a BoolArr'\n-    \n+\n     o.s1 = s1\n-    o.s2 = s2   \n-    \n+    o.s2 = s2\n+\n     return o\n \n \n def test_deepcopy():\n+    sc.heading('Testing deepcopy')\n     s1 = ss.Sim(pars=dict(diseases='sir', networks='embedding'), n_agents=small)\n-    s1.initialize()\n-    \n+    s1.init()\n+\n     s2 = sc.dcp(s1)\n \n     s1.run()\n     s2.run()\n     s1.plot()\n     s2.plot()\n-    \n+\n     ss.diff_sims(s1, s2, full=True)\n     assert np.allclose(s1.summary[:], s2.summary[:], rtol=0, atol=0, equal_nan=True)\n \n@@ -134,8 +136,9 @@ def test_deepcopy():\n \n \n def test_deepcopy_until():\n-    s1 = ss.Sim(pars=dict(diseases='sir', networks='embedding'), n_agents=small)\n-    s1.initialize()\n+    sc.heading('Testing deepcopy with until')\n+    s1 = ss.Sim(diseases='sir', networks='embedding', n_agents=small)\n+    s1.init()\n \n     s1.run(until=5)\n \n@@ -151,6 +154,34 @@ def test_deepcopy_until():\n     return s1, s2\n \n \n+def test_results():\n+    sc.heading('Testing results export and plotting')\n+    sim = ss.Sim(diseases='sis', networks='random', n_agents=medium)\n+    sim.run()\n+\n+    # Export to dataframe\n+    sis = sim.results.sis\n+    res = sis.new_infections\n+    df = res.to_df()\n+    dfs = sis.to_df()\n+    assert df.value.sum() == dfs.cum_infections.values[-1] == sim.summary.sis_cum_infections\n+\n+    # Plot\n+    res.plot()\n+    sim.results.sis.plot()\n+\n+    return sim\n+\n+\n+def test_check_reqiures():\n+    sc.heading('Testing check_requires')\n+    s1 = ss.Sim(diseases='sis', networks='random', n_agents=medium).init()\n+    ss.check_requires(s1, 'sis')\n+    ss.check_requires(s1, ss.SIS)\n+    with pytest.raises(AttributeError):\n+        ss.check_requires(s1, ss.SIR)\n+    return s1\n+\n \n # %% Run as a script\n if __name__ == '__main__':\n@@ -163,11 +194,13 @@ if __name__ == '__main__':\n     # Run tests\n     ppl = test_people()\n     sim1 = test_microsim(do_plot)\n-    sim2 = test_ppl_construction()\n+    sim2 = test_ppl_construction(do_plot)\n     sims = test_arrs()\n     sims2 = test_deepcopy()\n     sims3 = test_deepcopy_until()\n+    sim4 = test_results()\n+    sim5 = test_check_reqiures()\n \n     sc.toc(T)\n-    pl.show()\n+    plt.show()\n     print('Done.')\n\\ No newline at end of file\ndiff --git a/tests/test_plugins.py b/tests/test_plugins.py\nindex fc94e5d..6632d50 100644\n--- a/tests/test_plugins.py\n+++ b/tests/test_plugins.py\n@@ -4,7 +4,7 @@ Test connectors and custom interventions\n \n import sciris as sc\n import numpy as np\n-import pylab as pl\n+import matplotlib.pyplot as plt\n import starsim as ss\n \n sc.options(interactive=False) # Assume not running interactively\n@@ -13,8 +13,9 @@ sc.options(interactive=False) # Assume not running interactively\n class hiv_syph(ss.Connector):\n     \"\"\" Simple connector whereby rel_sus to NG doubles if CD4 count is <200\"\"\"\n     def __init__(self, pars=None, **kwargs):\n-        super().__init__(label='HIV-Syphilis', requires=[ss.HIV, ss.Syphilis])\n-        self.default_pars(\n+        super().__init__()\n+        self.define_pars(\n+            label = 'HIV-Syphilis',\n             rel_sus_syph_hiv    = 2,   # People with HIV are 2x more likely to acquire syphilis\n             rel_sus_syph_aids   = 5,   # People with AIDS are 5x more likely to acquire syphilis\n             rel_trans_syph_hiv  = 1.5, # People with HIV are 1.5x more likely to transmit syphilis\n@@ -25,13 +26,14 @@ class hiv_syph(ss.Connector):\n         self.update_pars(pars, **kwargs)\n         return\n \n-    def update(self):\n+    def step(self):\n         \"\"\" Specify HIV-syphilis interactions \"\"\"\n+\n         diseases = self.sim.diseases\n         syph = diseases.syphilis\n         hiv = diseases.hiv\n         cd4 = self.sim.people.hiv.cd4\n-        \n+\n         # People with HIV are more likely to acquire syphilis\n         syph.rel_sus[cd4 < 500] = self.pars.rel_sus_syph_hiv\n         syph.rel_sus[cd4 < 200] = self.pars.rel_sus_syph_aids\n@@ -50,14 +52,15 @@ class hiv_syph(ss.Connector):\n \n class Penicillin(ss.Intervention):\n     \"\"\" Create a penicillin (BPG) intervention for treating syphilis \"\"\"\n-    def __init__(self, year=2020, prob=0.5):\n+    def __init__(self, year=2020, prob=0.8):\n         super().__init__() # Initialize the intervention\n         self.prob = prob # Store the probability of treatment\n         self.year = year\n         return\n \n-    def apply(self, sim):\n-        if sim.year > self.year:\n+    def step(self):\n+        sim = self.sim\n+        if sim.now > self.year:\n             syphilis = sim.diseases.syphilis\n \n             # Define who is eligible for treatment\n@@ -76,9 +79,9 @@ class Penicillin(ss.Intervention):\n \n def make_args():\n     \"\"\" Make people, HIV, syphilis, and network \"\"\"\n-    pars = dict(n_agents=1000, verbose=0)\n-    mf = ss.MFNet(duration=ss.lognorm_ex(mean=5, stdev=0.5))\n-    hiv = ss.HIV(beta={'mf': [0.0008, 0.0004]}, init_prev=0.2)\n+    pars = dict(n_agents=2000, verbose=0)\n+    mf = ss.MFNet(duration=ss.lognorm_ex(mean=5, std=0.5)) # TODO: think about whether these should be ss.dur(); currently they are not since stored in natural units with -self.dt\n+    hiv = ss.HIV(beta={'mf': [0.0008, 0.0004]}, init_prev=0.2) # TODO: beta should wrap the other way\n     syph = ss.Syphilis(beta={'mf': [0.1, 0.05]}, init_prev=0.05)\n     args = dict(pars=pars, networks=mf, diseases=[hiv, syph])\n     return args\n@@ -87,23 +90,23 @@ def make_args():\n def test_connectors(do_plot=False):\n     \"\"\" Test connector example \"\"\"\n     sc.heading('Testing connectors')\n-    \n+\n     # Make arguments\n     args = make_args()\n     sims = sc.objdict() # List of sims\n-    \n+\n     # Make a sim with a connector, and run\n     sims.con = ss.Sim(label='With connector', connectors=hiv_syph(), **args)\n     sims.con.run()\n-    \n+\n     # Make a sim without a connector, and run\n     sims.nocon = ss.Sim(label='Without connector', **args)\n     sims.nocon.run()\n-    \n+\n     # Make a sim with a connector and syph treatment, and run\n     sims.treat = ss.Sim(label='With treatment', connectors=hiv_syph(), interventions=Penicillin(), **args)\n     sims.treat.run()\n-    \n+\n     # Parse results\n     results = sc.odict()\n     diseases = ['syphilis', 'hiv']\n@@ -114,35 +117,35 @@ def test_connectors(do_plot=False):\n \n     # Plot\n     if do_plot:\n-        pl.figure()\n-        \n-        pl.subplot(2,1,1)\n-        x = sims.con.yearvec\n+        plt.figure()\n+\n+        plt.subplot(2,1,1)\n+        x = sims.con.timevec\n         for label,res in results.items():\n-            pl.plot(x, res.syphilis, label=label)\n-        pl.title('Syphilis infections')\n-        pl.xlabel('Year')\n-        pl.ylabel('Count')\n-        pl.axvline(2020)\n-        pl.legend()\n-        \n-        pl.subplot(2,1,2)\n+            plt.plot(x, res.syphilis, label=label)\n+        plt.title('Syphilis infections')\n+        plt.xlabel('Year')\n+        plt.ylabel('Count')\n+        plt.axvline(2020)\n+        plt.legend()\n+\n+        plt.subplot(2,1,2)\n         for label,res in results.items():\n-            pl.plot(x, res.hiv, label=label)\n-        pl.title('HIV infections')\n-        pl.xlabel('Year')\n-        pl.ylabel('Count')\n-        pl.axvline(2020)\n-        pl.legend()\n-        \n+            plt.plot(x, res.hiv, label=label)\n+        plt.title('HIV infections')\n+        plt.xlabel('Year')\n+        plt.ylabel('Count')\n+        plt.axvline(2020)\n+        plt.legend()\n+\n         sc.figlayout()\n-        pl.show()\n-    \n+        plt.show()\n+\n     # Check results\n     for disease in diseases:\n         assert results[0][disease].sum() > results[1][disease].sum(), f'{disease.title()} infections should be higher with connector'\n         assert results[0][disease].sum() > results[2][disease].sum(), f'{disease.title()} infections should be lower with treatment'\n-   \n+\n     return sims\n \n \n@@ -150,8 +153,8 @@ if __name__ == '__main__':\n     do_plot = True\n     sc.options(interactive=do_plot)\n     T = sc.timer()\n-    \n+\n     sims = test_connectors(do_plot=do_plot)\n-    \n+\n     T.toc()\n-    \n\\ No newline at end of file\n+\ndiff --git a/tests/test_randomness.py b/tests/test_randomness.py\nindex 2b38f67..fba2c33 100644\n--- a/tests/test_randomness.py\n+++ b/tests/test_randomness.py\n@@ -5,8 +5,9 @@ Test the Dists object from distributions.py\n # %% Imports and settings\n import numpy as np\n import sciris as sc\n+import scipy.stats as sps\n+import matplotlib.pyplot as plt\n import starsim as ss\n-import matplotlib.pyplot as pl\n \n n = 5 # Default number of samples\n \n@@ -17,10 +18,10 @@ def make_dist(name='test', **kwargs):\n \n def make_dists(**kwargs):\n     \"\"\" Make a Dists object with two distributions in it \"\"\"\n-    sim = ss.Sim(n_agents=100).initialize() # Need an empty sim to initialize properly\n+    sim = ss.Sim(n_agents=100).init() # Need an empty sim to initialize properly\n     distlist = [make_dist(), make_dist()]\n     dists = ss.Dists(distlist)\n-    dists.initialize(sim=sim)\n+    dists.init(sim=sim)\n     return dists\n \n \n@@ -29,7 +30,7 @@ def make_dists(**kwargs):\n def test_seed():\n     \"\"\" Test assignment of seeds \"\"\"\n     sc.heading('Testing assignment of seeds')\n-    \n+\n     # Create and initialize two distributions\n     dists = make_dists()\n     dist0, dist1 = dists.dists.values()\n@@ -45,7 +46,7 @@ def test_reset(n=n):\n     dists = make_dists()\n     distlist = dists.dists.values()\n \n-    # Reset via the container, but only \n+    # Reset via the container, but only\n     before = sc.autolist()\n     after = sc.autolist()\n     for dist in distlist:\n@@ -57,7 +58,7 @@ def test_reset(n=n):\n     print(f'Initial sample:\\n{before}')\n     print(f'After reset sample:\\n{after}')\n     assert np.array_equal(before, after)\n-    \n+\n     return before, after\n \n \n@@ -79,7 +80,7 @@ def test_jump(n=n):\n     print(f'Initial sample:\\n{before}')\n     print(f'After jump sample:\\n{after}')\n     assert not np.array_equal(before, after)\n-    \n+\n     return before, after\n \n \n@@ -92,9 +93,9 @@ def test_order(n=n):\n     # Sample d0, d1\n     before = d0(n)\n     _ = d1(n)\n-    \n+\n     dists.reset()\n-    \n+\n     # Sample d1, d0\n     _ = d1(n)\n     after = d0(n)\n@@ -111,39 +112,47 @@ def test_order(n=n):\n class CountInf(ss.Intervention):\n     \"\"\" Store every infection state in a timepoints x people array \"\"\"\n     def init_pre(self, sim):\n+        super().init_pre(sim)\n         n_agents = len(sim.people)\n-        self.arr = np.zeros((sim.npts, n_agents))\n+        self.arr = np.zeros((len(sim), n_agents))\n         self.n_agents = n_agents\n         return\n-    \n-    def apply(self, sim):\n-        self.arr[sim.ti, :] = np.array(sim.diseases.sir.infected)[:self.n_agents]\n+\n+    def step(self):\n+        self.arr[self.sim.ti, :] = np.array(self.sim.diseases.sir.infected)[:self.n_agents]\n         return\n \n \n class OneMore(ss.Intervention):\n     \"\"\" Add one additional agent and infection \"\"\"\n+    def __init__(self, ti_apply=10):\n+        super().__init__()\n+        self.ti_apply = ti_apply\n+        return\n+\n     def init_pre(self, sim):\n+        super().init_pre(sim)\n         one_birth = ss.Pregnancy(name='one_birth', rel_fertility=0) # Ensure no default births\n         one_birth.init_pre(sim)\n         self.one_birth = one_birth\n         return\n-    \n-    def apply(self, sim, ti=10):\n+\n+    def step(self):\n         \"\"\" Create an extra agent \"\"\"\n-        if sim.ti == ti:\n+        sim = self.sim\n+        if sim.ti == self.ti_apply:\n             new_uids = self.one_birth.make_embryos(ss.uids(0)) # Assign 0th agent to be the \"mother\"\n             sim.people.age[new_uids] = -100 # Set to a very low number to never reach debut age\n-            \n+\n             # Infect that agent and immediately recover\n             sir = sim.diseases.sir\n             sir.set_prognoses(new_uids)\n             sir.ti_recovered[new_uids] = sim.ti + 1 # Reset recovery time to next timestep\n-            \n+\n             # Reset the random states\n             p = sir.pars\n             for dist in [p.dur_inf, p.p_death]:\n-                dist.jump(sim.ti+1)\n+                dist.jump_dt(force=True) # Already has correct dt value, but we need to force going back in time\n \n         return\n \n@@ -152,22 +161,22 @@ def plot_infs(s1, s2):\n     \"\"\" Compare infection arrays from two sims \"\"\"\n     a1 = s1.interventions.countinf.arr\n     a2 = s2.interventions.countinf.arr\n-    \n-    fig = pl.figure()\n-    pl.subplot(1,3,1)\n-    pl.pcolormesh(a1.T)\n-    pl.xlabel('Timestep')\n-    pl.ylabel('Person')\n-    pl.title('Baseline')\n-    \n-    pl.subplot(1,3,2)\n-    pl.pcolormesh(a2.T)\n-    pl.title('OneMore')\n-    \n-    pl.subplot(1,3,3)\n-    pl.pcolormesh(a2.T - a1.T)\n-    pl.title('Difference')\n-    \n+\n+    fig = plt.figure()\n+    plt.subplot(1,3,1)\n+    plt.pcolormesh(a1.T)\n+    plt.xlabel('Timestep')\n+    plt.ylabel('Person')\n+    plt.title('Baseline')\n+\n+    plt.subplot(1,3,2)\n+    plt.pcolormesh(a2.T)\n+    plt.title('OneMore')\n+\n+    plt.subplot(1,3,3)\n+    plt.pcolormesh(a2.T - a1.T)\n+    plt.title('Difference')\n+\n     sc.figlayout()\n     return fig\n \n@@ -175,12 +184,12 @@ def plot_infs(s1, s2):\n def test_worlds(do_plot=False):\n     \"\"\" Test that one extra birth leads to one extra infection \"\"\"\n     sc.heading('Testing worlds...')\n-    \n+\n     res = sc.objdict()\n-    \n+\n     pars = dict(\n         start = 2000,\n-        end = 2100,\n+        stop = 2100,\n         n_agents = 200,\n         verbose = 0.05,\n         diseases = dict(\n@@ -197,20 +206,20 @@ def test_worlds(do_plot=False):\n     )\n     s1 = ss.Sim(pars=pars, interventions=CountInf())\n     s2 = ss.Sim(pars=pars, interventions=[CountInf(), OneMore()])\n-    \n+\n     s1.run()\n     s2.run()\n-    \n+\n     sum1 = s1.summarize()\n     sum2 = s2.summarize()\n     res.sum1 = sum1\n     res.sum2 = sum2\n-    \n+\n     if do_plot:\n         s1.plot()\n         plot_infs(s1, s2)\n-        pl.show()\n-    \n+        plt.show()\n+\n     l1 = len(s1.people)\n     l2 = len(s2.people)\n     i1 = sum1.sir_cum_infections\n@@ -220,14 +229,14 @@ def test_worlds(do_plot=False):\n     assert l2 == l1 + 1, f'Expected one more person in s2 ({l2}) than s1 ({l1})'\n     assert i2 == i1 + 1, f'Expected one more infection in s2 ({i2}) than s1 ({i1})'\n     assert (a1 != a2).sum() == 0, f'Expected infection arrays to match:\\n{a1}\\n{a2}'\n-        \n+\n     return res\n \n \n def test_independence(do_plot=False, thresh=0.1):\n     \"\"\" Test that when variables are created, they are uncorrelated \"\"\"\n     sc.heading('Testing independence...')\n-    \n+\n     # Create the sim and initialize (do not run)\n     sim = ss.Sim(\n         n_agents = 1000,\n@@ -241,8 +250,8 @@ def test_independence(do_plot=False, thresh=0.1):\n             dict(type='mf', debut=ss.constant(0), participation=0.5), # To avoid age correlations\n         ]\n     )\n-    sim.initialize()\n-    \n+    sim.init()\n+\n     # Assemble measures\n     st = sim.people.states\n     arrs = sc.objdict()\n@@ -256,7 +265,7 @@ def test_independence(do_plot=False, thresh=0.1):\n             for uid in network.edges[p]:\n                 data[uid] += 1 # Could also use a histogram\n         arrs[key] = data\n-    \n+\n     # Compute the correlations\n     n = len(arrs)\n     stats = np.zeros((n,n))\n@@ -264,26 +273,49 @@ def test_independence(do_plot=False, thresh=0.1):\n         for j,arr2 in arrs.enumvals():\n             if i != j:\n                 stats[i,j] = np.corrcoef(arr1, arr2)[0,1]\n-                \n+\n     # Optionally plot\n     if do_plot:\n-        pl.figure()\n-        pl.imshow(stats)\n+        plt.figure()\n+        plt.imshow(stats)\n         ticks = np.arange(n)\n         labels = arrs.keys()\n-        pl.xticks(ticks, labels)\n-        pl.yticks(ticks, labels)\n-        pl.xticks(rotation=15)\n-        pl.colorbar()\n+        plt.xticks(ticks, labels)\n+        plt.yticks(ticks, labels)\n+        plt.xticks(rotation=15)\n+        plt.colorbar()\n         sc.figlayout()\n-        pl.show()\n-            \n+        plt.show()\n+\n     # Test that everything is independent\n     max_corr = abs(stats).max()\n     assert max_corr < thresh, f'The maximum correlation between variables was {max_corr}, above the threshold {thresh}'\n-    \n+\n     return sim\n-    \n+\n+\n+def test_combine_rands(do_plot=False):\n+    n = int(1e6)\n+    atol = 1e-3\n+    target = 0.5\n+    np.random.seed(2)\n+    a = np.random.randint(np.iinfo(np.uint64).max, size=n, dtype=np.uint64)\n+    b = np.random.randint(np.iinfo(np.uint64).max, size=n, dtype=np.uint64)\n+    c = ss.utils.combine_rands(a, b)\n+    if do_plot:\n+        plt.figure()\n+        for i,k,v in sc.objdict(a=a,b=b,combined=c).enumitems():\n+            plt.subplot(3,1,i+1)\n+            plt.hist(v)\n+            plt.title(k)\n+        sc.figlayout()\n+        plt.show()\n+\n+    mean = c.mean()\n+    assert np.isclose(mean, target, atol=atol), f'Expected value to be 0.5±{atol}, not {mean}'\n+    ks = sps.kstest(c, sps.uniform(0,1).cdf)\n+    assert ks.pvalue > 0.05, f'Distribution does not seem to be uniform, p={ks.pvalue}<0.05'\n+    return c\n \n \n # %% Run as a script\n@@ -297,6 +329,7 @@ if __name__ == '__main__':\n     o4 = test_order(n)\n     o5 = test_worlds(do_plot=do_plot)\n     o6 = test_independence(do_plot=do_plot)\n+    o7 = test_combine_rands(do_plot=do_plot)\n \n     T.toc()\n \ndiff --git a/tests/test_run.py b/tests/test_run.py\nnew file mode 100644\nindex 0000000..2cc9d82\n--- /dev/null\n+++ b/tests/test_run.py\n@@ -0,0 +1,111 @@\n+\"\"\"\n+Test run\n+\"\"\"\n+\n+# %% Imports and settings\n+import starsim as ss\n+import sciris as sc\n+import numpy as np\n+import matplotlib.pyplot as plt\n+\n+n_agents = 1_000\n+do_plot = False\n+sc.options(interactive=False) # Assume not running interactively\n+\n+\n+def make_sim_pars():\n+    pars = sc.objdict(\n+        n_agents = n_agents,\n+        demographics = True,\n+        networks = 'random',\n+        diseases = sc.objdict(type='sir', beta=0.1), # To allow for modification later\n+    )\n+    return pars\n+\n+\n+def test_parallel():\n+    \"\"\" Test running two identical sims in parallel \"\"\"\n+    sc.heading('Testing parallel...')\n+    pars = make_sim_pars()\n+\n+    # Check that two identical sims match\n+    msim = ss.MultiSim([ss.Sim(pars, label='Sim1'), ss.Sim(pars, label='Sim2')])\n+    msim.run(shrink=False)\n+    s1, s2 = msim.sims\n+    assert np.allclose(s1.summary[:], s2.summary[:], rtol=0, atol=0, equal_nan=True), \"Sims don't match and should\"\n+\n+    # Check that two non-identical sims don't match\n+    pars2 = sc.dcp(pars)\n+    pars2.diseases.beta *= 2\n+    sims = ss.MultiSim([ss.Sim(pars, label='Sim1'), ss.Sim(pars2, label='Sim2')])\n+    sims.run(shrink=False)\n+    s1, s2 = sims.sims\n+    assert not np.allclose(s1.summary[:], s2.summary[:], rtol=0, atol=0, equal_nan=True), \"Sims do match and shouldn't\"\n+\n+    return s1, s2\n+\n+\n+def test_multisim():\n+    \"\"\" Check MultiSim methods \"\"\"\n+    sc.heading('Testing MultiSim')\n+    pars = make_sim_pars()\n+    msim = ss.MultiSim(ss.Sim(pars))\n+    msim.init_sims()\n+    msim.run(n_runs=4)\n+\n+    # Plot individual sims\n+    msim.plot()\n+\n+    # Reduce and plot mean\n+    msim.mean()\n+    msim.plot()\n+\n+    # Reduce and plot median\n+    msim.median()\n+    msim.plot()\n+\n+    # Other methods\n+    msim.show()\n+    msim.summarize()\n+    msim.reset()\n+\n+    return msim\n+\n+\n+def test_other():\n+    \"\"\" Check other run options \"\"\"\n+    sc.heading('Testing other run options')\n+    # Check parallel\n+    pars = make_sim_pars()\n+    pars2 = sc.dcp(pars)\n+    pars2.diseases.beta *= 2\n+    s1 = ss.Sim(pars)\n+    s2 = ss.Sim(pars2)\n+    ss.parallel(s1, s2, inplace=False)\n+    assert not s1.initialized\n+    ss.parallel(s1, s2, inplace=True)\n+    assert not np.allclose(s1.summary[:], s2.summary[:], rtol=0, atol=0, equal_nan=True), \"Sims do match and shouldn't\"\n+\n+    # Check single run\n+    s3 = ss.Sim(pars)\n+    s4 = ss.Sim(pars)\n+    s3 = ss.single_run(s3)\n+    s4 = ss.single_run(s4, n_agents=2000)\n+    assert not np.allclose(s3.summary[:], s4.summary[:], rtol=0, atol=0, equal_nan=True), \"Sims do match and shouldn't\"\n+\n+    return s3,s4\n+\n+\n+if __name__ == '__main__':\n+    do_plot = True\n+    sc.options(interactive=do_plot)\n+    T = sc.timer()\n+\n+    s1, s2 = test_parallel()\n+    msim = test_multisim()\n+    s3,s4 = test_other()\n+\n+    T.toc()\n+\n+    if do_plot:\n+        plt.show()\ndiff --git a/tests/test_samples.py b/tests/test_samples.py\nindex 105662a..f39c737 100644\n--- a/tests/test_samples.py\n+++ b/tests/test_samples.py\n@@ -14,9 +14,9 @@ def get_outputs(p_death):\n         ppl = ss.People(1000)\n         network = ss.RandomNet(n_contacts=ss.poisson(5))\n         sir = ss.SIR(pars={'p_death':p_death})\n-        sim = ss.Sim(people=ppl, networks=network, diseases=sir, rand_seed=0, n_years=5)\n+        sim = ss.Sim(people=ppl, networks=network, diseases=sir, rand_seed=0, dur=5)\n         sim.run(verbose=0)\n-        df = sim.export_df()\n+        df = sim.to_df()\n         summary = {}\n         summary['seed'] = sim.pars['rand_seed']\n         summary['p_death'] = p_death\ndiff --git a/tests/test_sim.py b/tests/test_sim.py\nindex ae5d04c..9c8fef9 100644\n--- a/tests/test_sim.py\n+++ b/tests/test_sim.py\n@@ -5,7 +5,6 @@ Test Sim API\n # %% Imports and settings\n import starsim as ss\n import sciris as sc\n-import numpy as np\n import matplotlib.pyplot as plt\n import pytest\n \n@@ -36,11 +35,11 @@ def test_demo(do_plot=do_plot):\n     \"\"\" Test Starsim's demo run \"\"\"\n     sc.heading('Testing demo...')\n     s1 = ss.demo(plot=do_plot)\n-    \n+\n     # Test explicit demo\n     s2 = ss.Sim(diseases='sir', networks='random').run()\n-    \n-    # Test explicit \n+\n+    # Test explicit\n     sir = ss.SIR()\n     net = ss.RandomNet()\n     s3 = ss.Sim(diseases=sir, networks=net).run()\n@@ -71,57 +70,57 @@ def test_simple(do_plot=do_plot):\n def test_api():\n     \"\"\" Test all different ways of creating a sim \"\"\"\n     sc.heading('Testing sim API...')\n-    \n+\n     # Check different ways of specifying a sim\n     s1 = ss.Sim(n_agents=n_agents, diseases='sir', networks='random').run() # Supply strings directly\n     s2 = ss.Sim(pars=dict(n_agents=n_agents, diseases='sir', networks='random')).run() # Supply as parameters\n     s3 = ss.Sim(n_agents=n_agents, diseases=ss.SIR(), networks=ss.RandomNet()).run() # Supply as objects\n     ss.check_sims_match(s1, s2, s3), 'Sims should match'\n-    \n+\n     # Check different ways of setting a distribution\n     kw = dict(n_agents=n_agents, networks='random')\n     d1 = ss.lognorm_ex(10) # Create a distribution with an argument\n-    d2 = ss.lognorm_ex(mean=10, stdev=2) # Create a distribution with kwargs\n+    d2 = ss.lognorm_ex(mean=10, std=2) # Create a distribution with kwargs\n     d3 = ss.normal(loc=10) # Create a different type of distribution\n-    \n+\n     # Check specifying dist with a scalar\n     s4 = ss.Sim(diseases=dict(type='sir', dur_inf=10), **kw).run() # Supply values as a scalar\n     s5 = ss.Sim(diseases=dict(type='sir', dur_inf=d1), **kw).run() # Supply as a distribution\n     ss.check_sims_match(s4, s5), 'Sims should match'\n-    \n+\n     # Check specifying dist with a list and dict\n     s6 = ss.Sim(diseases=dict(type='sir', dur_inf=[10,2]), **kw).run() # Supply values as a list\n-    s7 = ss.Sim(diseases=dict(type='sir', dur_inf=dict(mean=10, stdev=2)), **kw).run() # Supply values as a dict\n+    s7 = ss.Sim(diseases=dict(type='sir', dur_inf=dict(mean=10, std=2)), **kw).run() # Supply values as a dict\n     s8 = ss.Sim(diseases=dict(type='sir', dur_inf=d2), **kw).run() # Supply as a distribution\n     ss.check_sims_match(s6, s7, s8), 'Sims should match'\n-    \n+\n     # Check changing dist type\n     s9  = ss.Sim(diseases=dict(type='sir', dur_inf=dict(type='normal', loc=10)), **kw).run() # Supply values as a dict\n     s10 = ss.Sim(diseases=dict(type='sir', dur_inf=d3), **kw).run() # Supply values as a distribution\n     ss.check_sims_match(s9, s10), 'Sims should match'\n-    \n+\n     # Check that Bernoulli distributions can't be changed\n     with pytest.raises(TypeError):\n-        ss.Sim(diseases=dict(type='sir', init_prev=dict(type='normal', loc=10)), **kw).initialize()\n-    \n+        ss.Sim(diseases=dict(type='sir', init_prev=dict(type='normal', loc=10)), **kw).init()\n+\n     return s1\n \n \n def test_complex_api():\n     \"\"\" Test that complex inputs can be parsed correctly \"\"\"\n     sc.heading('Testing complex API...')\n-    \n+\n     def jump_age(sim):\n         \"\"\" Arbitrary intervention to reduce people's ages in the simulation \"\"\"\n         if sim.ti == 20:\n             sim.people.age[:] = sim.people.age[:] + 1000\n-    \n+\n     # Specify parameters as a dictionary\n-    p = dict(\n+    pars1 = dict(\n         n_agents = 1000,\n         label = 'v1',\n         verbose = 'brief',\n-        end = 2020,\n+        stop = 2020,\n         networks = [\n             ss.RandomNet(name='random1', n_contacts=6),\n             dict(type='random', name='random2', n_contacts=4)\n@@ -136,35 +135,35 @@ def test_complex_api():\n         ],\n         interventions = jump_age,\n     )\n-    \n+\n     # Test with explicit initialization\n-    pars = ss.SimPars(n_agents=1000, label='v1', verbose='brief', end=2020)\n-    \n+    pars2 = ss.SimPars(n_agents=1000, label='v1', verbose='brief', stop=2020)\n+\n     net1 = ss.RandomNet(name='random1', n_contacts=6)\n     net2 = ss.RandomNet(name='random2', n_contacts=4)\n     networks = ss.ndict(net1, net2)\n-    \n+\n     dis1 = ss.SIR(dur_inf=ss.expon(scale=6.0))\n     dis2 = ss.SIS(beta=0.07, init_prev=ss.bernoulli(0.1))\n     diseases = ss.ndict(dis1, dis2)\n-    \n+\n     dem1 = ss.Births(birth_rate=20)\n     dem2 = ss.Deaths(death_rate=20)\n     demographics = ss.ndict(dem1, dem2)\n-    \n+\n     int1 = ss.Intervention.from_func(jump_age)\n     interventions = ss.ndict(int1)\n \n     # Assemble\n-    s1 = ss.Sim(p)\n-    s2 = ss.Sim(pars=pars, networks=networks, diseases=diseases, demographics=demographics, interventions=interventions)\n-    \n+    s1 = ss.Sim(pars1)\n+    s2 = ss.Sim(pars=pars2, networks=networks, diseases=diseases, demographics=demographics, interventions=interventions)\n+\n     # Run\n     s1.run()\n     s2.run()\n-    \n+\n     assert ss.check_sims_match(s1, s2), 'Sims should match'\n-    \n+\n     return s1\n \n \n@@ -180,14 +179,14 @@ def test_simple_vax(do_plot=do_plot):\n     intv = ss.routine_vx(start_year=2015, prob=0.2, product=my_vax)\n     sim_intv = ss.Sim(pars=pars, interventions=intv)\n     sim_intv.run()\n-    \n+\n     assert sim_intv.summary.sir_cum_infections < sim_base.summary.sir_cum_infections, 'Vaccine should avert infections'\n \n     # Check plots\n     if do_plot:\n         plt.figure()\n-        plt.plot(sim_base.yearvec, sim_base.results.sir.prevalence, label='Baseline')\n-        plt.plot(sim_intv.yearvec, sim_intv.results.sir.prevalence, label='Vax')\n+        plt.plot(sim_base.timevec, sim_base.results.sir.prevalence, label='Baseline')\n+        plt.plot(sim_intv.timevec, sim_intv.results.sir.prevalence, label='Vax')\n         plt.axvline(x=2015, color='k', ls='--')\n         plt.title('Prevalence')\n         plt.legend()\n@@ -198,12 +197,12 @@ def test_simple_vax(do_plot=do_plot):\n def test_shared_product(do_plot=do_plot):\n     \"\"\" Check that multiple interventions can use the same product \"\"\"\n     sc.heading('Testing sharing a product across interventions...')\n-    \n+\n     # Make interventions\n     vax = ss.sir_vaccine(pars=dict(efficacy=0.5))\n     routine1 = ss.routine_vx(name='early-small', start_year=2010, prob=0.05, product=vax)\n     routine2 = ss.routine_vx(name='late-big', start_year=2020, prob=0.5, product=vax)\n-    \n+\n     # Make and run sims\n     pars = make_sim_pars()\n     s1 = ss.Sim(pars, label='Baseline')\n@@ -212,16 +211,16 @@ def test_shared_product(do_plot=do_plot):\n     s1.run()\n     s2.run()\n     s3.run()\n-    \n+\n     if do_plot:\n         plt.figure()\n         for sim in [s1, s2, s3]:\n-            plt.plot(sim.yearvec, sim.results.sir.cum_infections, label=sim.label)\n+            plt.plot(sim.timevec, sim.results.sir.cum_infections, label=sim.label)\n         plt.legend()\n         plt.title('Impact of vaccination')\n         plt.xlabel('Year')\n         plt.ylabel('Cumulative infections')\n-        \n+\n     assert s2.summary.sir_cum_infections < s1.summary.sir_cum_infections, 'Vaccine should avert infections'\n     assert s3.summary.sir_cum_infections < s2.summary.sir_cum_infections, 'Vaccine should avert infections'\n     return s3\n@@ -240,33 +239,39 @@ def test_components(do_plot=do_plot):\n     return sim\n \n \n-def test_parallel():\n-    \"\"\" Test running two identical sims in parallel \"\"\"\n-    sc.heading('Testing parallel...')\n-    pars = make_sim_pars()\n+def test_save():\n+    \"\"\" Test save and export \"\"\"\n+    sc.heading('Testing save and export...')\n+    f = sc.objdict() # Filenames\n+    f.sim  = 'temp.sim'\n+    f.json = 'sim.json'\n+    sim = ss.Sim(n_agents=n_agents, diseases='sis', networks='random').run()\n+\n+    # Run the methods\n+    sim.save(filename=f.sim)\n+    sim.to_json(filename=f.json)\n+    json = sim.to_json()\n \n-    # Check that two identical sims match\n-    sims = ss.MultiSim([ss.Sim(pars, label='Sim1'), ss.Sim(pars, label='Sim2')])\n-    sims.run(keep_people=True)\n-    s1, s2 = sims.sims\n-    assert np.allclose(s1.summary[:], s2.summary[:], rtol=0, atol=0, equal_nan=True)\n+    # Run methods\n+    s2 = sc.load(f.sim)\n+    json2 = sc.loadjson(f.json)\n \n-    # Check that two non-identical sims don't match\n-    pars2 = sc.dcp(pars)\n-    pars2.diseases.beta *= 2\n-    sims = ss.MultiSim([ss.Sim(pars, label='Sim1'), ss.Sim(pars2, label='Sim2')])\n-    sims.run(keep_people=True)\n-    s1, s2 = sims.sims\n-    assert not np.allclose(s1.summary[:], s2.summary[:], rtol=0, atol=0, equal_nan=True)\n+    # Run tests\n+    assert sim.summary == s2.summary, 'Sims do not match'\n+    assert sim.pars.n_agents == json2['pars']['n_agents'], 'Parameters do not match'\n+    assert json == json2, 'Outputs do not match'\n \n-    return s1, s2\n+    # Delete files\n+    sc.rmpath(f.values())\n+\n+    return sim\n \n \n if __name__ == '__main__':\n     do_plot = True\n     sc.options(interactive=do_plot)\n     T = sc.timer()\n-    \n+\n     sim0 = test_demo(do_plot=do_plot)\n     sim1 = test_default(do_plot=do_plot)\n     sim2 = test_simple(do_plot=do_plot)\n@@ -275,9 +280,9 @@ if __name__ == '__main__':\n     sim5b, sim5i = test_simple_vax(do_plot=do_plot)\n     sim6 = test_shared_product(do_plot=do_plot)\n     sim7 = test_components(do_plot=do_plot)\n-    sim8a, sim8b = test_parallel()\n-    \n+    sim8 = test_save()\n+\n     T.toc()\n-    \n+\n     if do_plot:\n         plt.show()\ndiff --git a/tests/test_syphilis.py b/tests/test_syphilis.py\nindex 731eaf9..f914cda 100644\n--- a/tests/test_syphilis.py\n+++ b/tests/test_syphilis.py\n@@ -4,11 +4,13 @@ Run syphilis\n \n # %% Imports and settings\n import numpy as np\n-import starsim as ss\n import pandas as pd\n+import sciris as sc\n+import starsim as ss\n import matplotlib.pyplot as plt\n \n quick_run = True\n+datadir = ss.root / 'tests/test_data'\n \n \n def make_syph_sim(dt=1, n_agents=500):\n@@ -18,14 +20,14 @@ def make_syph_sim(dt=1, n_agents=500):\n     syph.pars.init_prev = ss.bernoulli(p=0.1)\n \n     # Make demographic modules\n-    fertility_rates = {'fertility_rate': pd.read_csv(ss.root / 'tests/test_data/nigeria_asfr.csv')}\n+    fertility_rates = {'fertility_rate': pd.read_csv(datadir/'nigeria_asfr.csv')}\n     pregnancy = ss.Pregnancy(pars=fertility_rates)\n-    death_rates = {'death_rate': pd.read_csv(ss.root / 'tests/test_data/nigeria_deaths.csv'), 'units': 1}\n+    death_rates = {'death_rate': pd.read_csv(datadir/'nigeria_deaths.csv'), 'rate_units': 1}\n     death = ss.Deaths(death_rates)\n \n     # Make people and networks\n     ss.set_seed(1)\n-    ppl = ss.People(n_agents, age_data=pd.read_csv(ss.root / 'tests/test_data/nigeria_age.csv'))\n+    ppl = ss.People(n_agents, age_data=datadir/'nigeria_age.csv')\n \n     # Marital\n     mf = ss.MFNet(duration=1/24)\n@@ -35,7 +37,7 @@ def make_syph_sim(dt=1, n_agents=500):\n         dt=dt,\n         total_pop=93963392,\n         start=1990,\n-        n_years=40,\n+        dur=40,\n         people=ppl,\n         diseases=syph,\n         networks=ss.ndict(mf, maternal),\n@@ -54,13 +56,11 @@ class check_states(ss.Analyzer):\n         self.okay = True\n         return\n \n-    def update_results(self, sim):\n-        return self.apply(sim)\n-\n-    def apply(self, sim):\n+    def step(self):\n         \"\"\"\n         Checks states that should be mutually exlusive and collectively exhaustive\n         \"\"\"\n+        sim = self.sim\n         sppl = sim.diseases.syphilis\n \n         # Infection states: people must be exactly one of these\n@@ -79,11 +79,10 @@ class check_states(ss.Analyzer):\n         checkall = np.array([s1a, s1b, s2a, s2b, s3])\n         if not checkall.all():\n             self.okay = False\n-\n         return\n \n \n-def test_syph(dt=1, n_agents=500):\n+def test_syph(dt=1, n_agents=500, do_plot=False):\n \n     sim_kwargs = make_syph_sim(dt=dt, n_agents=n_agents)\n     sim = ss.Sim(analyzers=check_states(), **sim_kwargs)\n@@ -91,33 +90,36 @@ def test_syph(dt=1, n_agents=500):\n \n     # Check plots\n     burnin = 0\n-    pi = int(burnin/sim.dt)\n-\n-    fig, ax = plt.subplots(2, 2)\n-    ax = ax.ravel()\n-    ax[0].stackplot(\n-        sim.yearvec[pi:],\n-        # sim.results.syphilis.n_susceptible[pi:],\n-        sim.results.syphilis.n_congenital[pi:],\n-        sim.results.syphilis.n_exposed[pi:],\n-        sim.results.syphilis.n_primary[pi:],\n-        sim.results.syphilis.n_secondary[pi:],\n-        (sim.results.syphilis.n_latent_temp[pi:]+sim.results.syphilis.n_latent_long[pi:]),\n-        sim.results.syphilis.n_tertiary[pi:],\n-    )\n-    ax[0].legend(['Congenital', 'Exposed', 'Primary', 'Secondary', 'Latent', 'Tertiary'], loc='lower right')\n-\n-    ax[1].plot(sim.yearvec[pi:], sim.results.syphilis.prevalence[pi:])\n-    ax[1].set_title('Syphilis prevalence')\n+    pi = int(burnin/dt)\n \n-    ax[2].plot(sim.yearvec[pi:], sim.results.n_alive[pi:])\n-    ax[2].set_title('Population')\n-\n-    ax[3].plot(sim.yearvec[pi:], sim.results.syphilis.new_infections[pi:])\n-    ax[3].set_title('New infections')\n-\n-    fig.tight_layout()\n-    plt.show()\n+    if do_plot:\n+        tvec = sim.timevec[pi:]\n+        res = sim.results.syphilis\n+        fig, ax = plt.subplots(2, 2)\n+        ax = ax.ravel()\n+        ax[0].stackplot(\n+            tvec,\n+            # res.n_susceptible[pi:],\n+            res.n_congenital[pi:],\n+            res.n_exposed[pi:],\n+            res.n_primary[pi:],\n+            res.n_secondary[pi:],\n+            (res.n_latent_temp[pi:]+res.n_latent_long[pi:]),\n+            res.n_tertiary[pi:],\n+        )\n+        ax[0].legend(['Congenital', 'Exposed', 'Primary', 'Secondary', 'Latent', 'Tertiary'], loc='lower right')\n+\n+        ax[1].plot(tvec, res.prevalence[pi:])\n+        ax[1].set_title('Syphilis prevalence')\n+\n+        ax[2].plot(tvec, sim.results.n_alive[pi:])\n+        ax[2].set_title('Population')\n+\n+        ax[3].plot(tvec, res.new_infections[pi:])\n+        ax[3].set_title('New infections')\n+\n+        fig.tight_layout()\n+        plt.show()\n \n     return sim\n \n@@ -126,7 +128,7 @@ def test_syph_intvs(dt=1, n_agents=500, do_plot=False):\n \n     # Interventions\n     # screen_eligible = lambda sim: sim.demographics.pregnancy.pregnant\n-    screen_eligible = lambda sim: sim.networks.mf.active(sim.people)\n+    screen_eligible = lambda sim: sim.networks.mfnet.active(sim.people)\n     syph_screening = ss.syph_screening(\n         product='rpr',\n         prob=0.99,\n@@ -135,7 +137,7 @@ def test_syph_intvs(dt=1, n_agents=500, do_plot=False):\n         label='syph_screening',\n     )\n \n-    treat_eligible = lambda sim: ss.uids(sim.get_intervention('syph_screening').outcomes['positive'])\n+    treat_eligible = lambda sim: ss.uids(sim.interventions['syph_screening'].outcomes['positive'])\n     bpg = ss.syph_treatment(\n         prob=0.9,\n         product='bpg',\n@@ -155,10 +157,12 @@ def test_syph_intvs(dt=1, n_agents=500, do_plot=False):\n         sim_base.run()\n \n         burnin = 10\n-        pi = int(burnin/sim_base.dt)\n+        syph_b = sim_base.diseases.syphilis\n+        syph_i = sim_intv.diseases.syphilis\n+        pi = int(burnin/syph_b.t.dt)\n         plt.figure()\n-        plt.plot(sim_base.yearvec[pi:], sim_base.results.syphilis.prevalence[pi:], label='Baseline')\n-        plt.plot(sim_intv.yearvec[pi:], sim_intv.results.syphilis.prevalence[pi:], label='S&T')\n+        plt.plot(syph_b.timevec[pi:], syph_b.results.prevalence[pi:], label='Baseline')\n+        plt.plot(syph_i.timevec[pi:], syph_i.results.prevalence[pi:], label='S&T')\n         plt.axvline(x=2020, color='k', ls='--')\n         plt.title('Syphilis prevalence')\n         plt.legend()\n@@ -171,10 +175,14 @@ def test_syph_intvs(dt=1, n_agents=500, do_plot=False):\n \n \n if __name__ == '__main__':\n+    T = sc.timer()\n+    do_plot = True\n \n     dt = [1/12, 1][quick_run]\n     n_agents = [20e3, 500][quick_run]\n \n-    sim = test_syph(dt=dt, n_agents=n_agents)\n+    sim = test_syph(dt=dt, n_agents=n_agents, do_plot=do_plot)\n     sim_base, sim_intv = test_syph_intvs(dt=dt, n_agents=n_agents, do_plot=True)\n \n+    T.toc()\n+\ndiff --git a/tests/test_time.py b/tests/test_time.py\nnew file mode 100644\nindex 0000000..18fd6d3\n--- /dev/null\n+++ b/tests/test_time.py\n@@ -0,0 +1,248 @@\n+\"\"\"\n+Test different time units and timesteps\n+\"\"\"\n+\n+import numpy as np\n+import sciris as sc\n+import starsim as ss\n+\n+small = 100\n+medium = 1000\n+sc.options(interactive=False)\n+\n+\n+# %% Define the tests\n+def test_ratio():\n+    sc.heading('Test behavior of time_ratio()')\n+\n+    assert ss.time_ratio() == 1.0\n+    assert ss.time_ratio(dt1=1.0, dt2=0.1) == 10.0\n+    assert ss.time_ratio(dt1=0.5, dt2=5) == 0.1\n+    assert ss.time_ratio(dt1=0.5, dt2=5) == 0.1\n+\n+    assert ss.time_ratio(unit1='year', unit2='day') == 365.25\n+    assert ss.time_ratio(unit1='day', unit2='year') == 1/365.25\n+\n+    return\n+\n+\n+def test_classes():\n+    sc.heading('Test behavior of dur() and rate()')\n+\n+    # Test duration dt\n+    d1 = ss.dur(2)\n+    d2 = ss.dur(3)\n+    d3 = ss.dur(2, parent_dt=0.1)\n+    d4 = ss.dur(3, parent_dt=0.2)\n+    for d in [d1,d2,d3,d4]: d.init()\n+\n+    assert d1 + d2 == 2+3\n+    assert d3 + d4 == 2/0.1 + 3/0.2\n+    assert d3 * 2 == 2/0.1*2\n+    assert d3 / 2 == 2/0.1/2\n+\n+    # Test rate dt\n+    r1 = ss.rate(2)\n+    r2 = ss.rate(3)\n+    r3 = ss.rate(2, parent_dt=0.1)\n+    r4 = ss.rate(3, parent_dt=0.2)\n+    for r in [r1,r2,r3,r4]: r.init()\n+\n+    assert r1 + r2 == 2 + 3\n+    assert r3 + r4 == 2*0.1 + 3*0.2\n+    assert r3 * 2 == 2*0.1*2\n+    assert r3 / 2 == 2*0.1/2\n+\n+    # Test duration units\n+    d5 = ss.dur(2, unit='year').init(parent_unit='day')\n+    d6 = ss.dur(3, unit='day').init(parent_unit='day')\n+    assert d5 + d6 == 2*365.25+3\n+\n+    # Test rate units\n+    rval = 0.7\n+    r5 = ss.rate(rval, unit='week').init(parent_unit='day')\n+    r6 = ss.rate(rval).init(parent_dt=0.1)\n+    assert np.isclose(r5.values, rval/7) # A limitation of this approach, not exact!\n+    assert np.isclose(r6.values, rval/10)\n+\n+    # Test time_prob\n+    tpval = 0.1\n+    tp0 = ss.time_prob(tpval).init(parent_dt=1.0)\n+    tp1 = ss.time_prob(tpval).init(parent_dt=0.5)\n+    tp2 = ss.time_prob(tpval).init(parent_dt=2)\n+    assert np.isclose(tp0.values, tpval)\n+    assert np.isclose(tp1.values, tpval/2, rtol=0.1)\n+    assert np.isclose(tp2.values, tpval*2, rtol=0.1)\n+    assert tp1.values > tpval/2\n+    assert tp2.values < tpval*2\n+\n+    return d3, d4, r3, r4, tp1\n+\n+\n+def test_units(do_plot=False):\n+    sc.heading('Test behavior of year vs day units')\n+\n+    sis = ss.SIS(\n+        beta = ss.beta(0.05, 'day'),\n+        init_prev = ss.bernoulli(p=0.1),\n+        dur_inf = ss.lognorm_ex(mean=ss.dur(10, 'day')),\n+        waning = ss.rate(0.05, 'day'),\n+        imm_boost = 1.0,\n+    )\n+\n+    rnet = ss.RandomNet(\n+        n_contacts = 10,\n+        dur = 0, # Note; network edge durations are required to have the same unit as the network\n+    )\n+\n+    pars = dict(\n+        diseases = sis,\n+        networks = rnet,\n+        n_agents = small,\n+    )\n+\n+    sims = sc.objdict()\n+    sims.y = ss.Sim(pars, unit='year', label='Year', start=2000, stop=2002, dt=1/365, verbose=0)\n+    sims.d = ss.Sim(pars, unit='day', label='Day', start='2000-01-01', stop='2002-01-01', dt=1, verbose=0)\n+\n+    for sim in sims.values():\n+        sim.run()\n+        if do_plot:\n+            sim.plot()\n+\n+    # Check that results match to within stochastic uncertainty\n+    rtol = 0.05\n+    vals = [sim.summary.sis_cum_infections for sim in [sims.y, sims.d]]\n+    assert np.isclose(*vals, rtol=rtol), f'Values for cum_infections do not match ({vals})'\n+\n+    return sims\n+\n+\n+def test_multi_timestep(do_plot=False):\n+    sc.heading('Test behavior of different modules having different timesteps')\n+\n+    pars = dict(\n+        diseases = ss.SIS(unit='day', dt=1.0, init_prev=0.1, beta=ss.beta(0.01)),\n+        demographics = ss.Births(unit='year', dt=0.25),\n+        networks = ss.RandomNet(unit='week'),\n+        n_agents = small,\n+        verbose = 0,\n+    )\n+\n+    sim = ss.Sim(pars, unit='day', dt=2, start='2000-01-01', stop='2002-01-01')\n+    sim.run()\n+\n+    twoyears = 366*2\n+    quarters = 2/0.25\n+    assert len(sim) == twoyears//2\n+    assert len(sim.diseases.sis) == twoyears\n+    assert len(sim.demographics.births) == quarters\n+\n+    if do_plot:\n+        sim.plot()\n+\n+    return sim\n+\n+\n+def test_mixed_timesteps():\n+    sc.heading('Test behavior of different commbinations of timesteps')\n+\n+    siskw = dict(dur_inf=ss.dur(50, 'day'), beta=ss.beta(0.01, 'day'), waning=ss.rate(0.005, 'day'))\n+    kw = dict(n_agents=1000, start='2001-01-01', stop='2001-07-01', networks='random', copy_inputs=False, verbose=0)\n+\n+    print('Year-year')\n+    sis1 = ss.SIS(unit='year', dt=1/365, **sc.dcp(siskw))\n+    sim1 = ss.Sim(unit='year', dt=1/365, diseases=sis1, label='year-year', **kw)\n+\n+    print('Day-day')\n+    sis2 = ss.SIS(unit='day', dt=1.0, **sc.dcp(siskw))\n+    sim2 = ss.Sim(unit='day', dt=1.0, diseases=sis2, label='day-day', **kw)\n+\n+    print('Day-year')\n+    sis3 = ss.SIS(unit='day', dt=1.0, **sc.dcp(siskw))\n+    sim3 = ss.Sim(unit='year', dt=1/365, diseases=sis3, label='day-year', **kw)\n+\n+    print('Year-day')\n+    sis4 = ss.SIS(unit='year', dt=1/365, **sc.dcp(siskw))\n+    sim4 = ss.Sim(unit='day', dt=1.0, diseases=sis4, label='year-day', **kw)\n+\n+    msim = ss.parallel(sim1, sim2, sim3, sim4)\n+\n+    # Check that al results are close\n+    threshold = 0.01\n+    summary = msim.summarize()\n+    for key,res in summary.items():\n+        if res.mean:\n+            ratio = res.std/res.mean\n+            assert ratio < threshold, f'Result {key} exceeds threshold: {ratio:n} > {threshold}'\n+            print(f'✓ Result {key} within threshold: {ratio:n} < {threshold}')\n+    return msim\n+\n+\n+def test_time_class():\n+    sc.heading('Test different instances of ss.Time')\n+\n+    def sim(start, stop, dt, unit):\n+        \"\"\" Generate a fake sim \"\"\"\n+        sim = sc.prettyobj()\n+        sim.t = ss.Time(start=start, stop=stop, dt=dt, unit=unit, sim=True)\n+        return sim\n+\n+    print('Testing dates vs. numeric')\n+    s1 = sim(start=2000, stop=2002, dt=0.1, unit='year')\n+    t1 = ss.Time(start='2001-01-01', stop='2001-06-30', dt=2.0, unit='day')\n+    t1.init(sim=s1)\n+    assert np.array_equal(s1.t.timevec, s1.t.yearvec)\n+    assert len(s1.t.timevec) == 21\n+    assert t1.npts == sc.daydiff('2001-01-01', '2001-06-30')//2 + 1\n+    assert sc.isnumber(s1.t.start)\n+    assert isinstance(t1.start, ss.date)\n+    assert s1.t.datevec[-1] == ss.date('2002-01-01')\n+    assert t1.datevec[-1] == ss.date('2001-06-30')\n+    assert t1.abstvec[0] == 1.0\n+\n+    print('Testing weeks vs. days')\n+    s2 = sim(start='2000-06-01', stop='2001-05-01', dt=1, unit='day')\n+    t2 = ss.Time(start='2000-06-01', stop='2001-05-01', dt=1, unit='week')\n+    t2.init(sim=s2)\n+    assert np.array_equal(s2.t.timevec, s2.t.datevec)\n+    assert isinstance(s2.t.start, ss.date)\n+    assert t2.npts*7 == s2.t.npts + 1\n+    assert np.array_equal(t2.abstvec, s2.t.abstvec[::7])\n+\n+    print('Testing different units and dt')\n+    s3 = sim(start='2001-01-01', stop='2003-01-01', dt=0.1, unit='year')\n+    t3 = ss.Time(start='2001-01-01', stop='2003-01-01', dt=2.0, unit='day')\n+    t3.init(sim=s3)\n+    assert np.array_equal(s3.t.timevec, s3.t.datevec)\n+    assert s3.t.datevec[-1] == ss.date('2003-01-01')\n+    assert s3.t.npts == 21\n+    assert np.isclose(s3.t.abstvec.mean(), t3.abstvec.mean(), atol=1e-3)\n+\n+    print('Testing unitless')\n+    s4 = sim(start=0, stop=10, dt=1.0, unit='unitless')\n+    t4 = ss.Time(start=2, stop=9, dt=0.1, unit='unitless')\n+    t4.init(sim=s4)\n+    assert np.array_equal(s4.t.timevec, s4.t.abstvec)\n+    assert s4.t.datevec[0] == ss.date(ss.time.default_start_year)\n+    assert len(s4.t) == 11\n+    assert len(t4) == (9-2)/0.1+1\n+\n+    return [s1, t1, s2, t2]\n+\n+\n+# %% Run as a script\n+if __name__ == '__main__':\n+    do_plot = True\n+    sc.options(interactive=do_plot)\n+\n+    T = sc.timer()\n+\n+    o1 = test_ratio()\n+    o2 = test_classes()\n+    o3 = test_units(do_plot)\n+    o4 = test_multi_timestep(do_plot)\n+    o5 = test_mixed_timesteps()\n+    o6 = test_time_class()\n+\n+    T.toc()\ndiff --git a/tests/update_baseline.py b/tests/update_baseline.py\nindex 67af0b8..39b8514 100755\n--- a/tests/update_baseline.py\n+++ b/tests/update_baseline.py\n@@ -1,10 +1,9 @@\n #!/usr/bin/env python3\n-\n-'''\n+\"\"\"\n Run this script to regenerate the baseline.\n-'''\n+\"\"\"\n \n-import test_baselines as tb\n+import test_baselines\n \n-tb.save_baseline()\n-tb.test_benchmark(do_save=True, repeats=5)\n+test_baselines.save_baseline()\n+test_baselines.test_benchmark(do_save=True, repeats=5)\n",
        "Now please refactor the below code to maintain compatibility with the starsim (ss) code: ",
        "import starsim as ss\nimport sciris as sc\nimport numpy as np\n\nclass Zombie(ss.SIR):\n    \"\"\" Extent the base SIR class to represent Zombies! \"\"\"\n    def __init__(self, pars=None, **kwargs):\n        super().__init__()\n\n        self.default_pars(\n            inherit = True, # Inherit from SIR defaults\n            dur_inf = ss.constant(v=1000), # Once a zombie, always a zombie! Units are years.\n\n            p_fast = ss.bernoulli(p=0.10), # Probability of being fast\n            dur_fast = ss.constant(v=1000), # Duration of fast before becoming slow\n            p_symptomatic = ss.bernoulli(p=1.0), # Probability of symptoms\n            p_death_on_zombie_infection = ss.bernoulli(p=0.25), # Probability of death at time of infection\n\n            p_death = ss.bernoulli(p=1), # All zombies die instead of recovering\n        )\n        self.update_pars(pars, **kwargs)\n\n        self.add_states(\n            ss.BoolArr('fast', default=self.pars.p_fast), # True if fast\n            ss.BoolArr('symptomatic', default=False), # True if symptomatic\n            ss.FloatArr('ti_slow'), # Time index of changing from fast to slow\n        )\n\n        # Counters for reporting\n        self.cum_congenital = 0 # Count cumulative congenital cases\n        self.cum_deaths = 0 # Count cumulative deaths\n\n        return\n\n    def update_pre(self):\n        \"\"\" Updates states before transmission on this timestep \"\"\"\n        self.cum_deaths += np.count_nonzero(self.ti_dead <= self.sim.ti)\n\n        super().update_pre()\n\n        # Transition from fast to slow\n        fast_to_slow_uids = (self.infected & self.fast & (self.ti_slow <= self.sim.ti)).uids\n        self.fast[fast_to_slow_uids] = False\n\n        return\n\n    def set_prognoses(self, uids, source_uids=None):\n        \"\"\" Set prognoses of new zombies \"\"\"\n        super().set_prognoses(uids, source_uids)\n\n        # Choose which new zombies will be symptomatic\n        self.symptomatic[uids] = self.pars.p_symptomatic.rvs(uids)\n\n        # Set timer for fast to slow transition\n        fast_uids = uids[self.fast[uids]]\n        dur_fast = self.pars.dur_fast.rvs(fast_uids)\n        self.ti_slow[fast_uids] = np.round(self.sim.ti + dur_fast / self.sim.dt)\n\n        # Handle possible immediate death on zombie infection\n        dead_uids = self.pars.p_death_on_zombie_infection.filter(uids)\n        self.cum_deaths += len(dead_uids)\n        self.sim.people.request_death(dead_uids)\n        return\n\n    def set_congenital(self, target_uids, source_uids=None):\n        \"\"\" Congenital zombies \"\"\"\n        self.cum_congenital += len(target_uids)\n        self.set_prognoses(target_uids, source_uids)\n        return\n\n    def init_results(self):\n        \"\"\" Initialize results \"\"\"\n        super().init_results()\n        sim = self.sim\n        self.results += [ ss.Result(self.name, 'cum_congenital', sim.npts, dtype=int, scale=True) ]\n        self.results += [ ss.Result(self.name, 'cum_deaths', sim.npts, dtype=int, scale=True) ]\n        return\n\n    def update_results(self):\n        \"\"\" Update results on each time step \"\"\"\n        super().update_results()\n        res = self.results\n        ti = self.sim.ti\n        res.cum_congenital[ti] = self.cum_congenital\n        res.cum_deaths[ti] = self.cum_deaths\n        return\n\n\nclass DeathZombies(ss.Deaths):\n    \"\"\" Extension of Deaths to make some agents who die turn into zombies \"\"\"\n    def __init__(self, pars=None, metadata=None, **kwargs):\n        super().__init__(death_rate=kwargs.pop('death_rate', None))\n        self.default_pars(\n            inherit = True,\n            p_zombie_on_natural_death = ss.bernoulli(p=0.75), # Probability of becoming a zombie on death\n        )\n\n        kwargs.pop('death_rate', None)\n        self.update_pars(pars, **kwargs)\n\n        return\n\n    def apply_deaths(self):\n        \"\"\" Select people to die \"\"\"\n\n        # Ensure that zombies do not die of natural causes\n        not_zombie = self.sim.people.alive.asnew() # Zombies do not die of natural (demographic) causes\n        for name, disease in self.sim.diseases.items():\n            if 'zombie' in name:\n                not_zombie = not_zombie & (~disease.infected)\n\n        death_uids = self.pars.death_rate.filter(not_zombie.uids)\n        zombie_uids, death_uids = self.pars.p_zombie_on_natural_death.filter(death_uids, both=True)\n\n        # These uids will die\n        if len(death_uids):\n            self.sim.people.request_death(death_uids)\n\n        # And these uids will become zombies\n        if len(zombie_uids):\n            # If we have fast_zombie and slow_zombie types, choose slow_zombie\n            zombie = 'zombie' if 'zombie' in self.sim.diseases else 'slow_zombie'\n            self.sim.diseases[zombie].set_prognoses(zombie_uids)\n\n        return len(death_uids)\n\n\nclass KillZombies(ss.Intervention):\n    \"\"\" Intervention that kills symptomatic zombies at a user-specified rate \"\"\"\n    def __init__(self, year, rate, **kwargs):\n        self.requires = Zombie\n        self.year = sc.promotetoarray(year)\n        self.rate = sc.promotetoarray(rate)\n        super().__init__(**kwargs)\n\n        # The killing rate is an interpolation of year-rate values\n        self.p = ss.bernoulli(p= lambda self, sim, uids: np.interp(sim.year, self.year, self.rate*sim.dt))\n        return\n\n    def apply(self, sim):\n        if sim.year < self.year[0]:\n            return\n\n        eligible = ~sim.people.alive.asnew()\n        for name, disease in sim.diseases.items():\n            if 'zombie' in name:\n                eligible = eligible | (disease.infected & disease.symptomatic)\n        death_uids = self.p.filter(eligible.uids)\n\n        sim.people.request_death(death_uids)\n\n        return len(death_uids)\n\nclass zombie_vaccine(ss.sir_vaccine):\n    \"\"\"\n    Create a vaccine product that affects the probability of infection.\n    \n    The vaccine can be either \"leaky\", in which everyone who receives the vaccine \n    receives the same amount of protection (specified by the efficacy parameter) \n    each time they are exposed to an infection. The alternative (leaky=False) is\n    that the efficacy is the probability that the vaccine \"takes\", in which case\n    that person is 100% protected (and the remaining people are 0% protected).\n    \n    Args:\n        efficacy (float): efficacy of the vaccine (0<=efficacy<=1)\n        leaky (bool): see above\n    \"\"\"\n    def administer(self, people, uids):        \n        if self.pars.leaky:\n            people.zombie.rel_sus[uids] *= 1-self.pars.efficacy\n        else:\n            people.zombie.rel_sus[uids] *= np.random.binomial(1, 1-self.pars.efficacy, len(uids))\n        return\n\n    \nclass ZombieConnector(ss.Connector):\n    \"\"\" Connect fast and slow zombies so agents don't become double-zombies \"\"\"\n\n    def __init__(self, pars=None, **kwargs):\n        super().__init__(label='Zombie Connector', requires=[Zombie])\n\n        self.default_pars(\n            rel_sus = 0\n        )\n        self.update_pars(pars, **kwargs)\n        return\n\n    def update(self):\n        \"\"\" Specify cross protection between fast and slow zombies \"\"\"\n\n        ppl = self.sim.people\n        fast = self.sim.diseases['fast_zombie']\n        slow = self.sim.diseases['slow_zombie']\n\n        fast.rel_sus[ppl.alive] = 1\n        fast.rel_sus[slow.infected] = self.pars.rel_sus\n\n        slow.rel_sus[ppl.alive] = 1\n        slow.rel_sus[fast.infected] = self.pars.rel_sus\n\n        return\n",
      ],
    },
    {
      "role": "model",
      "parts": [
        "```python\nimport starsim as ss\nimport sciris as sc\nimport numpy as np\n\nclass Zombie(ss.SIR):\n    \"\"\" Extent the base SIR class to represent Zombies! \"\"\"\n    def __init__(self, pars=None, **kwargs):\n        super().__init__()\n\n        self.define_pars(\n            inherit = True, # Inherit from SIR defaults\n            dur_inf = ss.constant(v=ss.years(1000)), # Once a zombie, always a zombie! Units are years.\n\n            p_fast = ss.bernoulli(p=0.10), # Probability of being fast\n            dur_fast = ss.constant(v=ss.years(1000)), # Duration of fast before becoming slow\n            p_symptomatic = ss.bernoulli(p=1.0), # Probability of symptoms\n            p_death_on_zombie_infection = ss.bernoulli(p=0.25), # Probability of death at time of infection\n            p_death = ss.bernoulli(p=1), # All zombies die instead of recovering\n        )\n        self.update_pars(pars, **kwargs)\n\n        self.define_states(\n            ss.State('fast', default=self.pars.p_fast, label='Fast zombie'), # True if fast\n            ss.State('symptomatic', label='Symptomatic zombie'), # True if symptomatic\n            ss.FloatArr('ti_slow', label='Time of becoming slow zombie'), # Time index of changing from fast to slow\n        )\n\n        # Counters for reporting\n        self.cum_congenital = 0 # Count cumulative congenital cases\n        self.cum_deaths = 0 # Count cumulative deaths\n\n        return\n\n    def step_state(self):\n        \"\"\" Updates states before transmission on this timestep \"\"\"\n        self.cum_deaths += (self.ti_dead <= self.ti).sum()\n\n        super().step_state()\n\n        # Transition from fast to slow\n        fast_to_slow_uids = (self.infected & self.fast & (self.ti_slow <= self.ti)).uids\n        self.fast[fast_to_slow_uids] = False\n\n        return\n\n    def set_prognoses(self, uids, sources=None):\n        \"\"\" Set prognoses of new zombies \"\"\"\n        super().set_prognoses(uids, sources)\n\n        # Choose which new zombies will be symptomatic\n        self.symptomatic[uids] = self.pars.p_symptomatic.rvs(uids)\n\n        # Set timer for fast to slow transition\n        fast_uids = uids[self.fast[uids]]\n        dur_fast = self.pars.dur_fast.rvs(fast_uids)\n        self.ti_slow[fast_uids] = self.ti + dur_fast # Already in time units\n\n        # Handle possible immediate death on zombie infection\n        dead_uids = self.pars.p_death_on_zombie_infection.filter(uids)\n        self.cum_deaths += len(dead_uids)\n        self.sim.people.request_death(dead_uids)\n        return\n\n    def set_congenital(self, uids, sources=None):\n        \"\"\" Congenital zombies \"\"\"\n        self.cum_congenital += len(uids)\n        self.set_prognoses(uids, sources)\n        return\n\n    def init_results(self):\n        \"\"\" Initialize results \"\"\"\n        super().init_results()\n        self.define_results(\n            ss.Result('cum_congenital', dtype=int, scale=True, label='Cumulative congenital zombies'),\n            ss.Result('cum_deaths', dtype=int, scale=True, label='Cumulative deaths'),\n        )\n        return\n\n    def update_results(self):\n        \"\"\" Update results on each time step \"\"\"\n        super().update_results()\n        self.results.cum_congenital[self.ti] = self.cum_congenital\n        self.results.cum_deaths[self.ti] = self.cum_deaths\n        return\n\n    def step_die(self, uids):\n        \"\"\" Reset infected/recovered flags for dead agents \"\"\"\n        super().step_die(uids)\n        self.fast[uids] = False\n        self.symptomatic[uids] = False\n        return\n\n\nclass DeathZombies(ss.Deaths):\n    \"\"\" Extension of Deaths to make some agents who die turn into zombies \"\"\"\n    def __init__(self, pars=None, metadata=None, **kwargs):\n        super().__init__()\n        self.define_pars(\n            inherit = True,\n            p_zombie_on_natural_death = ss.bernoulli(p=0.75), # Probability of becoming a zombie on death\n            death_rate = kwargs.pop('death_rate', None),\n        )\n        self.update_pars(pars, **kwargs)\n        return\n\n    def step(self):\n        \"\"\" Select people to die \"\"\"\n\n        # Ensure that zombies do not die of natural causes\n        not_zombie = self.sim.people.alive.asnew() # Zombies do not die of natural (demographic) causes\n        for name, disease in self.sim.diseases.items():\n            if 'zombie' in name:\n                not_zombie = not_zombie & (~disease.infected)\n\n        death_uids = self.pars.death_rate.filter(not_zombie.uids)\n        zombie_uids, death_uids = self.pars.p_zombie_on_natural_death.filter(death_uids, both=True)\n\n        # These uids will die\n        if len(death_uids):\n            self.sim.people.request_death(death_uids)\n\n        # And these uids will become zombies\n        if len(zombie_uids):\n            # If we have fast_zombie and slow_zombie types, choose slow_zombie\n            zombie = 'zombie' if 'zombie' in self.sim.diseases else 'slow_zombie'\n            self.sim.diseases[zombie].set_prognoses(zombie_uids)\n\n        return len(death_uids)\n\n\nclass KillZombies(ss.Intervention):\n    \"\"\" Intervention that kills symptomatic zombies at a user-specified rate \"\"\"\n    def __init__(self, year, rate, **kwargs):\n        self.requires = Zombie\n        self.year = sc.promotetoarray(year)\n        self.rate = sc.promotetoarray(rate)\n        super().__init__(**kwargs)\n        self.p = ss.bernoulli(p= lambda self, sim, uids: np.interp(sim.now('year'), self.year, self.rate))\n        return\n        \n    def step(self):\n        sim = self.sim\n        if sim.now('year') < self.year[0]:\n            return\n        \n        eligible = ~sim.people.alive.asnew()\n        for name, disease in sim.diseases.items():\n            if 'zombie' in name:\n                eligible = eligible | (disease.infected & disease.symptomatic)\n        death_uids = self.p.filter(eligible.uids)\n        sim.people.request_death(death_uids)\n        return len(death_uids)\n        \nclass zombie_vaccine(ss.sir_vaccine):\n    \"\"\"\n    Create a vaccine product that affects the probability of infection.\n    \n    The vaccine can be either \"leaky\", in which everyone who receives the vaccine \n    receives the same amount of protection (specified by the efficacy parameter) \n    each time they are exposed to an infection. The alternative (leaky=False) is\n    that the efficacy is the probability that the vaccine \"takes\", in which case\n    that person is 100% protected (and the remaining people are 0% protected).\n    \n    Args:\n        efficacy (float): efficacy of the vaccine (0<=efficacy<=1)\n        leaky (bool): see above\n    \"\"\"\n    def administer(self, people, uids):        \n        if self.pars.leaky:\n            people.zombie.rel_sus[uids] *= 1-self.pars.efficacy\n        else:\n            people.zombie.rel_sus[uids] *= np.random.binomial(1, 1-self.pars.efficacy, len(uids))\n        return\n\n    \nclass ZombieConnector(ss.Connector):\n    \"\"\" Connect fast and slow zombies so agents don't become double-zombies \"\"\"\n\n    def __init__(self, pars=None, **kwargs):\n        super().__init__()\n        self.define_pars(\n            label = 'Zombie Connector',\n            requires = [Zombie],\n            rel_sus = 0\n        )\n        self.update_pars(pars, **kwargs)\n        return\n\n    def step(self):\n        \"\"\" Specify cross protection between fast and slow zombies \"\"\"\n\n        ppl = self.sim.people\n        fast = self.sim.diseases['fast_zombie']\n        slow = self.sim.diseases['slow_zombie']\n\n        fast.rel_sus[ppl.alive] = 1\n        fast.rel_sus[slow.infected] = self.pars.rel_sus\n\n        slow.rel_sus[ppl.alive] = 1\n        slow.rel_sus[fast.infected] = self.pars.rel_sus\n\n        return\n\n```",
      ],
    },
  ]
)

response = chat_session.send_message("INSERT_INPUT_HERE")

print(response.text)